<html style><!--
 Page saved with SingleFile 
 url: https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/T/ 
 saved date: Wed Sep 25 2024 11:46:21 GMT+0800 (中国标准时间)
--><meta charset=utf-8><title>[PATCH 00/13] Linux RISC-V IOMMU Support</title><link rel=alternate title="Atom feed" href=https://lore.kernel.org/lkml/new.atom type=application/atom+xml><style>pre{white-space:pre-wrap}*{font-size:100%;font-family:monospace}</style><style media=screen,print>*{font-size:100%;font-family:monospace;background:#fff;color:#003}pre{white-space:pre-wrap}a:link{color:#00f;text-decoration:none}a:visited{color:#808}*.q{color:#006}*.add{color:#060}*.del{color:#900}*.head{color:#000}*.hunk{color:#960}</style><style media="screen and (prefers-color-scheme:dark)">*{font-size:100%;font-family:monospace;background:#000;color:#ccc}pre{white-space:pre-wrap}a:link{color:#69f;text-decoration:none}a:visited{color:#96f}*.q{color:#09f}*.add{color:#0ff}*.del{color:#f0f}*.head{color:#fff}*.hunk{color:#c93}</style><meta name=referrer content=no-referrer><style>.sf-hidden{display:none!important}</style><link rel=canonical href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/T/><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style><body><form action=../../><pre><a href="https://lore.kernel.org/lkml/?t=20240413102211"><b>linux-kernel.vger.kernel.org archive mirror</b></a>
<input name=q type=text value><input type=submit value=search> <a href=https://lore.kernel.org/lkml/_/text/help/>help</a> / <a href=https://lore.kernel.org/lkml/_/text/color/>color</a> / <a id=mirror href=https://lore.kernel.org/lkml/_/text/mirror/>mirror</a> / <a href=https://lore.kernel.org/lkml/new.atom>Atom feed</a></pre></form><pre><a href=#ee750bc2afd9a61b23a45ff7a3a05bb653a4e13ed id=me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>*</a> <u id=u><b>[PATCH 00/13] Linux RISC-V IOMMU Support</b></u>
<b>@ 2023-07-19 19:33 Tomasz Jeznach</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
                   ` <a href=#rcbff9602b4590805d9db0bce8ed33655b290f552>(11 more replies)</a>
  <a href=#re750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>0 siblings, 12 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193459">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193459">linux-kernel</a>, linux,
	Tomasz Jeznach

The RISC-V IOMMU specification is now ratified as-per the RISC-V international
process [1]. The latest frozen specifcation can be found at:
<a href=https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf>https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf</a>

At a high-level, the RISC-V IOMMU specification defines:
1) Memory-mapped programming interface
   - Mandatory and optional registers layout and description.
   - Software guidelines for device initialization and capabilities discovery.
2) In-memory queue interface
   - A command-queue used by software to queue commands to the IOMMU.
   - A fault/event queue used to bring faults and events to software’s attention.
   - A page-request queue used to report “Page Request” messages received from
     PCIe devices.
   - Message-signalled and wire-signaled interrupt mechanism.
3) In-memory data structures
   - Device-context: used to associate a device with an address space and to hold
     other per-device parameters used by the IOMMU to perform address translations.
   - Process-contexts: used to associate a different virtual address space based on
     device provided process identification number.
   - MSI page table configuration used to direct an MSI to a guest interrupt file
     in an IMSIC. The MSI page table formats are defined by the Advanced Interrupt
     Architecture specification [2].

This series introduces complete single-level translation support, including shared
virtual address (SVA), ATS/PRI interfaces in the kernel driver. Patches adding MSI
identity remapping and G-Stage translation (GPA to SPA) are added only to excercise
hardware interfaces, to be complemented with AIA/KVM bindings in follow-up series.

This series is a logical regrouping of series of incremental patches based on
RISC-V International IOMMU Task Group discussions and specification development
process. Original series can be found at the maintainer's repository branch [3].

These patches can also be found in the riscv_iommu_v1 branch at:
<a href=https://github.com/tjeznach/linux/tree/riscv_iommu_v1>https://github.com/tjeznach/linux/tree/riscv_iommu_v1</a>

To test this series, use QEMU/OpenSBI with RISC-V IOMMU implementation available in
the riscv_iommu_v1 branch at:
<a href=https://github.com/tjeznach/qemu/tree/riscv_iommu_v1>https://github.com/tjeznach/qemu/tree/riscv_iommu_v1</a>

References:
[1] - <a href=https://wiki.riscv.org/display/HOME/Specification+Status>https://wiki.riscv.org/display/HOME/Specification+Status</a>
[2] - <a href=https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf>https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf</a>
[3] - <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719</a>


Anup Patel (1):
  dt-bindings: Add RISC-V IOMMU bindings

Tomasz Jeznach (10):
  RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.
  RISC-V: arch/riscv/config: enable RISC-V IOMMU support
  MAINTAINERS: Add myself for RISC-V IOMMU driver
  RISC-V: drivers/iommu/riscv: Add sysfs interface
  RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues
  RISC-V: drivers/iommu/riscv: Add device context support
  RISC-V: drivers/iommu/riscv: Add page table support
  RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support.
  RISC-V: drivers/iommu/riscv: Add MSI identity remapping
  RISC-V: drivers/iommu/riscv: Add G-Stage translation support

 .../bindings/iommu/riscv,iommu.yaml           |  146 ++
 MAINTAINERS                                   |    7 +
 arch/riscv/configs/defconfig                  |    1 +
 drivers/iommu/Kconfig                         |    1 +
 drivers/iommu/Makefile                        |    2 +-
 drivers/iommu/io-pgtable.c                    |    3 +
 drivers/iommu/riscv/Kconfig                   |   22 +
 drivers/iommu/riscv/Makefile                  |    1 +
 drivers/iommu/riscv/io_pgtable.c              |  266 ++
 drivers/iommu/riscv/iommu-bits.h              |  704 ++++++
 drivers/iommu/riscv/iommu-pci.c               |  206 ++
 drivers/iommu/riscv/iommu-platform.c          |  160 ++
 drivers/iommu/riscv/iommu-sysfs.c             |  183 ++
 drivers/iommu/riscv/iommu.c                   | 2130 +++++++++++++++++
 drivers/iommu/riscv/iommu.h                   |  165 ++
 include/linux/io-pgtable.h                    |    2 +
 16 files changed, 3998 insertions(+), 1 deletion(-)
 create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
 create mode 100644 drivers/iommu/riscv/Kconfig
 create mode 100644 drivers/iommu/riscv/Makefile
 create mode 100644 drivers/iommu/riscv/io_pgtable.c
 create mode 100644 drivers/iommu/riscv/iommu-bits.h
 create mode 100644 drivers/iommu/riscv/iommu-pci.c
 create mode 100644 drivers/iommu/riscv/iommu-platform.c
 create mode 100644 drivers/iommu/riscv/iommu-sysfs.c
 create mode 100644 drivers/iommu/riscv/iommu.c
 create mode 100644 drivers/iommu/riscv/iommu.h

-- 
2.34.1


<a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed id=ee750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>^</a> <a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/#R>reply</a>	[<a href=#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#re750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>86+ messages in thread</a></pre><hr><pre><a href=#ecbff9602b4590805d9db0bce8ed33655b290f552 id=mcbff9602b4590805d9db0bce8ed33655b290f552>*</a> <b>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-19 20:49   ` <a href=#m475b3879d13e54e5f54247069b241516ceaf814e>Conor Dooley</a>
                     ` <a href=#r475b3879d13e54e5f54247069b241516ceaf814e>(7 more replies)</a>
  2023-07-19 19:33 ` <a href=#m20d2511b6c12906189c92aa1f0e9ce0c668c5a83>[PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</a> Tomasz Jeznach
                   ` <a href=#r20d2511b6c12906189c92aa1f0e9ce0c668c5a83>(10 subsequent siblings)</a>
  <a href=#rcbff9602b4590805d9db0bce8ed33655b290f552>11 siblings, 8 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193514">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193514">linux-kernel</a>, linux,
	Tomasz Jeznach

The patch introduces skeleton IOMMU device driver implementation as defined
by RISC-V IOMMU Architecture Specification, Version 1.0 [1], with minimal support
for pass-through mapping, basic initialization and bindings for platform and PCIe
hardware implementations.

Series of patches following specification evolution has been reorganized to provide
functional separation of implemented blocks, compliant with ratified specification.

This and following patch series includes code contributed by: Nick Kossifidis
&lt;mick@ics.forth.gr&gt; (iommu-platform device, number of specification clarification
and bugfixes and readability improvements), Sebastien Boeuf &lt;seb@rivosinc.com&gt; (page
table creation, ATS/PGR flow).

Complete history can be found at the maintainer's repository branch [2].

Device driver enables RISC-V 32/64 support for memory translation for DMA capable
PCI and platform devices, multilevel device directory table, process directory,
shared virtual address support, wired and message signaled interrupt for translation
I/O fault, page request interface and command processing.

Matching RISCV-V IOMMU device emulation implementation is available for QEMU project,
along with educational device extensions for PASID ATS/PRI support [3].

References:
 - [1] <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
 - [2] <a href=https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu</a>
 - [3] <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu</a>

Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Kconfig href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Kconfig>drivers/iommu/Kconfig</a>                |   1 +
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Makefile href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Makefile>drivers/iommu/Makefile</a>               |   2 +-
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Kconfig href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Kconfig>drivers/iommu/riscv/Kconfig</a>          |  22 +
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile>drivers/iommu/riscv/Makefile</a>         |   1 +
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-bits.h href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-bits.h>drivers/iommu/riscv/iommu-bits.h</a>     | 704 +++++++++++++++++++++++++++
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c>drivers/iommu/riscv/iommu-pci.c</a>      | 134 +++++
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c>drivers/iommu/riscv/iommu-platform.c</a> |  94 ++++
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a>          | 660 +++++++++++++++++++++++++
 <a id=iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a>          | 115 +++++
 9 files <a href=#ecbff9602b4590805d9db0bce8ed33655b290f552>changed</a>, 1732 insertions(+), 1 deletion(-)
 create mode 100644 drivers/iommu/riscv/Kconfig
 create mode 100644 drivers/iommu/riscv/Makefile
 create mode 100644 drivers/iommu/riscv/iommu-bits.h
 create mode 100644 drivers/iommu/riscv/iommu-pci.c
 create mode 100644 drivers/iommu/riscv/iommu-platform.c
 create mode 100644 drivers/iommu/riscv/iommu.c
 create mode 100644 drivers/iommu/riscv/iommu.h

<span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Kconfig id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Kconfig>diff</a> --git a/drivers/iommu/Kconfig b/drivers/iommu/Kconfig
index 2b12b583ef4b..36fcc6fd5b4e 100644
--- a/drivers/iommu/Kconfig
+++ b/drivers/iommu/Kconfig
</span><span class=hunk>@@ -187,6 +187,7 @@ config MSM_IOMMU
</span> source "drivers/iommu/amd/Kconfig"
 source "drivers/iommu/intel/Kconfig"
 source "drivers/iommu/iommufd/Kconfig"
<span class=add>+source "drivers/iommu/riscv/Kconfig"
</span> 
 config IRQ_REMAP
 	bool "Support for Interrupt Remapping"
<span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Makefile id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:Makefile>diff</a> --git a/drivers/iommu/Makefile b/drivers/iommu/Makefile
index 769e43d780ce..8f57110a9fb1 100644
--- a/drivers/iommu/Makefile
+++ b/drivers/iommu/Makefile
</span><span class=hunk>@@ -1,5 +1,5 @@
</span> # SPDX-License-Identifier: GPL-2.0
<span class=del>-obj-y += amd/ intel/ arm/ iommufd/
</span><span class=add>+obj-y += amd/ intel/ arm/ iommufd/ riscv/
</span> obj-$(CONFIG_IOMMU_API) += iommu.o
 obj-$(CONFIG_IOMMU_API) += iommu-traces.o
 obj-$(CONFIG_IOMMU_API) += iommu-sysfs.o
<span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Kconfig id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Kconfig>diff</a> --git a/drivers/iommu/riscv/Kconfig b/drivers/iommu/riscv/Kconfig
new file mode 100644
index 000000000000..01d4043849d4
--- /dev/null
+++ b/drivers/iommu/riscv/Kconfig
</span><span class=hunk>@@ -0,0 +1,22 @@
</span><span class=add>+# SPDX-License-Identifier: GPL-2.0-only
+# RISC-V IOMMU support
+
+config RISCV_IOMMU
+	bool "RISC-V IOMMU driver"
+	depends on RISCV
+	select IOMMU_API
+	select IOMMU_DMA
+	select IOMMU_SVA
+	select IOMMU_IOVA
+	select IOMMU_IO_PGTABLE
+	select IOASID
+	select PCI_MSI
+	select PCI_ATS
+	select PCI_PRI
+	select PCI_PASID
+	select MMU_NOTIFIER
+	help
+	  Support for devices following RISC-V IOMMU specification.
+
+	  If unsure, say N here.
+
</span><span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile>diff</a> --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
new file mode 100644
index 000000000000..38730c11e4a8
--- /dev/null
+++ b/drivers/iommu/riscv/Makefile
</span><span class=hunk>@@ -0,0 +1 @@
</span><span class=add>+obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o
</span>\ No newline at end of file
<span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-bits.h id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-bits.h>diff</a> --git a/drivers/iommu/riscv/iommu-bits.h b/drivers/iommu/riscv/iommu-bits.h
new file mode 100644
index 000000000000..b2946793a73d
--- /dev/null
+++ b/drivers/iommu/riscv/iommu-bits.h
</span><span class=hunk>@@ -0,0 +1,704 @@
</span><span class=add>+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright © 2022-2023 Rivos Inc.
+ * Copyright © 2023 FORTH-ICS/CARV
+ * Copyright © 2023 RISC-V IOMMU Task Group
+ *
+ * RISC-V Ziommu - Register Layout and Data Structures.
+ *
+ * Based on the 'RISC-V IOMMU Architecture Specification', Version 1.0
+ * Published at  <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
+ *
+ */
+
+#ifndef _RISCV_IOMMU_BITS_H_
+#define _RISCV_IOMMU_BITS_H_
+
+#include &lt;linux/types.h&gt;
+#include &lt;linux/bitfield.h&gt;
+#include &lt;linux/bits.h&gt;
+
+/*
+ * Chapter 5: Memory Mapped register interface
+ */
+
+/* Common field positions */
+#define RISCV_IOMMU_PPN_FIELD		GENMASK_ULL(53, 10)
+#define RISCV_IOMMU_QUEUE_LOGSZ_FIELD	GENMASK_ULL(4, 0)
+#define RISCV_IOMMU_QUEUE_INDEX_FIELD	GENMASK_ULL(31, 0)
+#define RISCV_IOMMU_QUEUE_ENABLE	BIT(0)
+#define RISCV_IOMMU_QUEUE_INTR_ENABLE	BIT(1)
+#define RISCV_IOMMU_QUEUE_MEM_FAULT	BIT(8)
+#define RISCV_IOMMU_QUEUE_OVERFLOW	BIT(9)
+#define RISCV_IOMMU_QUEUE_ACTIVE	BIT(16)
+#define RISCV_IOMMU_QUEUE_BUSY		BIT(17)
+
+#define RISCV_IOMMU_ATP_PPN_FIELD	GENMASK_ULL(43, 0)
+#define RISCV_IOMMU_ATP_MODE_FIELD	GENMASK_ULL(63, 60)
+
+/* 5.3 IOMMU Capabilities (64bits) */
+#define RISCV_IOMMU_REG_CAP		0x0000
+#define RISCV_IOMMU_CAP_VERSION		GENMASK_ULL(7, 0)
+#define RISCV_IOMMU_CAP_S_SV32		BIT_ULL(8)
+#define RISCV_IOMMU_CAP_S_SV39		BIT_ULL(9)
+#define RISCV_IOMMU_CAP_S_SV48		BIT_ULL(10)
+#define RISCV_IOMMU_CAP_S_SV57		BIT_ULL(11)
+#define RISCV_IOMMU_CAP_SVPBMT		BIT_ULL(15)
+#define RISCV_IOMMU_CAP_G_SV32		BIT_ULL(16)
+#define RISCV_IOMMU_CAP_G_SV39		BIT_ULL(17)
+#define RISCV_IOMMU_CAP_G_SV48		BIT_ULL(18)
+#define RISCV_IOMMU_CAP_G_SV57		BIT_ULL(19)
+#define RISCV_IOMMU_CAP_MSI_FLAT	BIT_ULL(22)
+#define RISCV_IOMMU_CAP_MSI_MRIF	BIT_ULL(23)
+#define RISCV_IOMMU_CAP_AMO		BIT_ULL(24)
+#define RISCV_IOMMU_CAP_ATS		BIT_ULL(25)
+#define RISCV_IOMMU_CAP_T2GPA		BIT_ULL(26)
+#define RISCV_IOMMU_CAP_END		BIT_ULL(27)
+#define RISCV_IOMMU_CAP_IGS		GENMASK_ULL(29, 28)
+#define RISCV_IOMMU_CAP_HPM		BIT_ULL(30)
+#define RISCV_IOMMU_CAP_DBG		BIT_ULL(31)
+#define RISCV_IOMMU_CAP_PAS		GENMASK_ULL(37, 32)
+#define RISCV_IOMMU_CAP_PD8		BIT_ULL(38)
+#define RISCV_IOMMU_CAP_PD17		BIT_ULL(39)
+#define RISCV_IOMMU_CAP_PD20		BIT_ULL(40)
+
+#define RISCV_IOMMU_CAP_VERSION_VER_MASK	0xF0
+#define RISCV_IOMMU_CAP_VERSION_REV_MASK	0x0F
+
+/**
+ * enum riscv_iommu_igs_settings - Interrupt Generation Support Settings
+ * @RISCV_IOMMU_CAP_IGS_MSI: I/O MMU supports only MSI generation
+ * @RISCV_IOMMU_CAP_IGS_WSI: I/O MMU supports only Wired-Signaled interrupt
+ * @RISCV_IOMMU_CAP_IGS_BOTH: I/O MMU supports both MSI and WSI generation
+ * @RISCV_IOMMU_CAP_IGS_RSRV: Reserved for standard use
+ */
+enum riscv_iommu_igs_settings {
+	RISCV_IOMMU_CAP_IGS_MSI = 0,
+	RISCV_IOMMU_CAP_IGS_WSI = 1,
+	RISCV_IOMMU_CAP_IGS_BOTH = 2,
+	RISCV_IOMMU_CAP_IGS_RSRV = 3
+};
+
+/* 5.4 Features control register (32bits) */
+#define RISCV_IOMMU_REG_FCTL		0x0008
+#define RISCV_IOMMU_FCTL_BE		BIT(0)
+#define RISCV_IOMMU_FCTL_WSI		BIT(1)
+#define RISCV_IOMMU_FCTL_GXL		BIT(2)
+
+/* 5.5 Device-directory-table pointer (64bits) */
+#define RISCV_IOMMU_REG_DDTP		0x0010
+#define RISCV_IOMMU_DDTP_MODE		GENMASK_ULL(3, 0)
+#define RISCV_IOMMU_DDTP_BUSY		BIT_ULL(4)
+#define RISCV_IOMMU_DDTP_PPN		RISCV_IOMMU_PPN_FIELD
+
+/**
+ * enum riscv_iommu_ddtp_modes - I/O MMU translation modes
+ * @RISCV_IOMMU_DDTP_MODE_OFF: No inbound transactions allowed
+ * @RISCV_IOMMU_DDTP_MODE_BARE: Pass-through mode
+ * @RISCV_IOMMU_DDTP_MODE_1LVL: One-level DDT
+ * @RISCV_IOMMU_DDTP_MODE_2LVL: Two-level DDT
+ * @RISCV_IOMMU_DDTP_MODE_3LVL: Three-level DDT
+ */
+enum riscv_iommu_ddtp_modes {
+	RISCV_IOMMU_DDTP_MODE_OFF = 0,
+	RISCV_IOMMU_DDTP_MODE_BARE = 1,
+	RISCV_IOMMU_DDTP_MODE_1LVL = 2,
+	RISCV_IOMMU_DDTP_MODE_2LVL = 3,
+	RISCV_IOMMU_DDTP_MODE_3LVL = 4,
+	RISCV_IOMMU_DDTP_MODE_MAX = 4
+};
+
+/* 5.6 Command Queue Base (64bits) */
+#define RISCV_IOMMU_REG_CQB		0x0018
+#define RISCV_IOMMU_CQB_ENTRIES		RISCV_IOMMU_QUEUE_LOGSZ_FIELD
+#define RISCV_IOMMU_CQB_PPN		RISCV_IOMMU_PPN_FIELD
+
+/* 5.7 Command Queue head (32bits) */
+#define RISCV_IOMMU_REG_CQH		0x0020
+#define RISCV_IOMMU_CQH_INDEX		RISCV_IOMMU_QUEUE_INDEX_FIELD
+
+/* 5.8 Command Queue tail (32bits) */
+#define RISCV_IOMMU_REG_CQT		0x0024
+#define RISCV_IOMMU_CQT_INDEX		RISCV_IOMMU_QUEUE_INDEX_FIELD
+
+/* 5.9 Fault Queue Base (64bits) */
+#define RISCV_IOMMU_REG_FQB		0x0028
+#define RISCV_IOMMU_FQB_ENTRIES		RISCV_IOMMU_QUEUE_LOGSZ_FIELD
+#define RISCV_IOMMU_FQB_PPN		RISCV_IOMMU_PPN_FIELD
+
+/* 5.10 Fault Queue Head (32bits) */
+#define RISCV_IOMMU_REG_FQH		0x0030
+#define RISCV_IOMMU_FQH_INDEX		RISCV_IOMMU_QUEUE_INDEX_FIELD
+
+/* 5.11 Fault Queue tail (32bits) */
+#define RISCV_IOMMU_REG_FQT		0x0034
+#define RISCV_IOMMU_FQT_INDEX		RISCV_IOMMU_QUEUE_INDEX_FIELD
+
+/* 5.12 Page Request Queue base (64bits) */
+#define RISCV_IOMMU_REG_PQB		0x0038
+#define RISCV_IOMMU_PQB_ENTRIES		RISCV_IOMMU_QUEUE_LOGSZ_FIELD
+#define RISCV_IOMMU_PQB_PPN		RISCV_IOMMU_PPN_FIELD
+
+/* 5.13 Page Request Queue head (32bits) */
+#define RISCV_IOMMU_REG_PQH		0x0040
+#define RISCV_IOMMU_PQH_INDEX		RISCV_IOMMU_QUEUE_INDEX_FIELD
+
+/* 5.14 Page Request Queue tail (32bits) */
+#define RISCV_IOMMU_REG_PQT		0x0044
+#define RISCV_IOMMU_PQT_INDEX_MASK	RISCV_IOMMU_QUEUE_INDEX_FIELD
+
+/* 5.15 Command Queue CSR (32bits) */
+#define RISCV_IOMMU_REG_CQCSR		0x0048
+#define RISCV_IOMMU_CQCSR_CQEN		RISCV_IOMMU_QUEUE_ENABLE
+#define RISCV_IOMMU_CQCSR_CIE		RISCV_IOMMU_QUEUE_INTR_ENABLE
+#define RISCV_IOMMU_CQCSR_CQMF		RISCV_IOMMU_QUEUE_MEM_FAULT
+#define RISCV_IOMMU_CQCSR_CMD_TO	BIT(9)
+#define RISCV_IOMMU_CQCSR_CMD_ILL	BIT(10)
+#define RISCV_IOMMU_CQCSR_FENCE_W_IP	BIT(11)
+#define RISCV_IOMMU_CQCSR_CQON		RISCV_IOMMU_QUEUE_ACTIVE
+#define RISCV_IOMMU_CQCSR_BUSY		RISCV_IOMMU_QUEUE_BUSY
+
+/* 5.16 Fault Queue CSR (32bits) */
+#define RISCV_IOMMU_REG_FQCSR		0x004C
+#define RISCV_IOMMU_FQCSR_FQEN		RISCV_IOMMU_QUEUE_ENABLE
+#define RISCV_IOMMU_FQCSR_FIE		RISCV_IOMMU_QUEUE_INTR_ENABLE
+#define RISCV_IOMMU_FQCSR_FQMF		RISCV_IOMMU_QUEUE_MEM_FAULT
+#define RISCV_IOMMU_FQCSR_FQOF		RISCV_IOMMU_QUEUE_OVERFLOW
+#define RISCV_IOMMU_FQCSR_FQON		RISCV_IOMMU_QUEUE_ACTIVE
+#define RISCV_IOMMU_FQCSR_BUSY		RISCV_IOMMU_QUEUE_BUSY
+
+/* 5.17 Page Request Queue CSR (32bits) */
+#define RISCV_IOMMU_REG_PQCSR		0x0050
+#define RISCV_IOMMU_PQCSR_PQEN		RISCV_IOMMU_QUEUE_ENABLE
+#define RISCV_IOMMU_PQCSR_PIE		RISCV_IOMMU_QUEUE_INTR_ENABLE
+#define RISCV_IOMMU_PQCSR_PQMF		RISCV_IOMMU_QUEUE_MEM_FAULT
+#define RISCV_IOMMU_PQCSR_PQOF		RISCV_IOMMU_QUEUE_OVERFLOW
+#define RISCV_IOMMU_PQCSR_PQON		RISCV_IOMMU_QUEUE_ACTIVE
+#define RISCV_IOMMU_PQCSR_BUSY		RISCV_IOMMU_QUEUE_BUSY
+
+/* 5.18 Interrupt Pending Status (32bits) */
+#define RISCV_IOMMU_REG_IPSR		0x0054
+
+#define RISCV_IOMMU_INTR_CQ		0
+#define RISCV_IOMMU_INTR_FQ		1
+#define RISCV_IOMMU_INTR_PM		2
+#define RISCV_IOMMU_INTR_PQ		3
+#define RISCV_IOMMU_INTR_COUNT		4
+
+#define RISCV_IOMMU_IPSR_CIP		BIT(RISCV_IOMMU_INTR_CQ)
+#define RISCV_IOMMU_IPSR_FIP		BIT(RISCV_IOMMU_INTR_FQ)
+#define RISCV_IOMMU_IPSR_PMIP		BIT(RISCV_IOMMU_INTR_PM)
+#define RISCV_IOMMU_IPSR_PIP		BIT(RISCV_IOMMU_INTR_PQ)
+
+/* 5.19 Performance monitoring counter overflow status (32bits) */
+#define RISCV_IOMMU_REG_IOCOUNTOVF	0x0058
+#define RISCV_IOMMU_IOCOUNTOVF_CY	BIT(0)
+#define RISCV_IOMMU_IOCOUNTOVF_HPM	GENMASK_ULL(31, 1)
+
+/* 5.20 Performance monitoring counter inhibits (32bits) */
+#define RISCV_IOMMU_REG_IOCOUNTINH	0x005C
+#define RISCV_IOMMU_IOCOUNTINH_CY	BIT(0)
+#define RISCV_IOMMU_IOCOUNTINH_HPM	GENMASK(31, 1)
+
+/* 5.21 Performance monitoring cycles counter (64bits) */
+#define RISCV_IOMMU_REG_IOHPMCYCLES     0x0060
+#define RISCV_IOMMU_IOHPMCYCLES_COUNTER	GENMASK_ULL(62, 0)
+#define RISCV_IOMMU_IOHPMCYCLES_OVF	BIT_ULL(63)
+
+/* 5.22 Performance monitoring event counters (31 * 64bits) */
+#define RISCV_IOMMU_REG_IOHPMCTR_BASE	0x0068
+#define RISCV_IOMMU_REG_IOHPMCTR(_n)	(RISCV_IOMMU_REG_IOHPMCTR_BASE + (_n * 0x8))
+
+/* 5.23 Performance monitoring event selectors (31 * 64bits) */
+#define RISCV_IOMMU_REG_IOHPMEVT_BASE	0x0160
+#define RISCV_IOMMU_REG_IOHPMEVT(_n)	(RISCV_IOMMU_REG_IOHPMEVT_BASE + (_n * 0x8))
+#define RISCV_IOMMU_IOHPMEVT_EVENT_ID	GENMASK_ULL(14, 0)
+#define RISCV_IOMMU_IOHPMEVT_DMASK	BIT_ULL(15)
+#define RISCV_IOMMU_IOHPMEVT_PID_PSCID	GENMASK_ULL(35, 16)
+#define RISCV_IOMMU_IOHPMEVT_DID_GSCID	GENMASK_ULL(59, 36)
+#define RISCV_IOMMU_IOHPMEVT_PV_PSCV	BIT_ULL(60)
+#define RISCV_IOMMU_IOHPMEVT_DV_GSCV	BIT_ULL(61)
+#define RISCV_IOMMU_IOHPMEVT_IDT	BIT_ULL(62)
+#define RISCV_IOMMU_IOHPMEVT_OF		BIT_ULL(63)
+
+/**
+ * enum riscv_iommu_hpmevent_id - Performance-monitoring event identifier
+ *
+ * @RISCV_IOMMU_HPMEVENT_INVALID: Invalid event, do not count
+ * @RISCV_IOMMU_HPMEVENT_URQ: Untranslated requests
+ * @RISCV_IOMMU_HPMEVENT_TRQ: Translated requests
+ * @RISCV_IOMMU_HPMEVENT_ATS_RQ: ATS translation requests
+ * @RISCV_IOMMU_HPMEVENT_TLB_MISS: TLB misses
+ * @RISCV_IOMMU_HPMEVENT_DD_WALK: Device directory walks
+ * @RISCV_IOMMU_HPMEVENT_PD_WALK: Process directory walks
+ * @RISCV_IOMMU_HPMEVENT_S_VS_WALKS: S/VS-Stage page table walks
+ * @RISCV_IOMMU_HPMEVENT_G_WALKS: G-Stage page table walks
+ * @RISCV_IOMMU_HPMEVENT_MAX: Value to denote maximum Event IDs
+ */
+enum riscv_iommu_hpmevent_id {
+	RISCV_IOMMU_HPMEVENT_INVALID    = 0,
+	RISCV_IOMMU_HPMEVENT_URQ        = 1,
+	RISCV_IOMMU_HPMEVENT_TRQ        = 2,
+	RISCV_IOMMU_HPMEVENT_ATS_RQ     = 3,
+	RISCV_IOMMU_HPMEVENT_TLB_MISS   = 4,
+	RISCV_IOMMU_HPMEVENT_DD_WALK    = 5,
+	RISCV_IOMMU_HPMEVENT_PD_WALK    = 6,
+	RISCV_IOMMU_HPMEVENT_S_VS_WALKS = 7,
+	RISCV_IOMMU_HPMEVENT_G_WALKS    = 8,
+	RISCV_IOMMU_HPMEVENT_MAX        = 9
+};
+
+/* 5.24 Translation request IOVA (64bits) */
+#define RISCV_IOMMU_REG_TR_REQ_IOVA     0x0258
+#define RISCV_IOMMU_TR_REQ_IOVA_VPN	GENMASK_ULL(63, 12)
+
+/* 5.25 Translation request control (64bits) */
+#define RISCV_IOMMU_REG_TR_REQ_CTL	0x0260
+#define RISCV_IOMMU_TR_REQ_CTL_GO_BUSY	BIT_ULL(0)
+#define RISCV_IOMMU_TR_REQ_CTL_PRIV	BIT_ULL(1)
+#define RISCV_IOMMU_TR_REQ_CTL_EXE	BIT_ULL(2)
+#define RISCV_IOMMU_TR_REQ_CTL_NW	BIT_ULL(3)
+#define RISCV_IOMMU_TR_REQ_CTL_PID	GENMASK_ULL(31, 12)
+#define RISCV_IOMMU_TR_REQ_CTL_PV	BIT_ULL(32)
+#define RISCV_IOMMU_TR_REQ_CTL_DID	GENMASK_ULL(63, 40)
+
+/* 5.26 Translation request response (64bits) */
+#define RISCV_IOMMU_REG_TR_RESPONSE	0x0268
+#define RISCV_IOMMU_TR_RESPONSE_FAULT	BIT_ULL(0)
+#define RISCV_IOMMU_TR_RESPONSE_PBMT	GENMASK_ULL(8, 7)
+#define RISCV_IOMMU_TR_RESPONSE_SZ	BIT_ULL(9)
+#define RISCV_IOMMU_TR_RESPONSE_PPN	RISCV_IOMMU_PPN_FIELD
+
+/* 5.27 Interrupt cause to vector (64bits) */
+#define RISCV_IOMMU_REG_IVEC		0x02F8
+#define RISCV_IOMMU_IVEC_CIV		GENMASK_ULL(3, 0)
+#define RISCV_IOMMU_IVEC_FIV		GENMASK_ULL(7, 4)
+#define RISCV_IOMMU_IVEC_PMIV		GENMASK_ULL(11, 8)
+#define RISCV_IOMMU_IVEC_PIV		GENMASK_ULL(15,12)
+
+/* 5.28 MSI Configuration table (32 * 64bits) */
+#define RISCV_IOMMU_REG_MSI_CONFIG	0x0300
+#define RISCV_IOMMU_REG_MSI_ADDR(_n)	(RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10))
+#define RISCV_IOMMU_MSI_ADDR		GENMASK_ULL(55, 2)
+#define RISCV_IOMMU_REG_MSI_DATA(_n)	(RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10) + 0x08)
+#define RISCV_IOMMU_MSI_DATA		GENMASK_ULL(31, 0)
+#define RISCV_IOMMU_REG_MSI_VEC_CTL(_n)	(RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10) + 0x0C)
+#define RISCV_IOMMU_MSI_VEC_CTL_M	BIT_ULL(0)
+
+#define RISCV_IOMMU_REG_SIZE	0x1000
+
+/*
+ * Chapter 2: Data structures
+ */
+
+/*
+ * Device Directory Table macros for non-leaf nodes
+ */
+#define RISCV_IOMMU_DDTE_VALID	BIT_ULL(0)
+#define RISCV_IOMMU_DDTE_PPN	RISCV_IOMMU_PPN_FIELD
+
+/**
+ * struct riscv_iommu_dc - Device Context
+ * @tc: Translation Control
+ * @iohgatp: I/O Hypervisor guest address translation and protection
+ *	     (Second stage context)
+ * @ta: Translation Attributes
+ * @fsc: First stage context
+ * @msiptpt: MSI page table pointer
+ * @msi_addr_mask: MSI address mask
+ * @msi_addr_pattern: MSI address pattern
+ *
+ * This structure is used for leaf nodes on the Device Directory Table,
+ * in case RISCV_IOMMU_CAP_MSI_FLAT is not set, the bottom 4 fields are
+ * not present and are skipped with pointer arithmetic to avoid
+ * casting, check out riscv_iommu_get_dc().
+ * See section 2.1 for more details
+ */
+struct riscv_iommu_dc {
+	u64 tc;
+	u64 iohgatp;
+	u64 ta;
+	u64 fsc;
+	u64 msiptp;
+	u64 msi_addr_mask;
+	u64 msi_addr_pattern;
+	u64 _reserved;
+};
+
+/* Translation control fields */
+#define RISCV_IOMMU_DC_TC_V		BIT_ULL(0)
+#define RISCV_IOMMU_DC_TC_EN_ATS	BIT_ULL(1)
+#define RISCV_IOMMU_DC_TC_EN_PRI	BIT_ULL(2)
+#define RISCV_IOMMU_DC_TC_T2GPA		BIT_ULL(3)
+#define RISCV_IOMMU_DC_TC_DTF		BIT_ULL(4)
+#define RISCV_IOMMU_DC_TC_PDTV		BIT_ULL(5)
+#define RISCV_IOMMU_DC_TC_PRPR		BIT_ULL(6)
+#define RISCV_IOMMU_DC_TC_GADE		BIT_ULL(7)
+#define RISCV_IOMMU_DC_TC_SADE		BIT_ULL(8)
+#define RISCV_IOMMU_DC_TC_DPE		BIT_ULL(9)
+#define RISCV_IOMMU_DC_TC_SBE		BIT_ULL(10)
+#define RISCV_IOMMU_DC_TC_SXL		BIT_ULL(11)
+
+/* Second-stage (aka G-stage) context fields */
+#define RISCV_IOMMU_DC_IOHGATP_PPN	RISCV_IOMMU_ATP_PPN_FIELD
+#define RISCV_IOMMU_DC_IOHGATP_GSCID	GENMASK_ULL(59, 44)
+#define RISCV_IOMMU_DC_IOHGATP_MODE	RISCV_IOMMU_ATP_MODE_FIELD
+
+/**
+ * enum riscv_iommu_dc_iohgatp_modes - Guest address translation/protection modes
+ * @RISCV_IOMMU_DC_IOHGATP_MODE_BARE: No translation/protection
+ * @RISCV_IOMMU_DC_IOHGATP_MODE_SV32X4: Sv32x4 (2-bit extension of Sv32), when fctl.GXL == 1
+ * @RISCV_IOMMU_DC_IOHGATP_MODE_SV39X4: Sv39x4 (2-bit extension of Sv39), when fctl.GXL == 0
+ * @RISCV_IOMMU_DC_IOHGATP_MODE_SV48X4: Sv48x4 (2-bit extension of Sv48), when fctl.GXL == 0
+ * @RISCV_IOMMU_DC_IOHGATP_MODE_SV57X4: Sv57x4 (2-bit extension of Sv57), when fctl.GXL == 0
+ */
+enum riscv_iommu_dc_iohgatp_modes {
+	RISCV_IOMMU_DC_IOHGATP_MODE_BARE = 0,
+	RISCV_IOMMU_DC_IOHGATP_MODE_SV32X4 = 8,
+	RISCV_IOMMU_DC_IOHGATP_MODE_SV39X4 = 8,
+	RISCV_IOMMU_DC_IOHGATP_MODE_SV48X4 = 9,
+	RISCV_IOMMU_DC_IOHGATP_MODE_SV57X4 = 10
+};
+
+/* Translation attributes fields */
+#define RISCV_IOMMU_DC_TA_PSCID		GENMASK_ULL(31,12)
+
+/* First-stage context fields */
+#define RISCV_IOMMU_DC_FSC_PPN		RISCV_IOMMU_ATP_PPN_FIELD
+#define RISCV_IOMMU_DC_FSC_MODE		RISCV_IOMMU_ATP_MODE_FIELD
+
+/**
+ * enum riscv_iommu_dc_fsc_atp_modes - First stage address translation/protection modes
+ * @RISCV_IOMMU_DC_FSC_MODE_BARE: No translation/protection
+ * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV32: Sv32, when dc.tc.SXL == 1
+ * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV39: Sv39, when dc.tc.SXL == 0
+ * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV48: Sv48, when dc.tc.SXL == 0
+ * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV57: Sv57, when dc.tc.SXL == 0
+ * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8: 1lvl PDT, 8bit process ids
+ * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD17: 2lvl PDT, 17bit process ids
+ * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD20: 3lvl PDT, 20bit process ids
+ *
+ * FSC holds IOSATP when RISCV_IOMMU_DC_TC_PDTV is 0 and PDTP otherwise.
+ * IOSATP controls the first stage address translation (same as the satp register on
+ * the RISC-V MMU), and PDTP holds the process directory table, used to select a
+ * first stage page table based on a process id (for devices that support multiple
+ * process ids).
+ */
+enum riscv_iommu_dc_fsc_atp_modes {
+	RISCV_IOMMU_DC_FSC_MODE_BARE = 0,
+	RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV32 = 8,
+	RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV39 = 8,
+	RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV48 = 9,
+	RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV57 = 10,
+	RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8 = 1,
+	RISCV_IOMMU_DC_FSC_PDTP_MODE_PD17 = 2,
+	RISCV_IOMMU_DC_FSC_PDTP_MODE_PD20 = 3
+};
+
+/* MSI page table pointer */
+#define RISCV_IOMMU_DC_MSIPTP_PPN	RISCV_IOMMU_ATP_PPN_FIELD
+#define RISCV_IOMMU_DC_MSIPTP_MODE	RISCV_IOMMU_ATP_MODE_FIELD
+#define RISCV_IOMMU_DC_MSIPTP_MODE_OFF	0
+#define RISCV_IOMMU_DC_MSIPTP_MODE_FLAT	1
+
+/* MSI address mask */
+#define RISCV_IOMMU_DC_MSI_ADDR_MASK	GENMASK_ULL(51, 0)
+
+/* MSI address pattern */
+#define RISCV_IOMMU_DC_MSI_PATTERN	GENMASK_ULL(51, 0)
+
+/**
+ * struct riscv_iommu_pc - Process Context
+ * @ta: Translation Attributes
+ * @fsc: First stage context
+ *
+ * This structure is used for leaf nodes on the Process Directory Table
+ * See section 2.3 for more details
+ */
+struct riscv_iommu_pc {
+	u64 ta;
+	u64 fsc;
+};
+
+/* Translation attributes fields */
+#define RISCV_IOMMU_PC_TA_V	BIT_ULL(0)
+#define RISCV_IOMMU_PC_TA_ENS	BIT_ULL(1)
+#define RISCV_IOMMU_PC_TA_SUM	BIT_ULL(2)
+#define RISCV_IOMMU_PC_TA_PSCID	GENMASK_ULL(31, 12)
+
+/* First stage context fields */
+#define RISCV_IOMMU_PC_FSC_PPN	RISCV_IOMMU_ATP_PPN_FIELD
+#define RISCV_IOMMU_PC_FSC_MODE	RISCV_IOMMU_ATP_MODE_FIELD
+
+/*
+ * Chapter 3: In-memory queue interface
+ */
+
+/**
+ * struct riscv_iommu_cmd - Generic I/O MMU command structure
+ * @dword0: Includes the opcode and the function identifier
+ * @dword1: Opcode specific data
+ *
+ * The commands are interpreted as two 64bit fields, where the first
+ * 7bits of the first field are the opcode which also defines the
+ * command's format, followed by a 3bit field that specifies the
+ * function invoked by that command, and the rest is opcode-specific.
+ * This is a generic struct which will be populated differently
+ * according to each command. For more infos on the commands and
+ * the command queue check section 3.1.
+ */
+struct riscv_iommu_command {
+	u64 dword0;
+	u64 dword1;
+};
+
+/* Fields on dword0, common for all commands */
+#define RISCV_IOMMU_CMD_OPCODE	GENMASK_ULL(6, 0)
+#define	RISCV_IOMMU_CMD_FUNC	GENMASK_ULL(9, 7)
+
+/* 3.1.1 I/O MMU Page-table cache invalidation */
+/* Fields on dword0 */
+#define RISCV_IOMMU_CMD_IOTINVAL_OPCODE		1
+#define RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA	0
+#define RISCV_IOMMU_CMD_IOTINVAL_FUNC_GVMA	1
+#define RISCV_IOMMU_CMD_IOTINVAL_AV		BIT_ULL(10)
+#define RISCV_IOMMU_CMD_IOTINVAL_PSCID		GENMASK_ULL(31, 12)
+#define RISCV_IOMMU_CMD_IOTINVAL_PSCV		BIT_ULL(32)
+#define RISCV_IOMMU_CMD_IOTINVAL_GV		BIT_ULL(33)
+#define RISCV_IOMMU_CMD_IOTINVAL_GSCID		GENMASK_ULL(59, 44)
+/* dword1 is the address, 4K-alligned and shifted to the right by
+ * two bits. */
+
+/* 3.1.2 I/O MMU Command Queue Fences */
+/* Fields on dword0 */
+#define RISCV_IOMMU_CMD_IOFENCE_OPCODE		2
+#define RISCV_IOMMU_CMD_IOFENCE_FUNC_C		0
+#define RISCV_IOMMU_CMD_IOFENCE_AV		BIT_ULL(10)
+#define RISCV_IOMMU_CMD_IOFENCE_WSI		BIT_ULL(11)
+#define RISCV_IOMMU_CMD_IOFENCE_PR		BIT_ULL(12)
+#define RISCV_IOMMU_CMD_IOFENCE_PW		BIT_ULL(13)
+#define RISCV_IOMMU_CMD_IOFENCE_DATA		GENMASK_ULL(63, 32)
+/* dword1 is the address, word-size alligned and shifted to the
+ * right by two bits. */
+
+/* 3.1.3 I/O MMU Directory cache invalidation */
+/* Fields on dword0 */
+#define RISCV_IOMMU_CMD_IODIR_OPCODE		3
+#define RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT	0
+#define RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT	1
+#define RISCV_IOMMU_CMD_IODIR_PID		GENMASK_ULL(31, 12)
+#define RISCV_IOMMU_CMD_IODIR_DV		BIT_ULL(33)
+#define RISCV_IOMMU_CMD_IODIR_DID		GENMASK_ULL(63, 40)
+/* dword1 is reserved for standard use */
+
+/* 3.1.4 I/O MMU PCIe ATS */
+/* Fields on dword0 */
+#define RISCV_IOMMU_CMD_ATS_OPCODE		4
+#define RISCV_IOMMU_CMD_ATS_FUNC_INVAL		0
+#define RISCV_IOMMU_CMD_ATS_FUNC_PRGR		1
+#define RISCV_IOMMU_CMD_ATS_PID			GENMASK_ULL(31, 12)
+#define RISCV_IOMMU_CMD_ATS_PV			BIT_ULL(32)
+#define RISCV_IOMMU_CMD_ATS_DSV			BIT_ULL(33)
+#define RISCV_IOMMU_CMD_ATS_RID			GENMASK_ULL(55, 40)
+#define RISCV_IOMMU_CMD_ATS_DSEG		GENMASK_ULL(63, 56)
+/* dword1 is the ATS payload, two different payload types for INVAL and PRGR */
+
+/* ATS.INVAL payload*/
+#define RISCV_IOMMU_CMD_ATS_INVAL_G		BIT_ULL(0)
+/* Bits 1 - 10 are zeroed */
+#define RISCV_IOMMU_CMD_ATS_INVAL_S		BIT_ULL(11)
+#define RISCV_IOMMU_CMD_ATS_INVAL_UADDR		GENMASK_ULL(63, 12)
+
+/* ATS.PRGR payload */
+/* Bits 0 - 31 are zeroed */
+#define RISCV_IOMMU_CMD_ATS_PRGR_PRG_INDEX	GENMASK_ULL(40, 32)
+/* Bits 41 - 43 are zeroed */
+#define RISCV_IOMMU_CMD_ATS_PRGR_RESP_CODE	GENMASK_ULL(47, 44)
+#define RISCV_IOMMU_CMD_ATS_PRGR_DST_ID		GENMASK_ULL(63, 48)
+
+/**
+ * struct riscv_iommu_fq_record - Fault/Event Queue Record
+ * @hdr: Header, includes fault/event cause, PID/DID, transaction type etc
+ * @_reserved: Low 32bits for custom use, high 32bits for standard use
+ * @iotval: Transaction-type/cause specific format
+ * @iotval2: Cause specific format
+ *
+ * The fault/event queue reports events and failures raised when
+ * processing transactions. Each record is a 32byte structure where
+ * the first dword has a fixed format for providing generic infos
+ * regarding the fault/event, and two more dwords are there for
+ * fault/event-specific information. For more details see section
+ * 3.2.
+ */
+struct riscv_iommu_fq_record {
+	u64 hdr;
+	u64 _reserved;
+	u64 iotval;
+	u64 iotval2;
+};
+
+/* Fields on header */
+#define RISCV_IOMMU_FQ_HDR_CAUSE	GENMASK_ULL(11, 0)
+#define RISCV_IOMMU_FQ_HDR_PID		GENMASK_ULL(31, 12)
+#define RISCV_IOMMU_FQ_HDR_PV		BIT_ULL(32)
+#define RISCV_IOMMU_FQ_HDR_PRIV		BIT_ULL(33)
+#define RISCV_IOMMU_FQ_HDR_TTYPE	GENMASK_ULL(39, 34)
+#define RISCV_IOMMU_FQ_HDR_DID		GENMASK_ULL(63, 40)
+
+/**
+ * enum riscv_iommu_fq_causes - Fault/event cause values
+ * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT: Instruction access fault
+ * @RISCV_IOMMU_FQ_CAUSE_RD_ADDR_MISALIGNED: Read address misaligned
+ * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT: Read load fault
+ * @RISCV_IOMMU_FQ_CAUSE_WR_ADDR_MISALIGNED: Write/AMO address misaligned
+ * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT: Write/AMO access fault
+ * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT_S: Instruction page fault
+ * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT_S: Read page fault
+ * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT_S: Write/AMO page fault
+ * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT_VS: Instruction guest page fault
+ * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT_VS: Read guest page fault
+ * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT_VS: Write/AMO guest page fault
+ * @RISCV_IOMMU_FQ_CAUSE_DMA_DISABLED: All inbound transactions disallowed
+ * @RISCV_IOMMU_FQ_CAUSE_DDT_LOAD_FAULT: DDT entry load access fault
+ * @RISCV_IOMMU_FQ_CAUSE_DDT_INVALID: DDT entry invalid
+ * @RISCV_IOMMU_FQ_CAUSE_DDT_MISCONFIGURED: DDT entry misconfigured
+ * @RISCV_IOMMU_FQ_CAUSE_TTYPE_BLOCKED: Transaction type disallowed
+ * @RISCV_IOMMU_FQ_CAUSE_MSI_LOAD_FAULT: MSI PTE load access fault
+ * @RISCV_IOMMU_FQ_CAUSE_MSI_INVALID: MSI PTE invalid
+ * @RISCV_IOMMU_FQ_CAUSE_MSI_MISCONFIGURED: MSI PTE misconfigured
+ * @RISCV_IOMMU_FQ_CAUSE_MRIF_FAULT: MRIF access fault
+ * @RISCV_IOMMU_FQ_CAUSE_PDT_LOAD_FAULT: PDT entry load access fault
+ * @RISCV_IOMMU_FQ_CAUSE_PDT_INVALID: PDT entry invalid
+ * @RISCV_IOMMU_FQ_CAUSE_PDT_MISCONFIGURED: PDT entry misconfigured
+ * @RISCV_IOMMU_FQ_CAUSE_DDT_CORRUPTED: DDT data corruption
+ * @RISCV_IOMMU_FQ_CAUSE_PDT_CORRUPTED: PDT data corruption
+ * @RISCV_IOMMU_FQ_CAUSE_MSI_PT_CORRUPTED: MSI page table data corruption
+ * @RISCV_IOMMU_FQ_CAUSE_MRIF_CORRUIPTED: MRIF data corruption
+ * @RISCV_IOMMU_FQ_CAUSE_INTERNAL_DP_ERROR: Internal data path error
+ * @RISCV_IOMMU_FQ_CAUSE_MSI_WR_FAULT: IOMMU MSI write access fault
+ * @RISCV_IOMMU_FQ_CAUSE_PT_CORRUPTED: First/second stage page table data corruption
+ *
+ * Values are on table 11 of the spec, encodings 275 - 2047 are reserved for standard
+ * use, and 2048 - 4095 for custom use.
+ */
+enum riscv_iommu_fq_causes {
+	RISCV_IOMMU_FQ_CAUSE_INST_FAULT = 1,
+	RISCV_IOMMU_FQ_CAUSE_RD_ADDR_MISALIGNED = 4,
+	RISCV_IOMMU_FQ_CAUSE_RD_FAULT = 5,
+	RISCV_IOMMU_FQ_CAUSE_WR_ADDR_MISALIGNED = 6,
+	RISCV_IOMMU_FQ_CAUSE_WR_FAULT = 7,
+	RISCV_IOMMU_FQ_CAUSE_INST_FAULT_S = 12,
+	RISCV_IOMMU_FQ_CAUSE_RD_FAULT_S = 13,
+	RISCV_IOMMU_FQ_CAUSE_WR_FAULT_S = 15,
+	RISCV_IOMMU_FQ_CAUSE_INST_FAULT_VS = 20,
+	RISCV_IOMMU_FQ_CAUSE_RD_FAULT_VS = 21,
+	RISCV_IOMMU_FQ_CAUSE_WR_FAULT_VS = 23,
+	RISCV_IOMMU_FQ_CAUSE_DMA_DISABLED = 256,
+	RISCV_IOMMU_FQ_CAUSE_DDT_LOAD_FAULT = 257,
+	RISCV_IOMMU_FQ_CAUSE_DDT_INVALID = 258,
+	RISCV_IOMMU_FQ_CAUSE_DDT_MISCONFIGURED = 259,
+	RISCV_IOMMU_FQ_CAUSE_TTYPE_BLOCKED = 260,
+	RISCV_IOMMU_FQ_CAUSE_MSI_LOAD_FAULT = 261,
+	RISCV_IOMMU_FQ_CAUSE_MSI_INVALID = 262,
+	RISCV_IOMMU_FQ_CAUSE_MSI_MISCONFIGURED = 263,
+	RISCV_IOMMU_FQ_CAUSE_MRIF_FAULT = 264,
+	RISCV_IOMMU_FQ_CAUSE_PDT_LOAD_FAULT = 265,
+	RISCV_IOMMU_FQ_CAUSE_PDT_INVALID = 266,
+	RISCV_IOMMU_FQ_CAUSE_PDT_MISCONFIGURED = 267,
+	RISCV_IOMMU_FQ_CAUSE_DDT_CORRUPTED = 268,
+	RISCV_IOMMU_FQ_CAUSE_PDT_CORRUPTED = 269,
+	RISCV_IOMMU_FQ_CAUSE_MSI_PT_CORRUPTED = 270,
+	RISCV_IOMMU_FQ_CAUSE_MRIF_CORRUIPTED = 271,
+	RISCV_IOMMU_FQ_CAUSE_INTERNAL_DP_ERROR = 272,
+	RISCV_IOMMU_FQ_CAUSE_MSI_WR_FAULT = 273,
+	RISCV_IOMMU_FQ_CAUSE_PT_CORRUPTED = 274
+};
+
+/**
+ * enum riscv_iommu_fq_ttypes: Fault/event transaction types
+ * @RISCV_IOMMU_FQ_TTYPE_NONE: None. Fault not caused by an inbound transaction.
+ * @RISCV_IOMMU_FQ_TTYPE_UADDR_INST_FETCH: Instruction fetch from untranslated address
+ * @RISCV_IOMMU_FQ_TTYPE_UADDR_RD: Read from untranslated address
+ * @RISCV_IOMMU_FQ_TTYPE_UADDR_WR: Write/AMO to untranslated address
+ * @RISCV_IOMMU_FQ_TTYPE_TADDR_INST_FETCH: Instruction fetch from translated address
+ * @RISCV_IOMMU_FQ_TTYPE_TADDR_RD: Read from translated address
+ * @RISCV_IOMMU_FQ_TTYPE_TADDR_WR: Write/AMO to translated address
+ * @RISCV_IOMMU_FQ_TTYPE_PCIE_ATS_REQ: PCIe ATS translation request
+ * @RISCV_IOMMU_FW_TTYPE_PCIE_MSG_REQ: PCIe message request
+ *
+ * Values are on table 12 of the spec, type 4 and 10 - 31 are reserved for standard use
+ * and 31 - 63 for custom use.
+ */
+enum riscv_iommu_fq_ttypes {
+	RISCV_IOMMU_FQ_TTYPE_NONE = 0,
+	RISCV_IOMMU_FQ_TTYPE_UADDR_INST_FETCH = 1,
+	RISCV_IOMMU_FQ_TTYPE_UADDR_RD = 2,
+	RISCV_IOMMU_FQ_TTYPE_UADDR_WR = 3,
+	RISCV_IOMMU_FQ_TTYPE_TADDR_INST_FETCH = 5,
+	RISCV_IOMMU_FQ_TTYPE_TADDR_RD = 6,
+	RISCV_IOMMU_FQ_TTYPE_TADDR_WR = 7,
+	RISCV_IOMMU_FQ_TTYPE_PCIE_ATS_REQ = 8,
+	RISCV_IOMMU_FW_TTYPE_PCIE_MSG_REQ = 9,
+};
+
+/**
+ * struct riscv_iommu_pq_record - PCIe Page Request record
+ * @hdr: Header, includes PID, DID etc
+ * @payload: Holds the page address, request group and permission bits
+ *
+ * For more infos on the PCIe Page Request queue see chapter 3.3.
+ */
+struct riscv_iommu_pq_record {
+	u64 hdr;
+	u64 payload;
+};
+
+/* Header fields */
+#define RISCV_IOMMU_PREQ_HDR_PID	GENMASK_ULL(31, 12)
+#define RISCV_IOMMU_PREQ_HDR_PV		BIT_ULL(32)
+#define RISCV_IOMMU_PREQ_HDR_PRIV	BIT_ULL(33)
+#define RISCV_IOMMU_PREQ_HDR_EXEC	BIT_ULL(34)
+#define RISCV_IOMMU_PREQ_HDR_DID	GENMASK_ULL(63, 40)
+
+/* Payload fields */
+#define RISCV_IOMMU_PREQ_PAYLOAD_R	BIT_ULL(0)
+#define RISCV_IOMMU_PREQ_PAYLOAD_W	BIT_ULL(1)
+#define RISCV_IOMMU_PREQ_PAYLOAD_L	BIT_ULL(2)
+#define RISCV_IOMMU_PREQ_PAYLOAD_M	GENMASK_ULL(2, 0)	/* Mask of RWL for convenience */
+#define RISCV_IOMMU_PREQ_PRG_INDEX	GENMASK_ULL(11, 3)
+#define RISCV_IOMMU_PREQ_UADDR		GENMASK_ULL(63, 12)
+
+/**
+ * struct riscv_iommu_msi_pte - MSI Page Table Entry
+ * @pte: MSI PTE
+ * @mrif_info: Memory-resident interrupt file info
+ *
+ * The MSI Page Table is used for virtualizing MSIs, so that when
+ * a device sends an MSI to a guest, the IOMMU can reroute it
+ * by translating the MSI address, either to a guest interrupt file
+ * or a memory resident interrupt file (MRIF). Note that this page table
+ * is an array of MSI PTEs, not a multi-level pt, each entry
+ * is a leaf entry. For more infos check out the the AIA spec, chapter 9.5.
+ *
+ * Also in basic mode the mrif_info field is ignored by the IOMMU and can
+ * be used by software, any other reserved fields on pte must be zeroed-out
+ * by software.
+ */
+struct riscv_iommu_msi_pte {
+	u64 pte;
+	u64 mrif_info;
+};
+
+/* Fields on pte */
+#define RISCV_IOMMU_MSI_PTE_V		BIT_ULL(0)
+#define RISCV_IOMMU_MSI_PTE_M		GENMASK_ULL(2, 1)
+#define RISCV_IOMMU_MSI_PTE_MRIF_ADDR	GENMASK_ULL(53, 7)	/* When M == 1 (MRIF mode) */
+#define RISCV_IOMMU_MSI_PTE_PPN		RISCV_IOMMU_PPN_FIELD	/* When M == 3 (basic mode) */
+#define RISCV_IOMMU_MSI_PTE_C		BIT_ULL(63)
+
+/* Fields on mrif_info */
+#define RISCV_IOMMU_MSI_MRIF_NID	GENMASK_ULL(9, 0)
+#define RISCV_IOMMU_MSI_MRIF_NPPN	RISCV_IOMMU_PPN_FIELD
+#define RISCV_IOMMU_MSI_MRIF_NID_MSB	BIT_ULL(60)
+
+#endif /* _RISCV_IOMMU_BITS_H_ */
</span><span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c>diff</a> --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
new file mode 100644
index 000000000000..c91f963d7a29
--- /dev/null
+++ b/drivers/iommu/riscv/iommu-pci.c
</span><span class=hunk>@@ -0,0 +1,134 @@
</span><span class=add>+// SPDX-License-Identifier: GPL-2.0-only
+
+/*
+ * Copyright © 2022-2023 Rivos Inc.
+ * Copyright © 2023 FORTH-ICS/CARV
+ *
+ * RISCV IOMMU as a PCIe device
+ *
+ * Authors
+ *	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
+ *	Nick Kossifidis &lt;mick@ics.forth.gr&gt;
+ */
+
+#include &lt;linux/module.h&gt;
+#include &lt;linux/kernel.h&gt;
+#include &lt;linux/compiler.h&gt;
+#include &lt;linux/pci.h&gt;
+#include &lt;linux/init.h&gt;
+#include &lt;linux/iommu.h&gt;
+#include &lt;linux/bitfield.h&gt;
+
+#include "iommu.h"
+
+/* Rivos Inc. assigned PCI Vendor and Device IDs */
+#ifndef PCI_VENDOR_ID_RIVOS
+#define PCI_VENDOR_ID_RIVOS             0x1efd
+#endif
+
+#ifndef PCI_DEVICE_ID_RIVOS_IOMMU
+#define PCI_DEVICE_ID_RIVOS_IOMMU       0xedf1
+#endif
+
+static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	struct device *dev = &amp;pdev-&gt;dev;
+	struct riscv_iommu_device *iommu;
+	int ret;
+
+	ret = pci_enable_device_mem(pdev);
+	if (ret &lt; 0)
+		return ret;
+
+	ret = pci_request_mem_regions(pdev, KBUILD_MODNAME);
+	if (ret &lt; 0)
+		goto fail;
+
+	ret = -ENOMEM;
+
+	iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
+	if (!iommu)
+		goto fail;
+
+	if (!(pci_resource_flags(pdev, 0) &amp; IORESOURCE_MEM))
+		goto fail;
+
+	if (pci_resource_len(pdev, 0) &lt; RISCV_IOMMU_REG_SIZE)
+		goto fail;
+
+	iommu-&gt;reg_phys = pci_resource_start(pdev, 0);
+	if (!iommu-&gt;reg_phys)
+		goto fail;
+
+	iommu-&gt;reg = devm_ioremap(dev, iommu-&gt;reg_phys, RISCV_IOMMU_REG_SIZE);
+	if (!iommu-&gt;reg)
+		goto fail;
+
+	iommu-&gt;dev = dev;
+	dev_set_drvdata(dev, iommu);
+
+	dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
+	pci_set_master(pdev);
+
+	ret = riscv_iommu_init(iommu);
+	if (!ret)
+		return ret;
+
+ fail:
+	pci_clear_master(pdev);
+	pci_release_regions(pdev);
+	pci_disable_device(pdev);
+	/* Note: devres_release_all() will release iommu and iommu-&gt;reg */
+	return ret;
+}
+
+static void riscv_iommu_pci_remove(struct pci_dev *pdev)
+{
+	riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
+	pci_clear_master(pdev);
+	pci_release_regions(pdev);
+	pci_disable_device(pdev);
+}
+
+static int riscv_iommu_suspend(struct device *dev)
+{
+	dev_warn(dev, "RISC-V IOMMU PM not implemented");
+	return -ENODEV;
+}
+
+static int riscv_iommu_resume(struct device *dev)
+{
+	dev_warn(dev, "RISC-V IOMMU PM not implemented");
+	return -ENODEV;
+}
+
+static DEFINE_SIMPLE_DEV_PM_OPS(riscv_iommu_pm_ops, riscv_iommu_suspend,
+				riscv_iommu_resume);
+
+static const struct pci_device_id riscv_iommu_pci_tbl[] = {
+	{PCI_VENDOR_ID_RIVOS, PCI_DEVICE_ID_RIVOS_IOMMU,
+	 PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0},
+	{0,}
+};
+
+MODULE_DEVICE_TABLE(pci, riscv_iommu_pci_tbl);
+
+static const struct of_device_id riscv_iommu_of_match[] = {
+	{.compatible = "riscv,pci-iommu",},
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
+
+static struct pci_driver riscv_iommu_pci_driver = {
+	.name = KBUILD_MODNAME,
+	.id_table = riscv_iommu_pci_tbl,
+	.probe = riscv_iommu_pci_probe,
+	.remove = riscv_iommu_pci_remove,
+	.driver = {
+		   .pm = pm_sleep_ptr(&amp;riscv_iommu_pm_ops),
+		   .of_match_table = riscv_iommu_of_match,
+		   },
+};
+
+module_driver(riscv_iommu_pci_driver, pci_register_driver, pci_unregister_driver);
</span><span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c>diff</a> --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
new file mode 100644
index 000000000000..e4e8ca6711e7
--- /dev/null
+++ b/drivers/iommu/riscv/iommu-platform.c
</span><span class=hunk>@@ -0,0 +1,94 @@
</span><span class=add>+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * RISC-V IOMMU as a platform device
+ *
+ * Copyright © 2023 FORTH-ICS/CARV
+ *
+ * Author: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
+ */
+
+#include &lt;linux/module.h&gt;
+#include &lt;linux/kernel.h&gt;
+#include &lt;linux/of_platform.h&gt;
+#include &lt;linux/bitfield.h&gt;
+
+#include "iommu-bits.h"
+#include "iommu.h"
+
+static int riscv_iommu_platform_probe(struct platform_device *pdev)
+{
+	struct device *dev = &amp;pdev-&gt;dev;
+	struct riscv_iommu_device *iommu = NULL;
+	struct resource *res = NULL;
+	int ret = 0;
+
+	iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
+	if (!iommu)
+		return -ENOMEM;
+
+	iommu-&gt;dev = dev;
+	dev_set_drvdata(dev, iommu);
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(dev, "could not find resource for register region\n");
+		return -EINVAL;
+	}
+
+	iommu-&gt;reg = devm_platform_get_and_ioremap_resource(pdev, 0, &amp;res);
+	if (IS_ERR(iommu-&gt;reg)) {
+		ret = dev_err_probe(dev, PTR_ERR(iommu-&gt;reg),
+				    "could not map register region\n");
+		goto fail;
+	};
+
+	iommu-&gt;reg_phys = res-&gt;start;
+
+	ret = -ENODEV;
+
+	/* Sanity check: Did we get the whole register space ? */
+	if ((res-&gt;end - res-&gt;start + 1) &lt; RISCV_IOMMU_REG_SIZE) {
+		dev_err(dev, "device region smaller than register file (0x%llx)\n",
+			res-&gt;end - res-&gt;start);
+		goto fail;
+	}
+
+	dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
+
+	return riscv_iommu_init(iommu);
+
+ fail:
+	/* Note: devres_release_all() will release iommu and iommu-&gt;reg */
+	return ret;
+};
+
+static void riscv_iommu_platform_remove(struct platform_device *pdev)
+{
+	riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
+};
+
+static void riscv_iommu_platform_shutdown(struct platform_device *pdev)
+{
+	return;
+};
+
+static const struct of_device_id riscv_iommu_of_match[] = {
+	{.compatible = "riscv,iommu",},
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
+
+static struct platform_driver riscv_iommu_platform_driver = {
+	.driver = {
+		   .name = "riscv,iommu",
+		   .of_match_table = riscv_iommu_of_match,
+		   .suppress_bind_attrs = true,
+		   },
+	.probe = riscv_iommu_platform_probe,
+	.remove_new = riscv_iommu_platform_remove,
+	.shutdown = riscv_iommu_platform_shutdown,
+};
+
+module_driver(riscv_iommu_platform_driver, platform_driver_register,
+	      platform_driver_unregister);
</span><span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
new file mode 100644
index 000000000000..8c236242e2cc
--- /dev/null
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -0,0 +1,660 @@
</span><span class=add>+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * IOMMU API for RISC-V architected Ziommu implementations.
+ *
+ * Copyright © 2022-2023 Rivos Inc.
+ * Copyright © 2023 FORTH-ICS/CARV
+ *
+ * Authors
+ *	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
+ *	Nick Kossifidis &lt;mick@ics.forth.gr&gt;
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include &lt;linux/bitfield.h&gt;
+#include &lt;linux/module.h&gt;
+#include &lt;linux/kernel.h&gt;
+#include &lt;linux/compiler.h&gt;
+#include &lt;linux/pci.h&gt;
+#include &lt;linux/pci-ats.h&gt;
+#include &lt;linux/init.h&gt;
+#include &lt;linux/completion.h&gt;
+#include &lt;linux/uaccess.h&gt;
+#include &lt;linux/iommu.h&gt;
+#include &lt;linux/irqdomain.h&gt;
+#include &lt;linux/platform_device.h&gt;
+#include &lt;linux/dma-map-ops.h&gt;
+#include &lt;asm/page.h&gt;
+
+#include "../dma-iommu.h"
+#include "../iommu-sva.h"
+#include "iommu.h"
+
+#include &lt;asm/csr.h&gt;
+#include &lt;asm/delay.h&gt;
+
+MODULE_DESCRIPTION("IOMMU driver for RISC-V architected Ziommu implementations");
+MODULE_AUTHOR("Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;");
+MODULE_AUTHOR("Nick Kossifidis &lt;mick@ics.forth.gr&gt;");
+MODULE_ALIAS("riscv-iommu");
+MODULE_LICENSE("GPL v2");
+
+/* Global IOMMU params. */
+static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
+module_param(ddt_mode, int, 0644);
+MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
+
+/* IOMMU PSCID allocation namespace. */
+#define RISCV_IOMMU_MAX_PSCID	(1U &lt;&lt; 20)
+static DEFINE_IDA(riscv_iommu_pscids);
+
+/* 1 second */
+#define RISCV_IOMMU_TIMEOUT	riscv_timebase
+
+/* RISC-V IOMMU PPN &lt;&gt; PHYS address conversions, PHYS &lt;=&gt; PPN[53:10] */
+#define phys_to_ppn(va)  (((va) &gt;&gt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 10))
+#define ppn_to_phys(pn)	 (((pn) &lt;&lt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 12))
+
+#define iommu_domain_to_riscv(iommu_domain) \
+    container_of(iommu_domain, struct riscv_iommu_domain, domain)
+
+#define iommu_device_to_riscv(iommu_device) \
+    container_of(iommu_device, struct riscv_iommu, iommu)
+
+static const struct iommu_domain_ops riscv_iommu_domain_ops;
+static const struct iommu_ops riscv_iommu_ops;
+
+/*
+ * Register device for IOMMU tracking.
+ */
+static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct device *dev)
+{
+	struct riscv_iommu_endpoint *ep, *rb_ep;
+	struct rb_node **new_node, *parent_node = NULL;
+
+	mutex_lock(&amp;iommu-&gt;eps_mutex);
+
+	ep = dev_iommu_priv_get(dev);
+
+	new_node = &amp;(iommu-&gt;eps.rb_node);
+	while (*new_node) {
+		rb_ep = rb_entry(*new_node, struct riscv_iommu_endpoint, node);
+		parent_node = *new_node;
+		if (rb_ep-&gt;devid &gt; ep-&gt;devid) {
+			new_node = &amp;((*new_node)-&gt;rb_left);
+		} else if (rb_ep-&gt;devid &lt; ep-&gt;devid) {
+			new_node = &amp;((*new_node)-&gt;rb_right);
+		} else {
+			dev_warn(dev, "device %u already in the tree\n", ep-&gt;devid);
+			break;
+		}
+	}
+
+	rb_link_node(&amp;ep-&gt;node, parent_node, new_node);
+	rb_insert_color(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
+
+	mutex_unlock(&amp;iommu-&gt;eps_mutex);
+}
+
+/*
+ * Endpoint management
+ */
+
+static int riscv_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)
+{
+	return iommu_fwspec_add_ids(dev, args-&gt;args, 1);
+}
+
+static bool riscv_iommu_capable(struct device *dev, enum iommu_cap cap)
+{
+	switch (cap) {
+	case IOMMU_CAP_CACHE_COHERENCY:
+	case IOMMU_CAP_PRE_BOOT_PROTECTION:
+		return true;
+
+	default:
+		break;
+	}
+
+	return false;
+}
+
+static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
+{
+	struct riscv_iommu_device *iommu;
+	struct riscv_iommu_endpoint *ep;
+	struct iommu_fwspec *fwspec;
+
+	fwspec = dev_iommu_fwspec_get(dev);
+	if (!fwspec || fwspec-&gt;ops != &amp;riscv_iommu_ops ||
+	    !fwspec-&gt;iommu_fwnode || !fwspec-&gt;iommu_fwnode-&gt;dev)
+		return ERR_PTR(-ENODEV);
+
+	iommu = dev_get_drvdata(fwspec-&gt;iommu_fwnode-&gt;dev);
+	if (!iommu)
+		return ERR_PTR(-ENODEV);
+
+	if (dev_iommu_priv_get(dev))
+		return &amp;iommu-&gt;iommu;
+
+	ep = kzalloc(sizeof(*ep), GFP_KERNEL);
+	if (!ep)
+		return ERR_PTR(-ENOMEM);
+
+	mutex_init(&amp;ep-&gt;lock);
+	INIT_LIST_HEAD(&amp;ep-&gt;domain);
+
+	if (dev_is_pci(dev)) {
+		ep-&gt;devid = pci_dev_id(to_pci_dev(dev));
+		ep-&gt;domid = pci_domain_nr(to_pci_dev(dev)-&gt;bus);
+	} else {
+		/* TODO: Make this generic, for now hardcode domain id to 0 */
+		ep-&gt;devid = fwspec-&gt;ids[0];
+		ep-&gt;domid = 0;
+	}
+
+	ep-&gt;iommu = iommu;
+	ep-&gt;dev = dev;
+
+	dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
+		ep-&gt;devid, ep-&gt;domid);
+
+	dev_iommu_priv_set(dev, ep);
+	riscv_iommu_add_device(iommu, dev);
+
+	return &amp;iommu-&gt;iommu;
+}
+
+static void riscv_iommu_probe_finalize(struct device *dev)
+{
+	set_dma_ops(dev, NULL);
+	iommu_setup_dma_ops(dev, 0, U64_MAX);
+}
+
+static void riscv_iommu_release_device(struct device *dev)
+{
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+	struct riscv_iommu_device *iommu = ep-&gt;iommu;
+
+	dev_info(dev, "device with devid %i released\n", ep-&gt;devid);
+
+	mutex_lock(&amp;ep-&gt;lock);
+	list_del(&amp;ep-&gt;domain);
+	mutex_unlock(&amp;ep-&gt;lock);
+
+	/* Remove endpoint from IOMMU tracking structures */
+	mutex_lock(&amp;iommu-&gt;eps_mutex);
+	rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
+	mutex_unlock(&amp;iommu-&gt;eps_mutex);
+
+	set_dma_ops(dev, NULL);
+	dev_iommu_priv_set(dev, NULL);
+
+	kfree(ep);
+}
+
+static struct iommu_group *riscv_iommu_device_group(struct device *dev)
+{
+	if (dev_is_pci(dev))
+		return pci_device_group(dev);
+	return generic_device_group(dev);
+}
+
+static void riscv_iommu_get_resv_regions(struct device *dev, struct list_head *head)
+{
+	iommu_dma_get_resv_regions(dev, head);
+}
+
+/*
+ * Domain management
+ */
+
+static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
+{
+	struct riscv_iommu_domain *domain;
+
+	if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
+	    type != IOMMU_DOMAIN_BLOCKED)
+		return NULL;
+
+	domain = kzalloc(sizeof(*domain), GFP_KERNEL);
+	if (!domain)
+		return NULL;
+
+	mutex_init(&amp;domain-&gt;lock);
+	INIT_LIST_HEAD(&amp;domain-&gt;endpoints);
+
+	domain-&gt;domain.ops = &amp;riscv_iommu_domain_ops;
+	domain-&gt;mode = RISCV_IOMMU_DC_FSC_MODE_BARE;
+	domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
+					RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
+
+	printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
+
+	return &amp;domain-&gt;domain;
+}
+
+static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
+{
+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+
+	if (!list_empty(&amp;domain-&gt;endpoints)) {
+		pr_warn("IOMMU domain is not empty!\n");
+	}
+
+	if (domain-&gt;pgd_root)
+		free_pages((unsigned long)domain-&gt;pgd_root, 0);
+
+	if ((int)domain-&gt;pscid &gt; 0)
+		ida_free(&amp;riscv_iommu_pscids, domain-&gt;pscid);
+
+	printk("domain free %u\n", domain-&gt;pscid);
+
+	kfree(domain);
+}
+
+static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
+				       struct riscv_iommu_device *iommu)
+{
+	struct iommu_domain_geometry *geometry;
+
+	/* Domain assigned to another iommu */
+	if (domain-&gt;iommu &amp;&amp; domain-&gt;iommu != iommu)
+		return -EINVAL;
+	/* Domain already initialized */
+	else if (domain-&gt;iommu)
+		return 0;
+
+	/*
+	 * TODO: Before using VA_BITS and satp_mode here, verify they
+	 * are supported by the iommu, through the capabilities register.
+	 */
+
+	geometry = &amp;domain-&gt;domain.geometry;
+
+	/*
+	 * Note: RISC-V Privilege spec mandates that virtual addresses
+	 * need to be sign-extended, so if (VA_BITS - 1) is set, all
+	 * bits &gt;= VA_BITS need to also be set or else we'll get a
+	 * page fault. However the code that creates the mappings
+	 * above us (e.g. iommu_dma_alloc_iova()) won't do that for us
+	 * for now, so we'll end up with invalid virtual addresses
+	 * to map. As a workaround until we get this sorted out
+	 * limit the available virtual addresses to VA_BITS - 1.
+	 */
+	geometry-&gt;aperture_start = 0;
+	geometry-&gt;aperture_end = DMA_BIT_MASK(VA_BITS - 1);
+	geometry-&gt;force_aperture = true;
+
+	domain-&gt;iommu = iommu;
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
+		return 0;
+
+	/* TODO: Fix this for RV32 */
+	domain-&gt;mode = satp_mode &gt;&gt; 60;
+	domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO, 0);
+
+	if (!domain-&gt;pgd_root)
+		return -ENOMEM;
+
+	return 0;
+}
+
+static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct device *dev)
+{
+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+	int ret;
+
+	/* PSCID not valid */
+	if ((int)domain-&gt;pscid &lt; 0)
+		return -ENOMEM;
+
+	mutex_lock(&amp;domain-&gt;lock);
+	mutex_lock(&amp;ep-&gt;lock);
+
+	if (!list_empty(&amp;ep-&gt;domain)) {
+		dev_warn(dev, "endpoint already attached to a domain. dropping\n");
+		list_del_init(&amp;ep-&gt;domain);
+	}
+
+	/* allocate root pages, initialize io-pgtable ops, etc. */
+	ret = riscv_iommu_domain_finalize(domain, ep-&gt;iommu);
+	if (ret &lt; 0) {
+		dev_err(dev, "can not finalize domain: %d\n", ret);
+		mutex_unlock(&amp;ep-&gt;lock);
+		mutex_unlock(&amp;domain-&gt;lock);
+		return ret;
+	}
+
+	if (ep-&gt;iommu-&gt;ddt_mode != RISCV_IOMMU_DDTP_MODE_BARE ||
+	    domain-&gt;domain.type != IOMMU_DOMAIN_IDENTITY) {
+		dev_warn(dev, "domain type %d not supported\n",
+		    domain-&gt;domain.type);
+		return -ENODEV;
+	}
+
+	list_add_tail(&amp;ep-&gt;domain, &amp;domain-&gt;endpoints);
+	mutex_unlock(&amp;ep-&gt;lock);
+	mutex_unlock(&amp;domain-&gt;lock);
+
+	dev_info(dev, "domain type %d attached w/ PSCID %u\n",
+	    domain-&gt;domain.type, domain-&gt;pscid);
+
+	return 0;
+}
+
+static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
+					  unsigned long *start, unsigned long *end,
+					  size_t *pgsize)
+{
+	/* Command interface not implemented */
+}
+
+static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
+{
+	riscv_iommu_flush_iotlb_range(iommu_domain, NULL, NULL, NULL);
+}
+
+static void riscv_iommu_iotlb_sync(struct iommu_domain *iommu_domain,
+				   struct iommu_iotlb_gather *gather)
+{
+	riscv_iommu_flush_iotlb_range(iommu_domain, &amp;gather-&gt;start, &amp;gather-&gt;end,
+				      &amp;gather-&gt;pgsize);
+}
+
+static void riscv_iommu_iotlb_sync_map(struct iommu_domain *iommu_domain,
+				       unsigned long iova, size_t size)
+{
+	unsigned long end = iova + size - 1;
+	/*
+	 * Given we don't know the page size used by this range, we assume the
+	 * smallest page size to ensure all possible entries are flushed from
+	 * the IOATC.
+	 */
+	size_t pgsize = PAGE_SIZE;
+	riscv_iommu_flush_iotlb_range(iommu_domain, &amp;iova, &amp;end, &amp;pgsize);
+}
+
+static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
+				 unsigned long iova, phys_addr_t phys,
+				 size_t pgsize, size_t pgcount, int prot,
+				 gfp_t gfp, size_t *mapped)
+{
+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
+		*mapped = pgsize * pgcount;
+		return 0;
+	}
+
+	return -ENODEV;
+}
+
+static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
+				      unsigned long iova, size_t pgsize,
+				      size_t pgcount, struct iommu_iotlb_gather *gather)
+{
+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
+		return pgsize * pgcount;
+
+	return 0;
+}
+
+static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
+					    dma_addr_t iova)
+{
+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
+		return (phys_addr_t) iova;
+
+	return 0;
+}
+
+/*
+ * Translation mode setup
+ */
+
+static u64 riscv_iommu_get_ddtp(struct riscv_iommu_device *iommu)
+{
+	u64 ddtp;
+	cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
+
+	/* Wait for DDTP.BUSY to be cleared and return latest value */
+	do {
+		ddtp = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_DDTP);
+		if (!(ddtp &amp; RISCV_IOMMU_DDTP_BUSY))
+			break;
+		cpu_relax();
+	} while (get_cycles() &lt; end_cycles);
+
+	return ddtp;
+}
+
+static void riscv_iommu_ddt_cleanup(struct riscv_iommu_device *iommu)
+{
+	/* TODO: teardown whole device directory tree. */
+	if (iommu-&gt;ddtp) {
+		if (iommu-&gt;ddtp_in_iomem) {
+			iounmap((void *)iommu-&gt;ddtp);
+		} else
+			free_page(iommu-&gt;ddtp);
+		iommu-&gt;ddtp = 0;
+	}
+}
+
+static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned requested_mode)
+{
+	struct device *dev = iommu-&gt;dev;
+	u64 ddtp = 0;
+	u64 ddtp_paddr = 0;
+	unsigned mode = requested_mode;
+	unsigned mode_readback = 0;
+
+	ddtp = riscv_iommu_get_ddtp(iommu);
+	if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY)
+		return -EBUSY;
+
+	/* Disallow state transtion from xLVL to xLVL. */
+	switch (FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp)) {
+	case RISCV_IOMMU_DDTP_MODE_BARE:
+	case RISCV_IOMMU_DDTP_MODE_OFF:
+		break;
+	default:
+		if ((mode != RISCV_IOMMU_DDTP_MODE_BARE)
+		    &amp;&amp; (mode != RISCV_IOMMU_DDTP_MODE_OFF))
+			return -EINVAL;
+		break;
+	}
+
+ retry:
+	switch (mode) {
+	case RISCV_IOMMU_DDTP_MODE_BARE:
+	case RISCV_IOMMU_DDTP_MODE_OFF:
+		riscv_iommu_ddt_cleanup(iommu);
+		ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode);
+		break;
+	case RISCV_IOMMU_DDTP_MODE_1LVL:
+	case RISCV_IOMMU_DDTP_MODE_2LVL:
+	case RISCV_IOMMU_DDTP_MODE_3LVL:
+		if (!iommu-&gt;ddtp) {
+			/*
+			 * We haven't initialized ddtp yet, since it's WARL make
+			 * sure that we don't have a hardwired PPN field there
+			 * that points to i/o memory instead.
+			 */
+			riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, 0);
+			ddtp = riscv_iommu_get_ddtp(iommu);
+			ddtp_paddr = ppn_to_phys(ddtp);
+			if (ddtp_paddr) {
+				dev_warn(dev, "ddtp at 0x%llx\n", ddtp_paddr);
+				iommu-&gt;ddtp =
+				    (unsigned long)ioremap(ddtp_paddr, PAGE_SIZE);
+				iommu-&gt;ddtp_in_iomem = true;
+			} else {
+				iommu-&gt;ddtp = get_zeroed_page(GFP_KERNEL);
+			}
+		}
+		if (!iommu-&gt;ddtp)
+			return -ENOMEM;
+
+		ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode) |
+		    phys_to_ppn(__pa(iommu-&gt;ddtp));
+
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, ddtp);
+	ddtp = riscv_iommu_get_ddtp(iommu);
+	if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY) {
+		dev_warn(dev, "timeout when setting ddtp (ddt mode: %i)\n", mode);
+		return -EBUSY;
+	}
+
+	mode_readback = FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp);
+	dev_info(dev, "mode_readback: %i, mode: %i\n", mode_readback, mode);
+	if (mode_readback != mode) {
+		/*
+		 * Mode field is WARL, an I/O MMU may support a subset of
+		 * directory table levels in which case if we tried to set
+		 * an unsupported number of levels we'll readback either
+		 * a valid xLVL or off/bare. If we got off/bare, try again
+		 * with a smaller xLVL.
+		 */
+		if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
+		    mode &gt; RISCV_IOMMU_DDTP_MODE_1LVL) {
+			mode--;
+			goto retry;
+		}
+
+		/*
+		 * We tried all supported xLVL modes and still got off/bare instead,
+		 * an I/O MMU must support at least one supported xLVL mode so something
+		 * went very wrong.
+		 */
+		if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
+		    mode == RISCV_IOMMU_DDTP_MODE_1LVL)
+			goto fail;
+
+		/*
+		 * We tried setting off or bare and got something else back, something
+		 * went very wrong since off/bare is always legal.
+		 */
+		if (mode &lt; RISCV_IOMMU_DDTP_MODE_1LVL)
+			goto fail;
+
+		/*
+		 * We tried setting an xLVL mode but got another xLVL mode that
+		 * we don't support (e.g. a custom one).
+		 */
+		if (mode_readback &gt; RISCV_IOMMU_DDTP_MODE_MAX)
+			goto fail;
+
+		/* We tried setting an xLVL mode but got another supported xLVL mode */
+		mode = mode_readback;
+	}
+
+	if (mode != requested_mode)
+		dev_warn(dev, "unsupported DDT mode requested (%i), using %i instead\n",
+			 requested_mode, mode);
+
+	iommu-&gt;ddt_mode = mode;
+	dev_info(dev, "ddt_mode: %i\n", iommu-&gt;ddt_mode);
+	return 0;
+
+ fail:
+	dev_err(dev, "failed to set DDT mode, tried: %i and got %i\n", mode,
+		mode_readback);
+	riscv_iommu_ddt_cleanup(iommu);
+	return -EINVAL;
+}
+
+/*
+ * Common I/O MMU driver probe/teardown
+ */
+
+static const struct iommu_domain_ops riscv_iommu_domain_ops = {
+	.free = riscv_iommu_domain_free,
+	.attach_dev = riscv_iommu_attach_dev,
+	.map_pages = riscv_iommu_map_pages,
+	.unmap_pages = riscv_iommu_unmap_pages,
+	.iova_to_phys = riscv_iommu_iova_to_phys,
+	.iotlb_sync = riscv_iommu_iotlb_sync,
+	.iotlb_sync_map = riscv_iommu_iotlb_sync_map,
+	.flush_iotlb_all = riscv_iommu_flush_iotlb_all,
+};
+
+static const struct iommu_ops riscv_iommu_ops = {
+	.owner = THIS_MODULE,
+	.pgsize_bitmap = SZ_4K | SZ_2M | SZ_512M,
+	.capable = riscv_iommu_capable,
+	.domain_alloc = riscv_iommu_domain_alloc,
+	.probe_device = riscv_iommu_probe_device,
+	.probe_finalize = riscv_iommu_probe_finalize,
+	.release_device = riscv_iommu_release_device,
+	.device_group = riscv_iommu_device_group,
+	.get_resv_regions = riscv_iommu_get_resv_regions,
+	.of_xlate = riscv_iommu_of_xlate,
+	.default_domain_ops = &amp;riscv_iommu_domain_ops,
+};
+
+void riscv_iommu_remove(struct riscv_iommu_device *iommu)
+{
+	iommu_device_unregister(&amp;iommu-&gt;iommu);
+	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
+}
+
+int riscv_iommu_init(struct riscv_iommu_device *iommu)
+{
+	struct device *dev = iommu-&gt;dev;
+	u32 fctl = 0;
+	int ret;
+
+	iommu-&gt;eps = RB_ROOT;
+
+	fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
+
+#ifdef CONFIG_CPU_BIG_ENDIAN
+	if (!(cap &amp; RISCV_IOMMU_CAP_END)) {
+		dev_err(dev, "IOMMU doesn't support Big Endian\n");
+		return -EIO;
+	} else if (!(fctl &amp; RISCV_IOMMU_FCTL_BE)) {
+		fctl |= FIELD_PREP(RISCV_IOMMU_FCTL_BE, 1);
+		riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
+	}
+#endif
+
+	/* Clear any pending interrupt flag. */
+	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
+			   RISCV_IOMMU_IPSR_CIP |
+			   RISCV_IOMMU_IPSR_FIP |
+			   RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
+	spin_lock_init(&amp;iommu-&gt;cq_lock);
+	mutex_init(&amp;iommu-&gt;eps_mutex);
+
+	ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
+
+	if (ret) {
+		dev_err(dev, "cannot enable iommu device (%d)\n", ret);
+		goto fail;
+	}
+
+	ret = iommu_device_register(&amp;iommu-&gt;iommu, &amp;riscv_iommu_ops, dev);
+	if (ret) {
+		dev_err(dev, "cannot register iommu interface (%d)\n", ret);
+		iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
+		goto fail;
+	}
+
+	return 0;
+ fail:
+	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
+	return ret;
+}
</span><span class=head><a href=#iZ2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
new file mode 100644
index 000000000000..7baefd3630b3
--- /dev/null
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -0,0 +1,115 @@
</span><span class=add>+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright © 2022-2023 Rivos Inc.
+ * Copyright © 2023 FORTH-ICS/CARV
+ *
+ * RISC-V Ziommu - IOMMU Interface Specification.
+ *
+ * Authors
+ *	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
+ *	Nick Kossifidis &lt;mick@ics.forth.gr&gt;
+ */
+
+#ifndef _RISCV_IOMMU_H_
+#define _RISCV_IOMMU_H_
+
+#include &lt;linux/types.h&gt;
+#include &lt;linux/iova.h&gt;
+#include &lt;linux/io.h&gt;
+#include &lt;linux/idr.h&gt;
+#include &lt;linux/list.h&gt;
+#include &lt;linux/iommu.h&gt;
+#include &lt;linux/io-pgtable.h&gt;
+
+#include "iommu-bits.h"
+
+#define IOMMU_PAGE_SIZE_4K	BIT_ULL(12)
+#define IOMMU_PAGE_SIZE_2M	BIT_ULL(21)
+#define IOMMU_PAGE_SIZE_1G	BIT_ULL(30)
+#define IOMMU_PAGE_SIZE_512G	BIT_ULL(39)
+
+struct riscv_iommu_device {
+	struct iommu_device iommu;	/* iommu core interface */
+	struct device *dev;		/* iommu hardware */
+
+	/* hardware control register space */
+	void __iomem *reg;
+	resource_size_t reg_phys;
+
+	/* IRQs for the various queues */
+	int irq_cmdq;
+	int irq_fltq;
+	int irq_pm;
+	int irq_priq;
+
+	/* supported and enabled hardware capabilities */
+	u64 cap;
+
+	/* global lock, to be removed */
+	spinlock_t cq_lock;
+
+	/* device directory table root pointer and mode */
+	unsigned long ddtp;
+	unsigned ddt_mode;
+	bool ddtp_in_iomem;
+
+	/* Connected end-points */
+	struct rb_root eps;
+	struct mutex eps_mutex;
+};
+
+struct riscv_iommu_domain {
+	struct iommu_domain domain;
+
+	struct list_head endpoints;
+	struct mutex lock;
+	struct riscv_iommu_device *iommu;
+
+	unsigned mode;		/* RIO_ATP_MODE_* enum */
+	unsigned pscid;		/* RISC-V IOMMU PSCID */
+
+	pgd_t *pgd_root;	/* page table root pointer */
+};
+
+/* Private dev_iommu_priv object, device-domain relationship. */
+struct riscv_iommu_endpoint {
+	struct device *dev;			/* platform or PCI endpoint device */
+	unsigned devid;      			/* PCI bus:device:function number */
+	unsigned domid;    			/* PCI domain number, segment */
+	struct rb_node node;    		/* device tracking node (lookup by devid) */
+	struct riscv_iommu_device *iommu;	/* parent iommu device */
+
+	struct mutex lock;
+	struct list_head domain;		/* endpoint attached managed domain */
+};
+
+/* Helper functions and macros */
+
+static inline u32 riscv_iommu_readl(struct riscv_iommu_device *iommu,
+				    unsigned offset)
+{
+	return readl_relaxed(iommu-&gt;reg + offset);
+}
+
+static inline void riscv_iommu_writel(struct riscv_iommu_device *iommu,
+				      unsigned offset, u32 val)
+{
+	writel_relaxed(val, iommu-&gt;reg + offset);
+}
+
+static inline u64 riscv_iommu_readq(struct riscv_iommu_device *iommu,
+				    unsigned offset)
+{
+	return readq_relaxed(iommu-&gt;reg + offset);
+}
+
+static inline void riscv_iommu_writeq(struct riscv_iommu_device *iommu,
+				      unsigned offset, u64 val)
+{
+	writeq_relaxed(val, iommu-&gt;reg + offset);
+}
+
+int riscv_iommu_init(struct riscv_iommu_device *iommu);
+void riscv_iommu_remove(struct riscv_iommu_device *iommu);
+
+#endif
</span>-- 
2.34.1


<a href=#mcbff9602b4590805d9db0bce8ed33655b290f552 id=ecbff9602b4590805d9db0bce8ed33655b290f552>^</a> <a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/c33c24036c06c023947ecb47177da273569b3ac7.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#rcbff9602b4590805d9db0bce8ed33655b290f552>86+ messages in thread</a></pre><hr><pre><a href=#e20d2511b6c12906189c92aa1f0e9ce0c668c5a83 id=m20d2511b6c12906189c92aa1f0e9ce0c668c5a83>*</a> <b>[PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-19 20:22   ` <a href=#m07e17b6f91977601733160534a5f82428a4a05be>Conor Dooley</a>
  2023-07-19 19:33 ` <a href=#mbf8dc4098fb09b87b2618c5c545ae882f11b114b>[PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</a> Tomasz Jeznach
                   ` <a href=#rbf8dc4098fb09b87b2618c5c545ae882f11b114b>(9 subsequent siblings)</a>
  <a href=#r20d2511b6c12906189c92aa1f0e9ce0c668c5a83>11 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193510">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193510">linux-kernel</a>, linux,
	Tomasz Jeznach

---
 <a id=iZ2e.:..:961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach::40rivosinc.com:1arch:riscv:configs:defconfig href=#Z2e.:..:961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach::40rivosinc.com:1arch:riscv:configs:defconfig>arch/riscv/configs/defconfig</a> | 1 +
 1 file <a href=#e20d2511b6c12906189c92aa1f0e9ce0c668c5a83>changed</a>, 1 insertion(+)

<span class=head><a href=#iZ2e.:..:961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach::40rivosinc.com:1arch:riscv:configs:defconfig id=Z2e.:..:961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach::40rivosinc.com:1arch:riscv:configs:defconfig>diff</a> --git a/arch/riscv/configs/defconfig b/arch/riscv/configs/defconfig
index 0a0107460a5c..1a0c3b24329f 100644
--- a/arch/riscv/configs/defconfig
+++ b/arch/riscv/configs/defconfig
</span><span class=hunk>@@ -178,6 +178,7 @@ CONFIG_VIRTIO_PCI=y
</span> CONFIG_VIRTIO_BALLOON=y
 CONFIG_VIRTIO_INPUT=y
 CONFIG_VIRTIO_MMIO=y
<span class=add>+CONFIG_RISCV_IOMMU=y
</span> CONFIG_SUN8I_DE2_CCU=m
 CONFIG_SUN50I_IOMMU=y
 CONFIG_RPMSG_CHAR=y
-- 
2.34.1


<a href=#m20d2511b6c12906189c92aa1f0e9ce0c668c5a83 id=e20d2511b6c12906189c92aa1f0e9ce0c668c5a83>^</a> <a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/961d125558137f7cb960de65e5f71da5d299d3bc.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#r20d2511b6c12906189c92aa1f0e9ce0c668c5a83>86+ messages in thread</a></pre><hr><pre><a href=#ebf8dc4098fb09b87b2618c5c545ae882f11b114b id=mbf8dc4098fb09b87b2618c5c545ae882f11b114b>*</a> <b>[PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
  2023-07-19 19:33 ` <a href=#m20d2511b6c12906189c92aa1f0e9ce0c668c5a83>[PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-19 20:19   ` <a href=#m88a4003327a711a111ee2c4d48bf98696a66bc8b>Conor Dooley</a>
  2023-07-24  8:03   ` <a href=#mefb742c2ddae58fd3cf54da7451501e4bd3a30a7>Zong Li</a>
  2023-07-19 19:33 ` <a href=#mc8ea74f153739ba422b2d84e3077559061512b9f>[PATCH 04/11] MAINTAINERS: Add myself for RISC-V IOMMU driver</a> Tomasz Jeznach
                   ` <a href=#rc8ea74f153739ba422b2d84e3077559061512b9f>(8 subsequent siblings)</a>
  <a href=#rbf8dc4098fb09b87b2618c5c545ae882f11b114b>11 siblings, 2 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193508">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193508">linux-kernel</a>, linux

From: Anup Patel &lt;apatel@ventanamicro.com&gt;

We add DT bindings document for RISC-V IOMMU platform and PCI devices
defined by the RISC-V IOMMU specification.

Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
---
 <a id=iZ2e.:..:d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach::40rivosinc.com:1bindings:iommu:riscv::2ciommu.yaml href=#Z2e.:..:d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach::40rivosinc.com:1bindings:iommu:riscv::2ciommu.yaml>.../bindings/iommu/riscv,iommu.yaml</a>           | 146 ++++++++++++++++++
 1 file <a href=#ebf8dc4098fb09b87b2618c5c545ae882f11b114b>changed</a>, 146 insertions(+)
 create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml

<span class=head><a href=#iZ2e.:..:d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach::40rivosinc.com:1bindings:iommu:riscv::2ciommu.yaml id=Z2e.:..:d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach::40rivosinc.com:1bindings:iommu:riscv::2ciommu.yaml>diff</a> --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
new file mode 100644
index 000000000000..8a9aedb61768
--- /dev/null
+++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
</span><span class=hunk>@@ -0,0 +1,146 @@
</span><span class=add>+# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
+%YAML 1.2
+---
+$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
+$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
+
+title: RISC-V IOMMU Implementation
+
+maintainers:
+  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
+
+description:
+  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
+  which can be a regular platform device or a PCI device connected to
+  the host root port.
+
+  The RISC-V IOMMU provides two stage translation, device directory table,
+  command queue and fault reporting as wired interrupt or MSIx event for
+  both PCI and platform devices.
+
+  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
+
+properties:
+  compatible:
+    oneOf:
+      - description: RISC-V IOMMU as a platform device
+        items:
+          - enum:
+              - vendor,chip-iommu
+          - const: riscv,iommu
+
+      - description: RISC-V IOMMU as a PCI device connected to root port
+        items:
+          - enum:
+              - vendor,chip-pci-iommu
+          - const: riscv,pci-iommu
+
+  reg:
+    maxItems: 1
+    description:
+      For RISC-V IOMMU as a platform device, this represents the MMIO base
+      address of registers.
+
+      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
+      details as described in Documentation/devicetree/bindings/pci/pci.txt
+
+  '#iommu-cells':
+    const: 2
+    description: |
+      Each IOMMU specifier represents the base device ID and number of
+      device IDs.
+
+  interrupts:
+    minItems: 1
+    maxItems: 16
+    description:
+      The presence of this property implies that given RISC-V IOMMU uses
+      wired interrupts to notify the RISC-V HARTS (or CPUs).
+
+  msi-parent:
+    description:
+      The presence of this property implies that given RISC-V IOMMU uses
+      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
+      considered only when the interrupts property is absent.
+
+  dma-coherent:
+    description:
+      Present if page table walks and DMA accessed made by the RISC-V IOMMU
+      are cache coherent with the CPU.
+
+  power-domains:
+    maxItems: 1
+
+required:
+  - compatible
+  - reg
+  - '#iommu-cells'
+
+additionalProperties: false
+
+examples:
+  - |
+    /* Example 1 (IOMMU platform device with wired interrupts) */
+    immu1: iommu@1bccd000 {
+        compatible = "vendor,chip-iommu", "riscv,iommu";
+        reg = &lt;0x1bccd000 0x1000&gt;;
+        interrupt-parent = &lt;&amp;aplic_smode&gt;;
+        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
+        #iommu-cells = &lt;2&gt;;
+    };
+
+    /* Device with two IOMMU device IDs, 0 and 7 */
+    master1 {
+        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
+    };
+
+  - |
+    /* Example 2 (IOMMU platform device with MSIs) */
+    immu2: iommu@1bcdd000 {
+        compatible = "vendor,chip-iommu", "riscv,iommu";
+        reg = &lt;0x1bccd000 0x1000&gt;;
+        msi-parent = &lt;&amp;imsics_smode&gt;;
+        #iommu-cells = &lt;2&gt;;
+    };
+
+    bus {
+        #address-cells = &lt;2&gt;;
+        #size-cells = &lt;2&gt;;
+
+        /* Device with IOMMU device IDs ranging from 32 to 64 */
+        master1 {
+                iommus = &lt;&amp;immu2 32 32&gt;;
+        };
+
+        pcie@40000000 {
+            compatible = "pci-host-cam-generic";
+            device_type = "pci";
+            #address-cells = &lt;3&gt;;
+            #size-cells = &lt;2&gt;;
+            bus-range = &lt;0x0 0x1&gt;;
+
+            /* CPU_PHYSICAL(2)  SIZE(2) */
+            reg = &lt;0x0 0x40000000 0x0 0x1000000&gt;;
+
+            /* BUS_ADDRESS(3)  CPU_PHYSICAL(2)  SIZE(2) */
+            ranges = &lt;0x01000000 0x0 0x01000000  0x0 0x01000000  0x0 0x00010000&gt;,
+                     &lt;0x02000000 0x0 0x41000000  0x0 0x41000000  0x0 0x3f000000&gt;;
+
+            #interrupt-cells = &lt;0x1&gt;;
+
+            /* PCI_DEVICE(3)  INT#(1)  CONTROLLER(PHANDLE)  CONTROLLER_DATA(2) */
+            interrupt-map = &lt;   0x0 0x0 0x0  0x1  &amp;aplic_smode  0x4 0x1&gt;,
+                            &lt; 0x800 0x0 0x0  0x1  &amp;aplic_smode  0x5 0x1&gt;,
+                            &lt;0x1000 0x0 0x0  0x1  &amp;aplic_smode  0x6 0x1&gt;,
+                            &lt;0x1800 0x0 0x0  0x1  &amp;aplic_smode  0x7 0x1&gt;;
+
+            /* PCI_DEVICE(3)  INT#(1) */
+            interrupt-map-mask = &lt;0xf800 0x0 0x0  0x7&gt;;
+
+            msi-parent = &lt;&amp;imsics_smode&gt;;
+
+            /* Devices with bus number 0-127 are mastered via immu2 */
+            iommu-map = &lt;0x0000 &amp;immu2 0x0000 0x8000&gt;;
+        };
+    };
+...
</span>-- 
2.34.1


<a href=#mbf8dc4098fb09b87b2618c5c545ae882f11b114b id=ebf8dc4098fb09b87b2618c5c545ae882f11b114b>^</a> <a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/d62ceb33620cab766d809e6bbf30eaf5b46bc955.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#rbf8dc4098fb09b87b2618c5c545ae882f11b114b>86+ messages in thread</a></pre><hr><pre><a href=#ec8ea74f153739ba422b2d84e3077559061512b9f id=mc8ea74f153739ba422b2d84e3077559061512b9f>*</a> <b>[PATCH 04/11] MAINTAINERS: Add myself for RISC-V IOMMU driver</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#rbf8dc4098fb09b87b2618c5c545ae882f11b114b>(2 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#mbf8dc4098fb09b87b2618c5c545ae882f11b114b>[PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-20 12:42   ` <a href=#mbad58991effdd4419c250623cc3d7d3d3edc6000>Baolu Lu</a>
  2023-07-19 19:33 ` <a href=#m64db79f82cb551d51fc635ba160962c425c8cbb2>[PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</a> Tomasz Jeznach
                   ` <a href=#r64db79f82cb551d51fc635ba160962c425c8cbb2>(7 subsequent siblings)</a>
  <a href=#rc8ea74f153739ba422b2d84e3077559061512b9f>11 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193517">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193517">linux-kernel</a>, linux,
	Tomasz Jeznach

Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach::40rivosinc.com:1MAINTAINERS href=#Z2e.:..:e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach::40rivosinc.com:1MAINTAINERS>MAINTAINERS</a> | 7 +++++++
 1 file <a href=#ec8ea74f153739ba422b2d84e3077559061512b9f>changed</a>, 7 insertions(+)

<span class=head><a href=#iZ2e.:..:e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach::40rivosinc.com:1MAINTAINERS id=Z2e.:..:e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach::40rivosinc.com:1MAINTAINERS>diff</a> --git a/MAINTAINERS b/MAINTAINERS
index aee340630eca..d28b1b99f4c6 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
</span><span class=hunk>@@ -18270,6 +18270,13 @@ F:	arch/riscv/
</span> N:	riscv
 K:	riscv
 
<span class=add>+RISC-V IOMMU
+M:	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
+L:	linux-riscv@lists.infradead.org
+S:	Maintained
+F:	Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
+F:	drivers/iommu/riscv/
+
</span> RISC-V MICROCHIP FPGA SUPPORT
 M:	Conor Dooley &lt;conor.dooley@microchip.com&gt;
 M:	Daire McNamara &lt;daire.mcnamara@microchip.com&gt;
-- 
2.34.1


<a href=#mc8ea74f153739ba422b2d84e3077559061512b9f id=ec8ea74f153739ba422b2d84e3077559061512b9f>^</a> <a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/e1578b96b9c75433d8c49b6a173ff47a64675c2b.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#rc8ea74f153739ba422b2d84e3077559061512b9f>86+ messages in thread</a></pre><hr><pre><a href=#e64db79f82cb551d51fc635ba160962c425c8cbb2 id=m64db79f82cb551d51fc635ba160962c425c8cbb2>*</a> <b>[PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#rc8ea74f153739ba422b2d84e3077559061512b9f>(3 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#mc8ea74f153739ba422b2d84e3077559061512b9f>[PATCH 04/11] MAINTAINERS: Add myself for RISC-V IOMMU driver</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-20  6:38   ` <a href=#m4531233107436be4728ad7c9e39b93b11e8c7e48>Krzysztof Kozlowski</a>
  2023-07-20 12:50   ` <a href=#m5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>Baolu Lu</a>
  2023-07-19 19:33 ` <a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</a> Tomasz Jeznach
                   ` <a href=#rf2090d8e2af99230540f3b1dd5c9495dcc6523b1>(6 subsequent siblings)</a>
  <a href=#r64db79f82cb551d51fc635ba160962c425c8cbb2>11 siblings, 2 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193521">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193521">linux-kernel</a>, linux,
	Tomasz Jeznach

Enable sysfs debug / visibility interface providing restricted
access to hardware registers.

Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile href=#Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile>drivers/iommu/riscv/Makefile</a>      |   2 +-
 <a id=iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-sysfs.c href=#Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-sysfs.c>drivers/iommu/riscv/iommu-sysfs.c</a> | 183 ++++++++++++++++++++++++++++++
 <a id=iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a>       |   7 ++
 <a id=iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a>       |   2 +
 4 files <a href=#e64db79f82cb551d51fc635ba160962c425c8cbb2>changed</a>, 193 insertions(+), 1 deletion(-)
 create mode 100644 drivers/iommu/riscv/iommu-sysfs.c

<span class=head><a href=#iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile id=Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile>diff</a> --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
index 38730c11e4a8..9523eb053cfc 100644
--- a/drivers/iommu/riscv/Makefile
+++ b/drivers/iommu/riscv/Makefile
</span><span class=hunk>@@ -1 +1 @@
</span><span class=del>-obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o
</span>\ No newline at end of file
<span class=add>+obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o
</span>\ No newline at end of file
<span class=head><a href=#iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-sysfs.c id=Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-sysfs.c>diff</a> --git a/drivers/iommu/riscv/iommu-sysfs.c b/drivers/iommu/riscv/iommu-sysfs.c
new file mode 100644
index 000000000000..f038ea8445c5
--- /dev/null
+++ b/drivers/iommu/riscv/iommu-sysfs.c
</span><span class=hunk>@@ -0,0 +1,183 @@
</span><span class=add>+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * IOMMU API for RISC-V architected Ziommu implementations.
+ *
+ * Copyright © 2022-2023 Rivos Inc.
+ *
+ * Author: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
+ */
+
+#include &lt;linux/module.h&gt;
+#include &lt;linux/kernel.h&gt;
+#include &lt;linux/compiler.h&gt;
+#include &lt;linux/iommu.h&gt;
+#include &lt;linux/platform_device.h&gt;
+#include &lt;asm/page.h&gt;
+
+#include "iommu.h"
+
+#define sysfs_dev_to_iommu(dev) \
+	container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
+
+static ssize_t address_show(struct device *dev,
+			    struct device_attribute *attr, char *buf)
+{
+	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);
+	return sprintf(buf, "%llx\n", iommu-&gt;reg_phys);
+}
+
+static DEVICE_ATTR_RO(address);
+
+#define ATTR_RD_REG32(name, offset)					\
+	ssize_t reg_ ## name ## _show(struct device *dev,		\
+			struct device_attribute *attr, char *buf)	\
+{									\
+	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
+	return sprintf(buf, "0x%x\n",					\
+			riscv_iommu_readl(iommu, offset));		\
+}
+
+#define ATTR_RD_REG64(name, offset)					\
+	ssize_t reg_ ## name ## _show(struct device *dev,		\
+			struct device_attribute *attr, char *buf)	\
+{									\
+	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
+	return sprintf(buf, "0x%llx\n",					\
+			riscv_iommu_readq(iommu, offset));		\
+}
+
+#define ATTR_WR_REG32(name, offset)					\
+	ssize_t reg_ ## name ## _store(struct device *dev,		\
+			struct device_attribute *attr,			\
+			const char *buf, size_t len)			\
+{									\
+	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
+	unsigned long val;						\
+	int ret;							\
+	ret = kstrtoul(buf, 0, &amp;val);					\
+	if (ret)							\
+		return ret;						\
+	riscv_iommu_writel(iommu, offset, val);				\
+	return len;							\
+}
+
+#define ATTR_WR_REG64(name, offset)					\
+	ssize_t reg_ ## name ## _store(struct device *dev,		\
+			struct device_attribute *attr,			\
+			const char *buf, size_t len)			\
+{									\
+	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
+	unsigned long long val;						\
+	int ret;							\
+	ret = kstrtoull(buf, 0, &amp;val);					\
+	if (ret)							\
+		return ret;						\
+	riscv_iommu_writeq(iommu, offset, val);				\
+	return len;							\
+}
+
+#define ATTR_RO_REG32(name, offset)					\
+static ATTR_RD_REG32(name, offset);					\
+static DEVICE_ATTR_RO(reg_ ## name)
+
+#define ATTR_RW_REG32(name, offset)					\
+static ATTR_RD_REG32(name, offset);					\
+static ATTR_WR_REG32(name, offset);					\
+static DEVICE_ATTR_RW(reg_ ## name)
+
+#define ATTR_RO_REG64(name, offset)					\
+static ATTR_RD_REG64(name, offset);					\
+static DEVICE_ATTR_RO(reg_ ## name)
+
+#define ATTR_RW_REG64(name, offset)					\
+static ATTR_RD_REG64(name, offset);					\
+static ATTR_WR_REG64(name, offset);					\
+static DEVICE_ATTR_RW(reg_ ## name)
+
+ATTR_RO_REG64(cap, RISCV_IOMMU_REG_CAP);
+ATTR_RO_REG64(fctl, RISCV_IOMMU_REG_FCTL);
+ATTR_RO_REG32(cqh, RISCV_IOMMU_REG_CQH);
+ATTR_RO_REG32(cqt, RISCV_IOMMU_REG_CQT);
+ATTR_RO_REG32(cqcsr, RISCV_IOMMU_REG_CQCSR);
+ATTR_RO_REG32(fqh, RISCV_IOMMU_REG_FQH);
+ATTR_RO_REG32(fqt, RISCV_IOMMU_REG_FQT);
+ATTR_RO_REG32(fqcsr, RISCV_IOMMU_REG_FQCSR);
+ATTR_RO_REG32(pqh, RISCV_IOMMU_REG_PQH);
+ATTR_RO_REG32(pqt, RISCV_IOMMU_REG_PQT);
+ATTR_RO_REG32(pqcsr, RISCV_IOMMU_REG_PQCSR);
+ATTR_RO_REG32(ipsr, RISCV_IOMMU_REG_IPSR);
+ATTR_RO_REG32(ivec, RISCV_IOMMU_REG_IVEC);
+ATTR_RW_REG64(tr_iova, RISCV_IOMMU_REG_TR_REQ_IOVA);
+ATTR_RW_REG64(tr_ctrl, RISCV_IOMMU_REG_TR_REQ_CTL);
+ATTR_RW_REG64(tr_response, RISCV_IOMMU_REG_TR_RESPONSE);
+ATTR_RW_REG32(iocntovf, RISCV_IOMMU_REG_IOCOUNTOVF);
+ATTR_RW_REG32(iocntinh, RISCV_IOMMU_REG_IOCOUNTINH);
+ATTR_RW_REG64(iohpmcycles, RISCV_IOMMU_REG_IOHPMCYCLES);
+ATTR_RW_REG64(iohpmevt_1, RISCV_IOMMU_REG_IOHPMEVT(0));
+ATTR_RW_REG64(iohpmevt_2, RISCV_IOMMU_REG_IOHPMEVT(1));
+ATTR_RW_REG64(iohpmevt_3, RISCV_IOMMU_REG_IOHPMEVT(2));
+ATTR_RW_REG64(iohpmevt_4, RISCV_IOMMU_REG_IOHPMEVT(3));
+ATTR_RW_REG64(iohpmevt_5, RISCV_IOMMU_REG_IOHPMEVT(4));
+ATTR_RW_REG64(iohpmevt_6, RISCV_IOMMU_REG_IOHPMEVT(5));
+ATTR_RW_REG64(iohpmevt_7, RISCV_IOMMU_REG_IOHPMEVT(6));
+ATTR_RW_REG64(iohpmctr_1, RISCV_IOMMU_REG_IOHPMCTR(0));
+ATTR_RW_REG64(iohpmctr_2, RISCV_IOMMU_REG_IOHPMCTR(1));
+ATTR_RW_REG64(iohpmctr_3, RISCV_IOMMU_REG_IOHPMCTR(2));
+ATTR_RW_REG64(iohpmctr_4, RISCV_IOMMU_REG_IOHPMCTR(3));
+ATTR_RW_REG64(iohpmctr_5, RISCV_IOMMU_REG_IOHPMCTR(4));
+ATTR_RW_REG64(iohpmctr_6, RISCV_IOMMU_REG_IOHPMCTR(5));
+ATTR_RW_REG64(iohpmctr_7, RISCV_IOMMU_REG_IOHPMCTR(6));
+
+static struct attribute *riscv_iommu_attrs[] = {
+	&amp;dev_attr_address.attr,
+	&amp;dev_attr_reg_cap.attr,
+	&amp;dev_attr_reg_fctl.attr,
+	&amp;dev_attr_reg_cqh.attr,
+	&amp;dev_attr_reg_cqt.attr,
+	&amp;dev_attr_reg_cqcsr.attr,
+	&amp;dev_attr_reg_fqh.attr,
+	&amp;dev_attr_reg_fqt.attr,
+	&amp;dev_attr_reg_fqcsr.attr,
+	&amp;dev_attr_reg_pqh.attr,
+	&amp;dev_attr_reg_pqt.attr,
+	&amp;dev_attr_reg_pqcsr.attr,
+	&amp;dev_attr_reg_ipsr.attr,
+	&amp;dev_attr_reg_ivec.attr,
+	&amp;dev_attr_reg_tr_iova.attr,
+	&amp;dev_attr_reg_tr_ctrl.attr,
+	&amp;dev_attr_reg_tr_response.attr,
+	&amp;dev_attr_reg_iocntovf.attr,
+	&amp;dev_attr_reg_iocntinh.attr,
+	&amp;dev_attr_reg_iohpmcycles.attr,
+	&amp;dev_attr_reg_iohpmctr_1.attr,
+	&amp;dev_attr_reg_iohpmevt_1.attr,
+	&amp;dev_attr_reg_iohpmctr_2.attr,
+	&amp;dev_attr_reg_iohpmevt_2.attr,
+	&amp;dev_attr_reg_iohpmctr_3.attr,
+	&amp;dev_attr_reg_iohpmevt_3.attr,
+	&amp;dev_attr_reg_iohpmctr_4.attr,
+	&amp;dev_attr_reg_iohpmevt_4.attr,
+	&amp;dev_attr_reg_iohpmctr_5.attr,
+	&amp;dev_attr_reg_iohpmevt_5.attr,
+	&amp;dev_attr_reg_iohpmctr_6.attr,
+	&amp;dev_attr_reg_iohpmevt_6.attr,
+	&amp;dev_attr_reg_iohpmctr_7.attr,
+	&amp;dev_attr_reg_iohpmevt_7.attr,
+	NULL,
+};
+
+static struct attribute_group riscv_iommu_group = {
+	.name = "riscv-iommu",
+	.attrs = riscv_iommu_attrs,
+};
+
+const struct attribute_group *riscv_iommu_groups[] = {
+	&amp;riscv_iommu_group,
+	NULL,
+};
+
+int riscv_iommu_sysfs_add(struct riscv_iommu_device *iommu) {
+	return iommu_device_sysfs_add(&amp;iommu-&gt;iommu, NULL,
+		riscv_iommu_groups, "riscv-iommu@%llx", iommu-&gt;reg_phys);
+}
+
</span><span class=head><a href=#iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
index 8c236242e2cc..31dc3c458e13 100644
--- a/drivers/iommu/riscv/iommu.c
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -608,6 +608,7 @@ static const struct iommu_ops riscv_iommu_ops = {
</span> void riscv_iommu_remove(struct riscv_iommu_device *iommu)
 {
 	iommu_device_unregister(&amp;iommu-&gt;iommu);
<span class=add>+	iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
</span> 	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
 }
 
<span class=hunk>@@ -646,6 +647,12 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 		goto fail;
 	}
 
<span class=add>+	ret = riscv_iommu_sysfs_add(iommu);
+	if (ret) {
+		dev_err(dev, "cannot register sysfs interface (%d)\n", ret);
+		goto fail;
+	}
+
</span> 	ret = iommu_device_register(&amp;iommu-&gt;iommu, &amp;riscv_iommu_ops, dev);
 	if (ret) {
 		dev_err(dev, "cannot register iommu interface (%d)\n", ret);
<span class=head><a href=#iZ2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
index 7baefd3630b3..7dc9baa59a50 100644
--- a/drivers/iommu/riscv/iommu.h
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -112,4 +112,6 @@ static inline void riscv_iommu_writeq(struct riscv_iommu_device *iommu,
</span> int riscv_iommu_init(struct riscv_iommu_device *iommu);
 void riscv_iommu_remove(struct riscv_iommu_device *iommu);
 
<span class=add>+int riscv_iommu_sysfs_add(struct riscv_iommu_device *iommu);
+
</span> #endif
-- 
2.34.1


<a href=#m64db79f82cb551d51fc635ba160962c425c8cbb2 id=e64db79f82cb551d51fc635ba160962c425c8cbb2>^</a> <a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/610abe685f90870be52bc7c2ca45ab5235bd8eb4.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#r64db79f82cb551d51fc635ba160962c425c8cbb2>86+ messages in thread</a></pre><hr><pre><a href=#ef2090d8e2af99230540f3b1dd5c9495dcc6523b1 id=mf2090d8e2af99230540f3b1dd5c9495dcc6523b1>*</a> <b>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#r64db79f82cb551d51fc635ba160962c425c8cbb2>(4 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#m64db79f82cb551d51fc635ba160962c425c8cbb2>[PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-20  3:11   ` <a href=#me036e876659d5bad1074323224ed7dc70b2e49db>Nick Kossifidis</a>
                     ` <a href=#re036e876659d5bad1074323224ed7dc70b2e49db>(3 more replies)</a>
  2023-07-19 19:33 ` <a href=#m02ea782700dca52c10fb471a2331de501bffb1a7>[PATCH 07/11] RISC-V: drivers/iommu/riscv: Add device context support</a> Tomasz Jeznach
                   ` <a href=#r02ea782700dca52c10fb471a2331de501bffb1a7>(5 subsequent siblings)</a>
  <a href=#rf2090d8e2af99230540f3b1dd5c9495dcc6523b1>11 siblings, 4 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193528">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193528">linux-kernel</a>, linux,
	Tomasz Jeznach

Enables message or wire signal interrupts for PCIe and platforms devices.

Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c href=#Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c>drivers/iommu/riscv/iommu-pci.c</a>      |  72 ++++
 <a id=iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c href=#Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c>drivers/iommu/riscv/iommu-platform.c</a> |  66 +++
 <a id=iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a>          | 604 ++++++++++++++++++++++++++-
 <a id=iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a>          |  28 ++
 4 files <a href=#ef2090d8e2af99230540f3b1dd5c9495dcc6523b1>changed</a>, 769 insertions(+), 1 deletion(-)

<span class=head><a href=#iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c id=Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-pci.c>diff</a> --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
index c91f963d7a29..9ea0647f7b92 100644
--- a/drivers/iommu/riscv/iommu-pci.c
+++ b/drivers/iommu/riscv/iommu-pci.c
</span><span class=hunk>@@ -34,6 +34,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
</span> {
 	struct device *dev = &amp;pdev-&gt;dev;
 	struct riscv_iommu_device *iommu;
<span class=add>+	u64 icvec;
</span> 	int ret;
 
 	ret = pci_enable_device_mem(pdev);
<span class=hunk>@@ -67,14 +68,84 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
</span> 	iommu-&gt;dev = dev;
 	dev_set_drvdata(dev, iommu);
 
<span class=add>+	/* Check device reported capabilities. */
+	iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
+
+	/* The PCI driver only uses MSIs, make sure the IOMMU supports this */
+	switch (FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap)) {
+	case RISCV_IOMMU_CAP_IGS_MSI:
+	case RISCV_IOMMU_CAP_IGS_BOTH:
+		break;
+	default:
+		dev_err(dev, "unable to use message-signaled interrupts\n");
+		ret = -ENODEV;
+		goto fail;
+	}
+
</span> 	dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
 	pci_set_master(pdev);
 
<span class=add>+	/* Allocate and assign IRQ vectors for the various events */
+	ret = pci_alloc_irq_vectors(pdev, 1, RISCV_IOMMU_INTR_COUNT, PCI_IRQ_MSIX);
+	if (ret &lt; 0) {
+		dev_err(dev, "unable to allocate irq vectors\n");
+		goto fail;
+	}
+
+	ret = -ENODEV;
+
+	iommu-&gt;irq_cmdq = msi_get_virq(dev, RISCV_IOMMU_INTR_CQ);
+	if (!iommu-&gt;irq_cmdq) {
+		dev_warn(dev, "no MSI vector %d for the command queue\n",
+			 RISCV_IOMMU_INTR_CQ);
+		goto fail;
+	}
+
+	iommu-&gt;irq_fltq = msi_get_virq(dev, RISCV_IOMMU_INTR_FQ);
+	if (!iommu-&gt;irq_fltq) {
+		dev_warn(dev, "no MSI vector %d for the fault/event queue\n",
+			 RISCV_IOMMU_INTR_FQ);
+		goto fail;
+	}
+
+	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
+		iommu-&gt;irq_pm = msi_get_virq(dev, RISCV_IOMMU_INTR_PM);
+		if (!iommu-&gt;irq_pm) {
+			dev_warn(dev,
+				 "no MSI vector %d for performance monitoring\n",
+				 RISCV_IOMMU_INTR_PM);
+			goto fail;
+		}
+	}
+
+	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
+		iommu-&gt;irq_priq = msi_get_virq(dev, RISCV_IOMMU_INTR_PQ);
+		if (!iommu-&gt;irq_priq) {
+			dev_warn(dev,
+				 "no MSI vector %d for page-request queue\n",
+				 RISCV_IOMMU_INTR_PQ);
+			goto fail;
+		}
+	}
+
+	/* Set simple 1:1 mapping for MSI vectors */
+	icvec = FIELD_PREP(RISCV_IOMMU_IVEC_CIV, RISCV_IOMMU_INTR_CQ) |
+	    FIELD_PREP(RISCV_IOMMU_IVEC_FIV, RISCV_IOMMU_INTR_FQ);
+
+	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM)
+		icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PMIV, RISCV_IOMMU_INTR_PM);
+
+	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS)
+		icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PIV, RISCV_IOMMU_INTR_PQ);
+
+	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IVEC, icvec);
+
</span> 	ret = riscv_iommu_init(iommu);
 	if (!ret)
 		return ret;
 
  fail:
<span class=add>+	pci_free_irq_vectors(pdev);
</span> 	pci_clear_master(pdev);
 	pci_release_regions(pdev);
 	pci_disable_device(pdev);
<span class=hunk>@@ -85,6 +156,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
</span> static void riscv_iommu_pci_remove(struct pci_dev *pdev)
 {
 	riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
<span class=add>+	pci_free_irq_vectors(pdev);
</span> 	pci_clear_master(pdev);
 	pci_release_regions(pdev);
 	pci_disable_device(pdev);
<span class=head><a href=#iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c id=Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu-platform.c>diff</a> --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
index e4e8ca6711e7..35935d3c7ef4 100644
--- a/drivers/iommu/riscv/iommu-platform.c
+++ b/drivers/iommu/riscv/iommu-platform.c
</span><span class=hunk>@@ -20,6 +20,8 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
</span> 	struct device *dev = &amp;pdev-&gt;dev;
 	struct riscv_iommu_device *iommu = NULL;
 	struct resource *res = NULL;
<span class=add>+	u32 fctl = 0;
+	int irq = 0;
</span> 	int ret = 0;
 
 	iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
<span class=hunk>@@ -53,6 +55,70 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
</span> 		goto fail;
 	}
 
<span class=add>+	iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
+
+	/* For now we only support WSIs until we have AIA support */
+	ret = FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap);
+	if (ret == RISCV_IOMMU_CAP_IGS_MSI) {
+		dev_err(dev, "IOMMU only supports MSIs\n");
+		goto fail;
+	}
+
+	/* Parse IRQ assignment */
+	irq = platform_get_irq_byname_optional(pdev, "cmdq");
+	if (irq &gt; 0)
+		iommu-&gt;irq_cmdq = irq;
+	else {
+		dev_err(dev, "no IRQ provided for the command queue\n");
+		goto fail;
+	}
+
+	irq = platform_get_irq_byname_optional(pdev, "fltq");
+	if (irq &gt; 0)
+		iommu-&gt;irq_fltq = irq;
+	else {
+		dev_err(dev, "no IRQ provided for the fault/event queue\n");
+		goto fail;
+	}
+
+	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
+		irq = platform_get_irq_byname_optional(pdev, "pm");
+		if (irq &gt; 0)
+			iommu-&gt;irq_pm = irq;
+		else {
+			dev_err(dev, "no IRQ provided for performance monitoring\n");
+			goto fail;
+		}
+	}
+
+	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
+		irq = platform_get_irq_byname_optional(pdev, "priq");
+		if (irq &gt; 0)
+			iommu-&gt;irq_priq = irq;
+		else {
+			dev_err(dev, "no IRQ provided for the page-request queue\n");
+			goto fail;
+		}
+	}
+
+	/* Make sure fctl.WSI is set */
+	fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
+	fctl |= RISCV_IOMMU_FCTL_WSI;
+	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
+
+	/* Parse Queue lengts */
+	ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
+	if (!ret)
+		dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
+
+	ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
+	if (!ret)
+		dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
+
+	ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
+	if (!ret)
+		dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
+
</span> 	dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
 
 	return riscv_iommu_init(iommu);
<span class=head><a href=#iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
index 31dc3c458e13..5c4cf9875302 100644
--- a/drivers/iommu/riscv/iommu.c
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -45,6 +45,18 @@ static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
</span> module_param(ddt_mode, int, 0644);
 MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
 
<span class=add>+static int cmdq_length = 1024;
+module_param(cmdq_length, int, 0644);
+MODULE_PARM_DESC(cmdq_length, "Command queue length.");
+
+static int fltq_length = 1024;
+module_param(fltq_length, int, 0644);
+MODULE_PARM_DESC(fltq_length, "Fault queue length.");
+
+static int priq_length = 1024;
+module_param(priq_length, int, 0644);
+MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
+
</span> /* IOMMU PSCID allocation namespace. */
 #define RISCV_IOMMU_MAX_PSCID	(1U &lt;&lt; 20)
 static DEFINE_IDA(riscv_iommu_pscids);
<span class=hunk>@@ -65,6 +77,497 @@ static DEFINE_IDA(riscv_iommu_pscids);
</span> static const struct iommu_domain_ops riscv_iommu_domain_ops;
 static const struct iommu_ops riscv_iommu_ops;
 
<span class=add>+/*
+ * Common queue management routines
+ */
+
+/* Note: offsets are the same for all queues */
+#define Q_HEAD(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQH - RISCV_IOMMU_REG_CQB))
+#define Q_TAIL(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQT - RISCV_IOMMU_REG_CQB))
+
+static unsigned riscv_iommu_queue_consume(struct riscv_iommu_device *iommu,
+					  struct riscv_iommu_queue *q, unsigned *ready)
+{
+	u32 tail = riscv_iommu_readl(iommu, Q_TAIL(q));
+	*ready = q-&gt;lui;
+
+	BUG_ON(q-&gt;cnt &lt;= tail);
+	if (q-&gt;lui &lt;= tail)
+		return tail - q-&gt;lui;
+	return q-&gt;cnt - q-&gt;lui;
+}
+
+static void riscv_iommu_queue_release(struct riscv_iommu_device *iommu,
+				      struct riscv_iommu_queue *q, unsigned count)
+{
+	q-&gt;lui = (q-&gt;lui + count) &amp; (q-&gt;cnt - 1);
+	riscv_iommu_writel(iommu, Q_HEAD(q), q-&gt;lui);
+}
+
+static u32 riscv_iommu_queue_ctrl(struct riscv_iommu_device *iommu,
+				  struct riscv_iommu_queue *q, u32 val)
+{
+	cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
+
+	riscv_iommu_writel(iommu, q-&gt;qcr, val);
+	do {
+		val = riscv_iommu_readl(iommu, q-&gt;qcr);
+		if (!(val &amp; RISCV_IOMMU_QUEUE_BUSY))
+			break;
+		cpu_relax();
+	} while (get_cycles() &lt; end_cycles);
+
+	return val;
+}
+
+static void riscv_iommu_queue_free(struct riscv_iommu_device *iommu,
+				   struct riscv_iommu_queue *q)
+{
+	size_t size = q-&gt;len * q-&gt;cnt;
+
+	riscv_iommu_queue_ctrl(iommu, q, 0);
+
+	if (q-&gt;base) {
+		if (q-&gt;in_iomem)
+			iounmap(q-&gt;base);
+		else
+			dmam_free_coherent(iommu-&gt;dev, size, q-&gt;base, q-&gt;base_dma);
+	}
+	if (q-&gt;irq)
+		free_irq(q-&gt;irq, q);
+}
+
+static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data);
+static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data);
+static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data);
+static irqreturn_t riscv_iommu_fltq_process(int irq, void *data);
+static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
+static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
+
+static int riscv_iommu_queue_init(struct riscv_iommu_device *iommu, int queue_id)
+{
+	struct device *dev = iommu-&gt;dev;
+	struct riscv_iommu_queue *q = NULL;
+	size_t queue_size = 0;
+	irq_handler_t irq_check;
+	irq_handler_t irq_process;
+	const char *name;
+	int count = 0;
+	int irq = 0;
+	unsigned order = 0;
+	u64 qbr_val = 0;
+	u64 qbr_readback = 0;
+	u64 qbr_paddr = 0;
+	int ret = 0;
+
+	switch (queue_id) {
+	case RISCV_IOMMU_COMMAND_QUEUE:
+		q = &amp;iommu-&gt;cmdq;
+		q-&gt;len = sizeof(struct riscv_iommu_command);
+		count = iommu-&gt;cmdq_len;
+		irq = iommu-&gt;irq_cmdq;
+		irq_check = riscv_iommu_cmdq_irq_check;
+		irq_process = riscv_iommu_cmdq_process;
+		q-&gt;qbr = RISCV_IOMMU_REG_CQB;
+		q-&gt;qcr = RISCV_IOMMU_REG_CQCSR;
+		name = "cmdq";
+		break;
+	case RISCV_IOMMU_FAULT_QUEUE:
+		q = &amp;iommu-&gt;fltq;
+		q-&gt;len = sizeof(struct riscv_iommu_fq_record);
+		count = iommu-&gt;fltq_len;
+		irq = iommu-&gt;irq_fltq;
+		irq_check = riscv_iommu_fltq_irq_check;
+		irq_process = riscv_iommu_fltq_process;
+		q-&gt;qbr = RISCV_IOMMU_REG_FQB;
+		q-&gt;qcr = RISCV_IOMMU_REG_FQCSR;
+		name = "fltq";
+		break;
+	case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
+		q = &amp;iommu-&gt;priq;
+		q-&gt;len = sizeof(struct riscv_iommu_pq_record);
+		count = iommu-&gt;priq_len;
+		irq = iommu-&gt;irq_priq;
+		irq_check = riscv_iommu_priq_irq_check;
+		irq_process = riscv_iommu_priq_process;
+		q-&gt;qbr = RISCV_IOMMU_REG_PQB;
+		q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
+		name = "priq";
+		break;
+	default:
+		dev_err(dev, "invalid queue interrupt index in queue_init!\n");
+		return -EINVAL;
+	}
+
+	/* Polling not implemented */
+	if (!irq)
+		return -ENODEV;
+
+	/* Allocate queue in memory and set the base register */
+	order = ilog2(count);
+	do {
+		queue_size = q-&gt;len * (1ULL &lt;&lt; order);
+		q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
+		if (q-&gt;base || queue_size &lt; PAGE_SIZE)
+			break;
+
+		order--;
+	} while (1);
+
+	if (!q-&gt;base) {
+		dev_err(dev, "failed to allocate %s queue (cnt: %u)\n", name, count);
+		return -ENOMEM;
+	}
+
+	q-&gt;cnt = 1ULL &lt;&lt; order;
+
+	qbr_val = phys_to_ppn(q-&gt;base_dma) |
+	    FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
+
+	riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
+
+	/*
+	 * Queue base registers are WARL, so it's possible that whatever we wrote
+	 * there was illegal/not supported by the hw in which case we need to make
+	 * sure we set a supported PPN and/or queue size.
+	 */
+	qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
+	if (qbr_readback == qbr_val)
+		goto irq;
+
+	dmam_free_coherent(dev, queue_size, q-&gt;base, q-&gt;base_dma);
+
+	/* Get supported queue size */
+	order = FIELD_GET(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, qbr_readback) + 1;
+	q-&gt;cnt = 1ULL &lt;&lt; order;
+	queue_size = q-&gt;len * q-&gt;cnt;
+
+	/*
+	 * In case we also failed to set PPN, it means the field is hardcoded and the
+	 * queue resides in I/O memory instead, so get its physical address and
+	 * ioremap it.
+	 */
+	qbr_paddr = ppn_to_phys(qbr_readback);
+	if (qbr_paddr != q-&gt;base_dma) {
+		dev_info(dev,
+			 "hardcoded ppn in %s base register, using io memory for the queue\n",
+			 name);
+		dev_info(dev, "queue length for %s set to %i\n", name, q-&gt;cnt);
+		q-&gt;in_iomem = true;
+		q-&gt;base = ioremap(qbr_paddr, queue_size);
+		if (!q-&gt;base) {
+			dev_err(dev, "failed to map %s queue (cnt: %u)\n", name, q-&gt;cnt);
+			return -ENOMEM;
+		}
+		q-&gt;base_dma = qbr_paddr;
+	} else {
+		/*
+		 * We only failed to set the queue size, re-try to allocate memory with
+		 * the queue size supported by the hw.
+		 */
+		dev_info(dev, "hardcoded queue size in %s base register\n", name);
+		dev_info(dev, "retrying with queue length: %i\n", q-&gt;cnt);
+		q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
+		if (!q-&gt;base) {
+			dev_err(dev, "failed to allocate %s queue (cnt: %u)\n",
+				name, q-&gt;cnt);
+			return -ENOMEM;
+		}
+	}
+
+	qbr_val = phys_to_ppn(q-&gt;base_dma) |
+	    FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
+	riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
+
+	/* Final check to make sure hw accepted our write */
+	qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
+	if (qbr_readback != qbr_val) {
+		dev_err(dev, "failed to set base register for %s\n", name);
+		goto fail;
+	}
+
+ irq:
+	if (request_threaded_irq(irq, irq_check, irq_process, IRQF_ONESHOT | IRQF_SHARED,
+				 dev_name(dev), q)) {
+		dev_err(dev, "fail to request irq %d for %s\n", irq, name);
+		goto fail;
+	}
+
+	q-&gt;irq = irq;
+
+	/* Note: All RIO_xQ_EN/IE fields are in the same offsets */
+	ret =
+	    riscv_iommu_queue_ctrl(iommu, q,
+				   RISCV_IOMMU_QUEUE_ENABLE |
+				   RISCV_IOMMU_QUEUE_INTR_ENABLE);
+	if (ret &amp; RISCV_IOMMU_QUEUE_BUSY) {
+		dev_err(dev, "%s init timeout\n", name);
+		ret = -EBUSY;
+		goto fail;
+	}
+
+	return 0;
+
+ fail:
+	riscv_iommu_queue_free(iommu, q);
+	return 0;
+}
+
+/*
+ * I/O MMU Command queue chapter 3.1
+ */
+
+static inline void riscv_iommu_cmd_inval_vma(struct riscv_iommu_command *cmd)
+{
+	cmd-&gt;dword0 =
+	    FIELD_PREP(RISCV_IOMMU_CMD_OPCODE,
+		       RISCV_IOMMU_CMD_IOTINVAL_OPCODE) | FIELD_PREP(RISCV_IOMMU_CMD_FUNC,
+								     RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA);
+	cmd-&gt;dword1 = 0;
+}
+
+static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
+						  u64 addr)
+{
+	cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
+	cmd-&gt;dword1 = addr;
+}
+
+static inline void riscv_iommu_cmd_inval_set_pscid(struct riscv_iommu_command *cmd,
+						   unsigned pscid)
+{
+	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_PSCID, pscid) |
+	    RISCV_IOMMU_CMD_IOTINVAL_PSCV;
+}
+
+static inline void riscv_iommu_cmd_inval_set_gscid(struct riscv_iommu_command *cmd,
+						   unsigned gscid)
+{
+	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_GSCID, gscid) |
+	    RISCV_IOMMU_CMD_IOTINVAL_GV;
+}
+
+static inline void riscv_iommu_cmd_iofence(struct riscv_iommu_command *cmd)
+{
+	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C);
+	cmd-&gt;dword1 = 0;
+}
+
+static inline void riscv_iommu_cmd_iofence_set_av(struct riscv_iommu_command *cmd,
+						  u64 addr, u32 data)
+{
+	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_IOFENCE_DATA, data) | RISCV_IOMMU_CMD_IOFENCE_AV;
+	cmd-&gt;dword1 = (addr &gt;&gt; 2);
+}
+
+static inline void riscv_iommu_cmd_iodir_inval_ddt(struct riscv_iommu_command *cmd)
+{
+	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT);
+	cmd-&gt;dword1 = 0;
+}
+
+static inline void riscv_iommu_cmd_iodir_inval_pdt(struct riscv_iommu_command *cmd)
+{
+	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT);
+	cmd-&gt;dword1 = 0;
+}
+
+static inline void riscv_iommu_cmd_iodir_set_did(struct riscv_iommu_command *cmd,
+						 unsigned devid)
+{
+	cmd-&gt;dword0 |=
+	    FIELD_PREP(RISCV_IOMMU_CMD_IODIR_DID, devid) | RISCV_IOMMU_CMD_IODIR_DV;
+}
+
+/* TODO: Convert into lock-less MPSC implementation. */
+static bool riscv_iommu_post_sync(struct riscv_iommu_device *iommu,
+				  struct riscv_iommu_command *cmd, bool sync)
+{
+	u32 head, tail, next, last;
+	unsigned long flags;
+
+	spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
+	head = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp; (iommu-&gt;cmdq.cnt - 1);
+	tail = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
+	last = iommu-&gt;cmdq.lui;
+	if (tail != last) {
+		spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
+		/*
+		 * FIXME: This is a workaround for dropped MMIO writes/reads on QEMU platform.
+		 *        While debugging of the problem is still ongoing, this provides
+		 *        a simple impolementation of try-again policy.
+		 *        Will be changed to lock-less algorithm in the feature.
+		 */
+		dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (1st)\n", last, tail);
+		spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
+		tail =
+		    riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
+		last = iommu-&gt;cmdq.lui;
+		if (tail != last) {
+			spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
+			dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (2nd)\n", last, tail);
+			spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
+		}
+	}
+
+	next = (last + 1) &amp; (iommu-&gt;cmdq.cnt - 1);
+	if (next != head) {
+		struct riscv_iommu_command *ptr = iommu-&gt;cmdq.base;
+		ptr[last] = *cmd;
+		wmb();
+		riscv_iommu_writel(iommu, RISCV_IOMMU_REG_CQT, next);
+		iommu-&gt;cmdq.lui = next;
+	}
+
+	spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
+
+	if (sync &amp;&amp; head != next) {
+		cycles_t start_time = get_cycles();
+		while (1) {
+			last = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp;
+			    (iommu-&gt;cmdq.cnt - 1);
+			if (head &lt; next &amp;&amp; last &gt;= next)
+				break;
+			if (head &gt; next &amp;&amp; last &lt; head &amp;&amp; last &gt;= next)
+				break;
+			if (RISCV_IOMMU_TIMEOUT &lt; (get_cycles() - start_time)) {
+				dev_err(iommu-&gt;dev, "IOFENCE TIMEOUT\n");
+				return false;
+			}
+			cpu_relax();
+		}
+	}
+
+	return next != head;
+}
+
+static bool riscv_iommu_post(struct riscv_iommu_device *iommu,
+			     struct riscv_iommu_command *cmd)
+{
+	return riscv_iommu_post_sync(iommu, cmd, false);
+}
+
+static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
+{
+	struct riscv_iommu_command cmd;
+	riscv_iommu_cmd_iofence(&amp;cmd);
+	return riscv_iommu_post_sync(iommu, &amp;cmd, true);
+}
+
+/* Command queue primary interrupt handler */
+static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data)
+{
+	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
+	struct riscv_iommu_device *iommu =
+	    container_of(q, struct riscv_iommu_device, cmdq);
+	u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
+	if (ipsr &amp; RISCV_IOMMU_IPSR_CIP)
+		return IRQ_WAKE_THREAD;
+	return IRQ_NONE;
+}
+
+/* Command queue interrupt hanlder thread function */
+static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data)
+{
+	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
+	struct riscv_iommu_device *iommu;
+	unsigned ctrl;
+
+	iommu = container_of(q, struct riscv_iommu_device, cmdq);
+
+	/* Error reporting, clear error reports if any. */
+	ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQCSR);
+	if (ctrl &amp; (RISCV_IOMMU_CQCSR_CQMF |
+		    RISCV_IOMMU_CQCSR_CMD_TO | RISCV_IOMMU_CQCSR_CMD_ILL)) {
+		riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;cmdq, ctrl);
+		dev_warn_ratelimited(iommu-&gt;dev,
+				     "Command queue error: fault: %d tout: %d err: %d\n",
+				     !!(ctrl &amp; RISCV_IOMMU_CQCSR_CQMF),
+				     !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_TO),
+				     !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_ILL));
+	}
+
+	/* Clear fault interrupt pending. */
+	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_CIP);
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * Fault/event queue, chapter 3.2
+ */
+
+static void riscv_iommu_fault_report(struct riscv_iommu_device *iommu,
+				     struct riscv_iommu_fq_record *event)
+{
+	unsigned err, devid;
+
+	err = FIELD_GET(RISCV_IOMMU_FQ_HDR_CAUSE, event-&gt;hdr);
+	devid = FIELD_GET(RISCV_IOMMU_FQ_HDR_DID, event-&gt;hdr);
+
+	dev_warn_ratelimited(iommu-&gt;dev,
+			     "Fault %d devid: %d" " iotval: %llx iotval2: %llx\n", err,
+			     devid, event-&gt;iotval, event-&gt;iotval2);
+}
+
+/* Fault/event queue primary interrupt handler */
+static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data)
+{
+	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
+	struct riscv_iommu_device *iommu =
+	    container_of(q, struct riscv_iommu_device, fltq);
+	u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
+	if (ipsr &amp; RISCV_IOMMU_IPSR_FIP)
+		return IRQ_WAKE_THREAD;
+	return IRQ_NONE;
+}
+
+/* Fault queue interrupt hanlder thread function */
+static irqreturn_t riscv_iommu_fltq_process(int irq, void *data)
+{
+	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
+	struct riscv_iommu_device *iommu;
+	struct riscv_iommu_fq_record *events;
+	unsigned cnt, len, idx, ctrl;
+
+	iommu = container_of(q, struct riscv_iommu_device, fltq);
+	events = (struct riscv_iommu_fq_record *)q-&gt;base;
+
+	/* Error reporting, clear error reports if any. */
+	ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FQCSR);
+	if (ctrl &amp; (RISCV_IOMMU_FQCSR_FQMF | RISCV_IOMMU_FQCSR_FQOF)) {
+		riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;fltq, ctrl);
+		dev_warn_ratelimited(iommu-&gt;dev,
+				     "Fault queue error: fault: %d full: %d\n",
+				     !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQMF),
+				     !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQOF));
+	}
+
+	/* Clear fault interrupt pending. */
+	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_FIP);
+
+	/* Report fault events. */
+	do {
+		cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
+		if (!cnt)
+			break;
+		for (len = 0; len &lt; cnt; idx++, len++)
+			riscv_iommu_fault_report(iommu, &amp;events[idx]);
+		riscv_iommu_queue_release(iommu, q, cnt);
+	} while (1);
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * Page request queue, chapter 3.3
+ */
+
</span> /*
  * Register device for IOMMU tracking.
  */
<span class=hunk>@@ -97,6 +600,54 @@ static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct devi
</span> 	mutex_unlock(&amp;iommu-&gt;eps_mutex);
 }
 
<span class=add>+/* Page request interface queue primary interrupt handler */
+static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data)
+{
+	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
+	struct riscv_iommu_device *iommu =
+	    container_of(q, struct riscv_iommu_device, priq);
+	u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
+	if (ipsr &amp; RISCV_IOMMU_IPSR_PIP)
+		return IRQ_WAKE_THREAD;
+	return IRQ_NONE;
+}
+
+/* Page request interface queue interrupt hanlder thread function */
+static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
+{
+	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
+	struct riscv_iommu_device *iommu;
+	struct riscv_iommu_pq_record *requests;
+	unsigned cnt, idx, ctrl;
+
+	iommu = container_of(q, struct riscv_iommu_device, priq);
+	requests = (struct riscv_iommu_pq_record *)q-&gt;base;
+
+	/* Error reporting, clear error reports if any. */
+	ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_PQCSR);
+	if (ctrl &amp; (RISCV_IOMMU_PQCSR_PQMF | RISCV_IOMMU_PQCSR_PQOF)) {
+		riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;priq, ctrl);
+		dev_warn_ratelimited(iommu-&gt;dev,
+				     "Page request queue error: fault: %d full: %d\n",
+				     !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQMF),
+				     !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQOF));
+	}
+
+	/* Clear page request interrupt pending. */
+	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_PIP);
+
+	/* Process page requests. */
+	do {
+		cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
+		if (!cnt)
+			break;
+		dev_warn(iommu-&gt;dev, "unexpected %u page requests\n", cnt);
+		riscv_iommu_queue_release(iommu, q, cnt);
+	} while (1);
+
+	return IRQ_HANDLED;
+}
+
</span> /*
  * Endpoint management
  */
<span class=hunk>@@ -350,7 +901,29 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
</span> 					  unsigned long *start, unsigned long *end,
 					  size_t *pgsize)
 {
<span class=del>-	/* Command interface not implemented */
</span><span class=add>+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+	struct riscv_iommu_command cmd;
+	unsigned long iova;
+
+	if (domain-&gt;mode == RISCV_IOMMU_DC_FSC_MODE_BARE)
+		return;
+
+	/* Domain not attached to an IOMMU! */
+	BUG_ON(!domain-&gt;iommu);
+
+	riscv_iommu_cmd_inval_vma(&amp;cmd);
+	riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
+
+	if (start &amp;&amp; end &amp;&amp; pgsize) {
+		/* Cover only the range that is needed */
+		for (iova = *start; iova &lt;= *end; iova += *pgsize) {
+			riscv_iommu_cmd_inval_set_addr(&amp;cmd, iova);
+			riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
+		}
+	} else {
+		riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
+	}
+	riscv_iommu_iofence_sync(domain-&gt;iommu);
</span> }
 
 static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
<span class=hunk>@@ -610,6 +1183,9 @@ void riscv_iommu_remove(struct riscv_iommu_device *iommu)
</span> 	iommu_device_unregister(&amp;iommu-&gt;iommu);
 	iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
 	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
<span class=add>+	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
+	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
+	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
</span> }
 
 int riscv_iommu_init(struct riscv_iommu_device *iommu)
<span class=hunk>@@ -632,6 +1208,16 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 	}
 #endif
 
<span class=add>+	/*
+	 * Assign queue lengths from module parameters if not already
+	 * set on the device tree.
+	 */
+	if (!iommu-&gt;cmdq_len)
+		iommu-&gt;cmdq_len = cmdq_length;
+	if (!iommu-&gt;fltq_len)
+		iommu-&gt;fltq_len = fltq_length;
+	if (!iommu-&gt;priq_len)
+		iommu-&gt;priq_len = priq_length;
</span> 	/* Clear any pending interrupt flag. */
 	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
 			   RISCV_IOMMU_IPSR_CIP |
<span class=hunk>@@ -639,7 +1225,20 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 			   RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
 	spin_lock_init(&amp;iommu-&gt;cq_lock);
 	mutex_init(&amp;iommu-&gt;eps_mutex);
<span class=add>+	ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_COMMAND_QUEUE);
+	if (ret)
+		goto fail;
+	ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_FAULT_QUEUE);
+	if (ret)
+		goto fail;
+	if (!(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS))
+		goto no_ats;
+
+	ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_PAGE_REQUEST_QUEUE);
+	if (ret)
+		goto fail;
</span> 
<span class=add>+ no_ats:
</span> 	ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
 
 	if (ret) {
<span class=hunk>@@ -663,5 +1262,8 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 	return 0;
  fail:
 	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
<span class=add>+	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
+	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
+	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
</span> 	return ret;
 }
<span class=head><a href=#iZ2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
index 7dc9baa59a50..04148a2a8ffd 100644
--- a/drivers/iommu/riscv/iommu.h
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -28,6 +28,24 @@
</span> #define IOMMU_PAGE_SIZE_1G	BIT_ULL(30)
 #define IOMMU_PAGE_SIZE_512G	BIT_ULL(39)
 
<span class=add>+struct riscv_iommu_queue {
+	dma_addr_t base_dma;	/* ring buffer bus address */
+	void *base;		/* ring buffer pointer */
+	size_t len;		/* single item length */
+	u32 cnt;		/* items count */
+	u32 lui;		/* last used index, consumer/producer share */
+	unsigned qbr;		/* queue base register offset */
+	unsigned qcr;		/* queue control and status register offset */
+	int irq;		/* registered interrupt number */
+	bool in_iomem;		/* indicates queue data are in I/O memory  */
+};
+
+enum riscv_queue_ids {
+	RISCV_IOMMU_COMMAND_QUEUE	= 0,
+	RISCV_IOMMU_FAULT_QUEUE		= 1,
+	RISCV_IOMMU_PAGE_REQUEST_QUEUE	= 2
+};
+
</span> struct riscv_iommu_device {
 	struct iommu_device iommu;	/* iommu core interface */
 	struct device *dev;		/* iommu hardware */
<span class=hunk>@@ -42,6 +60,11 @@ struct riscv_iommu_device {
</span> 	int irq_pm;
 	int irq_priq;
 
<span class=add>+	/* Queue lengths */
+	int cmdq_len;
+	int fltq_len;
+	int priq_len;
+
</span> 	/* supported and enabled hardware capabilities */
 	u64 cap;
 
<span class=hunk>@@ -53,6 +76,11 @@ struct riscv_iommu_device {
</span> 	unsigned ddt_mode;
 	bool ddtp_in_iomem;
 
<span class=add>+	/* hardware queues */
+	struct riscv_iommu_queue cmdq;
+	struct riscv_iommu_queue fltq;
+	struct riscv_iommu_queue priq;
+
</span> 	/* Connected end-points */
 	struct rb_root eps;
 	struct mutex eps_mutex;
-- 
2.34.1


<a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1 id=ef2090d8e2af99230540f3b1dd5c9495dcc6523b1>^</a> <a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/1fd79e5c53d9d6ed2264f60dd4261f293cc00472.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#rf2090d8e2af99230540f3b1dd5c9495dcc6523b1>86+ messages in thread</a></pre><hr><pre><a href=#e02ea782700dca52c10fb471a2331de501bffb1a7 id=m02ea782700dca52c10fb471a2331de501bffb1a7>*</a> <b>[PATCH 07/11] RISC-V: drivers/iommu/riscv: Add device context support</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#rf2090d8e2af99230540f3b1dd5c9495dcc6523b1>(5 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-08-16 19:08   ` <a href=#m794b93ecd24e4c126303d54185259a3506944063>Robin Murphy</a>
  2023-07-19 19:33 ` <a href=#m50b13653960cd6e88a7efb588257ac568bffb87b>[PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</a> Tomasz Jeznach
                   ` <a href=#r50b13653960cd6e88a7efb588257ac568bffb87b>(4 subsequent siblings)</a>
  <a href=#r02ea782700dca52c10fb471a2331de501bffb1a7>11 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193524">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193524">linux-kernel</a>, linux,
	Tomasz Jeznach

Introduces per device translation context, with 1,2 or 3 tree level
device tree structures.

Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a> | 163 ++++++++++++++++++++++++++++++++++--
 <a id=iZ2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a> |   1 +
 2 files <a href=#e02ea782700dca52c10fb471a2331de501bffb1a7>changed</a>, 158 insertions(+), 6 deletions(-)

<span class=head><a href=#iZ2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
index 5c4cf9875302..9ee7d2b222b5 100644
--- a/drivers/iommu/riscv/iommu.c
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -41,7 +41,7 @@ MODULE_ALIAS("riscv-iommu");
</span> MODULE_LICENSE("GPL v2");
 
 /* Global IOMMU params. */
<span class=del>-static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
</span><span class=add>+static int ddt_mode = RISCV_IOMMU_DDTP_MODE_3LVL;
</span> module_param(ddt_mode, int, 0644);
 MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
 
<span class=hunk>@@ -452,6 +452,14 @@ static bool riscv_iommu_post(struct riscv_iommu_device *iommu,
</span> 	return riscv_iommu_post_sync(iommu, cmd, false);
 }
 
<span class=add>+static bool riscv_iommu_iodir_inv_devid(struct riscv_iommu_device *iommu, unsigned devid)
+{
+	struct riscv_iommu_command cmd;
+	riscv_iommu_cmd_iodir_inval_ddt(&amp;cmd);
+	riscv_iommu_cmd_iodir_set_did(&amp;cmd, devid);
+	return riscv_iommu_post(iommu, &amp;cmd);
+}
+
</span> static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
 {
 	struct riscv_iommu_command cmd;
<span class=hunk>@@ -671,6 +679,94 @@ static bool riscv_iommu_capable(struct device *dev, enum iommu_cap cap)
</span> 	return false;
 }
 
<span class=add>+/* TODO: implement proper device context management, e.g. teardown flow */
+
+/* Lookup or initialize device directory info structure. */
+static struct riscv_iommu_dc *riscv_iommu_get_dc(struct riscv_iommu_device *iommu,
+						 unsigned devid)
+{
+	const bool base_format = !(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_MSI_FLAT);
+	unsigned depth = iommu-&gt;ddt_mode - RISCV_IOMMU_DDTP_MODE_1LVL;
+	u8 ddi_bits[3] = { 0 };
+	u64 *ddtp = NULL, ddt;
+
+	if (iommu-&gt;ddt_mode == RISCV_IOMMU_DDTP_MODE_OFF ||
+	    iommu-&gt;ddt_mode == RISCV_IOMMU_DDTP_MODE_BARE)
+		return NULL;
+
+	/* Make sure the mode is valid */
+	if (iommu-&gt;ddt_mode &gt; RISCV_IOMMU_DDTP_MODE_MAX)
+		return NULL;
+
+	/*
+	 * Device id partitioning for base format:
+	 * DDI[0]: bits 0 - 6   (1st level) (7 bits)
+	 * DDI[1]: bits 7 - 15  (2nd level) (9 bits)
+	 * DDI[2]: bits 16 - 23 (3rd level) (8 bits)
+	 *
+	 * For extended format:
+	 * DDI[0]: bits 0 - 5   (1st level) (6 bits)
+	 * DDI[1]: bits 6 - 14  (2nd level) (9 bits)
+	 * DDI[2]: bits 15 - 23 (3rd level) (9 bits)
+	 */
+	if (base_format) {
+		ddi_bits[0] = 7;
+		ddi_bits[1] = 7 + 9;
+		ddi_bits[2] = 7 + 9 + 8;
+	} else {
+		ddi_bits[0] = 6;
+		ddi_bits[1] = 6 + 9;
+		ddi_bits[2] = 6 + 9 + 9;
+	}
+
+	/* Make sure device id is within range */
+	if (devid &gt;= (1 &lt;&lt; ddi_bits[depth]))
+		return NULL;
+
+	/* Get to the level of the non-leaf node that holds the device context */
+	for (ddtp = (u64 *) iommu-&gt;ddtp; depth-- &gt; 0;) {
+		const int split = ddi_bits[depth];
+		/*
+		 * Each non-leaf node is 64bits wide and on each level
+		 * nodes are indexed by DDI[depth].
+		 */
+		ddtp += (devid &gt;&gt; split) &amp; 0x1FF;
+
+ retry:
+		/*
+		 * Check if this node has been populated and if not
+		 * allocate a new level and populate it.
+		 */
+		ddt = READ_ONCE(*ddtp);
+		if (ddt &amp; RISCV_IOMMU_DDTE_VALID) {
+			ddtp = __va(ppn_to_phys(ddt));
+		} else {
+			u64 old, new = get_zeroed_page(GFP_KERNEL);
+			if (!new)
+				return NULL;
+
+			old = cmpxchg64_relaxed(ddtp, ddt,
+						phys_to_ppn(__pa(new)) |
+						RISCV_IOMMU_DDTE_VALID);
+
+			if (old != ddt) {
+				free_page(new);
+				goto retry;
+			}
+
+			ddtp = (u64 *) new;
+		}
+	}
+
+	/*
+	 * Grab the node that matches DDI[depth], note that when using base
+	 * format the device context is 4 * 64bits, and the extended format
+	 * is 8 * 64bits, hence the (3 - base_format) below.
+	 */
+	ddtp += (devid &amp; ((64 &lt;&lt; base_format) - 1)) &lt;&lt; (3 - base_format);
+	return (struct riscv_iommu_dc *)ddtp;
+}
+
</span> static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
 {
 	struct riscv_iommu_device *iommu;
<span class=hunk>@@ -708,6 +804,9 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
</span> 	ep-&gt;iommu = iommu;
 	ep-&gt;dev = dev;
 
<span class=add>+	/* Initial DC pointer can be NULL if IOMMU is configured in OFF or BARE mode */
+	ep-&gt;dc = riscv_iommu_get_dc(iommu, ep-&gt;devid);
+
</span> 	dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
 		ep-&gt;devid, ep-&gt;domid);
 
<span class=hunk>@@ -734,6 +833,16 @@ static void riscv_iommu_release_device(struct device *dev)
</span> 	list_del(&amp;ep-&gt;domain);
 	mutex_unlock(&amp;ep-&gt;lock);
 
<span class=add>+	if (ep-&gt;dc) {
+		// this should be already done by domain detach.
+		ep-&gt;dc-&gt;tc = 0ULL;
+		wmb();
+		ep-&gt;dc-&gt;fsc = 0ULL;
+		ep-&gt;dc-&gt;iohgatp = 0ULL;
+		wmb();
+		riscv_iommu_iodir_inv_devid(iommu, ep-&gt;devid);
+	}
+
</span> 	/* Remove endpoint from IOMMU tracking structures */
 	mutex_lock(&amp;iommu-&gt;eps_mutex);
 	rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
<span class=hunk>@@ -853,11 +962,21 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
</span> 	return 0;
 }
 
<span class=add>+static u64 riscv_iommu_domain_atp(struct riscv_iommu_domain *domain)
+{
+	u64 atp = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, domain-&gt;mode);
+	if (domain-&gt;mode != RISCV_IOMMU_DC_FSC_MODE_BARE)
+		atp |= FIELD_PREP(RISCV_IOMMU_DC_FSC_PPN, virt_to_pfn(domain-&gt;pgd_root));
+	return atp;
+}
+
</span> static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct device *dev)
 {
 	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
 	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
<span class=add>+	struct riscv_iommu_dc *dc = ep-&gt;dc;
</span> 	int ret;
<span class=add>+	u64 val;
</span> 
 	/* PSCID not valid */
 	if ((int)domain-&gt;pscid &lt; 0)
<span class=hunk>@@ -880,17 +999,44 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
</span> 		return ret;
 	}
 
<span class=del>-	if (ep-&gt;iommu-&gt;ddt_mode != RISCV_IOMMU_DDTP_MODE_BARE ||
-	    domain-&gt;domain.type != IOMMU_DOMAIN_IDENTITY) {
-		dev_warn(dev, "domain type %d not supported\n",
-		    domain-&gt;domain.type);
</span><span class=add>+	if (ep-&gt;iommu-&gt;ddt_mode == RISCV_IOMMU_DDTP_MODE_BARE &amp;&amp;
+	    domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
+		dev_info(dev, "domain type %d attached w/ PSCID %u\n",
+		    domain-&gt;domain.type, domain-&gt;pscid);
+		return 0;
+	}
+
+	if (!dc) {
</span> 		return -ENODEV;
 	}
 
<span class=add>+	/*
+	 * S-Stage translation table. G-Stage remains unmodified (BARE).
+	 */
+	val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
+
+	dc-&gt;ta = cpu_to_le64(val);
+	dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
+
+	wmb();
+
+	/* Mark device context as valid, synchronise device context cache. */
+	val = RISCV_IOMMU_DC_TC_V;
+
+	if (ep-&gt;iommu-&gt;cap &amp; RISCV_IOMMU_CAP_AMO) {
+		val |= RISCV_IOMMU_DC_TC_GADE |
+		       RISCV_IOMMU_DC_TC_SADE;
+	}
+
+	dc-&gt;tc = cpu_to_le64(val);
+	wmb();
+
</span> 	list_add_tail(&amp;ep-&gt;domain, &amp;domain-&gt;endpoints);
 	mutex_unlock(&amp;ep-&gt;lock);
 	mutex_unlock(&amp;domain-&gt;lock);
 
<span class=add>+	riscv_iommu_iodir_inv_devid(ep-&gt;iommu, ep-&gt;devid);
+
</span> 	dev_info(dev, "domain type %d attached w/ PSCID %u\n",
 	    domain-&gt;domain.type, domain-&gt;pscid);
 
<span class=hunk>@@ -1239,7 +1385,12 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 		goto fail;
 
  no_ats:
<span class=del>-	ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
</span><span class=add>+	if (iommu_default_passthrough()) {
+		dev_info(dev, "iommu set to passthrough mode\n");
+		ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
+	} else {
+		ret = riscv_iommu_enable(iommu, ddt_mode);
+	}
</span> 
 	if (ret) {
 		dev_err(dev, "cannot enable iommu device (%d)\n", ret);
<span class=head><a href=#iZ2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
index 04148a2a8ffd..9140df71e17b 100644
--- a/drivers/iommu/riscv/iommu.h
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -105,6 +105,7 @@ struct riscv_iommu_endpoint {
</span> 	unsigned devid;      			/* PCI bus:device:function number */
 	unsigned domid;    			/* PCI domain number, segment */
 	struct rb_node node;    		/* device tracking node (lookup by devid) */
<span class=add>+	struct riscv_iommu_dc *dc;		/* device context pointer */
</span> 	struct riscv_iommu_device *iommu;	/* parent iommu device */
 
 	struct mutex lock;
-- 
2.34.1


<a href=#m02ea782700dca52c10fb471a2331de501bffb1a7 id=e02ea782700dca52c10fb471a2331de501bffb1a7>^</a> <a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/702670f5be2b641a231f2dda84be12024afd2002.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#r02ea782700dca52c10fb471a2331de501bffb1a7>86+ messages in thread</a></pre><hr><pre><a href=#e50b13653960cd6e88a7efb588257ac568bffb87b id=m50b13653960cd6e88a7efb588257ac568bffb87b>*</a> <b>[PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#r02ea782700dca52c10fb471a2331de501bffb1a7>(6 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#m02ea782700dca52c10fb471a2331de501bffb1a7>[PATCH 07/11] RISC-V: drivers/iommu/riscv: Add device context support</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-25 13:13   ` <a href=#m35e1f370635d089a8dde16e4c70b533d4b503ee0>Zong Li</a>
                     ` <a href=#r35e1f370635d089a8dde16e4c70b533d4b503ee0>(2 more replies)</a>
  2023-07-19 19:33 ` <a href=#mdc9e0e502299442d2ebce9ef9d4f317c16f89a05>[PATCH 09/11] RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support</a> Tomasz Jeznach
                   ` <a href=#rdc9e0e502299442d2ebce9ef9d4f317c16f89a05>(3 subsequent siblings)</a>
  <a href=#r50b13653960cd6e88a7efb588257ac568bffb87b>11 siblings, 3 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193531">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193531">linux-kernel</a>, linux,
	Tomasz Jeznach

Introduces I/O page level translation services, with 4K, 2M, 1G page
size support and enables page level iommu_map/unmap domain interfaces.

Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:io-pgtable.c href=#Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:io-pgtable.c>drivers/iommu/io-pgtable.c</a>       |   3 +
 <a id=iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile href=#Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile>drivers/iommu/riscv/Makefile</a>     |   2 +-
 <a id=iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:io_pgtable.c href=#Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:io_pgtable.c>drivers/iommu/riscv/io_pgtable.c</a> | 266 +++++++++++++++++++++++++++++++
 <a id=iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a>      |  40 +++--
 <a id=iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a>      |   1 +
 <a id=iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1include:linux:io-pgtable.h href=#Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1include:linux:io-pgtable.h>include/linux/io-pgtable.h</a>       |   2 +
 6 files <a href=#e50b13653960cd6e88a7efb588257ac568bffb87b>changed</a>, 297 insertions(+), 17 deletions(-)
 create mode 100644 drivers/iommu/riscv/io_pgtable.c

<span class=head><a href=#iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:io-pgtable.c id=Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:io-pgtable.c>diff</a> --git a/drivers/iommu/io-pgtable.c b/drivers/iommu/io-pgtable.c
index b843fcd365d2..c4807175934f 100644
--- a/drivers/iommu/io-pgtable.c
+++ b/drivers/iommu/io-pgtable.c
</span><span class=hunk>@@ -32,6 +32,9 @@ io_pgtable_init_table[IO_PGTABLE_NUM_FMTS] = {
</span> 	[AMD_IOMMU_V1] = &amp;io_pgtable_amd_iommu_v1_init_fns,
 	[AMD_IOMMU_V2] = &amp;io_pgtable_amd_iommu_v2_init_fns,
 #endif
<span class=add>+#ifdef CONFIG_RISCV_IOMMU
+	[RISCV_IOMMU] = &amp;io_pgtable_riscv_init_fns,
+#endif
</span> };
 
 struct io_pgtable_ops *alloc_io_pgtable_ops(enum io_pgtable_fmt fmt,
<span class=head><a href=#iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile id=Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:Makefile>diff</a> --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
index 9523eb053cfc..13af452c3052 100644
--- a/drivers/iommu/riscv/Makefile
+++ b/drivers/iommu/riscv/Makefile
</span><span class=hunk>@@ -1 +1 @@
</span><span class=del>-obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o
</span>\ No newline at end of file
<span class=add>+obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o io_pgtable.o
</span><span class=head><a href=#iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:io_pgtable.c id=Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:io_pgtable.c>diff</a> --git a/drivers/iommu/riscv/io_pgtable.c b/drivers/iommu/riscv/io_pgtable.c
new file mode 100644
index 000000000000..b6e603e6726e
--- /dev/null
+++ b/drivers/iommu/riscv/io_pgtable.c
</span><span class=hunk>@@ -0,0 +1,266 @@
</span><span class=add>+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright © 2022-2023 Rivos Inc.
+ *
+ * RISC-V IOMMU page table allocator.
+ *
+ * Authors:
+ *	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
+ *	Sebastien Boeuf &lt;seb@rivosinc.com&gt;
+ */
+
+#include &lt;linux/atomic.h&gt;
+#include &lt;linux/bitops.h&gt;
+#include &lt;linux/io-pgtable.h&gt;
+#include &lt;linux/kernel.h&gt;
+#include &lt;linux/sizes.h&gt;
+#include &lt;linux/slab.h&gt;
+#include &lt;linux/types.h&gt;
+#include &lt;linux/dma-mapping.h&gt;
+
+#include "iommu.h"
+
+#define io_pgtable_to_domain(x) \
+	container_of((x), struct riscv_iommu_domain, pgtbl)
+
+#define io_pgtable_ops_to_domain(x) \
+	io_pgtable_to_domain(container_of((x), struct io_pgtable, ops))
+
+static inline size_t get_page_size(size_t size)
+{
+	if (size &gt;= IOMMU_PAGE_SIZE_512G)
+		return IOMMU_PAGE_SIZE_512G;
+
+	if (size &gt;= IOMMU_PAGE_SIZE_1G)
+		return IOMMU_PAGE_SIZE_1G;
+
+	if (size &gt;= IOMMU_PAGE_SIZE_2M)
+		return IOMMU_PAGE_SIZE_2M;
+
+	return IOMMU_PAGE_SIZE_4K;
+}
+
+static void riscv_iommu_pt_walk_free(pmd_t * ptp, unsigned shift, bool root)
+{
+	pmd_t *pte, *pt_base;
+	int i;
+
+	if (shift == PAGE_SHIFT)
+		return;
+
+	if (root)
+		pt_base = ptp;
+	else
+		pt_base =
+		    (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp)));
+
+	/* Recursively free all sub page table pages */
+	for (i = 0; i &lt; PTRS_PER_PMD; i++) {
+		pte = pt_base + i;
+		if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
+			riscv_iommu_pt_walk_free(pte, shift - 9, false);
+	}
+
+	/* Now free the current page table page */
+	if (!root &amp;&amp; pmd_present(*pt_base))
+		free_page((unsigned long)pt_base);
+}
+
+static void riscv_iommu_free_pgtable(struct io_pgtable *iop)
+{
+	struct riscv_iommu_domain *domain = io_pgtable_to_domain(iop);
+	riscv_iommu_pt_walk_free((pmd_t *) domain-&gt;pgd_root, PGDIR_SHIFT, true);
+}
+
+static pte_t *riscv_iommu_pt_walk_alloc(pmd_t * ptp, unsigned long iova,
+					unsigned shift, bool root,
+					size_t pgsize,
+					unsigned long (*pd_alloc)(gfp_t),
+					gfp_t gfp)
+{
+	pmd_t *pte;
+	unsigned long pfn;
+
+	if (root)
+		pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
+	else
+		pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
+		    ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
+
+	if ((1ULL &lt;&lt; shift) &lt;= pgsize) {
+		if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
+			riscv_iommu_pt_walk_free(pte, shift - 9, false);
+		return (pte_t *) pte;
+	}
+
+	if (pmd_none(*pte)) {
+		pfn = pd_alloc ? virt_to_pfn(pd_alloc(gfp)) : 0;
+		if (!pfn)
+			return NULL;
+		set_pmd(pte, __pmd((pfn &lt;&lt; _PAGE_PFN_SHIFT) | _PAGE_TABLE));
+	}
+
+	return riscv_iommu_pt_walk_alloc(pte, iova, shift - 9, false,
+					 pgsize, pd_alloc, gfp);
+}
+
+static pte_t *riscv_iommu_pt_walk_fetch(pmd_t * ptp,
+					unsigned long iova, unsigned shift,
+					bool root)
+{
+	pmd_t *pte;
+
+	if (root)
+		pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
+	else
+		pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
+		    ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
+
+	if (pmd_leaf(*pte))
+		return (pte_t *) pte;
+	else if (pmd_none(*pte))
+		return NULL;
+	else if (shift == PAGE_SHIFT)
+		return NULL;
+
+	return riscv_iommu_pt_walk_fetch(pte, iova, shift - 9, false);
+}
+
+static int riscv_iommu_map_pages(struct io_pgtable_ops *ops,
+				 unsigned long iova, phys_addr_t phys,
+				 size_t pgsize, size_t pgcount, int prot,
+				 gfp_t gfp, size_t *mapped)
+{
+	struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
+	size_t size = 0;
+	size_t page_size = get_page_size(pgsize);
+	pte_t *pte;
+	pte_t pte_val;
+	pgprot_t pte_prot;
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_BLOCKED)
+		return -ENODEV;
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
+		*mapped = pgsize * pgcount;
+		return 0;
+	}
+
+	pte_prot = (prot &amp; IOMMU_WRITE) ?
+	    __pgprot(_PAGE_BASE | _PAGE_READ | _PAGE_WRITE | _PAGE_DIRTY) :
+	    __pgprot(_PAGE_BASE | _PAGE_READ);
+
+	while (pgcount--) {
+		pte =
+		    riscv_iommu_pt_walk_alloc((pmd_t *) domain-&gt;pgd_root, iova,
+					      PGDIR_SHIFT, true, page_size,
+					      get_zeroed_page, gfp);
+		if (!pte) {
+			*mapped = size;
+			return -ENOMEM;
+		}
+
+		pte_val = pfn_pte(phys_to_pfn(phys), pte_prot);
+
+		set_pte(pte, pte_val);
+
+		size += page_size;
+		iova += page_size;
+		phys += page_size;
+	}
+
+	*mapped = size;
+	return 0;
+}
+
+static size_t riscv_iommu_unmap_pages(struct io_pgtable_ops *ops,
+				      unsigned long iova, size_t pgsize,
+				      size_t pgcount,
+				      struct iommu_iotlb_gather *gather)
+{
+	struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
+	size_t size = 0;
+	size_t page_size = get_page_size(pgsize);
+	pte_t *pte;
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
+		return pgsize * pgcount;
+
+	while (pgcount--) {
+		pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
+						iova, PGDIR_SHIFT, true);
+		if (!pte)
+			return size;
+
+		set_pte(pte, __pte(0));
+
+		iommu_iotlb_gather_add_page(&amp;domain-&gt;domain, gather, iova,
+					    pgsize);
+
+		size += page_size;
+		iova += page_size;
+	}
+
+	return size;
+}
+
+static phys_addr_t riscv_iommu_iova_to_phys(struct io_pgtable_ops *ops,
+					    unsigned long iova)
+{
+	struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
+	pte_t *pte;
+
+	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
+		return (phys_addr_t) iova;
+
+	pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
+					iova, PGDIR_SHIFT, true);
+	if (!pte || !pte_present(*pte))
+		return 0;
+
+	return (pfn_to_phys(pte_pfn(*pte)) | (iova &amp; PAGE_MASK));
+}
+
+static void riscv_iommu_tlb_inv_all(void *cookie)
+{
+}
+
+static void riscv_iommu_tlb_inv_walk(unsigned long iova, size_t size,
+				     size_t granule, void *cookie)
+{
+}
+
+static void riscv_iommu_tlb_add_page(struct iommu_iotlb_gather *gather,
+				     unsigned long iova, size_t granule,
+				     void *cookie)
+{
+}
+
+static const struct iommu_flush_ops riscv_iommu_flush_ops = {
+	.tlb_flush_all = riscv_iommu_tlb_inv_all,
+	.tlb_flush_walk = riscv_iommu_tlb_inv_walk,
+	.tlb_add_page = riscv_iommu_tlb_add_page,
+};
+
+/* NOTE: cfg should point to riscv_iommu_domain structure member pgtbl.cfg */
+static struct io_pgtable *riscv_iommu_alloc_pgtable(struct io_pgtable_cfg *cfg,
+						    void *cookie)
+{
+	struct io_pgtable *iop = container_of(cfg, struct io_pgtable, cfg);
+
+	cfg-&gt;pgsize_bitmap = SZ_4K | SZ_2M | SZ_1G;
+	cfg-&gt;ias = 57;		// va mode, SvXX -&gt; ias
+	cfg-&gt;oas = 57;		// pa mode, or SvXX+4 -&gt; oas
+	cfg-&gt;tlb = &amp;riscv_iommu_flush_ops;
+
+	iop-&gt;ops.map_pages = riscv_iommu_map_pages;
+	iop-&gt;ops.unmap_pages = riscv_iommu_unmap_pages;
+	iop-&gt;ops.iova_to_phys = riscv_iommu_iova_to_phys;
+
+	return iop;
+}
+
+struct io_pgtable_init_fns io_pgtable_riscv_init_fns = {
+	.alloc = riscv_iommu_alloc_pgtable,
+	.free = riscv_iommu_free_pgtable,
+};
</span><span class=head><a href=#iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
index 9ee7d2b222b5..2ef6952a2109 100644
--- a/drivers/iommu/riscv/iommu.c
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -807,7 +807,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
</span> 	/* Initial DC pointer can be NULL if IOMMU is configured in OFF or BARE mode */
 	ep-&gt;dc = riscv_iommu_get_dc(iommu, ep-&gt;devid);
 
<span class=del>-	dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
</span><span class=add>+	dev_dbg(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
</span> 		ep-&gt;devid, ep-&gt;domid);
 
 	dev_iommu_priv_set(dev, ep);
<span class=hunk>@@ -874,7 +874,10 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
</span> {
 	struct riscv_iommu_domain *domain;
 
<span class=del>-	if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
</span><span class=add>+	if (type != IOMMU_DOMAIN_DMA &amp;&amp;
+	    type != IOMMU_DOMAIN_DMA_FQ &amp;&amp;
+	    type != IOMMU_DOMAIN_UNMANAGED &amp;&amp;
+	    type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
</span> 	    type != IOMMU_DOMAIN_BLOCKED)
 		return NULL;
 
<span class=hunk>@@ -890,7 +893,7 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
</span> 	domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
 					RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
 
<span class=del>-	printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
</span><span class=add>+	printk("domain alloc %u\n", domain-&gt;pscid);
</span> 
 	return &amp;domain-&gt;domain;
 }
<span class=hunk>@@ -903,6 +906,9 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
</span> 		pr_warn("IOMMU domain is not empty!\n");
 	}
 
<span class=add>+	if (domain-&gt;pgtbl.cookie)
+		free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
+
</span> 	if (domain-&gt;pgd_root)
 		free_pages((unsigned long)domain-&gt;pgd_root, 0);
 
<span class=hunk>@@ -959,6 +965,9 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
</span> 	if (!domain-&gt;pgd_root)
 		return -ENOMEM;
 
<span class=add>+	if (!alloc_io_pgtable_ops(RISCV_IOMMU, &amp;domain-&gt;pgtbl.cfg, domain))
+		return -ENOMEM;
+
</span> 	return 0;
 }
 
<span class=hunk>@@ -1006,9 +1015,8 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
</span> 		return 0;
 	}
 
<span class=del>-	if (!dc) {
</span><span class=add>+	if (!dc)
</span> 		return -ENODEV;
<span class=del>-	}
</span> 
 	/*
 	 * S-Stage translation table. G-Stage remains unmodified (BARE).
<span class=hunk>@@ -1104,12 +1112,11 @@ static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
</span> {
 	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
 
<span class=del>-	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
-		*mapped = pgsize * pgcount;
-		return 0;
-	}
</span><span class=add>+	if (!domain-&gt;pgtbl.ops.map_pages)
+		return -ENODEV;
</span> 
<span class=del>-	return -ENODEV;
</span><span class=add>+	return domain-&gt;pgtbl.ops.map_pages(&amp;domain-&gt;pgtbl.ops, iova, phys,
+					   pgsize, pgcount, prot, gfp, mapped);
</span> }
 
 static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
<span class=hunk>@@ -1118,10 +1125,11 @@ static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
</span> {
 	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
 
<span class=del>-	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
-		return pgsize * pgcount;
</span><span class=add>+	if (!domain-&gt;pgtbl.ops.unmap_pages)
+		return 0;
</span> 
<span class=del>-	return 0;
</span><span class=add>+	return domain-&gt;pgtbl.ops.unmap_pages(&amp;domain-&gt;pgtbl.ops, iova, pgsize,
+					     pgcount, gather);
</span> }
 
 static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
<span class=hunk>@@ -1129,10 +1137,10 @@ static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
</span> {
 	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
 
<span class=del>-	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
-		return (phys_addr_t) iova;
</span><span class=add>+	if (!domain-&gt;pgtbl.ops.iova_to_phys)
+		return 0;
</span> 
<span class=del>-	return 0;
</span><span class=add>+	return domain-&gt;pgtbl.ops.iova_to_phys(&amp;domain-&gt;pgtbl.ops, iova);
</span> }
 
 /*
<span class=head><a href=#iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
index 9140df71e17b..fe32a4eff14e 100644
--- a/drivers/iommu/riscv/iommu.h
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -88,6 +88,7 @@ struct riscv_iommu_device {
</span> 
 struct riscv_iommu_domain {
 	struct iommu_domain domain;
<span class=add>+	struct io_pgtable pgtbl;
</span> 
 	struct list_head endpoints;
 	struct mutex lock;
<span class=head><a href=#iZ2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1include:linux:io-pgtable.h id=Z2e.:..:2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach::40rivosinc.com:1include:linux:io-pgtable.h>diff</a> --git a/include/linux/io-pgtable.h b/include/linux/io-pgtable.h
index 1b7a44b35616..8dd9d3a28e3a 100644
--- a/include/linux/io-pgtable.h
+++ b/include/linux/io-pgtable.h
</span><span class=hunk>@@ -19,6 +19,7 @@ enum io_pgtable_fmt {
</span> 	AMD_IOMMU_V2,
 	APPLE_DART,
 	APPLE_DART2,
<span class=add>+	RISCV_IOMMU,
</span> 	IO_PGTABLE_NUM_FMTS,
 };
 
<span class=hunk>@@ -258,5 +259,6 @@ extern struct io_pgtable_init_fns io_pgtable_arm_mali_lpae_init_fns;
</span> extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v1_init_fns;
 extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v2_init_fns;
 extern struct io_pgtable_init_fns io_pgtable_apple_dart_init_fns;
<span class=add>+extern struct io_pgtable_init_fns io_pgtable_riscv_init_fns;
</span> 
 #endif /* __IO_PGTABLE_H */
-- 
2.34.1


<a href=#m50b13653960cd6e88a7efb588257ac568bffb87b id=e50b13653960cd6e88a7efb588257ac568bffb87b>^</a> <a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/2d5242e79a98dc75cd8fa0fefdb4e3ad37a920ba.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#r50b13653960cd6e88a7efb588257ac568bffb87b>86+ messages in thread</a></pre><hr><pre><a href=#edc9e0e502299442d2ebce9ef9d4f317c16f89a05 id=mdc9e0e502299442d2ebce9ef9d4f317c16f89a05>*</a> <b>[PATCH 09/11] RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support.</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#r50b13653960cd6e88a7efb588257ac568bffb87b>(7 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#m50b13653960cd6e88a7efb588257ac568bffb87b>[PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-31  9:04   ` <a href=#mdc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7>Zong Li</a>
  2023-07-19 19:33 ` <a href=#m2774c76ea4a5513d985e6c918e66c1e3730ad342>[PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</a> Tomasz Jeznach
                   ` <a href=#r2774c76ea4a5513d985e6c918e66c1e3730ad342>(2 subsequent siblings)</a>
  <a href=#rdc9e0e502299442d2ebce9ef9d4f317c16f89a05>11 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193541">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193541">linux-kernel</a>, linux,
	Tomasz Jeznach

Introduces SVA (Shared Virtual Address) for RISC-V IOMMU, with
ATS/PRI services for capable devices.

Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a> | 601 +++++++++++++++++++++++++++++++++++-
 <a id=iZ2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a> |  14 +
 2 files <a href=#edc9e0e502299442d2ebce9ef9d4f317c16f89a05>changed</a>, 610 insertions(+), 5 deletions(-)

<span class=head><a href=#iZ2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
index 2ef6952a2109..6042c35be3ca 100644
--- a/drivers/iommu/riscv/iommu.c
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -384,6 +384,89 @@ static inline void riscv_iommu_cmd_iodir_set_did(struct riscv_iommu_command *cmd
</span> 	    FIELD_PREP(RISCV_IOMMU_CMD_IODIR_DID, devid) | RISCV_IOMMU_CMD_IODIR_DV;
 }
 
<span class=add>+static inline void riscv_iommu_cmd_iodir_set_pid(struct riscv_iommu_command *cmd,
+						 unsigned pasid)
+{
+	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IODIR_PID, pasid);
+}
+
+static void riscv_iommu_cmd_ats_inval(struct riscv_iommu_command *cmd)
+{
+	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_ATS_OPCODE) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_ATS_FUNC_INVAL);
+	cmd-&gt;dword1 = 0;
+}
+
+static inline void riscv_iommu_cmd_ats_prgr(struct riscv_iommu_command *cmd)
+{
+	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_ATS_OPCODE) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_ATS_FUNC_PRGR);
+	cmd-&gt;dword1 = 0;
+}
+
+static void riscv_iommu_cmd_ats_set_rid(struct riscv_iommu_command *cmd, u32 rid)
+{
+	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_ATS_RID, rid);
+}
+
+static void riscv_iommu_cmd_ats_set_pid(struct riscv_iommu_command *cmd, u32 pid)
+{
+	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_ATS_PID, pid) | RISCV_IOMMU_CMD_ATS_PV;
+}
+
+static void riscv_iommu_cmd_ats_set_dseg(struct riscv_iommu_command *cmd, u8 seg)
+{
+	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_ATS_DSEG, seg) | RISCV_IOMMU_CMD_ATS_DSV;
+}
+
+static void riscv_iommu_cmd_ats_set_payload(struct riscv_iommu_command *cmd, u64 payload)
+{
+	cmd-&gt;dword1 = payload;
+}
+
+/* Prepare the ATS invalidation payload */
+static unsigned long riscv_iommu_ats_inval_payload(unsigned long start,
+						   unsigned long end, bool global_inv)
+{
+	size_t len = end - start + 1;
+	unsigned long payload = 0;
+
+	/*
+	 * PCI Express specification
+	 * Section 10.2.3.2 Translation Range Size (S) Field
+	 */
+	if (len &lt; PAGE_SIZE)
+		len = PAGE_SIZE;
+	else
+		len = __roundup_pow_of_two(len);
+
+	payload = (start &amp; ~(len - 1)) | (((len - 1) &gt;&gt; 12) &lt;&lt; 11);
+
+	if (global_inv)
+		payload |= RISCV_IOMMU_CMD_ATS_INVAL_G;
+
+	return payload;
+}
+
+/* Prepare the ATS invalidation payload for all translations to be invalidated. */
+static unsigned long riscv_iommu_ats_inval_all_payload(bool global_inv)
+{
+	unsigned long payload = GENMASK_ULL(62, 11);
+
+	if (global_inv)
+		payload |= RISCV_IOMMU_CMD_ATS_INVAL_G;
+
+	return payload;
+}
+
+/* Prepare the ATS "Page Request Group Response" payload */
+static unsigned long riscv_iommu_ats_prgr_payload(u16 dest_id, u8 resp_code, u16 grp_idx)
+{
+	return FIELD_PREP(RISCV_IOMMU_CMD_ATS_PRGR_DST_ID, dest_id) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_ATS_PRGR_RESP_CODE, resp_code) |
+	    FIELD_PREP(RISCV_IOMMU_CMD_ATS_PRGR_PRG_INDEX, grp_idx);
+}
+
</span> /* TODO: Convert into lock-less MPSC implementation. */
 static bool riscv_iommu_post_sync(struct riscv_iommu_device *iommu,
 				  struct riscv_iommu_command *cmd, bool sync)
<span class=hunk>@@ -460,6 +543,16 @@ static bool riscv_iommu_iodir_inv_devid(struct riscv_iommu_device *iommu, unsign
</span> 	return riscv_iommu_post(iommu, &amp;cmd);
 }
 
<span class=add>+static bool riscv_iommu_iodir_inv_pasid(struct riscv_iommu_device *iommu,
+					unsigned devid, unsigned pasid)
+{
+	struct riscv_iommu_command cmd;
+	riscv_iommu_cmd_iodir_inval_pdt(&amp;cmd);
+	riscv_iommu_cmd_iodir_set_did(&amp;cmd, devid);
+	riscv_iommu_cmd_iodir_set_pid(&amp;cmd, pasid);
+	return riscv_iommu_post(iommu, &amp;cmd);
+}
+
</span> static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
 {
 	struct riscv_iommu_command cmd;
<span class=hunk>@@ -467,6 +560,62 @@ static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
</span> 	return riscv_iommu_post_sync(iommu, &amp;cmd, true);
 }
 
<span class=add>+static void riscv_iommu_mm_invalidate(struct mmu_notifier *mn,
+				      struct mm_struct *mm, unsigned long start,
+				      unsigned long end)
+{
+	struct riscv_iommu_command cmd;
+	struct riscv_iommu_endpoint *endpoint;
+	struct riscv_iommu_domain *domain =
+	    container_of(mn, struct riscv_iommu_domain, mn);
+	unsigned long iova;
+	/*
+	 * The mm_types defines vm_end as the first byte after the end address,
+	 * different from IOMMU subsystem using the last address of an address
+	 * range. So do a simple translation here by updating what end means.
+	 */
+	unsigned long payload = riscv_iommu_ats_inval_payload(start, end - 1, true);
+
+	riscv_iommu_cmd_inval_vma(&amp;cmd);
+	riscv_iommu_cmd_inval_set_gscid(&amp;cmd, 0);
+	riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
+	if (end &gt; start) {
+		/* Cover only the range that is needed */
+		for (iova = start; iova &lt; end; iova += PAGE_SIZE) {
+			riscv_iommu_cmd_inval_set_addr(&amp;cmd, iova);
+			riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
+		}
+	} else {
+		riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
+	}
+
+	riscv_iommu_iofence_sync(domain-&gt;iommu);
+
+	/* ATS invalidation for every device and for specific translation range. */
+	list_for_each_entry(endpoint, &amp;domain-&gt;endpoints, domain) {
+		if (!endpoint-&gt;pasid_enabled)
+			continue;
+
+		riscv_iommu_cmd_ats_inval(&amp;cmd);
+		riscv_iommu_cmd_ats_set_dseg(&amp;cmd, endpoint-&gt;domid);
+		riscv_iommu_cmd_ats_set_rid(&amp;cmd, endpoint-&gt;devid);
+		riscv_iommu_cmd_ats_set_pid(&amp;cmd, domain-&gt;pasid);
+		riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
+		riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
+	}
+	riscv_iommu_iofence_sync(domain-&gt;iommu);
+}
+
+static void riscv_iommu_mm_release(struct mmu_notifier *mn, struct mm_struct *mm)
+{
+	/* TODO: removed from notifier, cleanup PSCID mapping, flush IOTLB */
+}
+
+static const struct mmu_notifier_ops riscv_iommu_mmuops = {
+	.release = riscv_iommu_mm_release,
+	.invalidate_range = riscv_iommu_mm_invalidate,
+};
+
</span> /* Command queue primary interrupt handler */
 static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data)
 {
<span class=hunk>@@ -608,6 +757,128 @@ static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct devi
</span> 	mutex_unlock(&amp;iommu-&gt;eps_mutex);
 }
 
<span class=add>+/*
+ * Get device reference based on device identifier (requester id).
+ * Decrement reference count with put_device() call.
+ */
+static struct device *riscv_iommu_get_device(struct riscv_iommu_device *iommu,
+					     unsigned devid)
+{
+	struct rb_node *node;
+	struct riscv_iommu_endpoint *ep;
+	struct device *dev = NULL;
+
+	mutex_lock(&amp;iommu-&gt;eps_mutex);
+
+	node = iommu-&gt;eps.rb_node;
+	while (node &amp;&amp; !dev) {
+		ep = rb_entry(node, struct riscv_iommu_endpoint, node);
+		if (ep-&gt;devid &lt; devid)
+			node = node-&gt;rb_right;
+		else if (ep-&gt;devid &gt; devid)
+			node = node-&gt;rb_left;
+		else
+			dev = get_device(ep-&gt;dev);
+	}
+
+	mutex_unlock(&amp;iommu-&gt;eps_mutex);
+
+	return dev;
+}
+
+static int riscv_iommu_ats_prgr(struct device *dev, struct iommu_page_response *msg)
+{
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+	struct riscv_iommu_command cmd;
+	u8 resp_code;
+	unsigned long payload;
+
+	switch (msg-&gt;code) {
+	case IOMMU_PAGE_RESP_SUCCESS:
+		resp_code = 0b0000;
+		break;
+	case IOMMU_PAGE_RESP_INVALID:
+		resp_code = 0b0001;
+		break;
+	case IOMMU_PAGE_RESP_FAILURE:
+		resp_code = 0b1111;
+		break;
+	}
+	payload = riscv_iommu_ats_prgr_payload(ep-&gt;devid, resp_code, msg-&gt;grpid);
+
+	/* ATS Page Request Group Response */
+	riscv_iommu_cmd_ats_prgr(&amp;cmd);
+	riscv_iommu_cmd_ats_set_dseg(&amp;cmd, ep-&gt;domid);
+	riscv_iommu_cmd_ats_set_rid(&amp;cmd, ep-&gt;devid);
+	if (msg-&gt;flags &amp; IOMMU_PAGE_RESP_PASID_VALID)
+		riscv_iommu_cmd_ats_set_pid(&amp;cmd, msg-&gt;pasid);
+	riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
+	riscv_iommu_post(ep-&gt;iommu, &amp;cmd);
+
+	return 0;
+}
+
+static void riscv_iommu_page_request(struct riscv_iommu_device *iommu,
+				     struct riscv_iommu_pq_record *req)
+{
+	struct iommu_fault_event event = { 0 };
+	struct iommu_fault_page_request *prm = &amp;event.fault.prm;
+	int ret;
+	struct device *dev;
+	unsigned devid = FIELD_GET(RISCV_IOMMU_PREQ_HDR_DID, req-&gt;hdr);
+
+	/* Ignore PGR Stop marker. */
+	if ((req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_M) == RISCV_IOMMU_PREQ_PAYLOAD_L)
+		return;
+
+	dev = riscv_iommu_get_device(iommu, devid);
+	if (!dev) {
+		/* TODO: Handle invalid page request */
+		return;
+	}
+
+	event.fault.type = IOMMU_FAULT_PAGE_REQ;
+
+	if (req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_L)
+		prm-&gt;flags |= IOMMU_FAULT_PAGE_REQUEST_LAST_PAGE;
+	if (req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_W)
+		prm-&gt;perm |= IOMMU_FAULT_PERM_WRITE;
+	if (req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_R)
+		prm-&gt;perm |= IOMMU_FAULT_PERM_READ;
+
+	prm-&gt;grpid = FIELD_GET(RISCV_IOMMU_PREQ_PRG_INDEX, req-&gt;payload);
+	prm-&gt;addr = FIELD_GET(RISCV_IOMMU_PREQ_UADDR, req-&gt;payload) &lt;&lt; PAGE_SHIFT;
+
+	if (req-&gt;hdr &amp; RISCV_IOMMU_PREQ_HDR_PV) {
+		prm-&gt;flags |= IOMMU_FAULT_PAGE_REQUEST_PASID_VALID;
+		/* TODO: where to find this bit */
+		prm-&gt;flags |= IOMMU_FAULT_PAGE_RESPONSE_NEEDS_PASID;
+		prm-&gt;pasid = FIELD_GET(RISCV_IOMMU_PREQ_HDR_PID, req-&gt;hdr);
+	}
+
+	ret = iommu_report_device_fault(dev, &amp;event);
+	if (ret) {
+		struct iommu_page_response resp = {
+			.grpid = prm-&gt;grpid,
+			.code = IOMMU_PAGE_RESP_FAILURE,
+		};
+		if (prm-&gt;flags &amp; IOMMU_FAULT_PAGE_RESPONSE_NEEDS_PASID) {
+			resp.flags |= IOMMU_PAGE_RESP_PASID_VALID;
+			resp.pasid = prm-&gt;pasid;
+		}
+		riscv_iommu_ats_prgr(dev, &amp;resp);
+	}
+
+	put_device(dev);
+}
+
+static int riscv_iommu_page_response(struct device *dev,
+				     struct iommu_fault_event *evt,
+				     struct iommu_page_response *msg)
+{
+	return riscv_iommu_ats_prgr(dev, msg);
+}
+
</span> /* Page request interface queue primary interrupt handler */
 static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data)
 {
<span class=hunk>@@ -626,7 +897,7 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
</span> 	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
 	struct riscv_iommu_device *iommu;
 	struct riscv_iommu_pq_record *requests;
<span class=del>-	unsigned cnt, idx, ctrl;
</span><span class=add>+	unsigned cnt, len, idx, ctrl;
</span> 
 	iommu = container_of(q, struct riscv_iommu_device, priq);
 	requests = (struct riscv_iommu_pq_record *)q-&gt;base;
<span class=hunk>@@ -649,7 +920,8 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
</span> 		cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
 		if (!cnt)
 			break;
<span class=del>-		dev_warn(iommu-&gt;dev, "unexpected %u page requests\n", cnt);
</span><span class=add>+		for (len = 0; len &lt; cnt; idx++, len++)
+			riscv_iommu_page_request(iommu, &amp;requests[idx]);
</span> 		riscv_iommu_queue_release(iommu, q, cnt);
 	} while (1);
 
<span class=hunk>@@ -660,6 +932,169 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
</span>  * Endpoint management
  */
 
<span class=add>+/* Endpoint features/capabilities */
+static void riscv_iommu_disable_ep(struct riscv_iommu_endpoint *ep)
+{
+	struct pci_dev *pdev;
+
+	if (!dev_is_pci(ep-&gt;dev))
+		return;
+
+	pdev = to_pci_dev(ep-&gt;dev);
+
+	if (ep-&gt;pasid_enabled) {
+		pci_disable_ats(pdev);
+		pci_disable_pri(pdev);
+		pci_disable_pasid(pdev);
+		ep-&gt;pasid_enabled = false;
+	}
+}
+
+static void riscv_iommu_enable_ep(struct riscv_iommu_endpoint *ep)
+{
+	int rc, feat, num;
+	struct pci_dev *pdev;
+	struct device *dev = ep-&gt;dev;
+
+	if (!dev_is_pci(dev))
+		return;
+
+	if (!ep-&gt;iommu-&gt;iommu.max_pasids)
+		return;
+
+	pdev = to_pci_dev(dev);
+
+	if (!pci_ats_supported(pdev))
+		return;
+
+	if (!pci_pri_supported(pdev))
+		return;
+
+	feat = pci_pasid_features(pdev);
+	if (feat &lt; 0)
+		return;
+
+	num = pci_max_pasids(pdev);
+	if (!num) {
+		dev_warn(dev, "Can't enable PASID (num: %d)\n", num);
+		return;
+	}
+
+	if (num &gt; ep-&gt;iommu-&gt;iommu.max_pasids)
+		num = ep-&gt;iommu-&gt;iommu.max_pasids;
+
+	rc = pci_enable_pasid(pdev, feat);
+	if (rc) {
+		dev_warn(dev, "Can't enable PASID (rc: %d)\n", rc);
+		return;
+	}
+
+	rc = pci_reset_pri(pdev);
+	if (rc) {
+		dev_warn(dev, "Can't reset PRI (rc: %d)\n", rc);
+		pci_disable_pasid(pdev);
+		return;
+	}
+
+	/* TODO: Get supported PRI queue length, hard-code to 32 entries */
+	rc = pci_enable_pri(pdev, 32);
+	if (rc) {
+		dev_warn(dev, "Can't enable PRI (rc: %d)\n", rc);
+		pci_disable_pasid(pdev);
+		return;
+	}
+
+	rc = pci_enable_ats(pdev, PAGE_SHIFT);
+	if (rc) {
+		dev_warn(dev, "Can't enable ATS (rc: %d)\n", rc);
+		pci_disable_pri(pdev);
+		pci_disable_pasid(pdev);
+		return;
+	}
+
+	ep-&gt;pc = (struct riscv_iommu_pc *)get_zeroed_page(GFP_KERNEL);
+	if (!ep-&gt;pc) {
+		pci_disable_ats(pdev);
+		pci_disable_pri(pdev);
+		pci_disable_pasid(pdev);
+		return;
+	}
+
+	ep-&gt;pasid_enabled = true;
+	ep-&gt;pasid_feat = feat;
+	ep-&gt;pasid_bits = ilog2(num);
+
+	dev_dbg(ep-&gt;dev, "PASID/ATS support enabled, %d bits\n", ep-&gt;pasid_bits);
+}
+
+static int riscv_iommu_enable_sva(struct device *dev)
+{
+	int ret;
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+
+	if (!ep || !ep-&gt;iommu || !ep-&gt;iommu-&gt;pq_work)
+		return -EINVAL;
+
+	if (!ep-&gt;pasid_enabled)
+		return -ENODEV;
+
+	ret = iopf_queue_add_device(ep-&gt;iommu-&gt;pq_work, dev);
+	if (ret)
+		return ret;
+
+	return iommu_register_device_fault_handler(dev, iommu_queue_iopf, dev);
+}
+
+static int riscv_iommu_disable_sva(struct device *dev)
+{
+	int ret;
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+
+	ret = iommu_unregister_device_fault_handler(dev);
+	if (!ret)
+		ret = iopf_queue_remove_device(ep-&gt;iommu-&gt;pq_work, dev);
+
+	return ret;
+}
+
+static int riscv_iommu_enable_iopf(struct device *dev)
+{
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+
+	if (ep &amp;&amp; ep-&gt;pasid_enabled)
+		return 0;
+
+	return -EINVAL;
+}
+
+static int riscv_iommu_dev_enable_feat(struct device *dev, enum iommu_dev_features feat)
+{
+	switch (feat) {
+	case IOMMU_DEV_FEAT_IOPF:
+		return riscv_iommu_enable_iopf(dev);
+
+	case IOMMU_DEV_FEAT_SVA:
+		return riscv_iommu_enable_sva(dev);
+
+	default:
+		return -ENODEV;
+	}
+}
+
+static int riscv_iommu_dev_disable_feat(struct device *dev, enum iommu_dev_features feat)
+{
+	switch (feat) {
+	case IOMMU_DEV_FEAT_IOPF:
+		return 0;
+
+	case IOMMU_DEV_FEAT_SVA:
+		return riscv_iommu_disable_sva(dev);
+
+	default:
+		return -ENODEV;
+	}
+}
+
</span> static int riscv_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)
 {
 	return iommu_fwspec_add_ids(dev, args-&gt;args, 1);
<span class=hunk>@@ -812,6 +1247,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
</span> 
 	dev_iommu_priv_set(dev, ep);
 	riscv_iommu_add_device(iommu, dev);
<span class=add>+	riscv_iommu_enable_ep(ep);
</span> 
 	return &amp;iommu-&gt;iommu;
 }
<span class=hunk>@@ -843,6 +1279,8 @@ static void riscv_iommu_release_device(struct device *dev)
</span> 		riscv_iommu_iodir_inv_devid(iommu, ep-&gt;devid);
 	}
 
<span class=add>+	riscv_iommu_disable_ep(ep);
+
</span> 	/* Remove endpoint from IOMMU tracking structures */
 	mutex_lock(&amp;iommu-&gt;eps_mutex);
 	rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
<span class=hunk>@@ -878,7 +1316,8 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
</span> 	    type != IOMMU_DOMAIN_DMA_FQ &amp;&amp;
 	    type != IOMMU_DOMAIN_UNMANAGED &amp;&amp;
 	    type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
<span class=del>-	    type != IOMMU_DOMAIN_BLOCKED)
</span><span class=add>+	    type != IOMMU_DOMAIN_BLOCKED &amp;&amp;
+	    type != IOMMU_DOMAIN_SVA)
</span> 		return NULL;
 
 	domain = kzalloc(sizeof(*domain), GFP_KERNEL);
<span class=hunk>@@ -906,6 +1345,9 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
</span> 		pr_warn("IOMMU domain is not empty!\n");
 	}
 
<span class=add>+	if (domain-&gt;mn.ops &amp;&amp; iommu_domain-&gt;mm)
+		mmu_notifier_unregister(&amp;domain-&gt;mn, iommu_domain-&gt;mm);
+
</span> 	if (domain-&gt;pgtbl.cookie)
 		free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
 
<span class=hunk>@@ -1023,14 +1465,29 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
</span> 	 */
 	val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
 
<span class=del>-	dc-&gt;ta = cpu_to_le64(val);
-	dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
</span><span class=add>+	if (ep-&gt;pasid_enabled) {
+		ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
+		ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
+		dc-&gt;ta = 0;
+		dc-&gt;fsc = cpu_to_le64(virt_to_pfn(ep-&gt;pc) |
+		    FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8));
+	} else {
+		dc-&gt;ta = cpu_to_le64(val);
+		dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
+	}
</span> 
 	wmb();
 
 	/* Mark device context as valid, synchronise device context cache. */
 	val = RISCV_IOMMU_DC_TC_V;
 
<span class=add>+	if (ep-&gt;pasid_enabled) {
+		val |= RISCV_IOMMU_DC_TC_EN_ATS |
+		       RISCV_IOMMU_DC_TC_EN_PRI |
+		       RISCV_IOMMU_DC_TC_DPE |
+		       RISCV_IOMMU_DC_TC_PDTV;
+	}
+
</span> 	if (ep-&gt;iommu-&gt;cap &amp; RISCV_IOMMU_CAP_AMO) {
 		val |= RISCV_IOMMU_DC_TC_GADE |
 		       RISCV_IOMMU_DC_TC_SADE;
<span class=hunk>@@ -1051,13 +1508,107 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
</span> 	return 0;
 }
 
<span class=add>+static int riscv_iommu_set_dev_pasid(struct iommu_domain *iommu_domain,
+				     struct device *dev, ioasid_t pasid)
+{
+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+	u64 ta, fsc;
+
+	if (!iommu_domain || !iommu_domain-&gt;mm)
+		return -EINVAL;
+
+	/* Driver uses TC.DPE mode, PASID #0 is incorrect. */
+	if (pasid == 0)
+		return -EINVAL;
+
+	/* Incorrect domain identifier */
+	if ((int)domain-&gt;pscid &lt; 0)
+		return -ENOMEM;
+
+	/* Process Context table should be set for pasid enabled endpoints. */
+	if (!ep || !ep-&gt;pasid_enabled || !ep-&gt;dc || !ep-&gt;pc)
+		return -ENODEV;
+
+	domain-&gt;pasid = pasid;
+	domain-&gt;iommu = ep-&gt;iommu;
+	domain-&gt;mn.ops = &amp;riscv_iommu_mmuops;
+
+	/* register mm notifier */
+	if (mmu_notifier_register(&amp;domain-&gt;mn, iommu_domain-&gt;mm))
+		return -ENODEV;
+
+	/* TODO: get SXL value for the process, use 32 bit or SATP mode */
+	fsc = virt_to_pfn(iommu_domain-&gt;mm-&gt;pgd) | satp_mode;
+	ta = RISCV_IOMMU_PC_TA_V | FIELD_PREP(RISCV_IOMMU_PC_TA_PSCID, domain-&gt;pscid);
+
+	fsc = le64_to_cpu(xchg_relaxed(&amp;(ep-&gt;pc[pasid].fsc), cpu_to_le64(fsc)));
+	ta = le64_to_cpu(xchg_relaxed(&amp;(ep-&gt;pc[pasid].ta), cpu_to_le64(ta)));
+
+	wmb();
+
+	if (ta &amp; RISCV_IOMMU_PC_TA_V) {
+		riscv_iommu_iodir_inv_pasid(ep-&gt;iommu, ep-&gt;devid, pasid);
+		riscv_iommu_iofence_sync(ep-&gt;iommu);
+	}
+
+	dev_info(dev, "domain type %d attached w/ PSCID %u PASID %u\n",
+	    domain-&gt;domain.type, domain-&gt;pscid, domain-&gt;pasid);
+
+	return 0;
+}
+
+static void riscv_iommu_remove_dev_pasid(struct device *dev, ioasid_t pasid)
+{
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+	struct riscv_iommu_command cmd;
+	unsigned long payload = riscv_iommu_ats_inval_all_payload(false);
+	u64 ta;
+
+	/* invalidate TA.V */
+	ta = le64_to_cpu(xchg_relaxed(&amp;(ep-&gt;pc[pasid].ta), 0));
+
+	wmb();
+
+	dev_info(dev, "domain removed w/ PSCID %u PASID %u\n",
+	    (unsigned)FIELD_GET(RISCV_IOMMU_PC_TA_PSCID, ta), pasid);
+
+	/* 1. invalidate PDT entry */
+	riscv_iommu_iodir_inv_pasid(ep-&gt;iommu, ep-&gt;devid, pasid);
+
+	/* 2. invalidate all matching IOATC entries (if PASID was valid) */
+	if (ta &amp; RISCV_IOMMU_PC_TA_V) {
+		riscv_iommu_cmd_inval_vma(&amp;cmd);
+		riscv_iommu_cmd_inval_set_gscid(&amp;cmd, 0);
+		riscv_iommu_cmd_inval_set_pscid(&amp;cmd,
+		    FIELD_GET(RISCV_IOMMU_PC_TA_PSCID, ta));
+		riscv_iommu_post(ep-&gt;iommu, &amp;cmd);
+	}
+
+	/* 3. Wait IOATC flush to happen */
+	riscv_iommu_iofence_sync(ep-&gt;iommu);
+
+	/* 4. ATS invalidation */
+	riscv_iommu_cmd_ats_inval(&amp;cmd);
+	riscv_iommu_cmd_ats_set_dseg(&amp;cmd, ep-&gt;domid);
+	riscv_iommu_cmd_ats_set_rid(&amp;cmd, ep-&gt;devid);
+	riscv_iommu_cmd_ats_set_pid(&amp;cmd, pasid);
+	riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
+	riscv_iommu_post(ep-&gt;iommu, &amp;cmd);
+
+	/* 5. Wait DevATC flush to happen */
+	riscv_iommu_iofence_sync(ep-&gt;iommu);
+}
+
</span> static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
 					  unsigned long *start, unsigned long *end,
 					  size_t *pgsize)
 {
 	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
 	struct riscv_iommu_command cmd;
<span class=add>+	struct riscv_iommu_endpoint *endpoint;
</span> 	unsigned long iova;
<span class=add>+	unsigned long payload;
</span> 
 	if (domain-&gt;mode == RISCV_IOMMU_DC_FSC_MODE_BARE)
 		return;
<span class=hunk>@@ -1065,6 +1616,12 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
</span> 	/* Domain not attached to an IOMMU! */
 	BUG_ON(!domain-&gt;iommu);
 
<span class=add>+	if (start &amp;&amp; end) {
+		payload = riscv_iommu_ats_inval_payload(*start, *end, true);
+	} else {
+		payload = riscv_iommu_ats_inval_all_payload(true);
+	}
+
</span> 	riscv_iommu_cmd_inval_vma(&amp;cmd);
 	riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
 
<span class=hunk>@@ -1078,6 +1635,20 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
</span> 		riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
 	}
 	riscv_iommu_iofence_sync(domain-&gt;iommu);
<span class=add>+
+	/* ATS invalidation for every device and for every translation */
+	list_for_each_entry(endpoint, &amp;domain-&gt;endpoints, domain) {
+		if (!endpoint-&gt;pasid_enabled)
+			continue;
+
+		riscv_iommu_cmd_ats_inval(&amp;cmd);
+		riscv_iommu_cmd_ats_set_dseg(&amp;cmd, endpoint-&gt;domid);
+		riscv_iommu_cmd_ats_set_rid(&amp;cmd, endpoint-&gt;devid);
+		riscv_iommu_cmd_ats_set_pid(&amp;cmd, domain-&gt;pasid);
+		riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
+		riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
+	}
+	riscv_iommu_iofence_sync(domain-&gt;iommu);
</span> }
 
 static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
<span class=hunk>@@ -1310,6 +1881,7 @@ static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned request
</span> static const struct iommu_domain_ops riscv_iommu_domain_ops = {
 	.free = riscv_iommu_domain_free,
 	.attach_dev = riscv_iommu_attach_dev,
<span class=add>+	.set_dev_pasid = riscv_iommu_set_dev_pasid,
</span> 	.map_pages = riscv_iommu_map_pages,
 	.unmap_pages = riscv_iommu_unmap_pages,
 	.iova_to_phys = riscv_iommu_iova_to_phys,
<span class=hunk>@@ -1326,9 +1898,13 @@ static const struct iommu_ops riscv_iommu_ops = {
</span> 	.probe_device = riscv_iommu_probe_device,
 	.probe_finalize = riscv_iommu_probe_finalize,
 	.release_device = riscv_iommu_release_device,
<span class=add>+	.remove_dev_pasid = riscv_iommu_remove_dev_pasid,
</span> 	.device_group = riscv_iommu_device_group,
 	.get_resv_regions = riscv_iommu_get_resv_regions,
 	.of_xlate = riscv_iommu_of_xlate,
<span class=add>+	.dev_enable_feat = riscv_iommu_dev_enable_feat,
+	.dev_disable_feat = riscv_iommu_dev_disable_feat,
+	.page_response = riscv_iommu_page_response,
</span> 	.default_domain_ops = &amp;riscv_iommu_domain_ops,
 };
 
<span class=hunk>@@ -1340,6 +1916,7 @@ void riscv_iommu_remove(struct riscv_iommu_device *iommu)
</span> 	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
 	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
 	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
<span class=add>+	iopf_queue_free(iommu-&gt;pq_work);
</span> }
 
 int riscv_iommu_init(struct riscv_iommu_device *iommu)
<span class=hunk>@@ -1362,6 +1939,12 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 	}
 #endif
 
<span class=add>+	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_PD20)
+		iommu-&gt;iommu.max_pasids = 1u &lt;&lt; 20;
+	else if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_PD17)
+		iommu-&gt;iommu.max_pasids = 1u &lt;&lt; 17;
+	else if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_PD8)
+		iommu-&gt;iommu.max_pasids = 1u &lt;&lt; 8;
</span> 	/*
 	 * Assign queue lengths from module parameters if not already
 	 * set on the device tree.
<span class=hunk>@@ -1387,6 +1970,13 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 		goto fail;
 	if (!(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS))
 		goto no_ats;
<span class=add>+	/* PRI functionally depends on ATS’s capabilities. */
+	iommu-&gt;pq_work = iopf_queue_alloc(dev_name(dev));
+	if (!iommu-&gt;pq_work) {
+		dev_err(dev, "failed to allocate iopf queue\n");
+		ret = -ENOMEM;
+		goto fail;
+	}
</span> 
 	ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_PAGE_REQUEST_QUEUE);
 	if (ret)
<span class=hunk>@@ -1424,5 +2014,6 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
</span> 	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
 	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
 	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
<span class=add>+	iopf_queue_free(iommu-&gt;pq_work);
</span> 	return ret;
 }
<span class=head><a href=#iZ2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
index fe32a4eff14e..83e8d00fd0f8 100644
--- a/drivers/iommu/riscv/iommu.h
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -17,9 +17,11 @@
</span> #include &lt;linux/iova.h&gt;
 #include &lt;linux/io.h&gt;
 #include &lt;linux/idr.h&gt;
<span class=add>+#include &lt;linux/mmu_notifier.h&gt;
</span> #include &lt;linux/list.h&gt;
 #include &lt;linux/iommu.h&gt;
 #include &lt;linux/io-pgtable.h&gt;
<span class=add>+#include &lt;linux/mmu_notifier.h&gt;
</span> 
 #include "iommu-bits.h"
 
<span class=hunk>@@ -76,6 +78,9 @@ struct riscv_iommu_device {
</span> 	unsigned ddt_mode;
 	bool ddtp_in_iomem;
 
<span class=add>+	/* I/O page fault queue */
+	struct iopf_queue *pq_work;
+
</span> 	/* hardware queues */
 	struct riscv_iommu_queue cmdq;
 	struct riscv_iommu_queue fltq;
<span class=hunk>@@ -91,11 +96,14 @@ struct riscv_iommu_domain {
</span> 	struct io_pgtable pgtbl;
 
 	struct list_head endpoints;
<span class=add>+	struct list_head notifiers;
</span> 	struct mutex lock;
<span class=add>+	struct mmu_notifier mn;
</span> 	struct riscv_iommu_device *iommu;
 
 	unsigned mode;		/* RIO_ATP_MODE_* enum */
 	unsigned pscid;		/* RISC-V IOMMU PSCID */
<span class=add>+	ioasid_t pasid;		/* IOMMU_DOMAIN_SVA: Cached PASID */
</span> 
 	pgd_t *pgd_root;	/* page table root pointer */
 };
<span class=hunk>@@ -107,10 +115,16 @@ struct riscv_iommu_endpoint {
</span> 	unsigned domid;    			/* PCI domain number, segment */
 	struct rb_node node;    		/* device tracking node (lookup by devid) */
 	struct riscv_iommu_dc *dc;		/* device context pointer */
<span class=add>+	struct riscv_iommu_pc *pc;		/* process context root, valid if pasid_enabled is true */
</span> 	struct riscv_iommu_device *iommu;	/* parent iommu device */
 
 	struct mutex lock;
 	struct list_head domain;		/* endpoint attached managed domain */
<span class=add>+
+	/* end point info bits */
+	unsigned pasid_bits;
+	unsigned pasid_feat;
+	bool pasid_enabled;
</span> };
 
 /* Helper functions and macros */
-- 
2.34.1


<a href=#mdc9e0e502299442d2ebce9ef9d4f317c16f89a05 id=edc9e0e502299442d2ebce9ef9d4f317c16f89a05>^</a> <a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/aa28455e21f606e6ba7e63268b538d558bcac9a9.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#rdc9e0e502299442d2ebce9ef9d4f317c16f89a05>86+ messages in thread</a></pre><hr><pre><a href=#e2774c76ea4a5513d985e6c918e66c1e3730ad342 id=m2774c76ea4a5513d985e6c918e66c1e3730ad342>*</a> <b>[PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#rdc9e0e502299442d2ebce9ef9d4f317c16f89a05>(8 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#mdc9e0e502299442d2ebce9ef9d4f317c16f89a05>[PATCH 09/11] RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-31  8:02   ` <a href=#m50f9bd691aa7ab3a5a8b02029fa5678c52ad628d>Zong Li</a>
  2023-08-16 21:43   ` <a href=#mf231abf8c9cfd6ea2015f815834751c8c88eb136>Robin Murphy</a>
  2023-07-19 19:33 ` <a href=#m6edef0662c8a8cd238cf3fa0929af7d0305c10f5>[PATCH 11/11] RISC-V: drivers/iommu/riscv: Add G-Stage translation support</a> Tomasz Jeznach
       [not found] ` &lt;<a href=#rfb5bfe039af10b3f60b7ff1b25962fb6b95beec7>CAHCEehJKYu3-GSX2L6L4_VVvYt1MagRgPJvYTbqekrjPw3ZSkA@mail.gmail.com</a>&gt;
  <a href=#r2774c76ea4a5513d985e6c918e66c1e3730ad342>11 siblings, 2 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193533">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193533">linux-kernel</a>, linux,
	Tomasz Jeznach

This change provides basic identity mapping support to
excercise MSI_FLAT hardware capability.

Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a> | 81 +++++++++++++++++++++++++++++++++++++
 <a id=iZ2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a> |  3 ++
 2 files <a href=#e2774c76ea4a5513d985e6c918e66c1e3730ad342>changed</a>, 84 insertions(+)

<span class=head><a href=#iZ2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
index 6042c35be3ca..7b3e3e135cf6 100644
--- a/drivers/iommu/riscv/iommu.c
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -61,6 +61,9 @@ MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
</span> #define RISCV_IOMMU_MAX_PSCID	(1U &lt;&lt; 20)
 static DEFINE_IDA(riscv_iommu_pscids);
 
<span class=add>+/* TODO: Enable MSI remapping */
+#define RISCV_IMSIC_BASE	0x28000000
+
</span> /* 1 second */
 #define RISCV_IOMMU_TIMEOUT	riscv_timebase
 
<span class=hunk>@@ -932,6 +935,72 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
</span>  * Endpoint management
  */
 
<span class=add>+static int riscv_iommu_enable_ir(struct riscv_iommu_endpoint *ep)
+{
+	struct riscv_iommu_device *iommu = ep-&gt;iommu;
+	struct iommu_resv_region *entry;
+	struct irq_domain *msi_domain;
+	u64 val;
+	int i;
+
+	/* Initialize MSI remapping */
+	if (!ep-&gt;dc || !(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_MSI_FLAT))
+		return 0;
+
+	ep-&gt;msi_root = (struct riscv_iommu_msi_pte *)get_zeroed_page(GFP_KERNEL);
+	if (!ep-&gt;msi_root)
+		return -ENOMEM;
+
+	for (i = 0; i &lt; 256; i++) {
+		ep-&gt;msi_root[i].pte = RISCV_IOMMU_MSI_PTE_V |
+		    FIELD_PREP(RISCV_IOMMU_MSI_PTE_M, 3) |
+		    phys_to_ppn(RISCV_IMSIC_BASE + i * PAGE_SIZE);
+	}
+
+	entry = iommu_alloc_resv_region(RISCV_IMSIC_BASE, PAGE_SIZE * 256, 0,
+					IOMMU_RESV_SW_MSI, GFP_KERNEL);
+	if (entry)
+		list_add_tail(&amp;entry-&gt;list, &amp;ep-&gt;regions);
+
+	val = virt_to_pfn(ep-&gt;msi_root) |
+	    FIELD_PREP(RISCV_IOMMU_DC_MSIPTP_MODE, RISCV_IOMMU_DC_MSIPTP_MODE_FLAT);
+	ep-&gt;dc-&gt;msiptp = cpu_to_le64(val);
+
+	/* Single page of MSIPTP, 256 IMSIC files */
+	ep-&gt;dc-&gt;msi_addr_mask = cpu_to_le64(255);
+	ep-&gt;dc-&gt;msi_addr_pattern = cpu_to_le64(RISCV_IMSIC_BASE &gt;&gt; 12);
+	wmb();
+
+	/* set msi domain for the device as isolated. hack. */
+	msi_domain = dev_get_msi_domain(ep-&gt;dev);
+	if (msi_domain) {
+		msi_domain-&gt;flags |= IRQ_DOMAIN_FLAG_ISOLATED_MSI;
+	}
+
+	dev_dbg(ep-&gt;dev, "RV-IR enabled\n");
+
+	ep-&gt;ir_enabled = true;
+
+	return 0;
+}
+
+static void riscv_iommu_disable_ir(struct riscv_iommu_endpoint *ep)
+{
+	if (!ep-&gt;ir_enabled)
+		return;
+
+	ep-&gt;dc-&gt;msi_addr_pattern = 0ULL;
+	ep-&gt;dc-&gt;msi_addr_mask = 0ULL;
+	ep-&gt;dc-&gt;msiptp = 0ULL;
+	wmb();
+
+	dev_dbg(ep-&gt;dev, "RV-IR disabled\n");
+
+	free_pages((unsigned long)ep-&gt;msi_root, 0);
+	ep-&gt;msi_root = NULL;
+	ep-&gt;ir_enabled = false;
+}
+
</span> /* Endpoint features/capabilities */
 static void riscv_iommu_disable_ep(struct riscv_iommu_endpoint *ep)
 {
<span class=hunk>@@ -1226,6 +1295,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
</span> 
 	mutex_init(&amp;ep-&gt;lock);
 	INIT_LIST_HEAD(&amp;ep-&gt;domain);
<span class=add>+	INIT_LIST_HEAD(&amp;ep-&gt;regions);
</span> 
 	if (dev_is_pci(dev)) {
 		ep-&gt;devid = pci_dev_id(to_pci_dev(dev));
<span class=hunk>@@ -1248,6 +1318,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
</span> 	dev_iommu_priv_set(dev, ep);
 	riscv_iommu_add_device(iommu, dev);
 	riscv_iommu_enable_ep(ep);
<span class=add>+	riscv_iommu_enable_ir(ep);
</span> 
 	return &amp;iommu-&gt;iommu;
 }
<span class=hunk>@@ -1279,6 +1350,7 @@ static void riscv_iommu_release_device(struct device *dev)
</span> 		riscv_iommu_iodir_inv_devid(iommu, ep-&gt;devid);
 	}
 
<span class=add>+	riscv_iommu_disable_ir(ep);
</span> 	riscv_iommu_disable_ep(ep);
 
 	/* Remove endpoint from IOMMU tracking structures */
<span class=hunk>@@ -1301,6 +1373,15 @@ static struct iommu_group *riscv_iommu_device_group(struct device *dev)
</span> 
 static void riscv_iommu_get_resv_regions(struct device *dev, struct list_head *head)
 {
<span class=add>+	struct iommu_resv_region *entry, *new_entry;
+	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
+
+	list_for_each_entry(entry, &amp;ep-&gt;regions, list) {
+		new_entry = kmemdup(entry, sizeof(*entry), GFP_KERNEL);
+		if (new_entry)
+			list_add_tail(&amp;new_entry-&gt;list, head);
+	}
+
</span> 	iommu_dma_get_resv_regions(dev, head);
 }
 
<span class=head><a href=#iZ2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
index 83e8d00fd0f8..55418a1144fb 100644
--- a/drivers/iommu/riscv/iommu.h
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -117,14 +117,17 @@ struct riscv_iommu_endpoint {
</span> 	struct riscv_iommu_dc *dc;		/* device context pointer */
 	struct riscv_iommu_pc *pc;		/* process context root, valid if pasid_enabled is true */
 	struct riscv_iommu_device *iommu;	/* parent iommu device */
<span class=add>+	struct riscv_iommu_msi_pte *msi_root;	/* interrupt re-mapping */
</span> 
 	struct mutex lock;
 	struct list_head domain;		/* endpoint attached managed domain */
<span class=add>+	struct list_head regions;		/* reserved regions, interrupt remapping window */
</span> 
 	/* end point info bits */
 	unsigned pasid_bits;
 	unsigned pasid_feat;
 	bool pasid_enabled;
<span class=add>+	bool ir_enabled;
</span> };
 
 /* Helper functions and macros */
-- 
2.34.1


<a href=#m2774c76ea4a5513d985e6c918e66c1e3730ad342 id=e2774c76ea4a5513d985e6c918e66c1e3730ad342>^</a> <a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/660b7a8707e494a6bb2706e10569a7414c3640a7.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#r2774c76ea4a5513d985e6c918e66c1e3730ad342>86+ messages in thread</a></pre><hr><pre><a href=#e6edef0662c8a8cd238cf3fa0929af7d0305c10f5 id=m6edef0662c8a8cd238cf3fa0929af7d0305c10f5>*</a> <b>[PATCH 11/11] RISC-V: drivers/iommu/riscv: Add G-Stage translation support</b>
  2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
                   ` <a href=#r2774c76ea4a5513d985e6c918e66c1e3730ad342>(9 preceding siblings ...)</a>
  2023-07-19 19:33 ` <a href=#m2774c76ea4a5513d985e6c918e66c1e3730ad342>[PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</a> Tomasz Jeznach
<b>@ 2023-07-19 19:33 ` Tomasz Jeznach</b>
  2023-07-31  8:12   ` <a href=#m1a63028351b0e86a470c474db2d582acd5369901>Zong Li</a>
  2023-08-16 21:13   ` <a href=#m0c898cce80d8dc67ea1c5e12243227adb68db208>Robin Murphy</a>
       [not found] ` &lt;<a href=#rfb5bfe039af10b3f60b7ff1b25962fb6b95beec7>CAHCEehJKYu3-GSX2L6L4_VVvYt1MagRgPJvYTbqekrjPw3ZSkA@mail.gmail.com</a>&gt;
  <a href=#r6edef0662c8a8cd238cf3fa0929af7d0305c10f5>11 siblings, 2 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 19:33 UTC (<a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/raw>raw</a>)
  To: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230719193538">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230719193538">linux-kernel</a>, linux,
	Tomasz Jeznach

This change introduces 2nd stage translation configuration
support, enabling nested translation for IOMMU hardware.
Pending integration with VMM IOMMUFD interfaces to manage
1st stage translation and IOMMU virtialization interfaces.

Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
---
 <a id=iZ2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c href=#Z2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>drivers/iommu/riscv/iommu.c</a> | 58 ++++++++++++++++++++++++++++---------
 <a id=iZ2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h href=#Z2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>drivers/iommu/riscv/iommu.h</a> |  3 +-
 2 files <a href=#e6edef0662c8a8cd238cf3fa0929af7d0305c10f5>changed</a>, 46 insertions(+), 15 deletions(-)

<span class=head><a href=#iZ2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c id=Z2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.c>diff</a> --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
index 7b3e3e135cf6..3ca2f0194d3c 100644
--- a/drivers/iommu/riscv/iommu.c
+++ b/drivers/iommu/riscv/iommu.c
</span><span class=hunk>@@ -1418,6 +1418,19 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
</span> 	return &amp;domain-&gt;domain;
 }
 
<span class=add>+/* mark domain as second-stage translation */
+static int riscv_iommu_enable_nesting(struct iommu_domain *iommu_domain)
+{
+	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
+
+	mutex_lock(&amp;domain-&gt;lock);
+	if (list_empty(&amp;domain-&gt;endpoints))
+		domain-&gt;g_stage = true;
+	mutex_unlock(&amp;domain-&gt;lock);
+
+	return domain-&gt;g_stage ? 0 : -EBUSY;
+}
+
</span> static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
 {
 	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
<span class=hunk>@@ -1433,7 +1446,7 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
</span> 		free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
 
 	if (domain-&gt;pgd_root)
<span class=del>-		free_pages((unsigned long)domain-&gt;pgd_root, 0);
</span><span class=add>+		free_pages((unsigned long)domain-&gt;pgd_root, domain-&gt;g_stage ? 2 : 0);
</span> 
 	if ((int)domain-&gt;pscid &gt; 0)
 		ida_free(&amp;riscv_iommu_pscids, domain-&gt;pscid);
<span class=hunk>@@ -1483,7 +1496,8 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
</span> 
 	/* TODO: Fix this for RV32 */
 	domain-&gt;mode = satp_mode &gt;&gt; 60;
<span class=del>-	domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO, 0);
</span><span class=add>+	domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO,
+						      domain-&gt;g_stage ? 2 : 0);
</span> 
 	if (!domain-&gt;pgd_root)
 		return -ENOMEM;
<span class=hunk>@@ -1499,6 +1513,8 @@ static u64 riscv_iommu_domain_atp(struct riscv_iommu_domain *domain)
</span> 	u64 atp = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, domain-&gt;mode);
 	if (domain-&gt;mode != RISCV_IOMMU_DC_FSC_MODE_BARE)
 		atp |= FIELD_PREP(RISCV_IOMMU_DC_FSC_PPN, virt_to_pfn(domain-&gt;pgd_root));
<span class=add>+	if (domain-&gt;g_stage)
+		atp |= FIELD_PREP(RISCV_IOMMU_DC_IOHGATP_GSCID, domain-&gt;pscid);
</span> 	return atp;
 }
 
<span class=hunk>@@ -1541,20 +1557,30 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
</span> 	if (!dc)
 		return -ENODEV;
 
<span class=del>-	/*
-	 * S-Stage translation table. G-Stage remains unmodified (BARE).
-	 */
-	val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
-
-	if (ep-&gt;pasid_enabled) {
-		ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
-		ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
</span><span class=add>+	if (domain-&gt;g_stage) {
+		/*
+		 * Enable G-Stage translation with initial pass-through mode
+		 * for S-Stage. VMM is responsible for more restrictive
+		 * guest VA translation scheme configuration.
+		 */
</span> 		dc-&gt;ta = 0;
<span class=del>-		dc-&gt;fsc = cpu_to_le64(virt_to_pfn(ep-&gt;pc) |
-		    FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8));
</span><span class=add>+		dc-&gt;fsc = 0ULL; /* RISCV_IOMMU_DC_FSC_MODE_BARE */ ;
+		dc-&gt;iohgatp = cpu_to_le64(riscv_iommu_domain_atp(domain));
</span> 	} else {
<span class=del>-		dc-&gt;ta = cpu_to_le64(val);
-		dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
</span><span class=add>+		/* S-Stage translation table. G-Stage remains unmodified. */
+		if (ep-&gt;pasid_enabled) {
+			val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
+			ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
+			ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
+			dc-&gt;ta = 0;
+			val = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE,
+					  RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8);
+			dc-&gt;fsc = cpu_to_le64(val | virt_to_pfn(ep-&gt;pc));
+		} else {
+			val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
+			dc-&gt;ta = cpu_to_le64(val);
+			dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
+		}
</span> 	}
 
 	wmb();
<span class=hunk>@@ -1599,6 +1625,9 @@ static int riscv_iommu_set_dev_pasid(struct iommu_domain *iommu_domain,
</span> 	if (!iommu_domain || !iommu_domain-&gt;mm)
 		return -EINVAL;
 
<span class=add>+	if (domain-&gt;g_stage)
+		return -EINVAL;
+
</span> 	/* Driver uses TC.DPE mode, PASID #0 is incorrect. */
 	if (pasid == 0)
 		return -EINVAL;
<span class=hunk>@@ -1969,6 +1998,7 @@ static const struct iommu_domain_ops riscv_iommu_domain_ops = {
</span> 	.iotlb_sync = riscv_iommu_iotlb_sync,
 	.iotlb_sync_map = riscv_iommu_iotlb_sync_map,
 	.flush_iotlb_all = riscv_iommu_flush_iotlb_all,
<span class=add>+	.enable_nesting = riscv_iommu_enable_nesting,
</span> };
 
 static const struct iommu_ops riscv_iommu_ops = {
<span class=head><a href=#iZ2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h id=Z2e.:..:0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach::40rivosinc.com:1drivers:iommu:riscv:iommu.h>diff</a> --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
index 55418a1144fb..55e5aafea5bc 100644
--- a/drivers/iommu/riscv/iommu.h
+++ b/drivers/iommu/riscv/iommu.h
</span><span class=hunk>@@ -102,8 +102,9 @@ struct riscv_iommu_domain {
</span> 	struct riscv_iommu_device *iommu;
 
 	unsigned mode;		/* RIO_ATP_MODE_* enum */
<span class=del>-	unsigned pscid;		/* RISC-V IOMMU PSCID */
</span><span class=add>+	unsigned pscid;		/* RISC-V IOMMU PSCID / GSCID */
</span> 	ioasid_t pasid;		/* IOMMU_DOMAIN_SVA: Cached PASID */
<span class=add>+	bool g_stage;		/* 2nd stage translation domain */
</span> 
 	pgd_t *pgd_root;	/* page table root pointer */
 };
-- 
2.34.1


<a href=#m6edef0662c8a8cd238cf3fa0929af7d0305c10f5 id=e6edef0662c8a8cd238cf3fa0929af7d0305c10f5>^</a> <a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/>permalink</a> <a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/#R>reply</a> <a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/#related>related</a>	[<a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/0c391072fe0be52b3bdf3d826e4313d960aecba0.1689792825.git.tjeznach@rivosinc.com/t/#u>nested</a>] <a href=#r6edef0662c8a8cd238cf3fa0929af7d0305c10f5>86+ messages in thread</a></pre><hr><pre><a href=#e88a4003327a711a111ee2c4d48bf98696a66bc8b id=m88a4003327a711a111ee2c4d48bf98696a66bc8b>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-19 19:33 ` <a href=#mbf8dc4098fb09b87b2618c5c545ae882f11b114b>[PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</a> Tomasz Jeznach
<b>@ 2023-07-19 20:19   ` Conor Dooley</b>
       [not found]     ` &lt;<a href=#red9fb23cde273365376c37e6496225c853d2784d>CAH2o1u6CZSb7pXcaXmh7dJQmNZYh3uORk4x7vJPrb+uCwFdU5g@mail.gmail.com</a>&gt;
  2023-07-19 21:37     ` <a href=#md805d888f455929658b15f37f3dec4e04cbef73e>Rob Herring</a>
  2023-07-24  8:03   ` <a href=#mefb742c2ddae58fd3cf54da7451501e4bd3a30a7>Zong Li</a>
  <a href=#r88a4003327a711a111ee2c4d48bf98696a66bc8b>1 sibling, 2 replies; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-19 20:19 UTC (<a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719202033">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230719202033">linux-riscv</a>, robh+dt,
	krzysztof.kozlowski+dt, <a href="https://lore.kernel.org/linux-devicetree/?t=20230719202033">devicetree</a>

<a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 5717 bytes --]</a>

Hey Tomasz,

On Wed, Jul 19, 2023 at 12:33:47PM -0700, Tomasz Jeznach wrote:
<span class=q>&gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; 
&gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; defined by the RISC-V IOMMU specification.
&gt; 
&gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
</span>
Your signoff is missing from here.

Secondly, as get_maintainer.pl would have told you, dt-bindings patches
need to be sent to the dt-binding maintainers and list.
+CC maintainers &amp; list.

Thirdly, dt-binding patches should come before their users.

<span class=q>&gt; ---
&gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt;  1 file changed, 146 insertions(+)
&gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; 
&gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; new file mode 100644
&gt; index 000000000000..8a9aedb61768
&gt; --- /dev/null
&gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; @@ -0,0 +1,146 @@
&gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; +%YAML 1.2
&gt; +---
&gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; +
&gt; +title: RISC-V IOMMU Implementation
&gt; +
&gt; +maintainers:
&gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
</span>
What about Anup, who seems to have written this?
Or your co-authors of the drivers?

<span class=q>&gt; +
&gt; +description:
&gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt; +  which can be a regular platform device or a PCI device connected to
&gt; +  the host root port.
&gt; +
&gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; +  both PCI and platform devices.
&gt; +
&gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; +
&gt; +properties:
&gt; +  compatible:
&gt; +    oneOf:
&gt; +      - description: RISC-V IOMMU as a platform device
&gt; +        items:
&gt; +          - enum:
&gt; +              - vendor,chip-iommu
</span>
These dummy compatibles are not valid, as was pointed out to Anup on
the AIA series. Please go look at what was done there instead:
<a href=https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/>https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/</a>

<span class=q>&gt; +          - const: riscv,iommu
&gt; +
&gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; +        items:
&gt; +          - enum:
&gt; +              - vendor,chip-pci-iommu
&gt; +          - const: riscv,pci-iommu
</span>
I'm not really au fait with the arm smmu stuff, but do any of its
versions support being connected to a root port? 

<span class=q>&gt; +  reg:
&gt; +    maxItems: 1
&gt; +    description:
&gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; +      address of registers.
&gt; +
&gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
&gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
&gt; +
&gt; +  '#iommu-cells':
&gt; +    const: 2
&gt; +    description: |
</span>
|s are only needed where formatting needs to be preserved.

<span class=q>&gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; +      device IDs.
&gt; +
&gt; +  interrupts:
&gt; +    minItems: 1
&gt; +    maxItems: 16
</span>
What are any of these interrupts?

<span class=q>&gt; +    description:
&gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; +
&gt; +  msi-parent:
&gt; +    description:
&gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; +      considered only when the interrupts property is absent.
&gt; +
&gt; +  dma-coherent:
</span>
RISC-V is dma-coherent by default, should this not be dma-noncoherent
instead?

<span class=q>&gt; +    description:
&gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; +      are cache coherent with the CPU.
&gt; +
&gt; +  power-domains:
&gt; +    maxItems: 1
&gt; +
&gt; +required:
&gt; +  - compatible
&gt; +  - reg
&gt; +  - '#iommu-cells'
&gt; +
&gt; +additionalProperties: false
&gt; +
&gt; +examples:
&gt; +  - |
&gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; +    immu1: iommu@1bccd000 {
</span>
Why is this "immu"? typo or intentional?

<span class=q>&gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; +        #iommu-cells = &lt;2&gt;;
&gt; +    };
&gt; +
&gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; +    master1 {
&gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; +    };
&gt; +
&gt; +  - |
&gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; +    immu2: iommu@1bcdd000 {
&gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; +        #iommu-cells = &lt;2&gt;;
&gt; +    };
&gt; +
&gt; +    bus {
&gt; +        #address-cells = &lt;2&gt;;
&gt; +        #size-cells = &lt;2&gt;;
&gt; +
&gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; +        master1 {
&gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; +        };
&gt; +
&gt; +        pcie@40000000 {
&gt; +            compatible = "pci-host-cam-generic";
&gt; +            device_type = "pci";
&gt; +            #address-cells = &lt;3&gt;;
&gt; +            #size-cells = &lt;2&gt;;
&gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; +
&gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
</span>
These sort of comments seem to just repeat what address-cells &amp;
size-cells has already said, no?

Thanks,
Conor.

<a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m88a4003327a711a111ee2c4d48bf98696a66bc8b id=e88a4003327a711a111ee2c4d48bf98696a66bc8b>^</a> <a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230719-unnoticed-scion-744fdf509151@spud/t/#u>nested</a>] <a href=#r88a4003327a711a111ee2c4d48bf98696a66bc8b>86+ messages in thread</a></pre><hr><pre><a href=#e07e17b6f91977601733160534a5f82428a4a05be id=m07e17b6f91977601733160534a5f82428a4a05be>*</a> <b>Re: [PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</b>
  2023-07-19 19:33 ` <a href=#m20d2511b6c12906189c92aa1f0e9ce0c668c5a83>[PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</a> Tomasz Jeznach
<b>@ 2023-07-19 20:22   ` Conor Dooley</b>
  2023-07-19 21:07     ` <a href=#me9f86974c28c0ca73e4be20e889e9ce55242ed8a>Tomasz Jeznach</a>
  <a href=#r07e17b6f91977601733160534a5f82428a4a05be>0 siblings, 1 reply; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-19 20:22 UTC (<a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719202248">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230719202248">linux-riscv</a>

<a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 1196 bytes --]</a>

On Wed, Jul 19, 2023 at 12:33:46PM -0700, Tomasz Jeznach wrote:

$subject: RISC-V: arch/riscv/config: enable RISC-V IOMMU support

Please look at any other commits to the files you are touching
and use a subject line that emulates them. In this case, try
git log --oneline --no-merges -- arch/riscv/configs/
Same goes for the odd pattern in your driver patches.

Also, the patch may be trivial, but you still need to sign off on it
and provide a commit message.

Thanks,
Conor.

<span class=q>&gt; ---
&gt;  arch/riscv/configs/defconfig | 1 +
&gt;  1 file changed, 1 insertion(+)
&gt; 
&gt; diff --git a/arch/riscv/configs/defconfig b/arch/riscv/configs/defconfig
&gt; index 0a0107460a5c..1a0c3b24329f 100644
&gt; --- a/arch/riscv/configs/defconfig
&gt; +++ b/arch/riscv/configs/defconfig
&gt; @@ -178,6 +178,7 @@ CONFIG_VIRTIO_PCI=y
&gt;  CONFIG_VIRTIO_BALLOON=y
&gt;  CONFIG_VIRTIO_INPUT=y
&gt;  CONFIG_VIRTIO_MMIO=y
&gt; +CONFIG_RISCV_IOMMU=y
&gt;  CONFIG_SUN8I_DE2_CCU=m
&gt;  CONFIG_SUN50I_IOMMU=y
&gt;  CONFIG_RPMSG_CHAR=y
&gt; -- 
&gt; 2.34.1
&gt; 
&gt; 
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m07e17b6f91977601733160534a5f82428a4a05be id=e07e17b6f91977601733160534a5f82428a4a05be>^</a> <a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230719-marbled-drivable-804aacbafee2@spud/t/#u>nested</a>] <a href=#r07e17b6f91977601733160534a5f82428a4a05be>86+ messages in thread</a></pre><hr><pre><a href=#e475b3879d13e54e5f54247069b241516ceaf814e id=m475b3879d13e54e5f54247069b241516ceaf814e>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
<b>@ 2023-07-19 20:49   ` Conor Dooley</b>
  2023-07-19 21:43     ` <a href=#m7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>Tomasz Jeznach</a>
  2023-07-20 10:38   ` <a href=#mce7ec12a032abfaca43b25278ff9762eb0fc2b37>Baolu Lu</a>
                     ` <a href=#rce7ec12a032abfaca43b25278ff9762eb0fc2b37>(6 subsequent siblings)</a>
  <a href=#r475b3879d13e54e5f54247069b241516ceaf814e>7 siblings, 1 reply; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-19 20:49 UTC (<a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719205043">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230719205043">linux-riscv</a>

<a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 2710 bytes --]</a>

Hey Tomasz,

On Wed, Jul 19, 2023 at 12:33:45PM -0700, Tomasz Jeznach wrote:
<span class=q>&gt; The patch introduces skeleton IOMMU device driver implementation as defined
&gt; by RISC-V IOMMU Architecture Specification, Version 1.0 [1], with minimal support
&gt; for pass-through mapping, basic initialization and bindings for platform and PCIe
&gt; hardware implementations.
&gt; 
&gt; Series of patches following specification evolution has been reorganized to provide
&gt; functional separation of implemented blocks, compliant with ratified specification.
&gt; 
&gt; This and following patch series includes code contributed by: Nick Kossifidis
&gt; &lt;mick@ics.forth.gr&gt; (iommu-platform device, number of specification clarification
&gt; and bugfixes and readability improvements), Sebastien Boeuf &lt;seb@rivosinc.com&gt; (page
&gt; table creation, ATS/PGR flow).
&gt; 
&gt; Complete history can be found at the maintainer's repository branch [2].
&gt; 
&gt; Device driver enables RISC-V 32/64 support for memory translation for DMA capable
&gt; PCI and platform devices, multilevel device directory table, process directory,
&gt; shared virtual address support, wired and message signaled interrupt for translation
&gt; I/O fault, page request interface and command processing.
&gt; 
&gt; Matching RISCV-V IOMMU device emulation implementation is available for QEMU project,
&gt; along with educational device extensions for PASID ATS/PRI support [3].
</span>
This commit message reads like a cover letter IMO. At whatever point
you send a v2, could you re-write this focusing on what is done in the
patch itself?

Also, since I am not going to reply to any of these iommu driver patches
in a meaningful capacity, please run checkpatch.pl on your work. There
are well over 100 style etc complaints that it has highlighted. Sparse
has also gone a bit nuts, with many warnings along the lines of:
drivers/iommu/riscv/iommu.c:1568:29: warning: incorrect type in assignment (different base types)
drivers/iommu/riscv/iommu.c:1568:29:    expected unsigned long long [usertype] iohgatp
drivers/iommu/riscv/iommu.c:1568:29:    got restricted __le64 [usertype]

I can provide you the full list when the patchwork automation has run
through the series.

Anyway, what I wanted to ask was whether it was valid to use the IOMMU
in a system if Ziommu is not present in whatever the ISA extension
communication mechanism is? Eg, riscv,isa or the ISA string property in
the ACPI tables.

Thanks,
Conor.

<span class=q>&gt; References:
&gt;  - [1] <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
&gt;  - [2] <a href=https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu</a>
&gt;  - [3] <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu</a>
</span>
FYI, we have the Link: tag/trailer for this.


<a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m475b3879d13e54e5f54247069b241516ceaf814e id=e475b3879d13e54e5f54247069b241516ceaf814e>^</a> <a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230719-confront-grass-6d0eb304b94f@spud/t/#u>nested</a>] <a href=#r475b3879d13e54e5f54247069b241516ceaf814e>86+ messages in thread</a></pre><hr><pre><a href=#ebba42ec3ff996c3818591fc58cabe98ad69cb42a id=mbba42ec3ff996c3818591fc58cabe98ad69cb42a>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
       [not found]     ` &lt;<a href=#red9fb23cde273365376c37e6496225c853d2784d>CAH2o1u6CZSb7pXcaXmh7dJQmNZYh3uORk4x7vJPrb+uCwFdU5g@mail.gmail.com</a>&gt;
<b>@ 2023-07-19 20:57       ` Conor Dooley</b>
  <a href=#rbba42ec3ff996c3818591fc58cabe98ad69cb42a>0 siblings, 0 replies; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-19 20:57 UTC (<a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719205810">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230719205810">linux-riscv</a>, robh+dt,
	krzysztof.kozlowski+dt, <a href="https://lore.kernel.org/linux-devicetree/?t=20230719205810">devicetree</a>

<a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 8126 bytes --]</a>

On Wed, Jul 19, 2023 at 01:52:28PM -0700, Tomasz Jeznach wrote:
<span class=q>&gt; On Wed, Jul 19, 2023 at 1:19 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
&gt; 
&gt; &gt; Hey Tomasz,
&gt; &gt;
&gt; &gt; On Wed, Jul 19, 2023 at 12:33:47PM -0700, Tomasz Jeznach wrote:
&gt; &gt; &gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt;
&gt; &gt; &gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; &gt; &gt; defined by the RISC-V IOMMU specification.
&gt; &gt; &gt;
&gt; &gt; &gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt;
&gt; &gt; Your signoff is missing from here.
&gt; &gt;
&gt; &gt; Secondly, as get_maintainer.pl would have told you, dt-bindings patches
&gt; &gt; need to be sent to the dt-binding maintainers and list.
&gt; &gt; +CC maintainers &amp; list.
&gt; &gt;
&gt; &gt; Thirdly, dt-binding patches should come before their users.
&gt; &gt;
&gt; 
&gt; 
&gt; Thank you for pointing out and adding DT maintainers.
&gt; The signoff is definitely missing, and I'll will amend with other fixes /
&gt; reordering.
</span>
Yeah, please wait until you get actual feedback on the drivers etc
though before you do that.

Also, don't send html emails to the mailing lists. They will be rejected
and those outside of direct-cc will not see the emails.

<span class=q>&gt; &gt; &gt; ---
&gt; &gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt; &gt; &gt;  1 file changed, 146 insertions(+)
&gt; &gt; &gt;  create mode 100644
&gt; &gt; Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt;
&gt; &gt; &gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; new file mode 100644
&gt; &gt; &gt; index 000000000000..8a9aedb61768
&gt; &gt; &gt; --- /dev/null
&gt; &gt; &gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; @@ -0,0 +1,146 @@
&gt; &gt; &gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; &gt; &gt; +%YAML 1.2
&gt; &gt; &gt; +---
&gt; &gt; &gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; &gt; &gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; &gt; &gt; +
&gt; &gt; &gt; +title: RISC-V IOMMU Implementation
&gt; &gt; &gt; +
&gt; &gt; &gt; +maintainers:
&gt; &gt; &gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt;
&gt; &gt; What about Anup, who seems to have written this?
&gt; &gt; Or your co-authors of the drivers?
&gt; &gt;
&gt; &gt;
&gt; Anup provided only device tree riscv,iommu bindings proposal, but handed
&gt; over its maintenance.
&gt; 
&gt; &gt; +
&gt; &gt; &gt; +description:
&gt; &gt; &gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt; &gt; &gt; +  which can be a regular platform device or a PCI device connected to
&gt; &gt; &gt; +  the host root port.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  The RISC-V IOMMU provides two stage translation, device directory
&gt; &gt; table,
&gt; &gt; &gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; &gt; &gt; +  both PCI and platform devices.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; &gt; &gt; +
&gt; &gt; &gt; +properties:
&gt; &gt; &gt; +  compatible:
&gt; &gt; &gt; +    oneOf:
&gt; &gt; &gt; +      - description: RISC-V IOMMU as a platform device
&gt; &gt; &gt; +        items:
&gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; +              - vendor,chip-iommu
&gt; &gt;
&gt; &gt; These dummy compatibles are not valid, as was pointed out to Anup on
&gt; &gt; the AIA series. Please go look at what was done there instead:
&gt; &gt;
&gt; &gt; <a href=https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/>https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/</a>
&gt; &gt;
&gt; &gt;
&gt; Thank you, good pointer, seams like the same comments apply here. Will go
&gt; through the discussion and update.
&gt; 
&gt; 
&gt; &gt; &gt; +          - const: riscv,iommu
&gt; &gt; &gt; +
&gt; &gt; &gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; &gt; &gt; +        items:
&gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; +              - vendor,chip-pci-iommu
&gt; &gt; &gt; +          - const: riscv,pci-iommu
&gt; &gt;
&gt; &gt; I'm not really au fait with the arm smmu stuff, but do any of its
&gt; &gt; versions support being connected to a root port?
&gt; &gt;
&gt; &gt;
&gt; RISC-V IOMMU allows them to be connected to the root port, or presented as
&gt; a platform device.
</span>
That is not quite what I asked... What I want to know is why we are
doing something different to Arm's SMMU stuff &amp; whether it is because
RISC-V has extra capabilities, or the binding itself is flawed.

(There's no more comments from me below, just making sure the mail's
contents reaches lore)

Cheers,
Conor.

<span class=q>&gt; &gt; &gt; +  reg:
&gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO
&gt; &gt; base
&gt; &gt; &gt; +      address of registers.
&gt; &gt; &gt; +
&gt; &gt; &gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI
&gt; &gt; bridge
&gt; &gt; &gt; +      details as described in
&gt; &gt; Documentation/devicetree/bindings/pci/pci.txt
&gt; &gt; &gt; +
&gt; &gt; &gt; +  '#iommu-cells':
&gt; &gt; &gt; +    const: 2
&gt; &gt; &gt; +    description: |
&gt; &gt;
&gt; &gt; |s are only needed where formatting needs to be preserved.
&gt; &gt;
&gt; &gt; &gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; &gt; &gt; +      device IDs.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  interrupts:
&gt; &gt; &gt; +    minItems: 1
&gt; &gt; &gt; +    maxItems: 16
&gt; &gt;
&gt; &gt; What are any of these interrupts?
&gt; &gt;
&gt; &gt;
&gt; I'll add a description to the file. In short queue interfaces signalling to
&gt; the driver.
&gt; 
&gt; 
&gt; &gt; +    description:
&gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; &gt; &gt; +
&gt; &gt; &gt; +  msi-parent:
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; &gt; &gt; +      considered only when the interrupts property is absent.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  dma-coherent:
&gt; &gt;
&gt; &gt; RISC-V is dma-coherent by default, should this not be dma-noncoherent
&gt; &gt; instead?
&gt; &gt;
&gt; &gt;
&gt; Very valid comment. I'm ok to reverse the flag unless anyone objects.
&gt; 
&gt; 
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      Present if page table walks and DMA accessed made by the RISC-V
&gt; &gt; IOMMU
&gt; &gt; &gt; +      are cache coherent with the CPU.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  power-domains:
&gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; +
&gt; &gt; &gt; +required:
&gt; &gt; &gt; +  - compatible
&gt; &gt; &gt; +  - reg
&gt; &gt; &gt; +  - '#iommu-cells'
&gt; &gt; &gt; +
&gt; &gt; &gt; +additionalProperties: false
&gt; &gt; &gt; +
&gt; &gt; &gt; +examples:
&gt; &gt; &gt; +  - |
&gt; &gt; &gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; &gt; &gt; +    immu1: iommu@1bccd000 {
&gt; &gt;
&gt; &gt; Why is this "immu"? typo or intentional?
&gt; &gt;
&gt; 
&gt; I guess there was no particular naming schema here, but I might defer this
&gt; question to the author.
&gt; 
&gt; 
&gt; &gt;
&gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; &gt; &gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; &gt; &gt; +    master1 {
&gt; &gt; &gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +  - |
&gt; &gt; &gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; &gt; &gt; +    immu2: iommu@1bcdd000 {
&gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +    bus {
&gt; &gt; &gt; +        #address-cells = &lt;2&gt;;
&gt; &gt; &gt; +        #size-cells = &lt;2&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; &gt; &gt; +        master1 {
&gt; &gt; &gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; &gt; &gt; +        };
&gt; &gt; &gt; +
&gt; &gt; &gt; +        pcie@40000000 {
&gt; &gt; &gt; +            compatible = "pci-host-cam-generic";
&gt; &gt; &gt; +            device_type = "pci";
&gt; &gt; &gt; +            #address-cells = &lt;3&gt;;
&gt; &gt; &gt; +            #size-cells = &lt;2&gt;;
&gt; &gt; &gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt;
&gt; &gt; These sort of comments seem to just repeat what address-cells &amp;
&gt; &gt; size-cells has already said, no?
&gt; &gt;
&gt; &gt;
&gt; Correct.
&gt; 
&gt; 
&gt; 
&gt; &gt; Thanks,
&gt; &gt; Conor.
&gt; &gt;
&gt; 
&gt; 
&gt; Thank you Conor for prompt response and comments.
&gt; I'll address them in the next version.
&gt; 
&gt; - Tomasz
</span>
<a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#mbba42ec3ff996c3818591fc58cabe98ad69cb42a id=ebba42ec3ff996c3818591fc58cabe98ad69cb42a>^</a> <a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230719-efficient-anew-8a67ab21a3aa@spud/t/#u>nested</a>] <a href=#rbba42ec3ff996c3818591fc58cabe98ad69cb42a>86+ messages in thread</a></pre><hr><pre><a href=#ee9f86974c28c0ca73e4be20e889e9ce55242ed8a id=me9f86974c28c0ca73e4be20e889e9ce55242ed8a>*</a> <b>Re: [PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</b>
  2023-07-19 20:22   ` <a href=#m07e17b6f91977601733160534a5f82428a4a05be>Conor Dooley</a>
<b>@ 2023-07-19 21:07     ` Tomasz Jeznach</b>
  2023-07-20  6:37       ` <a href=#mca75c01519c7dca768f770f0a0b7b6bb9c709a39>Krzysztof Kozlowski</a>
  <a href=#re9f86974c28c0ca73e4be20e889e9ce55242ed8a>0 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 21:07 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u4107Eve67gxEg1rtCLFyaABFsmfop1-ko=GT5wzeajiQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u4107Eve67gxEg1rtCLFyaABFsmfop1-ko=GT5wzeajiQ@mail.gmail.com/raw">raw</a>)
  To: Conor Dooley
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719210718">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230719210718">linux-riscv</a>

On Wed, Jul 19, 2023 at 1:22 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
<span class=q>&gt;
&gt; On Wed, Jul 19, 2023 at 12:33:46PM -0700, Tomasz Jeznach wrote:
&gt;
&gt; $subject: RISC-V: arch/riscv/config: enable RISC-V IOMMU support
&gt;
&gt; Please look at any other commits to the files you are touching
&gt; and use a subject line that emulates them. In this case, try
&gt; git log --oneline --no-merges -- arch/riscv/configs/
&gt; Same goes for the odd pattern in your driver patches.
&gt;
&gt; Also, the patch may be trivial, but you still need to sign off on it
&gt; and provide a commit message.
&gt;
</span>
ack. added to-do the list for v2.

Thank you,
- Tomasz

<span class=q>&gt; Thanks,
&gt; Conor.
&gt;
&gt; &gt; ---
&gt; &gt;  arch/riscv/configs/defconfig | 1 +
&gt; &gt;  1 file changed, 1 insertion(+)
&gt; &gt;
&gt; &gt; diff --git a/arch/riscv/configs/defconfig b/arch/riscv/configs/defconfig
&gt; &gt; index 0a0107460a5c..1a0c3b24329f 100644
&gt; &gt; --- a/arch/riscv/configs/defconfig
&gt; &gt; +++ b/arch/riscv/configs/defconfig
&gt; &gt; @@ -178,6 +178,7 @@ CONFIG_VIRTIO_PCI=y
&gt; &gt;  CONFIG_VIRTIO_BALLOON=y
&gt; &gt;  CONFIG_VIRTIO_INPUT=y
&gt; &gt;  CONFIG_VIRTIO_MMIO=y
&gt; &gt; +CONFIG_RISCV_IOMMU=y
&gt; &gt;  CONFIG_SUN8I_DE2_CCU=m
&gt; &gt;  CONFIG_SUN50I_IOMMU=y
&gt; &gt;  CONFIG_RPMSG_CHAR=y
&gt; &gt; --
&gt; &gt; 2.34.1
&gt; &gt;
&gt; &gt;
&gt; &gt; _______________________________________________
&gt; &gt; linux-riscv mailing list
&gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#me9f86974c28c0ca73e4be20e889e9ce55242ed8a id=ee9f86974c28c0ca73e4be20e889e9ce55242ed8a>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u4107Eve67gxEg1rtCLFyaABFsmfop1-ko=GT5wzeajiQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u4107Eve67gxEg1rtCLFyaABFsmfop1-ko=GT5wzeajiQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u4107Eve67gxEg1rtCLFyaABFsmfop1-ko=GT5wzeajiQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u4107Eve67gxEg1rtCLFyaABFsmfop1-ko=GT5wzeajiQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u4107Eve67gxEg1rtCLFyaABFsmfop1-ko=GT5wzeajiQ@mail.gmail.com/t/#u">nested</a>] <a href=#re9f86974c28c0ca73e4be20e889e9ce55242ed8a>86+ messages in thread</a></pre><hr><pre><a href=#ed805d888f455929658b15f37f3dec4e04cbef73e id=md805d888f455929658b15f37f3dec4e04cbef73e>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-19 20:19   ` <a href=#m88a4003327a711a111ee2c4d48bf98696a66bc8b>Conor Dooley</a>
       [not found]     ` &lt;<a href=#red9fb23cde273365376c37e6496225c853d2784d>CAH2o1u6CZSb7pXcaXmh7dJQmNZYh3uORk4x7vJPrb+uCwFdU5g@mail.gmail.com</a>&gt;
<b>@ 2023-07-19 21:37     ` Rob Herring</b>
  2023-07-19 23:04       ` <a href=#md853fd009dec300692af2fb72bf786e9682c55c5>Tomasz Jeznach</a>
  <a href=#rd805d888f455929658b15f37f3dec4e04cbef73e>1 sibling, 1 reply; 86+ messages in thread</a>
From: Rob Herring @ 2023-07-19 21:37 UTC (<a href="https://lore.kernel.org/lkml/CAL_JsqLsb801Z4H7+ViboBSGwd+XidcpYcJMHgw+6fofsXB=9Q@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAL_JsqLsb801Z4H7+ViboBSGwd+XidcpYcJMHgw+6fofsXB=9Q@mail.gmail.com/raw">raw</a>)
  To: Conor Dooley, Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719213747">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230719213747">linux-riscv</a>,
	krzysztof.kozlowski+dt, <a href="https://lore.kernel.org/linux-devicetree/?t=20230719213747">devicetree</a>

On Wed, Jul 19, 2023 at 2:19 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
<span class=q>&gt;
&gt; Hey Tomasz,
&gt;
&gt; On Wed, Jul 19, 2023 at 12:33:47PM -0700, Tomasz Jeznach wrote:
&gt; &gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt;
&gt; &gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; &gt; defined by the RISC-V IOMMU specification.
&gt; &gt;
&gt; &gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt;
&gt; Your signoff is missing from here.
&gt;
&gt; Secondly, as get_maintainer.pl would have told you, dt-bindings patches
&gt; need to be sent to the dt-binding maintainers and list.
&gt; +CC maintainers &amp; list.
&gt;
&gt; Thirdly, dt-binding patches should come before their users.
&gt;
&gt; &gt; ---
&gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt; &gt;  1 file changed, 146 insertions(+)
&gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt;
&gt; &gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; new file mode 100644
&gt; &gt; index 000000000000..8a9aedb61768
&gt; &gt; --- /dev/null
&gt; &gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; @@ -0,0 +1,146 @@
&gt; &gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; &gt; +%YAML 1.2
&gt; &gt; +---
&gt; &gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; &gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; &gt; +
&gt; &gt; +title: RISC-V IOMMU Implementation
&gt; &gt; +
&gt; &gt; +maintainers:
&gt; &gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt;
&gt; What about Anup, who seems to have written this?
&gt; Or your co-authors of the drivers?
&gt;
&gt; &gt; +
&gt; &gt; +description:
&gt; &gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
</span>
typo

<span class=q>&gt; &gt; +  which can be a regular platform device or a PCI device connected to
&gt; &gt; +  the host root port.
&gt; &gt; +
&gt; &gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; &gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; &gt; +  both PCI and platform devices.
</span>
TBC, you want a PCI device that's an IOMMU and the IOMMU serves
(provides translation for) PCI devices?

<span class=q>&gt; &gt; +
&gt; &gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; &gt; +
&gt; &gt; +properties:
&gt; &gt; +  compatible:
&gt; &gt; +    oneOf:
&gt; &gt; +      - description: RISC-V IOMMU as a platform device
</span>
"platform device" is a Linux term. Don't use Linux terms in bindings.

<span class=q>&gt; &gt; +        items:
&gt; &gt; +          - enum:
&gt; &gt; +              - vendor,chip-iommu
&gt;
&gt; These dummy compatibles are not valid, as was pointed out to Anup on
&gt; the AIA series. Please go look at what was done there instead:
&gt; <a href=https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/>https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/</a>
&gt;
&gt; &gt; +          - const: riscv,iommu
&gt; &gt; +
&gt; &gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; &gt; +        items:
&gt; &gt; +          - enum:
&gt; &gt; +              - vendor,chip-pci-iommu
&gt; &gt; +          - const: riscv,pci-iommu
&gt;
&gt; I'm not really au fait with the arm smmu stuff, but do any of its
&gt; versions support being connected to a root port?
</span>
PCI devices have a defined format for the compatible string based on
VID/PID. For PCI, also usually don't need to be described in DT
because they are discoverable. The exception is when there's parts
which aren't. Which parts aren't?

<span class=q>&gt; &gt; +  reg:
&gt; &gt; +    maxItems: 1
&gt; &gt; +    description:
&gt; &gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; &gt; +      address of registers.
&gt; &gt; +
&gt; &gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
</span>
Your IOMMU is also a PCI-PCI bridge? Is that a normal PCI thing?


<span class=q>&gt; &gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
</span>
Don't refer to pci.txt. It is going to be removed.

<span class=q>&gt; &gt; +
&gt; &gt; +  '#iommu-cells':
&gt; &gt; +    const: 2
&gt; &gt; +    description: |
&gt;
&gt; |s are only needed where formatting needs to be preserved.
&gt;
&gt; &gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; &gt; +      device IDs.
</span>
Doesn't that assume device IDs are contiguous? Generally not a safe assumption.

<span class=q>&gt; &gt; +
&gt; &gt; +  interrupts:
&gt; &gt; +    minItems: 1
&gt; &gt; +    maxItems: 16
&gt;
&gt; What are any of these interrupts?
&gt;
&gt; &gt; +    description:
&gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; &gt; +
&gt; &gt; +  msi-parent:
&gt; &gt; +    description:
&gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; &gt; +      considered only when the interrupts property is absent.
</span>
This doesn't make sense for a PCI device. PCI defines its own way to
describe MSI support.

<span class=q>&gt; &gt; +
&gt; &gt; +  dma-coherent:
&gt;
&gt; RISC-V is dma-coherent by default, should this not be dma-noncoherent
&gt; instead?
&gt;
&gt; &gt; +    description:
&gt; &gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; &gt; +      are cache coherent with the CPU.
&gt; &gt; +
&gt; &gt; +  power-domains:
&gt; &gt; +    maxItems: 1
&gt; &gt; +
&gt; &gt; +required:
&gt; &gt; +  - compatible
&gt; &gt; +  - reg
&gt; &gt; +  - '#iommu-cells'
&gt; &gt; +
&gt; &gt; +additionalProperties: false
&gt; &gt; +
&gt; &gt; +examples:
&gt; &gt; +  - |
&gt; &gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; &gt; +    immu1: iommu@1bccd000 {
&gt;
&gt; Why is this "immu"? typo or intentional?
&gt;
&gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; &gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; +    };
&gt; &gt; +
&gt; &gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; &gt; +    master1 {
&gt; &gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; &gt; +    };
&gt; &gt; +
&gt; &gt; +  - |
&gt; &gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; &gt; +    immu2: iommu@1bcdd000 {
&gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; +    };
&gt; &gt; +
&gt; &gt; +    bus {
&gt; &gt; +        #address-cells = &lt;2&gt;;
&gt; &gt; +        #size-cells = &lt;2&gt;;
&gt; &gt; +
&gt; &gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; &gt; +        master1 {
&gt; &gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; &gt; +        };
&gt; &gt; +
&gt; &gt; +        pcie@40000000 {
&gt; &gt; +            compatible = "pci-host-cam-generic";
&gt; &gt; +            device_type = "pci";
&gt; &gt; +            #address-cells = &lt;3&gt;;
&gt; &gt; +            #size-cells = &lt;2&gt;;
&gt; &gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; &gt; +
&gt; &gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
</span>
I'm guessing there was more after this, but I don't have it...

Guessing, immu2 is a PCI device, but it translates for master1 which
is not a PCI device? Weird. Why would anyone build such a thing?


Rob

<a href=#md805d888f455929658b15f37f3dec4e04cbef73e id=ed805d888f455929658b15f37f3dec4e04cbef73e>^</a> <a href="https://lore.kernel.org/lkml/CAL_JsqLsb801Z4H7+ViboBSGwd+XidcpYcJMHgw+6fofsXB=9Q@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAL_JsqLsb801Z4H7+ViboBSGwd+XidcpYcJMHgw+6fofsXB=9Q@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAL_JsqLsb801Z4H7+ViboBSGwd+XidcpYcJMHgw+6fofsXB=9Q@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAL_JsqLsb801Z4H7+ViboBSGwd+XidcpYcJMHgw+6fofsXB=9Q@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAL_JsqLsb801Z4H7+ViboBSGwd+XidcpYcJMHgw+6fofsXB=9Q@mail.gmail.com/t/#u">nested</a>] <a href=#rd805d888f455929658b15f37f3dec4e04cbef73e>86+ messages in thread</a></pre><hr><pre><a href=#e7a575a3d69ac16e6fcb589d3f5517a473ee1e27d id=m7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 20:49   ` <a href=#m475b3879d13e54e5f54247069b241516ceaf814e>Conor Dooley</a>
<b>@ 2023-07-19 21:43     ` Tomasz Jeznach</b>
  2023-07-20 19:27       ` <a href=#m7c76b2906bb58a75b5a08e305e41c946fb24f5af>Conor Dooley</a>
  2023-07-21  9:44       ` <a href=#m395bb5e2fc32d6655db1f3d57b32806919889e01>Conor Dooley</a>
  <a href=#r7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>0 siblings, 2 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 21:43 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u5pZQ6iKThFLgnn+_BBZ=j8fu91URYYxwWbfVt3OyerAA@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u5pZQ6iKThFLgnn+_BBZ=j8fu91URYYxwWbfVt3OyerAA@mail.gmail.com/raw">raw</a>)
  To: Conor Dooley
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719214406">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230719214406">linux-riscv</a>

On Wed, Jul 19, 2023 at 1:50 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
<span class=q>&gt;
&gt; Hey Tomasz,
&gt;
&gt; On Wed, Jul 19, 2023 at 12:33:45PM -0700, Tomasz Jeznach wrote:
&gt; &gt; The patch introduces skeleton IOMMU device driver implementation as defined
&gt;
&gt; This commit message reads like a cover letter IMO. At whatever point
&gt; you send a v2, could you re-write this focusing on what is done in the
&gt; patch itself?
&gt;
</span>
ack. will amend the commit message.


<span class=q>&gt; Also, since I am not going to reply to any of these iommu driver patches
&gt; in a meaningful capacity, please run checkpatch.pl on your work. There
&gt; are well over 100 style etc complaints that it has highlighted. Sparse
&gt; has also gone a bit nuts, with many warnings along the lines of:
&gt; drivers/iommu/riscv/iommu.c:1568:29: warning: incorrect type in assignment (different base types)
&gt; drivers/iommu/riscv/iommu.c:1568:29:    expected unsigned long long [usertype] iohgatp
&gt; drivers/iommu/riscv/iommu.c:1568:29:    got restricted __le64 [usertype]
&gt;
&gt; I can provide you the full list when the patchwork automation has run
&gt; through the series.
&gt;
</span>
Thank you, a list of used lint checkers definitely would help.


<span class=q>&gt; Anyway, what I wanted to ask was whether it was valid to use the IOMMU
&gt; in a system if Ziommu is not present in whatever the ISA extension
&gt; communication mechanism is? Eg, riscv,isa or the ISA string property in
&gt; the ACPI tables.
&gt;
</span>
Yes, this has been pointed out to me already. As far as I can recall,
there was a discussion
at some point to introduce those as Ziommu extensions, later agreeing
not to call IOMMU
using ISA string conventions.  Will remove remaining occurrences of
Ziommu from the series.


<span class=q>&gt; Thanks,
&gt; Conor.
&gt;
&gt; &gt; References:
&gt; &gt;  - [1] <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
&gt; &gt;  - [2] <a href=https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu</a>
&gt; &gt;  - [3] <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu</a>
&gt;
&gt; FYI, we have the Link: tag/trailer for this.
&gt;
</span>

Thanks,
- Tomasz

<a href=#m7a575a3d69ac16e6fcb589d3f5517a473ee1e27d id=e7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u5pZQ6iKThFLgnn+_BBZ=j8fu91URYYxwWbfVt3OyerAA@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u5pZQ6iKThFLgnn+_BBZ=j8fu91URYYxwWbfVt3OyerAA@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u5pZQ6iKThFLgnn+_BBZ=j8fu91URYYxwWbfVt3OyerAA@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u5pZQ6iKThFLgnn+_BBZ=j8fu91URYYxwWbfVt3OyerAA@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u5pZQ6iKThFLgnn+_BBZ=j8fu91URYYxwWbfVt3OyerAA@mail.gmail.com/t/#u">nested</a>] <a href=#r7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>86+ messages in thread</a></pre><hr><pre><a href=#ed853fd009dec300692af2fb72bf786e9682c55c5 id=md853fd009dec300692af2fb72bf786e9682c55c5>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-19 21:37     ` <a href=#md805d888f455929658b15f37f3dec4e04cbef73e>Rob Herring</a>
<b>@ 2023-07-19 23:04       ` Tomasz Jeznach</b>
  <a href=#rd853fd009dec300692af2fb72bf786e9682c55c5>0 siblings, 0 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-19 23:04 UTC (<a href=https://lore.kernel.org/lkml/CAH2o1u5VdOx+MgQFyjEr1__DZmsxLGGqf8v1pDvTHoPJ4OGfGA@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CAH2o1u5VdOx+MgQFyjEr1__DZmsxLGGqf8v1pDvTHoPJ4OGfGA@mail.gmail.com/raw>raw</a>)
  To: Rob Herring
  Cc: Conor Dooley, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230719230458">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230719230458">linux-riscv</a>, krzysztof.kozlowski+dt, <a href="https://lore.kernel.org/linux-devicetree/?t=20230719230458">devicetree</a>

On Wed, Jul 19, 2023 at 2:37 PM Rob Herring &lt;robh+dt@kernel.org&gt; wrote:
<span class=q>&gt;
&gt; On Wed, Jul 19, 2023 at 2:19 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
&gt; &gt;
&gt; &gt; Hey Tomasz,
&gt; &gt;
&gt; &gt; On Wed, Jul 19, 2023 at 12:33:47PM -0700, Tomasz Jeznach wrote:
&gt; &gt; &gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt;
&gt; &gt; &gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; &gt; &gt; defined by the RISC-V IOMMU specification.
&gt; &gt; &gt;
&gt; &gt; &gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt;
&gt; &gt; Your signoff is missing from here.
&gt; &gt;
&gt; &gt; Secondly, as get_maintainer.pl would have told you, dt-bindings patches
&gt; &gt; need to be sent to the dt-binding maintainers and list.
&gt; &gt; +CC maintainers &amp; list.
&gt; &gt;
&gt; &gt; Thirdly, dt-binding patches should come before their users.
&gt; &gt;
&gt; &gt; &gt; ---
&gt; &gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt; &gt; &gt;  1 file changed, 146 insertions(+)
&gt; &gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt;
&gt; &gt; &gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; new file mode 100644
&gt; &gt; &gt; index 000000000000..8a9aedb61768
&gt; &gt; &gt; --- /dev/null
&gt; &gt; &gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; @@ -0,0 +1,146 @@
&gt; &gt; &gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; &gt; &gt; +%YAML 1.2
&gt; &gt; &gt; +---
&gt; &gt; &gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; &gt; &gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; &gt; &gt; +
&gt; &gt; &gt; +title: RISC-V IOMMU Implementation
&gt; &gt; &gt; +
&gt; &gt; &gt; +maintainers:
&gt; &gt; &gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt;
&gt; &gt; What about Anup, who seems to have written this?
&gt; &gt; Or your co-authors of the drivers?
&gt; &gt;
&gt; &gt; &gt; +
&gt; &gt; &gt; +description:
&gt; &gt; &gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt;
&gt; typo
&gt;
</span>
ack

<span class=q>&gt; &gt; &gt; +  which can be a regular platform device or a PCI device connected to
&gt; &gt; &gt; +  the host root port.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; &gt; &gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; &gt; &gt; +  both PCI and platform devices.
&gt;
&gt; TBC, you want a PCI device that's an IOMMU and the IOMMU serves
&gt; (provides translation for) PCI devices?
&gt;
</span>
Yes, IOMMU as a PCIe device providing address translation services for
connect PCIe root complex.

<span class=q>&gt; &gt; &gt; +
&gt; &gt; &gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; &gt; &gt; +
&gt; &gt; &gt; +properties:
&gt; &gt; &gt; +  compatible:
&gt; &gt; &gt; +    oneOf:
&gt; &gt; &gt; +      - description: RISC-V IOMMU as a platform device
&gt;
&gt; "platform device" is a Linux term. Don't use Linux terms in bindings.
&gt;
</span>
ack.


<span class=q>&gt; &gt; &gt; +        items:
&gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; +              - vendor,chip-iommu
&gt; &gt;
&gt; &gt; These dummy compatibles are not valid, as was pointed out to Anup on
&gt; &gt; the AIA series. Please go look at what was done there instead:
&gt; &gt; <a href=https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/>https://lore.kernel.org/all/20230719113542.2293295-7-apatel@ventanamicro.com/</a>
&gt; &gt;
&gt; &gt; &gt; +          - const: riscv,iommu
&gt; &gt; &gt; +
&gt; &gt; &gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; &gt; &gt; +        items:
&gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; +              - vendor,chip-pci-iommu
&gt; &gt; &gt; +          - const: riscv,pci-iommu
&gt; &gt;
&gt; &gt; I'm not really au fait with the arm smmu stuff, but do any of its
&gt; &gt; versions support being connected to a root port?
&gt;
&gt; PCI devices have a defined format for the compatible string based on
&gt; VID/PID. For PCI, also usually don't need to be described in DT
&gt; because they are discoverable. The exception is when there's parts
&gt; which aren't. Which parts aren't?
&gt;
</span>
We've put 'riscv,pci-iommu' node here to describe relationship between PCIe
devices and IOMMU(s), needed for the pcie root complex description (iommu-map).
If there is a better way to reference PCI-IOMMU without adding
pci-iommu definition
that would solve the problem. Every other property of pci-iommu should
be discoverable.

<span class=q>&gt; &gt; &gt; +  reg:
&gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; &gt; &gt; +      address of registers.
&gt; &gt; &gt; +
&gt; &gt; &gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
&gt;
&gt; Your IOMMU is also a PCI-PCI bridge? Is that a normal PCI thing?
&gt;
</span>
It's allowed to be integrated with root complex / IO bridge, but it is
as a separate PCIe device.
I'll clarify the description.

<span class=q>&gt;
&gt; &gt; &gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
&gt;
&gt; Don't refer to pci.txt. It is going to be removed.
&gt;
</span>
ack.

<span class=q>&gt; &gt; &gt; +
&gt; &gt; &gt; +  '#iommu-cells':
&gt; &gt; &gt; +    const: 2
&gt; &gt; &gt; +    description: |
&gt; &gt;
&gt; &gt; |s are only needed where formatting needs to be preserved.
&gt; &gt;
&gt; &gt; &gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; &gt; &gt; +      device IDs.
&gt;
&gt; Doesn't that assume device IDs are contiguous? Generally not a safe assumption.
&gt;
</span>
ack.

<span class=q>&gt; &gt; &gt; +
&gt; &gt; &gt; +  interrupts:
&gt; &gt; &gt; +    minItems: 1
&gt; &gt; &gt; +    maxItems: 16
&gt; &gt;
&gt; &gt; What are any of these interrupts?
&gt; &gt;
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; &gt; &gt; +
&gt; &gt; &gt; +  msi-parent:
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; &gt; &gt; +      considered only when the interrupts property is absent.
&gt;
&gt; This doesn't make sense for a PCI device. PCI defines its own way to
&gt; describe MSI support.
&gt;
</span>
Agree, this is for IOMMU as a non-PCI device, capable of sending MSI.
Follows 'MSI clients' notes from
devicetree/bindings/interrupt-controller/msi.txt
Is this a proper way to describe this relationship?

<span class=q>&gt; &gt; &gt; +
&gt; &gt; &gt; +  dma-coherent:
&gt; &gt;
&gt; &gt; RISC-V is dma-coherent by default, should this not be dma-noncoherent
&gt; &gt; instead?
&gt; &gt;
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; &gt; &gt; +      are cache coherent with the CPU.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  power-domains:
&gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; +
&gt; &gt; &gt; +required:
&gt; &gt; &gt; +  - compatible
&gt; &gt; &gt; +  - reg
&gt; &gt; &gt; +  - '#iommu-cells'
&gt; &gt; &gt; +
&gt; &gt; &gt; +additionalProperties: false
&gt; &gt; &gt; +
&gt; &gt; &gt; +examples:
&gt; &gt; &gt; +  - |
&gt; &gt; &gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; &gt; &gt; +    immu1: iommu@1bccd000 {
&gt; &gt;
&gt; &gt; Why is this "immu"? typo or intentional?
&gt; &gt;
&gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; &gt; &gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; &gt; &gt; +    master1 {
&gt; &gt; &gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +  - |
&gt; &gt; &gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; &gt; &gt; +    immu2: iommu@1bcdd000 {
&gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +    bus {
&gt; &gt; &gt; +        #address-cells = &lt;2&gt;;
&gt; &gt; &gt; +        #size-cells = &lt;2&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; &gt; &gt; +        master1 {
&gt; &gt; &gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; &gt; &gt; +        };
&gt; &gt; &gt; +
&gt; &gt; &gt; +        pcie@40000000 {
&gt; &gt; &gt; +            compatible = "pci-host-cam-generic";
&gt; &gt; &gt; +            device_type = "pci";
&gt; &gt; &gt; +            #address-cells = &lt;3&gt;;
&gt; &gt; &gt; +            #size-cells = &lt;2&gt;;
&gt; &gt; &gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
&gt;
&gt; I'm guessing there was more after this, but I don't have it...
</span>
Complete patch 3 is at:
<a href=https://lore.kernel.org/linux-iommu/cover.1689792825.git.tjeznach@rivosinc.com/T/#mbf8dc4098fb09b87b2618c5c545ae882f11b114b>https://lore.kernel.org/linux-iommu/cover.1689792825.git.tjeznach@rivosinc.com/T/#mbf8dc4098fb09b87b2618c5c545ae882f11b114b</a>

<span class=q>&gt;
&gt; Guessing, immu2 is a PCI device, but it translates for master1 which
&gt; is not a PCI device? Weird. Why would anyone build such a thing?
&gt;
</span>
In this example immu2 is a non-PCI device. Agree, otherwise would be weird.

<span class=q>&gt;
&gt; Rob
</span>
Thank you,
- Tomasz

<a href=#md853fd009dec300692af2fb72bf786e9682c55c5 id=ed853fd009dec300692af2fb72bf786e9682c55c5>^</a> <a href=https://lore.kernel.org/lkml/CAH2o1u5VdOx+MgQFyjEr1__DZmsxLGGqf8v1pDvTHoPJ4OGfGA@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CAH2o1u5VdOx+MgQFyjEr1__DZmsxLGGqf8v1pDvTHoPJ4OGfGA@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CAH2o1u5VdOx+MgQFyjEr1__DZmsxLGGqf8v1pDvTHoPJ4OGfGA@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CAH2o1u5VdOx+MgQFyjEr1__DZmsxLGGqf8v1pDvTHoPJ4OGfGA@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CAH2o1u5VdOx+MgQFyjEr1__DZmsxLGGqf8v1pDvTHoPJ4OGfGA@mail.gmail.com/t/#u>nested</a>] <a href=#rd853fd009dec300692af2fb72bf786e9682c55c5>86+ messages in thread</a></pre><hr><pre><a href=#ee036e876659d5bad1074323224ed7dc70b2e49db id=me036e876659d5bad1074323224ed7dc70b2e49db>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-19 19:33 ` <a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</a> Tomasz Jeznach
<b>@ 2023-07-20  3:11   ` Nick Kossifidis</b>
  2023-07-20 18:00     ` <a href=#m505d10dd50c508c0a38b520f5cd63968f20076a8>Tomasz Jeznach</a>
  2023-07-20 13:08   ` <a href=#m1715001bd807613c4ae6715e3679cf47b74e2a60>Baolu Lu</a>
                     ` <a href=#r1715001bd807613c4ae6715e3679cf47b74e2a60>(2 subsequent siblings)</a>
  <a href=#re036e876659d5bad1074323224ed7dc70b2e49db>3 siblings, 1 reply; 86+ messages in thread</a>
From: Nick Kossifidis @ 2023-07-20  3:11 UTC (<a href=https://lore.kernel.org/lkml/5b8fd18e-8dfa-96bf-cdd4-4498b1d15ab9@ics.forth.gr/>permalink</a> / <a href=https://lore.kernel.org/lkml/5b8fd18e-8dfa-96bf-cdd4-4498b1d15ab9@ics.forth.gr/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Sebastien Boeuf,
	iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720033617">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720033617">linux-kernel</a>, linux

Hello Tomasz,

On 7/19/23 22:33, Tomasz Jeznach wrote:
<span class=q>&gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; 
</span>
The description doesn't match the subject nor the patch content (we 
don't jus enable interrupts, we also init the queues).

<span class=q>&gt; +	/* Parse Queue lengts */
&gt; +	ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; +	if (!ret)
&gt; +		dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; +
&gt; +	ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; +	if (!ret)
&gt; +		dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; +
&gt; +	ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; +	if (!ret)
&gt; +		dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; +
&gt;   	dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt;   
</span>
We need to add those to the device tree binding doc (or throw them away, 
I thought it would be better to have them as part of the device 
desciption than a module parameter).


<span class=q>&gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; +
</span>
<span class=q>&gt; +	case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; +		q = &amp;iommu-&gt;priq;
&gt; +		q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; +		count = iommu-&gt;priq_len;
&gt; +		irq = iommu-&gt;irq_priq;
&gt; +		irq_check = riscv_iommu_priq_irq_check;
&gt; +		irq_process = riscv_iommu_priq_process;
&gt; +		q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; +		q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; +		name = "priq";
&gt; +		break;
</span>

It makes more sense to add the code for the page request queue in the 
patch that adds ATS/PRI support IMHO. This comment also applies to its 
interrupt handlers below.


<span class=q>&gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; +						  u64 addr)
&gt; +{
&gt; +	cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; +	cmd-&gt;dword1 = addr;
&gt; +}
&gt; +
</span>
This needs to be (addr &gt;&gt; 2) to match the spec, same as in the iofence 
command.

Regards,
Nick


<a href=#me036e876659d5bad1074323224ed7dc70b2e49db id=ee036e876659d5bad1074323224ed7dc70b2e49db>^</a> <a href=https://lore.kernel.org/lkml/5b8fd18e-8dfa-96bf-cdd4-4498b1d15ab9@ics.forth.gr/>permalink</a> <a href=https://lore.kernel.org/lkml/5b8fd18e-8dfa-96bf-cdd4-4498b1d15ab9@ics.forth.gr/raw>raw</a> <a href=https://lore.kernel.org/lkml/5b8fd18e-8dfa-96bf-cdd4-4498b1d15ab9@ics.forth.gr/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/5b8fd18e-8dfa-96bf-cdd4-4498b1d15ab9@ics.forth.gr/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/5b8fd18e-8dfa-96bf-cdd4-4498b1d15ab9@ics.forth.gr/t/#u>nested</a>] <a href=#re036e876659d5bad1074323224ed7dc70b2e49db>86+ messages in thread</a></pre><hr><pre><a href=#eca75c01519c7dca768f770f0a0b7b6bb9c709a39 id=mca75c01519c7dca768f770f0a0b7b6bb9c709a39>*</a> <b>Re: [PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</b>
  2023-07-19 21:07     ` <a href=#me9f86974c28c0ca73e4be20e889e9ce55242ed8a>Tomasz Jeznach</a>
<b>@ 2023-07-20  6:37       ` Krzysztof Kozlowski</b>
  <a href=#rca75c01519c7dca768f770f0a0b7b6bb9c709a39>0 siblings, 0 replies; 86+ messages in thread</a>
From: Krzysztof Kozlowski @ 2023-07-20  6:37 UTC (<a href=https://lore.kernel.org/lkml/b3b3b21b-37e8-bd6f-6e4c-7ad9bd47446d@kernel.org/>permalink</a> / <a href=https://lore.kernel.org/lkml/b3b3b21b-37e8-bd6f-6e4c-7ad9bd47446d@kernel.org/raw>raw</a>)
  To: Tomasz Jeznach, Conor Dooley
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230720063903">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230720063903">linux-riscv</a>

On 19/07/2023 23:07, Tomasz Jeznach wrote:
<span class=q>&gt; On Wed, Jul 19, 2023 at 1:22 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
&gt;&gt;
&gt;&gt; On Wed, Jul 19, 2023 at 12:33:46PM -0700, Tomasz Jeznach wrote:
&gt;&gt;
&gt;&gt; $subject: RISC-V: arch/riscv/config: enable RISC-V IOMMU support
&gt;&gt;
&gt;&gt; Please look at any other commits to the files you are touching
&gt;&gt; and use a subject line that emulates them. In this case, try
&gt;&gt; git log --oneline --no-merges -- arch/riscv/configs/
&gt;&gt; Same goes for the odd pattern in your driver patches.
&gt;&gt;
&gt;&gt; Also, the patch may be trivial, but you still need to sign off on it
&gt;&gt; and provide a commit message.
&gt;&gt;
&gt; 
&gt; ack. added to-do the list for v2.
</span>
Please run checkpatch before sending.

Best regards,
Krzysztof


<a href=#mca75c01519c7dca768f770f0a0b7b6bb9c709a39 id=eca75c01519c7dca768f770f0a0b7b6bb9c709a39>^</a> <a href=https://lore.kernel.org/lkml/b3b3b21b-37e8-bd6f-6e4c-7ad9bd47446d@kernel.org/>permalink</a> <a href=https://lore.kernel.org/lkml/b3b3b21b-37e8-bd6f-6e4c-7ad9bd47446d@kernel.org/raw>raw</a> <a href=https://lore.kernel.org/lkml/b3b3b21b-37e8-bd6f-6e4c-7ad9bd47446d@kernel.org/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/b3b3b21b-37e8-bd6f-6e4c-7ad9bd47446d@kernel.org/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/b3b3b21b-37e8-bd6f-6e4c-7ad9bd47446d@kernel.org/t/#u>nested</a>] <a href=#rca75c01519c7dca768f770f0a0b7b6bb9c709a39>86+ messages in thread</a></pre><hr><pre><a href=#e4531233107436be4728ad7c9e39b93b11e8c7e48 id=m4531233107436be4728ad7c9e39b93b11e8c7e48>*</a> <b>Re: [PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-19 19:33 ` <a href=#m64db79f82cb551d51fc635ba160962c425c8cbb2>[PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</a> Tomasz Jeznach
<b>@ 2023-07-20  6:38   ` Krzysztof Kozlowski</b>
  2023-07-20 18:30     ` <a href=#m10ac8115fa338f5759d5ebc64181be18eecea21c>Tomasz Jeznach</a>
  2023-07-20 12:50   ` <a href=#m5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>Baolu Lu</a>
  <a href=#r4531233107436be4728ad7c9e39b93b11e8c7e48>1 sibling, 1 reply; 86+ messages in thread</a>
From: Krzysztof Kozlowski @ 2023-07-20  6:38 UTC (<a href=https://lore.kernel.org/lkml/c26d029e-dabc-9ad2-ed42-bb6ee276e3fb@kernel.org/>permalink</a> / <a href=https://lore.kernel.org/lkml/c26d029e-dabc-9ad2-ed42-bb6ee276e3fb@kernel.org/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720064001">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720064001">linux-kernel</a>, linux

On 19/07/2023 21:33, Tomasz Jeznach wrote:
<span class=q>&gt; Enable sysfs debug / visibility interface providing restricted
&gt; access to hardware registers.
</span>
Please use subject prefixes matching the subsystem. You can get them for
example with `git log --oneline -- DIRECTORY_OR_FILE` on the directory
your patch is touching.

<span class=q>&gt; 
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/riscv/Makefile      |   2 +-
&gt;  drivers/iommu/riscv/iommu-sysfs.c | 183 ++++++++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu.c       |   7 ++
&gt;  drivers/iommu/riscv/iommu.h       |   2 +
&gt;  4 files changed, 193 insertions(+), 1 deletion(-)
&gt;  create mode 100644 drivers/iommu/riscv/iommu-sysfs.c
&gt; 
&gt; diff --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
&gt; index 38730c11e4a8..9523eb053cfc 100644
&gt; --- a/drivers/iommu/riscv/Makefile
&gt; +++ b/drivers/iommu/riscv/Makefile
&gt; @@ -1 +1 @@
&gt; -obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o
&gt; \ No newline at end of file
&gt; +obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o
&gt; \ No newline at end of file
</span>
You have this error in multiple places.

<span class=q>&gt; diff --git a/drivers/iommu/riscv/iommu-sysfs.c b/drivers/iommu/riscv/iommu-sysfs.c
&gt; new file mode 100644
&gt; index 000000000000..f038ea8445c5
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-sysfs.c
&gt; @@ -0,0 +1,183 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * IOMMU API for RISC-V architected Ziommu implementations.
&gt; + *
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + *
&gt; + * Author: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/compiler.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/platform_device.h&gt;
&gt; +#include &lt;asm/page.h&gt;
&gt; +
&gt; +#include "iommu.h"
&gt; +
&gt; +#define sysfs_dev_to_iommu(dev) \
&gt; +	container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
&gt; +
&gt; +static ssize_t address_show(struct device *dev,
&gt; +			    struct device_attribute *attr, char *buf)
</span>

Where is the sysfs ABI documented?


Best regards,
Krzysztof


<a href=#m4531233107436be4728ad7c9e39b93b11e8c7e48 id=e4531233107436be4728ad7c9e39b93b11e8c7e48>^</a> <a href=https://lore.kernel.org/lkml/c26d029e-dabc-9ad2-ed42-bb6ee276e3fb@kernel.org/>permalink</a> <a href=https://lore.kernel.org/lkml/c26d029e-dabc-9ad2-ed42-bb6ee276e3fb@kernel.org/raw>raw</a> <a href=https://lore.kernel.org/lkml/c26d029e-dabc-9ad2-ed42-bb6ee276e3fb@kernel.org/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/c26d029e-dabc-9ad2-ed42-bb6ee276e3fb@kernel.org/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/c26d029e-dabc-9ad2-ed42-bb6ee276e3fb@kernel.org/t/#u>nested</a>] <a href=#r4531233107436be4728ad7c9e39b93b11e8c7e48>86+ messages in thread</a></pre><hr><pre><a href=#ece7ec12a032abfaca43b25278ff9762eb0fc2b37 id=mce7ec12a032abfaca43b25278ff9762eb0fc2b37>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
  2023-07-19 20:49   ` <a href=#m475b3879d13e54e5f54247069b241516ceaf814e>Conor Dooley</a>
<b>@ 2023-07-20 10:38   ` Baolu Lu</b>
  2023-07-20 12:31   ` <a href=#m5c32a5e8f769114a8ba7611812fa02c944920207>Baolu Lu</a>
                     ` <a href=#r5c32a5e8f769114a8ba7611812fa02c944920207>(5 subsequent siblings)</a>
  <a href=#rce7ec12a032abfaca43b25278ff9762eb0fc2b37>7 siblings, 0 replies; 86+ messages in thread</a>
From: Baolu Lu @ 2023-07-20 10:38 UTC (<a href=https://lore.kernel.org/lkml/68e3a7ab-0387-3e58-8c30-3ace807acee5@linux.intel.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/68e3a7ab-0387-3e58-8c30-3ace807acee5@linux.intel.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: baolu.lu, Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L,
	Nick Kossifidis, Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720103852">linux-riscv</a>,
	<a href="https://lore.kernel.org/lkml/?t=20230720103852">linux-kernel</a>, linux

On 2023/7/20 3:33, Tomasz Jeznach wrote:
<span class=q>&gt; +struct riscv_iommu_domain {
&gt; +	struct iommu_domain domain;
&gt; +
&gt; +	struct list_head endpoints;
&gt; +	struct mutex lock;
&gt; +	struct riscv_iommu_device *iommu;
</span>
How are domains and iommu devices connected? A domain can be attached to
multiple devices, which are possibly behind different iommu devices. So
a domain is possibly connected to multiple iommu devices.

Is it possible?

<span class=q>&gt; +
&gt; +	unsigned mode;		/* RIO_ATP_MODE_* enum */
&gt; +	unsigned pscid;		/* RISC-V IOMMU PSCID */
&gt; +
&gt; +	pgd_t *pgd_root;	/* page table root pointer */
&gt; +};
&gt; +
&gt; +/* Private dev_iommu_priv object, device-domain relationship. */
&gt; +struct riscv_iommu_endpoint {
&gt; +	struct device *dev;			/* platform or PCI endpoint device */
&gt; +	unsigned devid;      			/* PCI bus:device:function number */
&gt; +	unsigned domid;    			/* PCI domain number, segment */
&gt; +	struct rb_node node;    		/* device tracking node (lookup by devid) */
&gt; +	struct riscv_iommu_device *iommu;	/* parent iommu device */
&gt; +
&gt; +	struct mutex lock;
&gt; +	struct list_head domain;		/* endpoint attached managed domain */
&gt; +};
</span>
Best regards,
baolu

<a href=#mce7ec12a032abfaca43b25278ff9762eb0fc2b37 id=ece7ec12a032abfaca43b25278ff9762eb0fc2b37>^</a> <a href=https://lore.kernel.org/lkml/68e3a7ab-0387-3e58-8c30-3ace807acee5@linux.intel.com/>permalink</a> <a href=https://lore.kernel.org/lkml/68e3a7ab-0387-3e58-8c30-3ace807acee5@linux.intel.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/68e3a7ab-0387-3e58-8c30-3ace807acee5@linux.intel.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/68e3a7ab-0387-3e58-8c30-3ace807acee5@linux.intel.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/68e3a7ab-0387-3e58-8c30-3ace807acee5@linux.intel.com/t/#u>nested</a>] <a href=#rce7ec12a032abfaca43b25278ff9762eb0fc2b37>86+ messages in thread</a></pre><hr><pre><a href=#e5c32a5e8f769114a8ba7611812fa02c944920207 id=m5c32a5e8f769114a8ba7611812fa02c944920207>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
  2023-07-19 20:49   ` <a href=#m475b3879d13e54e5f54247069b241516ceaf814e>Conor Dooley</a>
  2023-07-20 10:38   ` <a href=#mce7ec12a032abfaca43b25278ff9762eb0fc2b37>Baolu Lu</a>
<b>@ 2023-07-20 12:31   ` Baolu Lu</b>
  2023-07-20 17:30     ` <a href=#m22bfe5a5766790fcc48e9b406ffb296ff8be6413>Tomasz Jeznach</a>
  2023-07-28  2:42   ` <a href=#m522f968d0909aad51fe7e480809ea548917990fa>Zong Li</a>
                     ` <a href=#r522f968d0909aad51fe7e480809ea548917990fa>(4 subsequent siblings)</a>
  <a href=#r5c32a5e8f769114a8ba7611812fa02c944920207>7 siblings, 1 reply; 86+ messages in thread</a>
From: Baolu Lu @ 2023-07-20 12:31 UTC (<a href=https://lore.kernel.org/lkml/45d32e95-9d57-a424-63bd-b894cf0d3a2b@linux.intel.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/45d32e95-9d57-a424-63bd-b894cf0d3a2b@linux.intel.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: baolu.lu, Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L,
	Nick Kossifidis, Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720123213">linux-riscv</a>,
	<a href="https://lore.kernel.org/lkml/?t=20230720123213">linux-kernel</a>, linux

On 2023/7/20 3:33, Tomasz Jeznach wrote:
<span class=q>&gt; +static void riscv_iommu_iotlb_sync_map(struct iommu_domain *iommu_domain,
&gt; +				       unsigned long iova, size_t size)
&gt; +{
&gt; +	unsigned long end = iova + size - 1;
&gt; +	/*
&gt; +	 * Given we don't know the page size used by this range, we assume the
&gt; +	 * smallest page size to ensure all possible entries are flushed from
&gt; +	 * the IOATC.
&gt; +	 */
&gt; +	size_t pgsize = PAGE_SIZE;
&gt; +	riscv_iommu_flush_iotlb_range(iommu_domain, &amp;iova, &amp;end, &amp;pgsize);
&gt; +}
</span>
Does RISC-V IOMMU require to invalidate the TLB cache after new mappings
are created?

Best regards,
baolu

<a href=#m5c32a5e8f769114a8ba7611812fa02c944920207 id=e5c32a5e8f769114a8ba7611812fa02c944920207>^</a> <a href=https://lore.kernel.org/lkml/45d32e95-9d57-a424-63bd-b894cf0d3a2b@linux.intel.com/>permalink</a> <a href=https://lore.kernel.org/lkml/45d32e95-9d57-a424-63bd-b894cf0d3a2b@linux.intel.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/45d32e95-9d57-a424-63bd-b894cf0d3a2b@linux.intel.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/45d32e95-9d57-a424-63bd-b894cf0d3a2b@linux.intel.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/45d32e95-9d57-a424-63bd-b894cf0d3a2b@linux.intel.com/t/#u>nested</a>] <a href=#r5c32a5e8f769114a8ba7611812fa02c944920207>86+ messages in thread</a></pre><hr><pre><a href=#ebad58991effdd4419c250623cc3d7d3d3edc6000 id=mbad58991effdd4419c250623cc3d7d3d3edc6000>*</a> <b>Re: [PATCH 04/11] MAINTAINERS: Add myself for RISC-V IOMMU driver</b>
  2023-07-19 19:33 ` <a href=#mc8ea74f153739ba422b2d84e3077559061512b9f>[PATCH 04/11] MAINTAINERS: Add myself for RISC-V IOMMU driver</a> Tomasz Jeznach
<b>@ 2023-07-20 12:42   ` Baolu Lu</b>
  2023-07-20 17:32     ` <a href=#m592c653ab4affb67beeea816ec6af8c525df604f>Tomasz Jeznach</a>
  <a href=#rbad58991effdd4419c250623cc3d7d3d3edc6000>0 siblings, 1 reply; 86+ messages in thread</a>
From: Baolu Lu @ 2023-07-20 12:42 UTC (<a href=https://lore.kernel.org/lkml/376985dd-a8b9-b86a-3c12-4633dd4505d7@linux.intel.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/376985dd-a8b9-b86a-3c12-4633dd4505d7@linux.intel.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: baolu.lu, Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L,
	Nick Kossifidis, Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720124301">linux-riscv</a>,
	<a href="https://lore.kernel.org/lkml/?t=20230720124301">linux-kernel</a>, linux

On 2023/7/20 3:33, Tomasz Jeznach wrote:
<span class=q>&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;   MAINTAINERS | 7 +++++++
&gt;   1 file changed, 7 insertions(+)
&gt; 
&gt; diff --git a/MAINTAINERS b/MAINTAINERS
&gt; index aee340630eca..d28b1b99f4c6 100644
&gt; --- a/MAINTAINERS
&gt; +++ b/MAINTAINERS
&gt; @@ -18270,6 +18270,13 @@ F:	arch/riscv/
&gt;   N:	riscv
&gt;   K:	riscv
&gt;   
&gt; +RISC-V IOMMU
&gt; +M:	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; +L:	linux-riscv@lists.infradead.org
</span>
Please add the iommu subsystem mailing list.

iommu@lists.linux.dev

It's the right place to discuss iommu drivers.

<span class=q>&gt; +S:	Maintained
&gt; +F:	Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; +F:	drivers/iommu/riscv/
&gt; +
&gt;   RISC-V MICROCHIP FPGA SUPPORT
&gt;   M:	Conor Dooley &lt;conor.dooley@microchip.com&gt;
&gt;   M:	Daire McNamara &lt;daire.mcnamara@microchip.com&gt;
</span>
Best regards,
baolu

<a href=#mbad58991effdd4419c250623cc3d7d3d3edc6000 id=ebad58991effdd4419c250623cc3d7d3d3edc6000>^</a> <a href=https://lore.kernel.org/lkml/376985dd-a8b9-b86a-3c12-4633dd4505d7@linux.intel.com/>permalink</a> <a href=https://lore.kernel.org/lkml/376985dd-a8b9-b86a-3c12-4633dd4505d7@linux.intel.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/376985dd-a8b9-b86a-3c12-4633dd4505d7@linux.intel.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/376985dd-a8b9-b86a-3c12-4633dd4505d7@linux.intel.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/376985dd-a8b9-b86a-3c12-4633dd4505d7@linux.intel.com/t/#u>nested</a>] <a href=#rbad58991effdd4419c250623cc3d7d3d3edc6000>86+ messages in thread</a></pre><hr><pre><a href=#e5f68224a21ecbc3e04df1c010fdc4945c78bf2fe id=m5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>*</a> <b>Re: [PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-19 19:33 ` <a href=#m64db79f82cb551d51fc635ba160962c425c8cbb2>[PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</a> Tomasz Jeznach
  2023-07-20  6:38   ` <a href=#m4531233107436be4728ad7c9e39b93b11e8c7e48>Krzysztof Kozlowski</a>
<b>@ 2023-07-20 12:50   ` Baolu Lu</b>
  2023-07-20 17:47     ` <a href=#m8378ca0f43c5f33e4a911ef72b4b758bca264722>Tomasz Jeznach</a>
  <a href=#r5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>1 sibling, 1 reply; 86+ messages in thread</a>
From: Baolu Lu @ 2023-07-20 12:50 UTC (<a href=https://lore.kernel.org/lkml/2556751a-c439-bb69-a102-583dd985fc5e@linux.intel.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/2556751a-c439-bb69-a102-583dd985fc5e@linux.intel.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: baolu.lu, Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L,
	Nick Kossifidis, Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720125158">linux-riscv</a>,
	<a href="https://lore.kernel.org/lkml/?t=20230720125158">linux-kernel</a>, linux

On 2023/7/20 3:33, Tomasz Jeznach wrote:
<span class=q>&gt; +#define sysfs_dev_to_iommu(dev) \
&gt; +	container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
&gt; +
&gt; +static ssize_t address_show(struct device *dev,
&gt; +			    struct device_attribute *attr, char *buf)
&gt; +{
&gt; +	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);
&gt; +	return sprintf(buf, "%llx\n", iommu-&gt;reg_phys);
</span>
Use sysfs_emit() please.

<span class=q>&gt; +}
&gt; +
&gt; +static DEVICE_ATTR_RO(address);
&gt; +
&gt; +#define ATTR_RD_REG32(name, offset)					\
&gt; +	ssize_t reg_ ## name ## _show(struct device *dev,		\
&gt; +			struct device_attribute *attr, char *buf)	\
&gt; +{									\
&gt; +	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
&gt; +	return sprintf(buf, "0x%x\n",					\
&gt; +			riscv_iommu_readl(iommu, offset));		\
&gt; +}
&gt; +
&gt; +#define ATTR_RD_REG64(name, offset)					\
&gt; +	ssize_t reg_ ## name ## _show(struct device *dev,		\
&gt; +			struct device_attribute *attr, char *buf)	\
&gt; +{									\
&gt; +	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
&gt; +	return sprintf(buf, "0x%llx\n",					\
&gt; +			riscv_iommu_readq(iommu, offset));		\
&gt; +}
&gt; +
&gt; +#define ATTR_WR_REG32(name, offset)					\
&gt; +	ssize_t reg_ ## name ## _store(struct device *dev,		\
&gt; +			struct device_attribute *attr,			\
&gt; +			const char *buf, size_t len)			\
&gt; +{									\
&gt; +	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
&gt; +	unsigned long val;						\
&gt; +	int ret;							\
&gt; +	ret = kstrtoul(buf, 0, &amp;val);					\
&gt; +	if (ret)							\
&gt; +		return ret;						\
&gt; +	riscv_iommu_writel(iommu, offset, val);				\
&gt; +	return len;							\
&gt; +}
&gt; +
&gt; +#define ATTR_WR_REG64(name, offset)					\
&gt; +	ssize_t reg_ ## name ## _store(struct device *dev,		\
&gt; +			struct device_attribute *attr,			\
&gt; +			const char *buf, size_t len)			\
&gt; +{									\
&gt; +	struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);	\
&gt; +	unsigned long long val;						\
&gt; +	int ret;							\
&gt; +	ret = kstrtoull(buf, 0, &amp;val);					\
&gt; +	if (ret)							\
&gt; +		return ret;						\
&gt; +	riscv_iommu_writeq(iommu, offset, val);				\
&gt; +	return len;							\
&gt; +}
</span>
So this allows users to change the registers through sysfs? How does
it synchronize with the iommu driver?

Best regards,
baolu

<a href=#m5f68224a21ecbc3e04df1c010fdc4945c78bf2fe id=e5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>^</a> <a href=https://lore.kernel.org/lkml/2556751a-c439-bb69-a102-583dd985fc5e@linux.intel.com/>permalink</a> <a href=https://lore.kernel.org/lkml/2556751a-c439-bb69-a102-583dd985fc5e@linux.intel.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/2556751a-c439-bb69-a102-583dd985fc5e@linux.intel.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/2556751a-c439-bb69-a102-583dd985fc5e@linux.intel.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/2556751a-c439-bb69-a102-583dd985fc5e@linux.intel.com/t/#u>nested</a>] <a href=#r5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>86+ messages in thread</a></pre><hr><pre><a href=#e1715001bd807613c4ae6715e3679cf47b74e2a60 id=m1715001bd807613c4ae6715e3679cf47b74e2a60>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-19 19:33 ` <a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</a> Tomasz Jeznach
  2023-07-20  3:11   ` <a href=#me036e876659d5bad1074323224ed7dc70b2e49db>Nick Kossifidis</a>
<b>@ 2023-07-20 13:08   ` Baolu Lu</b>
  2023-07-20 17:49     ` <a href=#m58e762ce3954cfadac358e8316dbdbc9a05cf2d0>Tomasz Jeznach</a>
  2023-07-29 12:58   ` <a href=#m47475dde350a53202c60665ebadd89162dc278d8>Zong Li</a>
  2023-08-16 18:49   ` <a href=#mf18bd90d921132d02c05d7d5894300a045bab960>Robin Murphy</a>
  <a href=#r1715001bd807613c4ae6715e3679cf47b74e2a60>3 siblings, 1 reply; 86+ messages in thread</a>
From: Baolu Lu @ 2023-07-20 13:08 UTC (<a href=https://lore.kernel.org/lkml/d766f11f-45a6-9d47-3bfb-b3632a0b0f0b@linux.intel.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/d766f11f-45a6-9d47-3bfb-b3632a0b0f0b@linux.intel.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: baolu.lu, Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L,
	Nick Kossifidis, Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720131835">linux-riscv</a>,
	<a href="https://lore.kernel.org/lkml/?t=20230720131835">linux-kernel</a>, linux

On 2023/7/20 3:33, Tomasz Jeznach wrote:
<span class=q>&gt; Enables message or wire signal interrupts for PCIe and platforms devices.
</span>
If this patch could be divided into multiple small patches, each
logically doing one specific thing, it will help people better review
the code.

Best regards,
baolu

<a href=#m1715001bd807613c4ae6715e3679cf47b74e2a60 id=e1715001bd807613c4ae6715e3679cf47b74e2a60>^</a> <a href=https://lore.kernel.org/lkml/d766f11f-45a6-9d47-3bfb-b3632a0b0f0b@linux.intel.com/>permalink</a> <a href=https://lore.kernel.org/lkml/d766f11f-45a6-9d47-3bfb-b3632a0b0f0b@linux.intel.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/d766f11f-45a6-9d47-3bfb-b3632a0b0f0b@linux.intel.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/d766f11f-45a6-9d47-3bfb-b3632a0b0f0b@linux.intel.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/d766f11f-45a6-9d47-3bfb-b3632a0b0f0b@linux.intel.com/t/#u>nested</a>] <a href=#r1715001bd807613c4ae6715e3679cf47b74e2a60>86+ messages in thread</a></pre><hr><pre><a href=#e22bfe5a5766790fcc48e9b406ffb296ff8be6413 id=m22bfe5a5766790fcc48e9b406ffb296ff8be6413>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-20 12:31   ` <a href=#m5c32a5e8f769114a8ba7611812fa02c944920207>Baolu Lu</a>
<b>@ 2023-07-20 17:30     ` Tomasz Jeznach</b>
  <a href=#r22bfe5a5766790fcc48e9b406ffb296ff8be6413>0 siblings, 0 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-20 17:30 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u4q1=cKz7yFxKWrP2goypsxTxusYV_aSD-Os33bDZwepQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u4q1=cKz7yFxKWrP2goypsxTxusYV_aSD-Os33bDZwepQ@mail.gmail.com/raw">raw</a>)
  To: Baolu Lu
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720173035">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720173035">linux-kernel</a>, linux

On Thu, Jul 20, 2023 at 5:31 AM Baolu Lu &lt;baolu.lu@linux.intel.com&gt; wrote:
<span class=q>&gt;
&gt; On 2023/7/20 3:33, Tomasz Jeznach wrote:
&gt; &gt; +static void riscv_iommu_iotlb_sync_map(struct iommu_domain *iommu_domain,
&gt; &gt; +                                    unsigned long iova, size_t size)
&gt; &gt; +{
&gt; &gt; +     unsigned long end = iova + size - 1;
&gt; &gt; +     /*
&gt; &gt; +      * Given we don't know the page size used by this range, we assume the
&gt; &gt; +      * smallest page size to ensure all possible entries are flushed from
&gt; &gt; +      * the IOATC.
&gt; &gt; +      */
&gt; &gt; +     size_t pgsize = PAGE_SIZE;
&gt; &gt; +     riscv_iommu_flush_iotlb_range(iommu_domain, &amp;iova, &amp;end, &amp;pgsize);
&gt; &gt; +}
&gt;
&gt; Does RISC-V IOMMU require to invalidate the TLB cache after new mappings
&gt; are created?
&gt;
</span>
No. Only on unmapping / permission change.
Thanks for pointing this out.

<span class=q>&gt; Best regards,
&gt; baolu
</span>
regards,
- Tomasz

<a href=#m22bfe5a5766790fcc48e9b406ffb296ff8be6413 id=e22bfe5a5766790fcc48e9b406ffb296ff8be6413>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u4q1=cKz7yFxKWrP2goypsxTxusYV_aSD-Os33bDZwepQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u4q1=cKz7yFxKWrP2goypsxTxusYV_aSD-Os33bDZwepQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u4q1=cKz7yFxKWrP2goypsxTxusYV_aSD-Os33bDZwepQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u4q1=cKz7yFxKWrP2goypsxTxusYV_aSD-Os33bDZwepQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u4q1=cKz7yFxKWrP2goypsxTxusYV_aSD-Os33bDZwepQ@mail.gmail.com/t/#u">nested</a>] <a href=#r22bfe5a5766790fcc48e9b406ffb296ff8be6413>86+ messages in thread</a></pre><hr><pre><a href=#e592c653ab4affb67beeea816ec6af8c525df604f id=m592c653ab4affb67beeea816ec6af8c525df604f>*</a> <b>Re: [PATCH 04/11] MAINTAINERS: Add myself for RISC-V IOMMU driver</b>
  2023-07-20 12:42   ` <a href=#mbad58991effdd4419c250623cc3d7d3d3edc6000>Baolu Lu</a>
<b>@ 2023-07-20 17:32     ` Tomasz Jeznach</b>
  <a href=#r592c653ab4affb67beeea816ec6af8c525df604f>0 siblings, 0 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-20 17:32 UTC (<a href=https://lore.kernel.org/lkml/CAH2o1u4GuVw-V0AVar97F7ByRWpgRBMrAEP_FTvsrxSKqF8pEw@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CAH2o1u4GuVw-V0AVar97F7ByRWpgRBMrAEP_FTvsrxSKqF8pEw@mail.gmail.com/raw>raw</a>)
  To: Baolu Lu
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720173312">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720173312">linux-kernel</a>, linux

On Thu, Jul 20, 2023 at 5:42 AM Baolu Lu &lt;baolu.lu@linux.intel.com&gt; wrote:
<span class=q>&gt;
&gt; On 2023/7/20 3:33, Tomasz Jeznach wrote:
&gt; &gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; ---
&gt; &gt;   MAINTAINERS | 7 +++++++
&gt; &gt;   1 file changed, 7 insertions(+)
&gt; &gt;
&gt; &gt; diff --git a/MAINTAINERS b/MAINTAINERS
&gt; &gt; index aee340630eca..d28b1b99f4c6 100644
&gt; &gt; --- a/MAINTAINERS
&gt; &gt; +++ b/MAINTAINERS
&gt; &gt; @@ -18270,6 +18270,13 @@ F:   arch/riscv/
&gt; &gt;   N:  riscv
&gt; &gt;   K:  riscv
&gt; &gt;
&gt; &gt; +RISC-V IOMMU
&gt; &gt; +M:   Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; +L:   linux-riscv@lists.infradead.org
&gt;
&gt; Please add the iommu subsystem mailing list.
&gt;
&gt; iommu@lists.linux.dev
&gt;
&gt; It's the right place to discuss iommu drivers.
&gt;
</span>
ack. will add in the next version. Thanks

<span class=q>&gt; &gt; +S:   Maintained
&gt; &gt; +F:   Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; +F:   drivers/iommu/riscv/
&gt; &gt; +
&gt; &gt;   RISC-V MICROCHIP FPGA SUPPORT
&gt; &gt;   M:  Conor Dooley &lt;conor.dooley@microchip.com&gt;
&gt; &gt;   M:  Daire McNamara &lt;daire.mcnamara@microchip.com&gt;
&gt;
&gt; Best regards,
&gt; baolu
</span>
regards,
- Tomasz

<a href=#m592c653ab4affb67beeea816ec6af8c525df604f id=e592c653ab4affb67beeea816ec6af8c525df604f>^</a> <a href=https://lore.kernel.org/lkml/CAH2o1u4GuVw-V0AVar97F7ByRWpgRBMrAEP_FTvsrxSKqF8pEw@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CAH2o1u4GuVw-V0AVar97F7ByRWpgRBMrAEP_FTvsrxSKqF8pEw@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CAH2o1u4GuVw-V0AVar97F7ByRWpgRBMrAEP_FTvsrxSKqF8pEw@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CAH2o1u4GuVw-V0AVar97F7ByRWpgRBMrAEP_FTvsrxSKqF8pEw@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CAH2o1u4GuVw-V0AVar97F7ByRWpgRBMrAEP_FTvsrxSKqF8pEw@mail.gmail.com/t/#u>nested</a>] <a href=#r592c653ab4affb67beeea816ec6af8c525df604f>86+ messages in thread</a></pre><hr><pre><a href=#e8378ca0f43c5f33e4a911ef72b4b758bca264722 id=m8378ca0f43c5f33e4a911ef72b4b758bca264722>*</a> <b>Re: [PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-20 12:50   ` <a href=#m5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>Baolu Lu</a>
<b>@ 2023-07-20 17:47     ` Tomasz Jeznach</b>
  <a href=#r8378ca0f43c5f33e4a911ef72b4b758bca264722>0 siblings, 0 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-20 17:47 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u7WO=Kpki1qMGoq3uJ2vVqhCvffvX0hLGc7o9op2vTCbw@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u7WO=Kpki1qMGoq3uJ2vVqhCvffvX0hLGc7o9op2vTCbw@mail.gmail.com/raw">raw</a>)
  To: Baolu Lu
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720174756">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720174756">linux-kernel</a>, linux

On Thu, Jul 20, 2023 at 5:51 AM Baolu Lu &lt;baolu.lu@linux.intel.com&gt; wrote:
<span class=q>&gt;
&gt; On 2023/7/20 3:33, Tomasz Jeznach wrote:
&gt; &gt; +#define sysfs_dev_to_iommu(dev) \
&gt; &gt; +     container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
&gt; &gt; +
&gt; &gt; +static ssize_t address_show(struct device *dev,
&gt; &gt; +                         struct device_attribute *attr, char *buf)
&gt; &gt; +{
&gt; &gt; +     struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);
&gt; &gt; +     return sprintf(buf, "%llx\n", iommu-&gt;reg_phys);
&gt;
&gt; Use sysfs_emit() please.
&gt;
</span>
ack. Thanks, will update.

<span class=q>&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static DEVICE_ATTR_RO(address);
&gt; &gt; +
&gt; &gt; +#define ATTR_RD_REG32(name, offset)                                  \
&gt; &gt; +     ssize_t reg_ ## name ## _show(struct device *dev,               \
&gt; &gt; +                     struct device_attribute *attr, char *buf)       \
&gt; &gt; +{                                                                    \
&gt; &gt; +     struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);     \
&gt; &gt; +     return sprintf(buf, "0x%x\n",                                   \
&gt; &gt; +                     riscv_iommu_readl(iommu, offset));              \
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +#define ATTR_RD_REG64(name, offset)                                  \
&gt; &gt; +     ssize_t reg_ ## name ## _show(struct device *dev,               \
&gt; &gt; +                     struct device_attribute *attr, char *buf)       \
&gt; &gt; +{                                                                    \
&gt; &gt; +     struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);     \
&gt; &gt; +     return sprintf(buf, "0x%llx\n",                                 \
&gt; &gt; +                     riscv_iommu_readq(iommu, offset));              \
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +#define ATTR_WR_REG32(name, offset)                                  \
&gt; &gt; +     ssize_t reg_ ## name ## _store(struct device *dev,              \
&gt; &gt; +                     struct device_attribute *attr,                  \
&gt; &gt; +                     const char *buf, size_t len)                    \
&gt; &gt; +{                                                                    \
&gt; &gt; +     struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);     \
&gt; &gt; +     unsigned long val;                                              \
&gt; &gt; +     int ret;                                                        \
&gt; &gt; +     ret = kstrtoul(buf, 0, &amp;val);                                   \
&gt; &gt; +     if (ret)                                                        \
&gt; &gt; +             return ret;                                             \
&gt; &gt; +     riscv_iommu_writel(iommu, offset, val);                         \
&gt; &gt; +     return len;                                                     \
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +#define ATTR_WR_REG64(name, offset)                                  \
&gt; &gt; +     ssize_t reg_ ## name ## _store(struct device *dev,              \
&gt; &gt; +                     struct device_attribute *attr,                  \
&gt; &gt; +                     const char *buf, size_t len)                    \
&gt; &gt; +{                                                                    \
&gt; &gt; +     struct riscv_iommu_device *iommu = sysfs_dev_to_iommu(dev);     \
&gt; &gt; +     unsigned long long val;                                         \
&gt; &gt; +     int ret;                                                        \
&gt; &gt; +     ret = kstrtoull(buf, 0, &amp;val);                                  \
&gt; &gt; +     if (ret)                                                        \
&gt; &gt; +             return ret;                                             \
&gt; &gt; +     riscv_iommu_writeq(iommu, offset, val);                         \
&gt; &gt; +     return len;                                                     \
&gt; &gt; +}
&gt;
&gt; So this allows users to change the registers through sysfs? How does
&gt; it synchronize with the iommu driver?
&gt;
</span>
The only writable registers are for debug interface and performance
monitoring counters, without any synchronization requirements between
user / driver.  In follow up patch series performance counters will be
also removed from sysfs, replaced by integration with perfmon
subsystem. The only remaining will be a debug access, providing user
access to address translation, in short it provides an interface to
query SPA based on provided IOVA/RID/PASID. There was a discussion in
RVI IOMMU TG forum if it's acceptable to expose such an interface to
the privileged user, and the conclusion was that it's very likely not
exposing more info than privileged users already are able to acquire
by looking at in-memory data structures.

Read-only registers are to provide debug access to track queue
head/tail pointers and interrupt states.

<span class=q>&gt; Best regards,
&gt; baolu
</span>
regards,
- Tomasz

<a href=#m8378ca0f43c5f33e4a911ef72b4b758bca264722 id=e8378ca0f43c5f33e4a911ef72b4b758bca264722>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u7WO=Kpki1qMGoq3uJ2vVqhCvffvX0hLGc7o9op2vTCbw@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u7WO=Kpki1qMGoq3uJ2vVqhCvffvX0hLGc7o9op2vTCbw@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u7WO=Kpki1qMGoq3uJ2vVqhCvffvX0hLGc7o9op2vTCbw@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u7WO=Kpki1qMGoq3uJ2vVqhCvffvX0hLGc7o9op2vTCbw@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u7WO=Kpki1qMGoq3uJ2vVqhCvffvX0hLGc7o9op2vTCbw@mail.gmail.com/t/#u">nested</a>] <a href=#r8378ca0f43c5f33e4a911ef72b4b758bca264722>86+ messages in thread</a></pre><hr><pre><a href=#e58e762ce3954cfadac358e8316dbdbc9a05cf2d0 id=m58e762ce3954cfadac358e8316dbdbc9a05cf2d0>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-20 13:08   ` <a href=#m1715001bd807613c4ae6715e3679cf47b74e2a60>Baolu Lu</a>
<b>@ 2023-07-20 17:49     ` Tomasz Jeznach</b>
  <a href=#r58e762ce3954cfadac358e8316dbdbc9a05cf2d0>0 siblings, 0 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-20 17:49 UTC (<a href=https://lore.kernel.org/lkml/CAH2o1u4Y5R16QQsed4TuKKiv6ir+uWB98A3Z5adBaF8pPLQ5Eg@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CAH2o1u4Y5R16QQsed4TuKKiv6ir+uWB98A3Z5adBaF8pPLQ5Eg@mail.gmail.com/raw>raw</a>)
  To: Baolu Lu
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720174941">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720174941">linux-kernel</a>, linux

On Thu, Jul 20, 2023 at 6:18 AM Baolu Lu &lt;baolu.lu@linux.intel.com&gt; wrote:
<span class=q>&gt;
&gt; On 2023/7/20 3:33, Tomasz Jeznach wrote:
&gt; &gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt;
&gt; If this patch could be divided into multiple small patches, each
&gt; logically doing one specific thing, it will help people better review
&gt; the code.
&gt;
</span>
ack. I've got a similar comment regarding this patch already.
I will split and add more notes to the commit message. Thanks.


<span class=q>&gt; Best regards,
&gt; baolu
&gt;
</span>

regards,
- Tomasz

<a href=#m58e762ce3954cfadac358e8316dbdbc9a05cf2d0 id=e58e762ce3954cfadac358e8316dbdbc9a05cf2d0>^</a> <a href=https://lore.kernel.org/lkml/CAH2o1u4Y5R16QQsed4TuKKiv6ir+uWB98A3Z5adBaF8pPLQ5Eg@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CAH2o1u4Y5R16QQsed4TuKKiv6ir+uWB98A3Z5adBaF8pPLQ5Eg@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CAH2o1u4Y5R16QQsed4TuKKiv6ir+uWB98A3Z5adBaF8pPLQ5Eg@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CAH2o1u4Y5R16QQsed4TuKKiv6ir+uWB98A3Z5adBaF8pPLQ5Eg@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CAH2o1u4Y5R16QQsed4TuKKiv6ir+uWB98A3Z5adBaF8pPLQ5Eg@mail.gmail.com/t/#u>nested</a>] <a href=#r58e762ce3954cfadac358e8316dbdbc9a05cf2d0>86+ messages in thread</a></pre><hr><pre><a href=#e505d10dd50c508c0a38b520f5cd63968f20076a8 id=m505d10dd50c508c0a38b520f5cd63968f20076a8>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-20  3:11   ` <a href=#me036e876659d5bad1074323224ed7dc70b2e49db>Nick Kossifidis</a>
<b>@ 2023-07-20 18:00     ` Tomasz Jeznach</b>
  2023-07-20 18:43       ` <a href=#m132855bc1023899551b404f99620d13a649274e8>Conor Dooley</a>
  2023-07-24  9:47       ` <a href=#ma907ef87338b36d71e27c34ee0ef394c7f908811>Zong Li</a>
  <a href=#r505d10dd50c508c0a38b520f5cd63968f20076a8>0 siblings, 2 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-20 18:00 UTC (<a href=https://lore.kernel.org/lkml/CAH2o1u7uAuXsD6+6Dvam4kzQuUj8s98G0sR26_-q31wvSUYZNA@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CAH2o1u7uAuXsD6+6Dvam4kzQuUj8s98G0sR26_-q31wvSUYZNA@mail.gmail.com/raw>raw</a>)
  To: Nick Kossifidis
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Sebastien Boeuf,
	iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720180028">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720180028">linux-kernel</a>, linux

On Wed, Jul 19, 2023 at 8:12 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
<span class=q>&gt;
&gt; Hello Tomasz,
&gt;
&gt; On 7/19/23 22:33, Tomasz Jeznach wrote:
&gt; &gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; &gt;
&gt;
&gt; The description doesn't match the subject nor the patch content (we
&gt; don't jus enable interrupts, we also init the queues).
&gt;
&gt; &gt; +     /* Parse Queue lengts */
&gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt; +     if (!ret)
&gt; &gt; +             dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt; +
&gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt; +     if (!ret)
&gt; &gt; +             dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt; +
&gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt; +     if (!ret)
&gt; &gt; +             dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt; +
&gt; &gt;       dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt;
&gt;
&gt; We need to add those to the device tree binding doc (or throw them away,
&gt; I thought it would be better to have them as part of the device
&gt; desciption than a module parameter).
&gt;
</span>
We can add them as an optional fields to DT.
Alternatively, I've been looking into an option to auto-scale CQ/PQ
based on number of attached devices, but this gets trickier for
hot-pluggable systems. I've added module parameters as a bare-minimum,
but still looking for better solutions.

<span class=q>&gt;
&gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; &gt; +
&gt;
&gt; &gt; +     case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; &gt; +             q = &amp;iommu-&gt;priq;
&gt; &gt; +             q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; &gt; +             count = iommu-&gt;priq_len;
&gt; &gt; +             irq = iommu-&gt;irq_priq;
&gt; &gt; +             irq_check = riscv_iommu_priq_irq_check;
&gt; &gt; +             irq_process = riscv_iommu_priq_process;
&gt; &gt; +             q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; &gt; +             q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; &gt; +             name = "priq";
&gt; &gt; +             break;
&gt;
&gt;
&gt; It makes more sense to add the code for the page request queue in the
&gt; patch that adds ATS/PRI support IMHO. This comment also applies to its
&gt; interrupt handlers below.
&gt;
</span>
ack. will do.

<span class=q>&gt;
&gt; &gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; &gt; +                                               u64 addr)
&gt; &gt; +{
&gt; &gt; +     cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; &gt; +     cmd-&gt;dword1 = addr;
&gt; &gt; +}
&gt; &gt; +
&gt;
&gt; This needs to be (addr &gt;&gt; 2) to match the spec, same as in the iofence
&gt; command.
&gt;
</span>
oops. Thanks!

<span class=q>&gt; Regards,
&gt; Nick
&gt;
</span>
regards,
- Tomasz

<a href=#m505d10dd50c508c0a38b520f5cd63968f20076a8 id=e505d10dd50c508c0a38b520f5cd63968f20076a8>^</a> <a href=https://lore.kernel.org/lkml/CAH2o1u7uAuXsD6+6Dvam4kzQuUj8s98G0sR26_-q31wvSUYZNA@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CAH2o1u7uAuXsD6+6Dvam4kzQuUj8s98G0sR26_-q31wvSUYZNA@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CAH2o1u7uAuXsD6+6Dvam4kzQuUj8s98G0sR26_-q31wvSUYZNA@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CAH2o1u7uAuXsD6+6Dvam4kzQuUj8s98G0sR26_-q31wvSUYZNA@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CAH2o1u7uAuXsD6+6Dvam4kzQuUj8s98G0sR26_-q31wvSUYZNA@mail.gmail.com/t/#u>nested</a>] <a href=#r505d10dd50c508c0a38b520f5cd63968f20076a8>86+ messages in thread</a></pre><hr><pre><a href=#e10ac8115fa338f5759d5ebc64181be18eecea21c id=m10ac8115fa338f5759d5ebc64181be18eecea21c>*</a> <b>Re: [PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-20  6:38   ` <a href=#m4531233107436be4728ad7c9e39b93b11e8c7e48>Krzysztof Kozlowski</a>
<b>@ 2023-07-20 18:30     ` Tomasz Jeznach</b>
  2023-07-20 21:37       ` <a href=#m553a62188f2eeca66633e2f6351bc323ed35dd3f>Krzysztof Kozlowski</a>
  <a href=#r10ac8115fa338f5759d5ebc64181be18eecea21c>0 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-20 18:30 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u6pMF3MN=oFBcs9kOf-nwnEYfD2Vv=89+DzUanV59R5dw@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u6pMF3MN=oFBcs9kOf-nwnEYfD2Vv=89+DzUanV59R5dw@mail.gmail.com/raw">raw</a>)
  To: Krzysztof Kozlowski
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720183019">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720183019">linux-kernel</a>, linux

On Wed, Jul 19, 2023 at 11:38 PM Krzysztof Kozlowski &lt;krzk@kernel.org&gt; wrote:
<span class=q>&gt;
&gt; On 19/07/2023 21:33, Tomasz Jeznach wrote:
&gt; &gt; Enable sysfs debug / visibility interface providing restricted
&gt; &gt; access to hardware registers.
&gt;
&gt; Please use subject prefixes matching the subsystem. You can get them for
&gt; example with `git log --oneline -- DIRECTORY_OR_FILE` on the directory
&gt; your patch is touching.
&gt;
</span>
ack.

<span class=q>&gt; &gt;
&gt; &gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; ---
&gt; &gt;  drivers/iommu/riscv/Makefile      |   2 +-
&gt; &gt;  drivers/iommu/riscv/iommu-sysfs.c | 183 ++++++++++++++++++++++++++++++
&gt; &gt;  drivers/iommu/riscv/iommu.c       |   7 ++
&gt; &gt;  drivers/iommu/riscv/iommu.h       |   2 +
&gt; &gt;  4 files changed, 193 insertions(+), 1 deletion(-)
&gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-sysfs.c
&gt; &gt;
&gt; &gt; diff --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
&gt; &gt; index 38730c11e4a8..9523eb053cfc 100644
&gt; &gt; --- a/drivers/iommu/riscv/Makefile
&gt; &gt; +++ b/drivers/iommu/riscv/Makefile
&gt; &gt; @@ -1 +1 @@
&gt; &gt; -obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o
&gt; &gt; \ No newline at end of file
&gt; &gt; +obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o
&gt; &gt; \ No newline at end of file
&gt;
&gt; You have this error in multiple places.
&gt;
</span>
ack. next version will run through checkpatch.pl, should spot such problems.

<span class=q>&gt; &gt; diff --git a/drivers/iommu/riscv/iommu-sysfs.c b/drivers/iommu/riscv/iommu-sysfs.c
&gt; &gt; new file mode 100644
&gt; &gt; index 000000000000..f038ea8445c5
&gt; &gt; --- /dev/null
&gt; &gt; +++ b/drivers/iommu/riscv/iommu-sysfs.c
&gt; &gt; @@ -0,0 +1,183 @@
&gt; &gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; &gt; +/*
&gt; &gt; + * IOMMU API for RISC-V architected Ziommu implementations.
&gt; &gt; + *
&gt; &gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; &gt; + *
&gt; &gt; + * Author: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; + */
&gt; &gt; +
&gt; &gt; +#include &lt;linux/module.h&gt;
&gt; &gt; +#include &lt;linux/kernel.h&gt;
&gt; &gt; +#include &lt;linux/compiler.h&gt;
&gt; &gt; +#include &lt;linux/iommu.h&gt;
&gt; &gt; +#include &lt;linux/platform_device.h&gt;
&gt; &gt; +#include &lt;asm/page.h&gt;
&gt; &gt; +
&gt; &gt; +#include "iommu.h"
&gt; &gt; +
&gt; &gt; +#define sysfs_dev_to_iommu(dev) \
&gt; &gt; +     container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
&gt; &gt; +
&gt; &gt; +static ssize_t address_show(struct device *dev,
&gt; &gt; +                         struct device_attribute *attr, char *buf)
&gt;
&gt;
&gt; Where is the sysfs ABI documented?
&gt;
</span>
Sysfs for now is used only to expose selected IOMMU memory mapped
registers, with complete documentation in the RISC-V IOMMU Arch Spec
[1], and some comments in iommu-bits.h file.
LMK If it would be better to put a dedicated file documenting those
with the patch itself.


[1] <a href=https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf>https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf</a>

<span class=q>&gt;
&gt; Best regards,
&gt; Krzysztof
&gt;
</span>
regards,
- Tomasz

<a href=#m10ac8115fa338f5759d5ebc64181be18eecea21c id=e10ac8115fa338f5759d5ebc64181be18eecea21c>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6pMF3MN=oFBcs9kOf-nwnEYfD2Vv=89+DzUanV59R5dw@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6pMF3MN=oFBcs9kOf-nwnEYfD2Vv=89+DzUanV59R5dw@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6pMF3MN=oFBcs9kOf-nwnEYfD2Vv=89+DzUanV59R5dw@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u6pMF3MN=oFBcs9kOf-nwnEYfD2Vv=89+DzUanV59R5dw@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u6pMF3MN=oFBcs9kOf-nwnEYfD2Vv=89+DzUanV59R5dw@mail.gmail.com/t/#u">nested</a>] <a href=#r10ac8115fa338f5759d5ebc64181be18eecea21c>86+ messages in thread</a></pre><hr><pre><a href=#e132855bc1023899551b404f99620d13a649274e8 id=m132855bc1023899551b404f99620d13a649274e8>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-20 18:00     ` <a href=#m505d10dd50c508c0a38b520f5cd63968f20076a8>Tomasz Jeznach</a>
<b>@ 2023-07-20 18:43       ` Conor Dooley</b>
  2023-07-24  9:47       ` <a href=#ma907ef87338b36d71e27c34ee0ef394c7f908811>Zong Li</a>
  <a href=#r132855bc1023899551b404f99620d13a649274e8>1 sibling, 0 replies; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-20 18:43 UTC (<a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Nick Kossifidis, Anup Patel, Albert Ou, linux, Will Deacon,
	Joerg Roedel, <a href="https://lore.kernel.org/lkml/?t=20230720184315">linux-kernel</a>, Sebastien Boeuf, iommu,
	Palmer Dabbelt, Paul Walmsley, <a href="https://lore.kernel.org/linux-riscv/?t=20230720184315">linux-riscv</a>, Robin Murphy

<a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 1986 bytes --]</a>

On Thu, Jul 20, 2023 at 11:00:10AM -0700, Tomasz Jeznach wrote:
<span class=q>&gt; On Wed, Jul 19, 2023 at 8:12 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt; &gt; On 7/19/23 22:33, Tomasz Jeznach wrote:
&gt; &gt; The description doesn't match the subject nor the patch content (we
&gt; &gt; don't jus enable interrupts, we also init the queues).
&gt; &gt;
&gt; &gt; &gt; +     /* Parse Queue lengts */
&gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; +             dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; +             dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; +             dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt;       dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; We need to add those to the device tree binding doc (or throw them away,
&gt; &gt; I thought it would be better to have them as part of the device
&gt; &gt; desciption than a module parameter).
</span>
Aye, I didn't notice these. Any DT properties /must/ be documented.
To avoid having to make the comments on v2, properties should also not
contain underscores.

<span class=q>&gt; We can add them as an optional fields to DT.
&gt; Alternatively, I've been looking into an option to auto-scale CQ/PQ
&gt; based on number of attached devices, but this gets trickier for
&gt; hot-pluggable systems. I've added module parameters as a bare-minimum,
&gt; but still looking for better solutions.
</span>
If they're properties of the hardware, they should come from DT/ACPI,
unless they're auto-detectable, in which case that is preferred.
To quote GregKH "please do not add new module parameters for drivers,
this is not the 1990s" :)

<a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m132855bc1023899551b404f99620d13a649274e8 id=e132855bc1023899551b404f99620d13a649274e8>^</a> <a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230720-heftiness-refill-465b3d122049@spud/t/#u>nested</a>] <a href=#r132855bc1023899551b404f99620d13a649274e8>86+ messages in thread</a></pre><hr><pre><a href=#e7c76b2906bb58a75b5a08e305e41c946fb24f5af id=m7c76b2906bb58a75b5a08e305e41c946fb24f5af>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 21:43     ` <a href=#m7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>Tomasz Jeznach</a>
<b>@ 2023-07-20 19:27       ` Conor Dooley</b>
  2023-07-21  9:44       ` <a href=#m395bb5e2fc32d6655db1f3d57b32806919889e01>Conor Dooley</a>
  <a href=#r7c76b2906bb58a75b5a08e305e41c946fb24f5af>1 sibling, 0 replies; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-20 19:27 UTC (<a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230720192716">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230720192716">linux-riscv</a>

<a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 753 bytes --]</a>

On Wed, Jul 19, 2023 at 02:43:51PM -0700, Tomasz Jeznach wrote:
<span class=q>&gt; On Wed, Jul 19, 2023 at 1:50 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
</span>
<span class=q>&gt; &gt; Anyway, what I wanted to ask was whether it was valid to use the IOMMU
&gt; &gt; in a system if Ziommu is not present in whatever the ISA extension
&gt; &gt; communication mechanism is? Eg, riscv,isa or the ISA string property in
&gt; &gt; the ACPI tables.
&gt; &gt;
&gt; 
&gt; Yes, this has been pointed out to me already. As far as I can recall,
&gt; there was a discussion
&gt; at some point to introduce those as Ziommu extensions, later agreeing
&gt; not to call IOMMU
&gt; using ISA string conventions.  Will remove remaining occurrences of
&gt; Ziommu from the series.
</span>
Right, thanks for clearing that up. I got a bit confused :)

<a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m7c76b2906bb58a75b5a08e305e41c946fb24f5af id=e7c76b2906bb58a75b5a08e305e41c946fb24f5af>^</a> <a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230720-charter-lustrous-061e7550ce7c@spud/t/#u>nested</a>] <a href=#r7c76b2906bb58a75b5a08e305e41c946fb24f5af>86+ messages in thread</a></pre><hr><pre><a href=#e553a62188f2eeca66633e2f6351bc323ed35dd3f id=m553a62188f2eeca66633e2f6351bc323ed35dd3f>*</a> <b>Re: [PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-20 18:30     ` <a href=#m10ac8115fa338f5759d5ebc64181be18eecea21c>Tomasz Jeznach</a>
<b>@ 2023-07-20 21:37       ` Krzysztof Kozlowski</b>
  2023-07-20 22:08         ` <a href=#m6000bce5c9a4c95efc9f2efc56d8acb45105082b>Conor Dooley</a>
  <a href=#r553a62188f2eeca66633e2f6351bc323ed35dd3f>0 siblings, 1 reply; 86+ messages in thread</a>
From: Krzysztof Kozlowski @ 2023-07-20 21:37 UTC (<a href=https://lore.kernel.org/lkml/69800c58-2df8-25e5-09e0-c9929bae2193@kernel.org/>permalink</a> / <a href=https://lore.kernel.org/lkml/69800c58-2df8-25e5-09e0-c9929bae2193@kernel.org/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720213814">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230720213814">linux-kernel</a>, linux

On 20/07/2023 20:30, Tomasz Jeznach wrote:
u.h"
<span class=q>&gt;&gt;&gt; +
&gt;&gt;&gt; +#define sysfs_dev_to_iommu(dev) \
&gt;&gt;&gt; +     container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
&gt;&gt;&gt; +
&gt;&gt;&gt; +static ssize_t address_show(struct device *dev,
&gt;&gt;&gt; +                         struct device_attribute *attr, char *buf)
&gt;&gt;
&gt;&gt;
&gt;&gt; Where is the sysfs ABI documented?
&gt;&gt;
&gt; 
&gt; Sysfs for now is used only to expose selected IOMMU memory mapped
&gt; registers, with complete documentation in the RISC-V IOMMU Arch Spec
&gt; [1], and some comments in iommu-bits.h file.
&gt; LMK If it would be better to put a dedicated file documenting those
&gt; with the patch itself.
</span>
I meant, you created new sysfs interface. Maybe I missed something in
the patchset, but each new sysfs interface required documenting in
Documentation/ABI/.

Best regards,
Krzysztof


<a href=#m553a62188f2eeca66633e2f6351bc323ed35dd3f id=e553a62188f2eeca66633e2f6351bc323ed35dd3f>^</a> <a href=https://lore.kernel.org/lkml/69800c58-2df8-25e5-09e0-c9929bae2193@kernel.org/>permalink</a> <a href=https://lore.kernel.org/lkml/69800c58-2df8-25e5-09e0-c9929bae2193@kernel.org/raw>raw</a> <a href=https://lore.kernel.org/lkml/69800c58-2df8-25e5-09e0-c9929bae2193@kernel.org/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/69800c58-2df8-25e5-09e0-c9929bae2193@kernel.org/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/69800c58-2df8-25e5-09e0-c9929bae2193@kernel.org/t/#u>nested</a>] <a href=#r553a62188f2eeca66633e2f6351bc323ed35dd3f>86+ messages in thread</a></pre><hr><pre><a href=#e6000bce5c9a4c95efc9f2efc56d8acb45105082b id=m6000bce5c9a4c95efc9f2efc56d8acb45105082b>*</a> <b>Re: [PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-20 21:37       ` <a href=#m553a62188f2eeca66633e2f6351bc323ed35dd3f>Krzysztof Kozlowski</a>
<b>@ 2023-07-20 22:08         ` Conor Dooley</b>
  2023-07-21  3:49           ` <a href=#m4f06e2bc03df48f15ed4a8577c6e825304ac91f1>Tomasz Jeznach</a>
  <a href=#r6000bce5c9a4c95efc9f2efc56d8acb45105082b>0 siblings, 1 reply; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-20 22:08 UTC (<a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/raw>raw</a>)
  To: Krzysztof Kozlowski
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L,
	Nick Kossifidis, Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230720220857">linux-riscv</a>,
	<a href="https://lore.kernel.org/lkml/?t=20230720220857">linux-kernel</a>, linux

<a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 1317 bytes --]</a>

On Thu, Jul 20, 2023 at 11:37:50PM +0200, Krzysztof Kozlowski wrote:
<span class=q>&gt; On 20/07/2023 20:30, Tomasz Jeznach wrote:
</span>
<span class=q>&gt; &gt;&gt;&gt; +#define sysfs_dev_to_iommu(dev) \
&gt; &gt;&gt;&gt; +     container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
&gt; &gt;&gt;&gt; +
&gt; &gt;&gt;&gt; +static ssize_t address_show(struct device *dev,
&gt; &gt;&gt;&gt; +                         struct device_attribute *attr, char *buf)
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; Where is the sysfs ABI documented?
&gt; &gt;&gt;
&gt; &gt; 
&gt; &gt; Sysfs for now is used only to expose selected IOMMU memory mapped
&gt; &gt; registers, with complete documentation in the RISC-V IOMMU Arch Spec
&gt; &gt; [1], and some comments in iommu-bits.h file.
&gt; &gt; LMK If it would be better to put a dedicated file documenting those
&gt; &gt; with the patch itself.
&gt; 
&gt; I meant, you created new sysfs interface. Maybe I missed something in
&gt; the patchset, but each new sysfs interface required documenting in
&gt; Documentation/ABI/.
</span>
| expose selected IOMMU memory mapped registers

| Enable sysfs debug / visibility interface providing restricted
| access to hardware registers.

Documentation requirements of sysfs stuff aside, I'm not sure that we
even want a sysfs interface for this in the first place? Seems like, if
at all, this should be debugfs instead? Seems like the only use case for
it is debugging/development...

<a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m6000bce5c9a4c95efc9f2efc56d8acb45105082b id=e6000bce5c9a4c95efc9f2efc56d8acb45105082b>^</a> <a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230720-bully-famine-dfc9a5e688ef@spud/t/#u>nested</a>] <a href=#r6000bce5c9a4c95efc9f2efc56d8acb45105082b>86+ messages in thread</a></pre><hr><pre><a href=#e4f06e2bc03df48f15ed4a8577c6e825304ac91f1 id=m4f06e2bc03df48f15ed4a8577c6e825304ac91f1>*</a> <b>Re: [PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</b>
  2023-07-20 22:08         ` <a href=#m6000bce5c9a4c95efc9f2efc56d8acb45105082b>Conor Dooley</a>
<b>@ 2023-07-21  3:49           ` Tomasz Jeznach</b>
  <a href=#r4f06e2bc03df48f15ed4a8577c6e825304ac91f1>0 siblings, 0 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-21  3:49 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u77EpQN6QOatc9vr7NjVk3Yzn=mjFkHmTB13PCxZfbqoQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u77EpQN6QOatc9vr7NjVk3Yzn=mjFkHmTB13PCxZfbqoQ@mail.gmail.com/raw">raw</a>)
  To: Conor Dooley
  Cc: Krzysztof Kozlowski, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L,
	Nick Kossifidis, Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230721035003">linux-riscv</a>,
	<a href="https://lore.kernel.org/lkml/?t=20230721035003">linux-kernel</a>, linux

On Thu, Jul 20, 2023 at 3:08 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
<span class=q>&gt;
&gt; On Thu, Jul 20, 2023 at 11:37:50PM +0200, Krzysztof Kozlowski wrote:
&gt; &gt; On 20/07/2023 20:30, Tomasz Jeznach wrote:
&gt;
&gt; &gt; &gt;&gt;&gt; +#define sysfs_dev_to_iommu(dev) \
&gt; &gt; &gt;&gt;&gt; +     container_of(dev_get_drvdata(dev), struct riscv_iommu_device, iommu)
&gt; &gt; &gt;&gt;&gt; +
&gt; &gt; &gt;&gt;&gt; +static ssize_t address_show(struct device *dev,
&gt; &gt; &gt;&gt;&gt; +                         struct device_attribute *attr, char *buf)
&gt; &gt; &gt;&gt;
&gt; &gt; &gt;&gt;
&gt; &gt; &gt;&gt; Where is the sysfs ABI documented?
&gt; &gt; &gt;&gt;
&gt; &gt; &gt;
&gt; &gt; &gt; Sysfs for now is used only to expose selected IOMMU memory mapped
&gt; &gt; &gt; registers, with complete documentation in the RISC-V IOMMU Arch Spec
&gt; &gt; &gt; [1], and some comments in iommu-bits.h file.
&gt; &gt; &gt; LMK If it would be better to put a dedicated file documenting those
&gt; &gt; &gt; with the patch itself.
&gt; &gt;
&gt; &gt; I meant, you created new sysfs interface. Maybe I missed something in
&gt; &gt; the patchset, but each new sysfs interface required documenting in
&gt; &gt; Documentation/ABI/.
&gt;
&gt; | expose selected IOMMU memory mapped registers
&gt;
&gt; | Enable sysfs debug / visibility interface providing restricted
&gt; | access to hardware registers.
&gt;
&gt; Documentation requirements of sysfs stuff aside, I'm not sure that we
&gt; even want a sysfs interface for this in the first place? Seems like, if
&gt; at all, this should be debugfs instead? Seems like the only use case for
&gt; it is debugging/development...
</span>
Thanks Conor, will switch to debugfs. This will be a more suitable interface.

regards,
- Tomasz

<a href=#m4f06e2bc03df48f15ed4a8577c6e825304ac91f1 id=e4f06e2bc03df48f15ed4a8577c6e825304ac91f1>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u77EpQN6QOatc9vr7NjVk3Yzn=mjFkHmTB13PCxZfbqoQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u77EpQN6QOatc9vr7NjVk3Yzn=mjFkHmTB13PCxZfbqoQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u77EpQN6QOatc9vr7NjVk3Yzn=mjFkHmTB13PCxZfbqoQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u77EpQN6QOatc9vr7NjVk3Yzn=mjFkHmTB13PCxZfbqoQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u77EpQN6QOatc9vr7NjVk3Yzn=mjFkHmTB13PCxZfbqoQ@mail.gmail.com/t/#u">nested</a>] <a href=#r4f06e2bc03df48f15ed4a8577c6e825304ac91f1>86+ messages in thread</a></pre><hr><pre><a href=#e395bb5e2fc32d6655db1f3d57b32806919889e01 id=m395bb5e2fc32d6655db1f3d57b32806919889e01>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 21:43     ` <a href=#m7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>Tomasz Jeznach</a>
  2023-07-20 19:27       ` <a href=#m7c76b2906bb58a75b5a08e305e41c946fb24f5af>Conor Dooley</a>
<b>@ 2023-07-21  9:44       ` Conor Dooley</b>
  <a href=#r395bb5e2fc32d6655db1f3d57b32806919889e01>1 sibling, 0 replies; 86+ messages in thread</a>
From: Conor Dooley @ 2023-07-21  9:44 UTC (<a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230721094512">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230721094512">linux-riscv</a>

<a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 1311 bytes --]</a>

On Wed, Jul 19, 2023 at 02:43:51PM -0700, Tomasz Jeznach wrote:
<span class=q>&gt; On Wed, Jul 19, 2023 at 1:50 PM Conor Dooley &lt;conor@kernel.org&gt; wrote:
</span>
<span class=q>&gt; &gt; Also, since I am not going to reply to any of these iommu driver patches
&gt; &gt; in a meaningful capacity, please run checkpatch.pl on your work. There
&gt; &gt; are well over 100 style etc complaints that it has highlighted. Sparse
&gt; &gt; has also gone a bit nuts, with many warnings along the lines of:
&gt; &gt; drivers/iommu/riscv/iommu.c:1568:29: warning: incorrect type in assignment (different base types)
&gt; &gt; drivers/iommu/riscv/iommu.c:1568:29:    expected unsigned long long [usertype] iohgatp
&gt; &gt; drivers/iommu/riscv/iommu.c:1568:29:    got restricted __le64 [usertype]
&gt; &gt;
&gt; &gt; I can provide you the full list when the patchwork automation has run
&gt; &gt; through the series.
&gt; &gt;
&gt; 
&gt; Thank you, a list of used lint checkers definitely would help.
</span>
checkpatch is mentioned in the patch submission documentation ;)

Anyway, here's the series on patchwork:
<a href="https://patchwork.kernel.org/project/linux-riscv/list/?series=767543">https://patchwork.kernel.org/project/linux-riscv/list/?series=767543</a>
You can see there's quite a few failure for each patch, so you'll need
to resolve those.

Also, I noticed the 32-bit build is broken in some patches, so please
build this driver for 32-bit before sending a v2.

Thanks,
Conor.

<a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m395bb5e2fc32d6655db1f3d57b32806919889e01 id=e395bb5e2fc32d6655db1f3d57b32806919889e01>^</a> <a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230721-obedience-prenatal-77f3c02632be@spud/t/#u>nested</a>] <a href=#r395bb5e2fc32d6655db1f3d57b32806919889e01>86+ messages in thread</a></pre><hr><pre><a href=#eefb742c2ddae58fd3cf54da7451501e4bd3a30a7 id=mefb742c2ddae58fd3cf54da7451501e4bd3a30a7>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-19 19:33 ` <a href=#mbf8dc4098fb09b87b2618c5c545ae882f11b114b>[PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</a> Tomasz Jeznach
  2023-07-19 20:19   ` <a href=#m88a4003327a711a111ee2c4d48bf98696a66bc8b>Conor Dooley</a>
<b>@ 2023-07-24  8:03   ` Zong Li</b>
  2023-07-24 10:02     ` <a href=#m570ddc11336ccb2371984a53d8c2206a4b125953>Anup Patel</a>
  <a href=#refb742c2ddae58fd3cf54da7451501e4bd3a30a7>1 sibling, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-24  8:03 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0r=2eqpy9wLjVt1U0J7=LpnJLcKV7N9d90jvCss=7+Fzg@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0r=2eqpy9wLjVt1U0J7=LpnJLcKV7N9d90jvCss=7+Fzg@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230724080342">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230724080342">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:35 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt;
&gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; defined by the RISC-V IOMMU specification.
&gt;
&gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; ---
&gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt;  1 file changed, 146 insertions(+)
&gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt;
&gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; new file mode 100644
&gt; index 000000000000..8a9aedb61768
&gt; --- /dev/null
&gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; @@ -0,0 +1,146 @@
&gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; +%YAML 1.2
&gt; +---
&gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; +
&gt; +title: RISC-V IOMMU Implementation
&gt; +
&gt; +maintainers:
&gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; +
&gt; +description:
&gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt; +  which can be a regular platform device or a PCI device connected to
&gt; +  the host root port.
&gt; +
&gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; +  both PCI and platform devices.
&gt; +
&gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; +
&gt; +properties:
&gt; +  compatible:
&gt; +    oneOf:
&gt; +      - description: RISC-V IOMMU as a platform device
&gt; +        items:
&gt; +          - enum:
&gt; +              - vendor,chip-iommu
&gt; +          - const: riscv,iommu
&gt; +
&gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; +        items:
&gt; +          - enum:
&gt; +              - vendor,chip-pci-iommu
&gt; +          - const: riscv,pci-iommu
&gt; +
&gt; +  reg:
&gt; +    maxItems: 1
&gt; +    description:
&gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; +      address of registers.
&gt; +
&gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
&gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
&gt; +
&gt; +  '#iommu-cells':
&gt; +    const: 2
&gt; +    description: |
&gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; +      device IDs.
&gt; +
&gt; +  interrupts:
&gt; +    minItems: 1
&gt; +    maxItems: 16
&gt; +    description:
&gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; +
&gt; +  msi-parent:
&gt; +    description:
&gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; +      considered only when the interrupts property is absent.
&gt; +
&gt; +  dma-coherent:
&gt; +    description:
&gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; +      are cache coherent with the CPU.
&gt; +
&gt; +  power-domains:
&gt; +    maxItems: 1
&gt; +
</span>
In RISC-V IOMMU, certain devices can be set to bypass mode when the
IOMMU is in translation mode. To identify the devices that require
bypass mode by default, does it be sensible to add a property to
indicate this behavior?

<span class=q>&gt; +required:
&gt; +  - compatible
&gt; +  - reg
&gt; +  - '#iommu-cells'
&gt; +
&gt; +additionalProperties: false
&gt; +
&gt; +examples:
&gt; +  - |
&gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; +    immu1: iommu@1bccd000 {
&gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; +        #iommu-cells = &lt;2&gt;;
&gt; +    };
&gt; +
&gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; +    master1 {
&gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; +    };
&gt; +
&gt; +  - |
&gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; +    immu2: iommu@1bcdd000 {
&gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; +        #iommu-cells = &lt;2&gt;;
&gt; +    };
&gt; +
&gt; +    bus {
&gt; +        #address-cells = &lt;2&gt;;
&gt; +        #size-cells = &lt;2&gt;;
&gt; +
&gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; +        master1 {
&gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; +        };
&gt; +
&gt; +        pcie@40000000 {
&gt; +            compatible = "pci-host-cam-generic";
&gt; +            device_type = "pci";
&gt; +            #address-cells = &lt;3&gt;;
&gt; +            #size-cells = &lt;2&gt;;
&gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; +
&gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
&gt; +            reg = &lt;0x0 0x40000000 0x0 0x1000000&gt;;
&gt; +
&gt; +            /* BUS_ADDRESS(3)  CPU_PHYSICAL(2)  SIZE(2) */
&gt; +            ranges = &lt;0x01000000 0x0 0x01000000  0x0 0x01000000  0x0 0x00010000&gt;,
&gt; +                     &lt;0x02000000 0x0 0x41000000  0x0 0x41000000  0x0 0x3f000000&gt;;
&gt; +
&gt; +            #interrupt-cells = &lt;0x1&gt;;
&gt; +
&gt; +            /* PCI_DEVICE(3)  INT#(1)  CONTROLLER(PHANDLE)  CONTROLLER_DATA(2) */
&gt; +            interrupt-map = &lt;   0x0 0x0 0x0  0x1  &amp;aplic_smode  0x4 0x1&gt;,
&gt; +                            &lt; 0x800 0x0 0x0  0x1  &amp;aplic_smode  0x5 0x1&gt;,
&gt; +                            &lt;0x1000 0x0 0x0  0x1  &amp;aplic_smode  0x6 0x1&gt;,
&gt; +                            &lt;0x1800 0x0 0x0  0x1  &amp;aplic_smode  0x7 0x1&gt;;
&gt; +
&gt; +            /* PCI_DEVICE(3)  INT#(1) */
&gt; +            interrupt-map-mask = &lt;0xf800 0x0 0x0  0x7&gt;;
&gt; +
&gt; +            msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; +
&gt; +            /* Devices with bus number 0-127 are mastered via immu2 */
&gt; +            iommu-map = &lt;0x0000 &amp;immu2 0x0000 0x8000&gt;;
&gt; +        };
&gt; +    };
&gt; +...
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#mefb742c2ddae58fd3cf54da7451501e4bd3a30a7 id=eefb742c2ddae58fd3cf54da7451501e4bd3a30a7>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0r=2eqpy9wLjVt1U0J7=LpnJLcKV7N9d90jvCss=7+Fzg@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0r=2eqpy9wLjVt1U0J7=LpnJLcKV7N9d90jvCss=7+Fzg@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0r=2eqpy9wLjVt1U0J7=LpnJLcKV7N9d90jvCss=7+Fzg@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0r=2eqpy9wLjVt1U0J7=LpnJLcKV7N9d90jvCss=7+Fzg@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0r=2eqpy9wLjVt1U0J7=LpnJLcKV7N9d90jvCss=7+Fzg@mail.gmail.com/t/#u">nested</a>] <a href=#refb742c2ddae58fd3cf54da7451501e4bd3a30a7>86+ messages in thread</a></pre><hr><pre><a href=#ea907ef87338b36d71e27c34ee0ef394c7f908811 id=ma907ef87338b36d71e27c34ee0ef394c7f908811>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-20 18:00     ` <a href=#m505d10dd50c508c0a38b520f5cd63968f20076a8>Tomasz Jeznach</a>
  2023-07-20 18:43       ` <a href=#m132855bc1023899551b404f99620d13a649274e8>Conor Dooley</a>
<b>@ 2023-07-24  9:47       ` Zong Li</b>
  2023-07-28  5:18         ` <a href=#m2c22e456fe699f9bda99e7579498d35ce7c66c0b>Tomasz Jeznach</a>
  <a href=#ra907ef87338b36d71e27c34ee0ef394c7f908811>1 sibling, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-24  9:47 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0rz1J+0t9M-e5NY015HhDT1Yy024_-Uan9CSJ4rMqtyng@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0rz1J+0t9M-e5NY015HhDT1Yy024_-Uan9CSJ4rMqtyng@mail.gmail.com/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Nick Kossifidis, Anup Patel, Albert Ou, linux, Will Deacon,
	Joerg Roedel, <a href="https://lore.kernel.org/lkml/?t=20230724095131">linux-kernel</a>, Sebastien Boeuf, iommu,
	Palmer Dabbelt, Paul Walmsley, <a href="https://lore.kernel.org/linux-riscv/?t=20230724095131">linux-riscv</a>, Robin Murphy

On Fri, Jul 21, 2023 at 2:00 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; On Wed, Jul 19, 2023 at 8:12 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt; &gt;
&gt; &gt; Hello Tomasz,
&gt; &gt;
&gt; &gt; On 7/19/23 22:33, Tomasz Jeznach wrote:
&gt; &gt; &gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; The description doesn't match the subject nor the patch content (we
&gt; &gt; don't jus enable interrupts, we also init the queues).
&gt; &gt;
&gt; &gt; &gt; +     /* Parse Queue lengts */
&gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; +             dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; +             dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; +             dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt;       dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; We need to add those to the device tree binding doc (or throw them away,
&gt; &gt; I thought it would be better to have them as part of the device
&gt; &gt; desciption than a module parameter).
&gt; &gt;
&gt;
&gt; We can add them as an optional fields to DT.
&gt; Alternatively, I've been looking into an option to auto-scale CQ/PQ
&gt; based on number of attached devices, but this gets trickier for
&gt; hot-pluggable systems. I've added module parameters as a bare-minimum,
&gt; but still looking for better solutions.
&gt;
&gt; &gt;
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; &gt; &gt; +
&gt; &gt;
&gt; &gt; &gt; +     case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; &gt; &gt; +             q = &amp;iommu-&gt;priq;
&gt; &gt; &gt; +             q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; &gt; &gt; +             count = iommu-&gt;priq_len;
&gt; &gt; &gt; +             irq = iommu-&gt;irq_priq;
&gt; &gt; &gt; +             irq_check = riscv_iommu_priq_irq_check;
&gt; &gt; &gt; +             irq_process = riscv_iommu_priq_process;
&gt; &gt; &gt; +             q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; &gt; &gt; +             q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; &gt; &gt; +             name = "priq";
&gt; &gt; &gt; +             break;
&gt; &gt;
&gt; &gt;
&gt; &gt; It makes more sense to add the code for the page request queue in the
&gt; &gt; patch that adds ATS/PRI support IMHO. This comment also applies to its
&gt; &gt; interrupt handlers below.
&gt; &gt;
&gt;
&gt; ack. will do.
&gt;
&gt; &gt;
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; +                                               u64 addr)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +     cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; &gt; &gt; +     cmd-&gt;dword1 = addr;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt;
&gt; &gt; This needs to be (addr &gt;&gt; 2) to match the spec, same as in the iofence
&gt; &gt; command.
&gt; &gt;
&gt;
&gt; oops. Thanks!
&gt;
</span>
I think it should be (addr &gt;&gt; 12) according to the spec.

<span class=q>&gt; &gt; Regards,
&gt; &gt; Nick
&gt; &gt;
&gt;
&gt; regards,
&gt; - Tomasz
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#ma907ef87338b36d71e27c34ee0ef394c7f908811 id=ea907ef87338b36d71e27c34ee0ef394c7f908811>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0rz1J+0t9M-e5NY015HhDT1Yy024_-Uan9CSJ4rMqtyng@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0rz1J+0t9M-e5NY015HhDT1Yy024_-Uan9CSJ4rMqtyng@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0rz1J+0t9M-e5NY015HhDT1Yy024_-Uan9CSJ4rMqtyng@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0rz1J+0t9M-e5NY015HhDT1Yy024_-Uan9CSJ4rMqtyng@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0rz1J+0t9M-e5NY015HhDT1Yy024_-Uan9CSJ4rMqtyng@mail.gmail.com/t/#u>nested</a>] <a href=#ra907ef87338b36d71e27c34ee0ef394c7f908811>86+ messages in thread</a></pre><hr><pre><a href=#e570ddc11336ccb2371984a53d8c2206a4b125953 id=m570ddc11336ccb2371984a53d8c2206a4b125953>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-24  8:03   ` <a href=#mefb742c2ddae58fd3cf54da7451501e4bd3a30a7>Zong Li</a>
<b>@ 2023-07-24 10:02     ` Anup Patel</b>
  2023-07-24 11:31       ` <a href=#m2d7203bf37bc25c9576411b6e1fc88441dab6256>Zong Li</a>
  <a href=#r570ddc11336ccb2371984a53d8c2206a4b125953>0 siblings, 1 reply; 86+ messages in thread</a>
From: Anup Patel @ 2023-07-24 10:02 UTC (<a href="https://lore.kernel.org/lkml/CAK9=C2Vg9eR5LJPeqDDQ0pHZcrT5DOUzA8_wYEVEjfnhb6s8pw@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAK9=C2Vg9eR5LJPeqDDQ0pHZcrT5DOUzA8_wYEVEjfnhb6s8pw@mail.gmail.com/raw">raw</a>)
  To: Zong Li
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230724101104">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230724101104">linux-riscv</a>

On Mon, Jul 24, 2023 at 1:33 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
<span class=q>&gt;
&gt; On Thu, Jul 20, 2023 at 3:35 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt;
&gt; &gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt;
&gt; &gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; &gt; defined by the RISC-V IOMMU specification.
&gt; &gt;
&gt; &gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; ---
&gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt; &gt;  1 file changed, 146 insertions(+)
&gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt;
&gt; &gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; new file mode 100644
&gt; &gt; index 000000000000..8a9aedb61768
&gt; &gt; --- /dev/null
&gt; &gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; @@ -0,0 +1,146 @@
&gt; &gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; &gt; +%YAML 1.2
&gt; &gt; +---
&gt; &gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; &gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; &gt; +
&gt; &gt; +title: RISC-V IOMMU Implementation
&gt; &gt; +
&gt; &gt; +maintainers:
&gt; &gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; +
&gt; &gt; +description:
&gt; &gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt; &gt; +  which can be a regular platform device or a PCI device connected to
&gt; &gt; +  the host root port.
&gt; &gt; +
&gt; &gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; &gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; &gt; +  both PCI and platform devices.
&gt; &gt; +
&gt; &gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; &gt; +
&gt; &gt; +properties:
&gt; &gt; +  compatible:
&gt; &gt; +    oneOf:
&gt; &gt; +      - description: RISC-V IOMMU as a platform device
&gt; &gt; +        items:
&gt; &gt; +          - enum:
&gt; &gt; +              - vendor,chip-iommu
&gt; &gt; +          - const: riscv,iommu
&gt; &gt; +
&gt; &gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; &gt; +        items:
&gt; &gt; +          - enum:
&gt; &gt; +              - vendor,chip-pci-iommu
&gt; &gt; +          - const: riscv,pci-iommu
&gt; &gt; +
&gt; &gt; +  reg:
&gt; &gt; +    maxItems: 1
&gt; &gt; +    description:
&gt; &gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; &gt; +      address of registers.
&gt; &gt; +
&gt; &gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
&gt; &gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
&gt; &gt; +
&gt; &gt; +  '#iommu-cells':
&gt; &gt; +    const: 2
&gt; &gt; +    description: |
&gt; &gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; &gt; +      device IDs.
&gt; &gt; +
&gt; &gt; +  interrupts:
&gt; &gt; +    minItems: 1
&gt; &gt; +    maxItems: 16
&gt; &gt; +    description:
&gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; &gt; +
&gt; &gt; +  msi-parent:
&gt; &gt; +    description:
&gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; &gt; +      considered only when the interrupts property is absent.
&gt; &gt; +
&gt; &gt; +  dma-coherent:
&gt; &gt; +    description:
&gt; &gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; &gt; +      are cache coherent with the CPU.
&gt; &gt; +
&gt; &gt; +  power-domains:
&gt; &gt; +    maxItems: 1
&gt; &gt; +
&gt;
&gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt; IOMMU is in translation mode. To identify the devices that require
&gt; bypass mode by default, does it be sensible to add a property to
&gt; indicate this behavior?
</span>
Bypass mode for a device is a property of that device (similar to dma-coherent)
and not of the IOMMU. Other architectures (ARM and x86) never added such
a device property for bypass mode so I guess it is NOT ADVISABLE to do it.

If this is REALLY required then we can do something similar to the QCOM
SMMU driver where they have a whitelist of devices which are allowed to
be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
compatible string and any device outside this whitelist is blocked by default.

Regards,
Anup

<span class=q>&gt;
&gt; &gt; +required:
&gt; &gt; +  - compatible
&gt; &gt; +  - reg
&gt; &gt; +  - '#iommu-cells'
&gt; &gt; +
&gt; &gt; +additionalProperties: false
&gt; &gt; +
&gt; &gt; +examples:
&gt; &gt; +  - |
&gt; &gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; &gt; +    immu1: iommu@1bccd000 {
&gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; &gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; +    };
&gt; &gt; +
&gt; &gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; &gt; +    master1 {
&gt; &gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; &gt; +    };
&gt; &gt; +
&gt; &gt; +  - |
&gt; &gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; &gt; +    immu2: iommu@1bcdd000 {
&gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; +    };
&gt; &gt; +
&gt; &gt; +    bus {
&gt; &gt; +        #address-cells = &lt;2&gt;;
&gt; &gt; +        #size-cells = &lt;2&gt;;
&gt; &gt; +
&gt; &gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; &gt; +        master1 {
&gt; &gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; &gt; +        };
&gt; &gt; +
&gt; &gt; +        pcie@40000000 {
&gt; &gt; +            compatible = "pci-host-cam-generic";
&gt; &gt; +            device_type = "pci";
&gt; &gt; +            #address-cells = &lt;3&gt;;
&gt; &gt; +            #size-cells = &lt;2&gt;;
&gt; &gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; &gt; +
&gt; &gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; +            reg = &lt;0x0 0x40000000 0x0 0x1000000&gt;;
&gt; &gt; +
&gt; &gt; +            /* BUS_ADDRESS(3)  CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; +            ranges = &lt;0x01000000 0x0 0x01000000  0x0 0x01000000  0x0 0x00010000&gt;,
&gt; &gt; +                     &lt;0x02000000 0x0 0x41000000  0x0 0x41000000  0x0 0x3f000000&gt;;
&gt; &gt; +
&gt; &gt; +            #interrupt-cells = &lt;0x1&gt;;
&gt; &gt; +
&gt; &gt; +            /* PCI_DEVICE(3)  INT#(1)  CONTROLLER(PHANDLE)  CONTROLLER_DATA(2) */
&gt; &gt; +            interrupt-map = &lt;   0x0 0x0 0x0  0x1  &amp;aplic_smode  0x4 0x1&gt;,
&gt; &gt; +                            &lt; 0x800 0x0 0x0  0x1  &amp;aplic_smode  0x5 0x1&gt;,
&gt; &gt; +                            &lt;0x1000 0x0 0x0  0x1  &amp;aplic_smode  0x6 0x1&gt;,
&gt; &gt; +                            &lt;0x1800 0x0 0x0  0x1  &amp;aplic_smode  0x7 0x1&gt;;
&gt; &gt; +
&gt; &gt; +            /* PCI_DEVICE(3)  INT#(1) */
&gt; &gt; +            interrupt-map-mask = &lt;0xf800 0x0 0x0  0x7&gt;;
&gt; &gt; +
&gt; &gt; +            msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; +
&gt; &gt; +            /* Devices with bus number 0-127 are mastered via immu2 */
&gt; &gt; +            iommu-map = &lt;0x0000 &amp;immu2 0x0000 0x8000&gt;;
&gt; &gt; +        };
&gt; &gt; +    };
&gt; &gt; +...
&gt; &gt; --
&gt; &gt; 2.34.1
&gt; &gt;
&gt; &gt;
&gt; &gt; _______________________________________________
&gt; &gt; linux-riscv mailing list
&gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m570ddc11336ccb2371984a53d8c2206a4b125953 id=e570ddc11336ccb2371984a53d8c2206a4b125953>^</a> <a href="https://lore.kernel.org/lkml/CAK9=C2Vg9eR5LJPeqDDQ0pHZcrT5DOUzA8_wYEVEjfnhb6s8pw@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAK9=C2Vg9eR5LJPeqDDQ0pHZcrT5DOUzA8_wYEVEjfnhb6s8pw@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAK9=C2Vg9eR5LJPeqDDQ0pHZcrT5DOUzA8_wYEVEjfnhb6s8pw@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAK9=C2Vg9eR5LJPeqDDQ0pHZcrT5DOUzA8_wYEVEjfnhb6s8pw@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAK9=C2Vg9eR5LJPeqDDQ0pHZcrT5DOUzA8_wYEVEjfnhb6s8pw@mail.gmail.com/t/#u">nested</a>] <a href=#r570ddc11336ccb2371984a53d8c2206a4b125953>86+ messages in thread</a></pre><hr><pre><a href=#e2d7203bf37bc25c9576411b6e1fc88441dab6256 id=m2d7203bf37bc25c9576411b6e1fc88441dab6256>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-24 10:02     ` <a href=#m570ddc11336ccb2371984a53d8c2206a4b125953>Anup Patel</a>
<b>@ 2023-07-24 11:31       ` Zong Li</b>
  2023-07-24 12:10         ` <a href=#m843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8>Anup Patel</a>
  <a href=#r2d7203bf37bc25c9576411b6e1fc88441dab6256>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-24 11:31 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0oTrU_-OQroW7H+hvxcU7YROhkgdCF9g_WtPTzVFQL7gA@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0oTrU_-OQroW7H+hvxcU7YROhkgdCF9g_WtPTzVFQL7gA@mail.gmail.com/raw>raw</a>)
  To: Anup Patel
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230724113306">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230724113306">linux-riscv</a>

On Mon, Jul 24, 2023 at 6:02 PM Anup Patel &lt;apatel@ventanamicro.com&gt; wrote:
<span class=q>&gt;
&gt; On Mon, Jul 24, 2023 at 1:33 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Thu, Jul 20, 2023 at 3:35 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt;
&gt; &gt; &gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; &gt; &gt; defined by the RISC-V IOMMU specification.
&gt; &gt; &gt;
&gt; &gt; &gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt; ---
&gt; &gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt; &gt; &gt;  1 file changed, 146 insertions(+)
&gt; &gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt;
&gt; &gt; &gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; new file mode 100644
&gt; &gt; &gt; index 000000000000..8a9aedb61768
&gt; &gt; &gt; --- /dev/null
&gt; &gt; &gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; @@ -0,0 +1,146 @@
&gt; &gt; &gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; &gt; &gt; +%YAML 1.2
&gt; &gt; &gt; +---
&gt; &gt; &gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; &gt; &gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; &gt; &gt; +
&gt; &gt; &gt; +title: RISC-V IOMMU Implementation
&gt; &gt; &gt; +
&gt; &gt; &gt; +maintainers:
&gt; &gt; &gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; &gt; +
&gt; &gt; &gt; +description:
&gt; &gt; &gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt; &gt; &gt; +  which can be a regular platform device or a PCI device connected to
&gt; &gt; &gt; +  the host root port.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; &gt; &gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; &gt; &gt; +  both PCI and platform devices.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; &gt; &gt; +
&gt; &gt; &gt; +properties:
&gt; &gt; &gt; +  compatible:
&gt; &gt; &gt; +    oneOf:
&gt; &gt; &gt; +      - description: RISC-V IOMMU as a platform device
&gt; &gt; &gt; +        items:
&gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; +              - vendor,chip-iommu
&gt; &gt; &gt; +          - const: riscv,iommu
&gt; &gt; &gt; +
&gt; &gt; &gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; &gt; &gt; +        items:
&gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; +              - vendor,chip-pci-iommu
&gt; &gt; &gt; +          - const: riscv,pci-iommu
&gt; &gt; &gt; +
&gt; &gt; &gt; +  reg:
&gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; &gt; &gt; +      address of registers.
&gt; &gt; &gt; +
&gt; &gt; &gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
&gt; &gt; &gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
&gt; &gt; &gt; +
&gt; &gt; &gt; +  '#iommu-cells':
&gt; &gt; &gt; +    const: 2
&gt; &gt; &gt; +    description: |
&gt; &gt; &gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; &gt; &gt; +      device IDs.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  interrupts:
&gt; &gt; &gt; +    minItems: 1
&gt; &gt; &gt; +    maxItems: 16
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; &gt; &gt; +
&gt; &gt; &gt; +  msi-parent:
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; &gt; &gt; +      considered only when the interrupts property is absent.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  dma-coherent:
&gt; &gt; &gt; +    description:
&gt; &gt; &gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; &gt; &gt; +      are cache coherent with the CPU.
&gt; &gt; &gt; +
&gt; &gt; &gt; +  power-domains:
&gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; +
&gt; &gt;
&gt; &gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt; &gt; IOMMU is in translation mode. To identify the devices that require
&gt; &gt; bypass mode by default, does it be sensible to add a property to
&gt; &gt; indicate this behavior?
&gt;
&gt; Bypass mode for a device is a property of that device (similar to dma-coherent)
&gt; and not of the IOMMU. Other architectures (ARM and x86) never added such
&gt; a device property for bypass mode so I guess it is NOT ADVISABLE to do it.
&gt;
&gt; If this is REALLY required then we can do something similar to the QCOM
&gt; SMMU driver where they have a whitelist of devices which are allowed to
&gt; be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
&gt; compatible string and any device outside this whitelist is blocked by default.
&gt;
</span>
I have considered that adding the property of bypass mode to that
device would be more appropriate. However, if we want to define this
property for the device, it might need to go through the generic IOMMU
dt-bindings, but I'm not sure if other IOMMU devices need this. I am
bringing up this topic here because I would like to explore if there
are any solutions on the IOMMU side, such as a property that indicates
the phandle of devices wishing to set bypass mode, somewhat similar to
the whitelist you mentioned earlier. Do you think we should address
this? After all, this is a case of RISC-V IOMMU supported.

<span class=q>&gt; Regards,
&gt; Anup
&gt;
&gt; &gt;
&gt; &gt; &gt; +required:
&gt; &gt; &gt; +  - compatible
&gt; &gt; &gt; +  - reg
&gt; &gt; &gt; +  - '#iommu-cells'
&gt; &gt; &gt; +
&gt; &gt; &gt; +additionalProperties: false
&gt; &gt; &gt; +
&gt; &gt; &gt; +examples:
&gt; &gt; &gt; +  - |
&gt; &gt; &gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; &gt; &gt; +    immu1: iommu@1bccd000 {
&gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; &gt; &gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; &gt; &gt; +    master1 {
&gt; &gt; &gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +  - |
&gt; &gt; &gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; &gt; &gt; +    immu2: iommu@1bcdd000 {
&gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +
&gt; &gt; &gt; +    bus {
&gt; &gt; &gt; +        #address-cells = &lt;2&gt;;
&gt; &gt; &gt; +        #size-cells = &lt;2&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; &gt; &gt; +        master1 {
&gt; &gt; &gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; &gt; &gt; +        };
&gt; &gt; &gt; +
&gt; &gt; &gt; +        pcie@40000000 {
&gt; &gt; &gt; +            compatible = "pci-host-cam-generic";
&gt; &gt; &gt; +            device_type = "pci";
&gt; &gt; &gt; +            #address-cells = &lt;3&gt;;
&gt; &gt; &gt; +            #size-cells = &lt;2&gt;;
&gt; &gt; &gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; &gt; +            reg = &lt;0x0 0x40000000 0x0 0x1000000&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            /* BUS_ADDRESS(3)  CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; &gt; +            ranges = &lt;0x01000000 0x0 0x01000000  0x0 0x01000000  0x0 0x00010000&gt;,
&gt; &gt; &gt; +                     &lt;0x02000000 0x0 0x41000000  0x0 0x41000000  0x0 0x3f000000&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            #interrupt-cells = &lt;0x1&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            /* PCI_DEVICE(3)  INT#(1)  CONTROLLER(PHANDLE)  CONTROLLER_DATA(2) */
&gt; &gt; &gt; +            interrupt-map = &lt;   0x0 0x0 0x0  0x1  &amp;aplic_smode  0x4 0x1&gt;,
&gt; &gt; &gt; +                            &lt; 0x800 0x0 0x0  0x1  &amp;aplic_smode  0x5 0x1&gt;,
&gt; &gt; &gt; +                            &lt;0x1000 0x0 0x0  0x1  &amp;aplic_smode  0x6 0x1&gt;,
&gt; &gt; &gt; +                            &lt;0x1800 0x0 0x0  0x1  &amp;aplic_smode  0x7 0x1&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            /* PCI_DEVICE(3)  INT#(1) */
&gt; &gt; &gt; +            interrupt-map-mask = &lt;0xf800 0x0 0x0  0x7&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; +
&gt; &gt; &gt; +            /* Devices with bus number 0-127 are mastered via immu2 */
&gt; &gt; &gt; +            iommu-map = &lt;0x0000 &amp;immu2 0x0000 0x8000&gt;;
&gt; &gt; &gt; +        };
&gt; &gt; &gt; +    };
&gt; &gt; &gt; +...
&gt; &gt; &gt; --
&gt; &gt; &gt; 2.34.1
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; _______________________________________________
&gt; &gt; &gt; linux-riscv mailing list
&gt; &gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m2d7203bf37bc25c9576411b6e1fc88441dab6256 id=e2d7203bf37bc25c9576411b6e1fc88441dab6256>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0oTrU_-OQroW7H+hvxcU7YROhkgdCF9g_WtPTzVFQL7gA@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0oTrU_-OQroW7H+hvxcU7YROhkgdCF9g_WtPTzVFQL7gA@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0oTrU_-OQroW7H+hvxcU7YROhkgdCF9g_WtPTzVFQL7gA@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0oTrU_-OQroW7H+hvxcU7YROhkgdCF9g_WtPTzVFQL7gA@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0oTrU_-OQroW7H+hvxcU7YROhkgdCF9g_WtPTzVFQL7gA@mail.gmail.com/t/#u>nested</a>] <a href=#r2d7203bf37bc25c9576411b6e1fc88441dab6256>86+ messages in thread</a></pre><hr><pre><a href=#e843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8 id=m843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-24 11:31       ` <a href=#m2d7203bf37bc25c9576411b6e1fc88441dab6256>Zong Li</a>
<b>@ 2023-07-24 12:10         ` Anup Patel</b>
  2023-07-24 13:23           ` <a href=#m2f68d3d87e65ff461879a6fa2ab08e51464f5507>Zong Li</a>
  <a href=#r843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8>0 siblings, 1 reply; 86+ messages in thread</a>
From: Anup Patel @ 2023-07-24 12:10 UTC (<a href="https://lore.kernel.org/lkml/CAK9=C2XoQjPzZ5yB5jfTbee4-Pb8GgFAZRbfcMwMk9pyo39WxQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAK9=C2XoQjPzZ5yB5jfTbee4-Pb8GgFAZRbfcMwMk9pyo39WxQ@mail.gmail.com/raw">raw</a>)
  To: Zong Li
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230724121033">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230724121033">linux-riscv</a>

On Mon, Jul 24, 2023 at 5:01 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
<span class=q>&gt;
&gt; On Mon, Jul 24, 2023 at 6:02 PM Anup Patel &lt;apatel@ventanamicro.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Mon, Jul 24, 2023 at 1:33 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; On Thu, Jul 20, 2023 at 3:35 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; &gt; &gt; &gt; defined by the RISC-V IOMMU specification.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt; &gt; ---
&gt; &gt; &gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt; &gt; &gt; &gt;  1 file changed, 146 insertions(+)
&gt; &gt; &gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; &gt; new file mode 100644
&gt; &gt; &gt; &gt; index 000000000000..8a9aedb61768
&gt; &gt; &gt; &gt; --- /dev/null
&gt; &gt; &gt; &gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; &gt; @@ -0,0 +1,146 @@
&gt; &gt; &gt; &gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; &gt; &gt; &gt; +%YAML 1.2
&gt; &gt; &gt; &gt; +---
&gt; &gt; &gt; &gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; &gt; &gt; &gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +title: RISC-V IOMMU Implementation
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +maintainers:
&gt; &gt; &gt; &gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +description:
&gt; &gt; &gt; &gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt; &gt; &gt; &gt; +  which can be a regular platform device or a PCI device connected to
&gt; &gt; &gt; &gt; +  the host root port.
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; &gt; &gt; &gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; &gt; &gt; &gt; +  both PCI and platform devices.
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +properties:
&gt; &gt; &gt; &gt; +  compatible:
&gt; &gt; &gt; &gt; +    oneOf:
&gt; &gt; &gt; &gt; +      - description: RISC-V IOMMU as a platform device
&gt; &gt; &gt; &gt; +        items:
&gt; &gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; &gt; +              - vendor,chip-iommu
&gt; &gt; &gt; &gt; +          - const: riscv,iommu
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; &gt; &gt; &gt; +        items:
&gt; &gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; &gt; +              - vendor,chip-pci-iommu
&gt; &gt; &gt; &gt; +          - const: riscv,pci-iommu
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  reg:
&gt; &gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; &gt; &gt; &gt; +      address of registers.
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
&gt; &gt; &gt; &gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  '#iommu-cells':
&gt; &gt; &gt; &gt; +    const: 2
&gt; &gt; &gt; &gt; +    description: |
&gt; &gt; &gt; &gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; &gt; &gt; &gt; +      device IDs.
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  interrupts:
&gt; &gt; &gt; &gt; +    minItems: 1
&gt; &gt; &gt; &gt; +    maxItems: 16
&gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; &gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  msi-parent:
&gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; &gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; &gt; &gt; &gt; +      considered only when the interrupts property is absent.
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  dma-coherent:
&gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; &gt; &gt; &gt; +      are cache coherent with the CPU.
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  power-domains:
&gt; &gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt;
&gt; &gt; &gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt; &gt; &gt; IOMMU is in translation mode. To identify the devices that require
&gt; &gt; &gt; bypass mode by default, does it be sensible to add a property to
&gt; &gt; &gt; indicate this behavior?
&gt; &gt;
&gt; &gt; Bypass mode for a device is a property of that device (similar to dma-coherent)
&gt; &gt; and not of the IOMMU. Other architectures (ARM and x86) never added such
&gt; &gt; a device property for bypass mode so I guess it is NOT ADVISABLE to do it.
&gt; &gt;
&gt; &gt; If this is REALLY required then we can do something similar to the QCOM
&gt; &gt; SMMU driver where they have a whitelist of devices which are allowed to
&gt; &gt; be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
&gt; &gt; compatible string and any device outside this whitelist is blocked by default.
&gt; &gt;
&gt;
&gt; I have considered that adding the property of bypass mode to that
&gt; device would be more appropriate. However, if we want to define this
&gt; property for the device, it might need to go through the generic IOMMU
&gt; dt-bindings, but I'm not sure if other IOMMU devices need this. I am
&gt; bringing up this topic here because I would like to explore if there
&gt; are any solutions on the IOMMU side, such as a property that indicates
&gt; the phandle of devices wishing to set bypass mode, somewhat similar to
&gt; the whitelist you mentioned earlier. Do you think we should address
&gt; this? After all, this is a case of RISC-V IOMMU supported.
</span>
Bypass mode is a common feature across IOMMUs. Other IOMMUs don't
have a special property for bypass mode at device-level or at IOMMU level,
which clearly indicates that defining a RISC-V specific property is not the
right way to go.

The real question is how do we set IOMMU_DOMAIN_IDENTITY (i.e.
bypass/identity domain) as the default domain for certain devices ?

One possible option is to implement def_domain_type() IOMMU operation
for RISC-V IOMMU which will return IOMMU_DOMAIN_IDENTITY for
certain devices based on compatible string matching (i.e. whitelist of
devices). As an example, refer qcom_smmu_def_domain_type()
of drivers/iommu/arm/arm-smmu/arm-smmu-qcom.c

Regards,
Anup





<span class=q>&gt;
&gt; &gt; Regards,
&gt; &gt; Anup
&gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; +required:
&gt; &gt; &gt; &gt; +  - compatible
&gt; &gt; &gt; &gt; +  - reg
&gt; &gt; &gt; &gt; +  - '#iommu-cells'
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +additionalProperties: false
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +examples:
&gt; &gt; &gt; &gt; +  - |
&gt; &gt; &gt; &gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; &gt; &gt; &gt; +    immu1: iommu@1bccd000 {
&gt; &gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; &gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; &gt; &gt; &gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; &gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; &gt; &gt; &gt; +    master1 {
&gt; &gt; &gt; &gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +  - |
&gt; &gt; &gt; &gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; &gt; &gt; &gt; +    immu2: iommu@1bcdd000 {
&gt; &gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; &gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +    bus {
&gt; &gt; &gt; &gt; +        #address-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; +        #size-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; &gt; &gt; &gt; +        master1 {
&gt; &gt; &gt; &gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; &gt; &gt; &gt; +        };
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +        pcie@40000000 {
&gt; &gt; &gt; &gt; +            compatible = "pci-host-cam-generic";
&gt; &gt; &gt; &gt; +            device_type = "pci";
&gt; &gt; &gt; &gt; +            #address-cells = &lt;3&gt;;
&gt; &gt; &gt; &gt; +            #size-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; &gt; &gt; +            reg = &lt;0x0 0x40000000 0x0 0x1000000&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +            /* BUS_ADDRESS(3)  CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; &gt; &gt; +            ranges = &lt;0x01000000 0x0 0x01000000  0x0 0x01000000  0x0 0x00010000&gt;,
&gt; &gt; &gt; &gt; +                     &lt;0x02000000 0x0 0x41000000  0x0 0x41000000  0x0 0x3f000000&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +            #interrupt-cells = &lt;0x1&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +            /* PCI_DEVICE(3)  INT#(1)  CONTROLLER(PHANDLE)  CONTROLLER_DATA(2) */
&gt; &gt; &gt; &gt; +            interrupt-map = &lt;   0x0 0x0 0x0  0x1  &amp;aplic_smode  0x4 0x1&gt;,
&gt; &gt; &gt; &gt; +                            &lt; 0x800 0x0 0x0  0x1  &amp;aplic_smode  0x5 0x1&gt;,
&gt; &gt; &gt; &gt; +                            &lt;0x1000 0x0 0x0  0x1  &amp;aplic_smode  0x6 0x1&gt;,
&gt; &gt; &gt; &gt; +                            &lt;0x1800 0x0 0x0  0x1  &amp;aplic_smode  0x7 0x1&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +            /* PCI_DEVICE(3)  INT#(1) */
&gt; &gt; &gt; &gt; +            interrupt-map-mask = &lt;0xf800 0x0 0x0  0x7&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +            msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +            /* Devices with bus number 0-127 are mastered via immu2 */
&gt; &gt; &gt; &gt; +            iommu-map = &lt;0x0000 &amp;immu2 0x0000 0x8000&gt;;
&gt; &gt; &gt; &gt; +        };
&gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; +...
&gt; &gt; &gt; &gt; --
&gt; &gt; &gt; &gt; 2.34.1
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; _______________________________________________
&gt; &gt; &gt; &gt; linux-riscv mailing list
&gt; &gt; &gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; &gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8 id=e843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8>^</a> <a href="https://lore.kernel.org/lkml/CAK9=C2XoQjPzZ5yB5jfTbee4-Pb8GgFAZRbfcMwMk9pyo39WxQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAK9=C2XoQjPzZ5yB5jfTbee4-Pb8GgFAZRbfcMwMk9pyo39WxQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAK9=C2XoQjPzZ5yB5jfTbee4-Pb8GgFAZRbfcMwMk9pyo39WxQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAK9=C2XoQjPzZ5yB5jfTbee4-Pb8GgFAZRbfcMwMk9pyo39WxQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAK9=C2XoQjPzZ5yB5jfTbee4-Pb8GgFAZRbfcMwMk9pyo39WxQ@mail.gmail.com/t/#u">nested</a>] <a href=#r843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8>86+ messages in thread</a></pre><hr><pre><a href=#e2f68d3d87e65ff461879a6fa2ab08e51464f5507 id=m2f68d3d87e65ff461879a6fa2ab08e51464f5507>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-24 12:10         ` <a href=#m843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8>Anup Patel</a>
<b>@ 2023-07-24 13:23           ` Zong Li</b>
  2023-07-26  3:21             ` <a href=#mc929b28389818fb366cddb7da7fa1c8aefd86240>Baolu Lu</a>
  <a href=#r2f68d3d87e65ff461879a6fa2ab08e51464f5507>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-24 13:23 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0q7R9Srx6U=fReq7LDLFgW6rMmjKH=o6MzDT5AWNRXP6w@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0q7R9Srx6U=fReq7LDLFgW6rMmjKH=o6MzDT5AWNRXP6w@mail.gmail.com/raw">raw</a>)
  To: Anup Patel
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230724132413">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230724132413">linux-riscv</a>

On Mon, Jul 24, 2023 at 8:10 PM Anup Patel &lt;apatel@ventanamicro.com&gt; wrote:
<span class=q>&gt;
&gt; On Mon, Jul 24, 2023 at 5:01 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Mon, Jul 24, 2023 at 6:02 PM Anup Patel &lt;apatel@ventanamicro.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; On Mon, Jul 24, 2023 at 1:33 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; On Thu, Jul 20, 2023 at 3:35 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; From: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; We add DT bindings document for RISC-V IOMMU platform and PCI devices
&gt; &gt; &gt; &gt; &gt; defined by the RISC-V IOMMU specification.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; Signed-off-by: Anup Patel &lt;apatel@ventanamicro.com&gt;
&gt; &gt; &gt; &gt; &gt; ---
&gt; &gt; &gt; &gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           | 146 ++++++++++++++++++
&gt; &gt; &gt; &gt; &gt;  1 file changed, 146 insertions(+)
&gt; &gt; &gt; &gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; diff --git a/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; &gt; &gt; new file mode 100644
&gt; &gt; &gt; &gt; &gt; index 000000000000..8a9aedb61768
&gt; &gt; &gt; &gt; &gt; --- /dev/null
&gt; &gt; &gt; &gt; &gt; +++ b/Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt; &gt; &gt; @@ -0,0 +1,146 @@
&gt; &gt; &gt; &gt; &gt; +# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
&gt; &gt; &gt; &gt; &gt; +%YAML 1.2
&gt; &gt; &gt; &gt; &gt; +---
&gt; &gt; &gt; &gt; &gt; +$id: <a href=http://devicetree.org/schemas/iommu/riscv,iommu.yaml>http://devicetree.org/schemas/iommu/riscv,iommu.yaml</a>#
&gt; &gt; &gt; &gt; &gt; +$schema: <a href=http://devicetree.org/meta-schemas/core.yaml>http://devicetree.org/meta-schemas/core.yaml</a>#
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +title: RISC-V IOMMU Implementation
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +maintainers:
&gt; &gt; &gt; &gt; &gt; +  - Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +description:
&gt; &gt; &gt; &gt; &gt; +  The RISC-V IOMMU specificaiton defines an IOMMU for RISC-V platforms
&gt; &gt; &gt; &gt; &gt; +  which can be a regular platform device or a PCI device connected to
&gt; &gt; &gt; &gt; &gt; +  the host root port.
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  The RISC-V IOMMU provides two stage translation, device directory table,
&gt; &gt; &gt; &gt; &gt; +  command queue and fault reporting as wired interrupt or MSIx event for
&gt; &gt; &gt; &gt; &gt; +  both PCI and platform devices.
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  Visit <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a> for more details.
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +properties:
&gt; &gt; &gt; &gt; &gt; +  compatible:
&gt; &gt; &gt; &gt; &gt; +    oneOf:
&gt; &gt; &gt; &gt; &gt; +      - description: RISC-V IOMMU as a platform device
&gt; &gt; &gt; &gt; &gt; +        items:
&gt; &gt; &gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; &gt; &gt; +              - vendor,chip-iommu
&gt; &gt; &gt; &gt; &gt; +          - const: riscv,iommu
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +      - description: RISC-V IOMMU as a PCI device connected to root port
&gt; &gt; &gt; &gt; &gt; +        items:
&gt; &gt; &gt; &gt; &gt; +          - enum:
&gt; &gt; &gt; &gt; &gt; +              - vendor,chip-pci-iommu
&gt; &gt; &gt; &gt; &gt; +          - const: riscv,pci-iommu
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  reg:
&gt; &gt; &gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; &gt; +      For RISC-V IOMMU as a platform device, this represents the MMIO base
&gt; &gt; &gt; &gt; &gt; +      address of registers.
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +      For RISC-V IOMMU as a PCI device, this represents the PCI-PCI bridge
&gt; &gt; &gt; &gt; &gt; +      details as described in Documentation/devicetree/bindings/pci/pci.txt
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  '#iommu-cells':
&gt; &gt; &gt; &gt; &gt; +    const: 2
&gt; &gt; &gt; &gt; &gt; +    description: |
&gt; &gt; &gt; &gt; &gt; +      Each IOMMU specifier represents the base device ID and number of
&gt; &gt; &gt; &gt; &gt; +      device IDs.
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  interrupts:
&gt; &gt; &gt; &gt; &gt; +    minItems: 1
&gt; &gt; &gt; &gt; &gt; +    maxItems: 16
&gt; &gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; &gt; &gt; +      wired interrupts to notify the RISC-V HARTS (or CPUs).
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  msi-parent:
&gt; &gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; &gt; +      The presence of this property implies that given RISC-V IOMMU uses
&gt; &gt; &gt; &gt; &gt; +      MSIx to notify the RISC-V HARTs (or CPUs). This property should be
&gt; &gt; &gt; &gt; &gt; +      considered only when the interrupts property is absent.
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  dma-coherent:
&gt; &gt; &gt; &gt; &gt; +    description:
&gt; &gt; &gt; &gt; &gt; +      Present if page table walks and DMA accessed made by the RISC-V IOMMU
&gt; &gt; &gt; &gt; &gt; +      are cache coherent with the CPU.
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  power-domains:
&gt; &gt; &gt; &gt; &gt; +    maxItems: 1
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt; &gt; &gt; &gt; IOMMU is in translation mode. To identify the devices that require
&gt; &gt; &gt; &gt; bypass mode by default, does it be sensible to add a property to
&gt; &gt; &gt; &gt; indicate this behavior?
&gt; &gt; &gt;
&gt; &gt; &gt; Bypass mode for a device is a property of that device (similar to dma-coherent)
&gt; &gt; &gt; and not of the IOMMU. Other architectures (ARM and x86) never added such
&gt; &gt; &gt; a device property for bypass mode so I guess it is NOT ADVISABLE to do it.
&gt; &gt; &gt;
&gt; &gt; &gt; If this is REALLY required then we can do something similar to the QCOM
&gt; &gt; &gt; SMMU driver where they have a whitelist of devices which are allowed to
&gt; &gt; &gt; be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
&gt; &gt; &gt; compatible string and any device outside this whitelist is blocked by default.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; I have considered that adding the property of bypass mode to that
&gt; &gt; device would be more appropriate. However, if we want to define this
&gt; &gt; property for the device, it might need to go through the generic IOMMU
&gt; &gt; dt-bindings, but I'm not sure if other IOMMU devices need this. I am
&gt; &gt; bringing up this topic here because I would like to explore if there
&gt; &gt; are any solutions on the IOMMU side, such as a property that indicates
&gt; &gt; the phandle of devices wishing to set bypass mode, somewhat similar to
&gt; &gt; the whitelist you mentioned earlier. Do you think we should address
&gt; &gt; this? After all, this is a case of RISC-V IOMMU supported.
&gt;
&gt; Bypass mode is a common feature across IOMMUs. Other IOMMUs don't
&gt; have a special property for bypass mode at device-level or at IOMMU level,
&gt; which clearly indicates that defining a RISC-V specific property is not the
&gt; right way to go.
&gt;
&gt; The real question is how do we set IOMMU_DOMAIN_IDENTITY (i.e.
&gt; bypass/identity domain) as the default domain for certain devices ?
&gt;
&gt; One possible option is to implement def_domain_type() IOMMU operation
&gt; for RISC-V IOMMU which will return IOMMU_DOMAIN_IDENTITY for
&gt; certain devices based on compatible string matching (i.e. whitelist of
&gt; devices). As an example, refer qcom_smmu_def_domain_type()
&gt; of drivers/iommu/arm/arm-smmu/arm-smmu-qcom.c
&gt;
</span>
That is indeed one way to approach it, and we can modify the
compatible string when we want to change the mode. However, it would
be preferable to explore a more flexible approach to achieve this
goal. By doing so, we can avoid hard coding anything in the driver or
having to rebuild the kernel  whenever we want to change the mode for
certain devices. While I have considered extending a cell in the
'iommus' property to indicate a device's desire to set bypass mode, it
doesn't comply with the iommu documentation and could lead to
ambiguous definitions.

If, at present, we are unable to find a suitable solution, perhaps
let's keep this topic in mind until we discover a more appropriate
approach. In the meantime, we can continue to explore other
possibilities to implement it. Thanks.

<span class=q>&gt; Regards,
&gt; Anup
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; &gt;
&gt; &gt; &gt; Regards,
&gt; &gt; &gt; Anup
&gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; +required:
&gt; &gt; &gt; &gt; &gt; +  - compatible
&gt; &gt; &gt; &gt; &gt; +  - reg
&gt; &gt; &gt; &gt; &gt; +  - '#iommu-cells'
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +additionalProperties: false
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +examples:
&gt; &gt; &gt; &gt; &gt; +  - |
&gt; &gt; &gt; &gt; &gt; +    /* Example 1 (IOMMU platform device with wired interrupts) */
&gt; &gt; &gt; &gt; &gt; +    immu1: iommu@1bccd000 {
&gt; &gt; &gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; &gt; &gt; +        interrupt-parent = &lt;&amp;aplic_smode&gt;;
&gt; &gt; &gt; &gt; &gt; +        interrupts = &lt;32 4&gt;, &lt;33 4&gt;, &lt;34 4&gt;, &lt;35 4&gt;;
&gt; &gt; &gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +    /* Device with two IOMMU device IDs, 0 and 7 */
&gt; &gt; &gt; &gt; &gt; +    master1 {
&gt; &gt; &gt; &gt; &gt; +        iommus = &lt;&amp;immu1 0 1&gt;, &lt;&amp;immu1 7 1&gt;;
&gt; &gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +  - |
&gt; &gt; &gt; &gt; &gt; +    /* Example 2 (IOMMU platform device with MSIs) */
&gt; &gt; &gt; &gt; &gt; +    immu2: iommu@1bcdd000 {
&gt; &gt; &gt; &gt; &gt; +        compatible = "vendor,chip-iommu", "riscv,iommu";
&gt; &gt; &gt; &gt; &gt; +        reg = &lt;0x1bccd000 0x1000&gt;;
&gt; &gt; &gt; &gt; &gt; +        msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; &gt; &gt; +        #iommu-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +    bus {
&gt; &gt; &gt; &gt; &gt; +        #address-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; &gt; +        #size-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +        /* Device with IOMMU device IDs ranging from 32 to 64 */
&gt; &gt; &gt; &gt; &gt; +        master1 {
&gt; &gt; &gt; &gt; &gt; +                iommus = &lt;&amp;immu2 32 32&gt;;
&gt; &gt; &gt; &gt; &gt; +        };
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +        pcie@40000000 {
&gt; &gt; &gt; &gt; &gt; +            compatible = "pci-host-cam-generic";
&gt; &gt; &gt; &gt; &gt; +            device_type = "pci";
&gt; &gt; &gt; &gt; &gt; +            #address-cells = &lt;3&gt;;
&gt; &gt; &gt; &gt; &gt; +            #size-cells = &lt;2&gt;;
&gt; &gt; &gt; &gt; &gt; +            bus-range = &lt;0x0 0x1&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +            /* CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; &gt; &gt; &gt; +            reg = &lt;0x0 0x40000000 0x0 0x1000000&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +            /* BUS_ADDRESS(3)  CPU_PHYSICAL(2)  SIZE(2) */
&gt; &gt; &gt; &gt; &gt; +            ranges = &lt;0x01000000 0x0 0x01000000  0x0 0x01000000  0x0 0x00010000&gt;,
&gt; &gt; &gt; &gt; &gt; +                     &lt;0x02000000 0x0 0x41000000  0x0 0x41000000  0x0 0x3f000000&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +            #interrupt-cells = &lt;0x1&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +            /* PCI_DEVICE(3)  INT#(1)  CONTROLLER(PHANDLE)  CONTROLLER_DATA(2) */
&gt; &gt; &gt; &gt; &gt; +            interrupt-map = &lt;   0x0 0x0 0x0  0x1  &amp;aplic_smode  0x4 0x1&gt;,
&gt; &gt; &gt; &gt; &gt; +                            &lt; 0x800 0x0 0x0  0x1  &amp;aplic_smode  0x5 0x1&gt;,
&gt; &gt; &gt; &gt; &gt; +                            &lt;0x1000 0x0 0x0  0x1  &amp;aplic_smode  0x6 0x1&gt;,
&gt; &gt; &gt; &gt; &gt; +                            &lt;0x1800 0x0 0x0  0x1  &amp;aplic_smode  0x7 0x1&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +            /* PCI_DEVICE(3)  INT#(1) */
&gt; &gt; &gt; &gt; &gt; +            interrupt-map-mask = &lt;0xf800 0x0 0x0  0x7&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +            msi-parent = &lt;&amp;imsics_smode&gt;;
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +            /* Devices with bus number 0-127 are mastered via immu2 */
&gt; &gt; &gt; &gt; &gt; +            iommu-map = &lt;0x0000 &amp;immu2 0x0000 0x8000&gt;;
&gt; &gt; &gt; &gt; &gt; +        };
&gt; &gt; &gt; &gt; &gt; +    };
&gt; &gt; &gt; &gt; &gt; +...
&gt; &gt; &gt; &gt; &gt; --
&gt; &gt; &gt; &gt; &gt; 2.34.1
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; _______________________________________________
&gt; &gt; &gt; &gt; &gt; linux-riscv mailing list
&gt; &gt; &gt; &gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; &gt; &gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m2f68d3d87e65ff461879a6fa2ab08e51464f5507 id=e2f68d3d87e65ff461879a6fa2ab08e51464f5507>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0q7R9Srx6U=fReq7LDLFgW6rMmjKH=o6MzDT5AWNRXP6w@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0q7R9Srx6U=fReq7LDLFgW6rMmjKH=o6MzDT5AWNRXP6w@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0q7R9Srx6U=fReq7LDLFgW6rMmjKH=o6MzDT5AWNRXP6w@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0q7R9Srx6U=fReq7LDLFgW6rMmjKH=o6MzDT5AWNRXP6w@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0q7R9Srx6U=fReq7LDLFgW6rMmjKH=o6MzDT5AWNRXP6w@mail.gmail.com/t/#u">nested</a>] <a href=#r2f68d3d87e65ff461879a6fa2ab08e51464f5507>86+ messages in thread</a></pre><hr><pre><a href=#e35e1f370635d089a8dde16e4c70b533d4b503ee0 id=m35e1f370635d089a8dde16e4c70b533d4b503ee0>*</a> <b>Re: [PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</b>
  2023-07-19 19:33 ` <a href=#m50b13653960cd6e88a7efb588257ac568bffb87b>[PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</a> Tomasz Jeznach
<b>@ 2023-07-25 13:13   ` Zong Li</b>
  2023-07-31  7:19   ` <a href=#m525805e3cb4b98064a03306b5a208399736c02b0>Zong Li</a>
  2023-08-16 21:04   ` <a href=#m4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259>Robin Murphy</a>
  <a href=#r35e1f370635d089a8dde16e4c70b533d4b503ee0>2 siblings, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-07-25 13:13 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0qX0QuJRghAem-2q-raXqYOLdyaWyb7YfF9J9gazeo5Fw@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0qX0QuJRghAem-2q-raXqYOLdyaWyb7YfF9J9gazeo5Fw@mail.gmail.com/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230725131350">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230725131350">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; Introduces I/O page level translation services, with 4K, 2M, 1G page
&gt; size support and enables page level iommu_map/unmap domain interfaces.
&gt;
&gt; Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/io-pgtable.c       |   3 +
&gt;  drivers/iommu/riscv/Makefile     |   2 +-
&gt;  drivers/iommu/riscv/io_pgtable.c | 266 +++++++++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu.c      |  40 +++--
&gt;  drivers/iommu/riscv/iommu.h      |   1 +
&gt;  include/linux/io-pgtable.h       |   2 +
&gt;  6 files changed, 297 insertions(+), 17 deletions(-)
&gt;  create mode 100644 drivers/iommu/riscv/io_pgtable.c
&gt;
&gt; diff --git a/drivers/iommu/io-pgtable.c b/drivers/iommu/io-pgtable.c
&gt; index b843fcd365d2..c4807175934f 100644
&gt; --- a/drivers/iommu/io-pgtable.c
&gt; +++ b/drivers/iommu/io-pgtable.c
&gt; @@ -32,6 +32,9 @@ io_pgtable_init_table[IO_PGTABLE_NUM_FMTS] = {
&gt;         [AMD_IOMMU_V1] = &amp;io_pgtable_amd_iommu_v1_init_fns,
&gt;         [AMD_IOMMU_V2] = &amp;io_pgtable_amd_iommu_v2_init_fns,
&gt;  #endif
&gt; +#ifdef CONFIG_RISCV_IOMMU
&gt; +       [RISCV_IOMMU] = &amp;io_pgtable_riscv_init_fns,
&gt; +#endif
&gt;  };
&gt;
&gt;  struct io_pgtable_ops *alloc_io_pgtable_ops(enum io_pgtable_fmt fmt,
&gt; diff --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
&gt; index 9523eb053cfc..13af452c3052 100644
&gt; --- a/drivers/iommu/riscv/Makefile
&gt; +++ b/drivers/iommu/riscv/Makefile
&gt; @@ -1 +1 @@
&gt; -obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o
&gt; \ No newline at end of file
&gt; +obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o io_pgtable.o
&gt; diff --git a/drivers/iommu/riscv/io_pgtable.c b/drivers/iommu/riscv/io_pgtable.c
&gt; new file mode 100644
&gt; index 000000000000..b6e603e6726e
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/io_pgtable.c
&gt; @@ -0,0 +1,266 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + *
&gt; + * RISC-V IOMMU page table allocator.
&gt; + *
&gt; + * Authors:
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/atomic.h&gt;
&gt; +#include &lt;linux/bitops.h&gt;
&gt; +#include &lt;linux/io-pgtable.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/sizes.h&gt;
&gt; +#include &lt;linux/slab.h&gt;
&gt; +#include &lt;linux/types.h&gt;
&gt; +#include &lt;linux/dma-mapping.h&gt;
&gt; +
&gt; +#include "iommu.h"
&gt; +
&gt; +#define io_pgtable_to_domain(x) \
&gt; +       container_of((x), struct riscv_iommu_domain, pgtbl)
&gt; +
&gt; +#define io_pgtable_ops_to_domain(x) \
&gt; +       io_pgtable_to_domain(container_of((x), struct io_pgtable, ops))
&gt; +
&gt; +static inline size_t get_page_size(size_t size)
&gt; +{
&gt; +       if (size &gt;= IOMMU_PAGE_SIZE_512G)
&gt; +               return IOMMU_PAGE_SIZE_512G;
&gt; +
&gt; +       if (size &gt;= IOMMU_PAGE_SIZE_1G)
&gt; +               return IOMMU_PAGE_SIZE_1G;
&gt; +
&gt; +       if (size &gt;= IOMMU_PAGE_SIZE_2M)
&gt; +               return IOMMU_PAGE_SIZE_2M;
&gt; +
&gt; +       return IOMMU_PAGE_SIZE_4K;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_pt_walk_free(pmd_t * ptp, unsigned shift, bool root)
&gt; +{
&gt; +       pmd_t *pte, *pt_base;
&gt; +       int i;
&gt; +
&gt; +       if (shift == PAGE_SHIFT)
&gt; +               return;
&gt; +
&gt; +       if (root)
&gt; +               pt_base = ptp;
&gt; +       else
&gt; +               pt_base =
&gt; +                   (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp)));
&gt; +
&gt; +       /* Recursively free all sub page table pages */
&gt; +       for (i = 0; i &lt; PTRS_PER_PMD; i++) {
&gt; +               pte = pt_base + i;
&gt; +               if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
&gt; +                       riscv_iommu_pt_walk_free(pte, shift - 9, false);
&gt; +       }
&gt; +
&gt; +       /* Now free the current page table page */
&gt; +       if (!root &amp;&amp; pmd_present(*pt_base))
&gt; +               free_page((unsigned long)pt_base);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_free_pgtable(struct io_pgtable *iop)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_to_domain(iop);
&gt; +       riscv_iommu_pt_walk_free((pmd_t *) domain-&gt;pgd_root, PGDIR_SHIFT, true);
&gt; +}
&gt; +
&gt; +static pte_t *riscv_iommu_pt_walk_alloc(pmd_t * ptp, unsigned long iova,
&gt; +                                       unsigned shift, bool root,
&gt; +                                       size_t pgsize,
&gt; +                                       unsigned long (*pd_alloc)(gfp_t),
&gt; +                                       gfp_t gfp)
&gt; +{
&gt; +       pmd_t *pte;
&gt; +       unsigned long pfn;
&gt; +
&gt; +       if (root)
&gt; +               pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +       else
&gt; +               pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
&gt; +                   ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +
&gt; +       if ((1ULL &lt;&lt; shift) &lt;= pgsize) {
&gt; +               if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
&gt; +                       riscv_iommu_pt_walk_free(pte, shift - 9, false);
&gt; +               return (pte_t *) pte;
&gt; +       }
&gt; +
&gt; +       if (pmd_none(*pte)) {
&gt; +               pfn = pd_alloc ? virt_to_pfn(pd_alloc(gfp)) : 0;
&gt; +               if (!pfn)
&gt; +                       return NULL;
&gt; +               set_pmd(pte, __pmd((pfn &lt;&lt; _PAGE_PFN_SHIFT) | _PAGE_TABLE));
&gt; +       }
&gt; +
&gt; +       return riscv_iommu_pt_walk_alloc(pte, iova, shift - 9, false,
&gt; +                                        pgsize, pd_alloc, gfp);
&gt; +}
&gt; +
&gt; +static pte_t *riscv_iommu_pt_walk_fetch(pmd_t * ptp,
&gt; +                                       unsigned long iova, unsigned shift,
&gt; +                                       bool root)
&gt; +{
&gt; +       pmd_t *pte;
&gt; +
&gt; +       if (root)
&gt; +               pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +       else
&gt; +               pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
&gt; +                   ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +
&gt; +       if (pmd_leaf(*pte))
&gt; +               return (pte_t *) pte;
&gt; +       else if (pmd_none(*pte))
&gt; +               return NULL;
&gt; +       else if (shift == PAGE_SHIFT)
&gt; +               return NULL;
&gt; +
&gt; +       return riscv_iommu_pt_walk_fetch(pte, iova, shift - 9, false);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_map_pages(struct io_pgtable_ops *ops,
&gt; +                                unsigned long iova, phys_addr_t phys,
&gt; +                                size_t pgsize, size_t pgcount, int prot,
&gt; +                                gfp_t gfp, size_t *mapped)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +       size_t size = 0;
&gt; +       size_t page_size = get_page_size(pgsize);
&gt; +       pte_t *pte;
&gt; +       pte_t pte_val;
&gt; +       pgprot_t pte_prot;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_BLOCKED)
&gt; +               return -ENODEV;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; +               *mapped = pgsize * pgcount;
&gt; +               return 0;
&gt; +       }
&gt; +
&gt; +       pte_prot = (prot &amp; IOMMU_WRITE) ?
&gt; +           __pgprot(_PAGE_BASE | _PAGE_READ | _PAGE_WRITE | _PAGE_DIRTY) :
&gt; +           __pgprot(_PAGE_BASE | _PAGE_READ);
&gt; +
&gt; +       while (pgcount--) {
&gt; +               pte =
&gt; +                   riscv_iommu_pt_walk_alloc((pmd_t *) domain-&gt;pgd_root, iova,
&gt; +                                             PGDIR_SHIFT, true, page_size,
&gt; +                                             get_zeroed_page, gfp);
&gt; +               if (!pte) {
&gt; +                       *mapped = size;
&gt; +                       return -ENOMEM;
&gt; +               }
&gt; +
&gt; +               pte_val = pfn_pte(phys_to_pfn(phys), pte_prot);
&gt; +
&gt; +               set_pte(pte, pte_val);
&gt; +
&gt; +               size += page_size;
&gt; +               iova += page_size;
&gt; +               phys += page_size;
&gt; +       }
&gt; +
&gt; +       *mapped = size;
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static size_t riscv_iommu_unmap_pages(struct io_pgtable_ops *ops,
&gt; +                                     unsigned long iova, size_t pgsize,
&gt; +                                     size_t pgcount,
&gt; +                                     struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +       size_t size = 0;
&gt; +       size_t page_size = get_page_size(pgsize);
&gt; +       pte_t *pte;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return pgsize * pgcount;
&gt; +
&gt; +       while (pgcount--) {
&gt; +               pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
&gt; +                                               iova, PGDIR_SHIFT, true);
&gt; +               if (!pte)
&gt; +                       return size;
&gt; +
&gt; +               set_pte(pte, __pte(0));
&gt; +
&gt; +               iommu_iotlb_gather_add_page(&amp;domain-&gt;domain, gather, iova,
&gt; +                                           pgsize);
&gt; +
&gt; +               size += page_size;
&gt; +               iova += page_size;
&gt; +       }
&gt; +
&gt; +       return size;
&gt; +}
&gt; +
&gt; +static phys_addr_t riscv_iommu_iova_to_phys(struct io_pgtable_ops *ops,
&gt; +                                           unsigned long iova)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +       pte_t *pte;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return (phys_addr_t) iova;
&gt; +
&gt; +       pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
&gt; +                                       iova, PGDIR_SHIFT, true);
&gt; +       if (!pte || !pte_present(*pte))
&gt; +               return 0;
&gt; +
&gt; +       return (pfn_to_phys(pte_pfn(*pte)) | (iova &amp; PAGE_MASK));
</span>
It should be (iova &amp; ~PAGE_MASK) for getting low 12 bits.

<span class=q>&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_inv_all(void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_inv_walk(unsigned long iova, size_t size,
&gt; +                                    size_t granule, void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_add_page(struct iommu_iotlb_gather *gather,
&gt; +                                    unsigned long iova, size_t granule,
&gt; +                                    void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static const struct iommu_flush_ops riscv_iommu_flush_ops = {
&gt; +       .tlb_flush_all = riscv_iommu_tlb_inv_all,
&gt; +       .tlb_flush_walk = riscv_iommu_tlb_inv_walk,
&gt; +       .tlb_add_page = riscv_iommu_tlb_add_page,
&gt; +};
&gt; +
&gt; +/* NOTE: cfg should point to riscv_iommu_domain structure member pgtbl.cfg */
&gt; +static struct io_pgtable *riscv_iommu_alloc_pgtable(struct io_pgtable_cfg *cfg,
&gt; +                                                   void *cookie)
&gt; +{
&gt; +       struct io_pgtable *iop = container_of(cfg, struct io_pgtable, cfg);
&gt; +
&gt; +       cfg-&gt;pgsize_bitmap = SZ_4K | SZ_2M | SZ_1G;
&gt; +       cfg-&gt;ias = 57;          // va mode, SvXX -&gt; ias
&gt; +       cfg-&gt;oas = 57;          // pa mode, or SvXX+4 -&gt; oas
&gt; +       cfg-&gt;tlb = &amp;riscv_iommu_flush_ops;
&gt; +
&gt; +       iop-&gt;ops.map_pages = riscv_iommu_map_pages;
&gt; +       iop-&gt;ops.unmap_pages = riscv_iommu_unmap_pages;
&gt; +       iop-&gt;ops.iova_to_phys = riscv_iommu_iova_to_phys;
&gt; +
&gt; +       return iop;
&gt; +}
&gt; +
&gt; +struct io_pgtable_init_fns io_pgtable_riscv_init_fns = {
&gt; +       .alloc = riscv_iommu_alloc_pgtable,
&gt; +       .free = riscv_iommu_free_pgtable,
&gt; +};
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 9ee7d2b222b5..2ef6952a2109 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -807,7 +807,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;         /* Initial DC pointer can be NULL if IOMMU is configured in OFF or BARE mode */
&gt;         ep-&gt;dc = riscv_iommu_get_dc(iommu, ep-&gt;devid);
&gt;
&gt; -       dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt; +       dev_dbg(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt;                 ep-&gt;devid, ep-&gt;domid);
&gt;
&gt;         dev_iommu_priv_set(dev, ep);
&gt; @@ -874,7 +874,10 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;  {
&gt;         struct riscv_iommu_domain *domain;
&gt;
&gt; -       if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; +       if (type != IOMMU_DOMAIN_DMA &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_DMA_FQ &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_UNMANAGED &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt;             type != IOMMU_DOMAIN_BLOCKED)
&gt;                 return NULL;
&gt;
&gt; @@ -890,7 +893,7 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;         domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt;                                         RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
&gt;
&gt; -       printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; +       printk("domain alloc %u\n", domain-&gt;pscid);
&gt;
&gt;         return &amp;domain-&gt;domain;
&gt;  }
&gt; @@ -903,6 +906,9 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;                 pr_warn("IOMMU domain is not empty!\n");
&gt;         }
&gt;
&gt; +       if (domain-&gt;pgtbl.cookie)
&gt; +               free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
&gt; +
&gt;         if (domain-&gt;pgd_root)
&gt;                 free_pages((unsigned long)domain-&gt;pgd_root, 0);
&gt;
&gt; @@ -959,6 +965,9 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt;         if (!domain-&gt;pgd_root)
&gt;                 return -ENOMEM;
&gt;
&gt; +       if (!alloc_io_pgtable_ops(RISCV_IOMMU, &amp;domain-&gt;pgtbl.cfg, domain))
&gt; +               return -ENOMEM;
&gt; +
&gt;         return 0;
&gt;  }
&gt;
&gt; @@ -1006,9 +1015,8 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;                 return 0;
&gt;         }
&gt;
&gt; -       if (!dc) {
&gt; +       if (!dc)
&gt;                 return -ENODEV;
&gt; -       }
&gt;
&gt;         /*
&gt;          * S-Stage translation table. G-Stage remains unmodified (BARE).
&gt; @@ -1104,12 +1112,11 @@ static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;
&gt; -       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; -               *mapped = pgsize * pgcount;
&gt; -               return 0;
&gt; -       }
&gt; +       if (!domain-&gt;pgtbl.ops.map_pages)
&gt; +               return -ENODEV;
&gt;
&gt; -       return -ENODEV;
&gt; +       return domain-&gt;pgtbl.ops.map_pages(&amp;domain-&gt;pgtbl.ops, iova, phys,
&gt; +                                          pgsize, pgcount, prot, gfp, mapped);
&gt;  }
&gt;
&gt;  static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt; @@ -1118,10 +1125,11 @@ static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;
&gt; -       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; -               return pgsize * pgcount;
&gt; +       if (!domain-&gt;pgtbl.ops.unmap_pages)
&gt; +               return 0;
&gt;
&gt; -       return 0;
&gt; +       return domain-&gt;pgtbl.ops.unmap_pages(&amp;domain-&gt;pgtbl.ops, iova, pgsize,
&gt; +                                            pgcount, gather);
&gt;  }
&gt;
&gt;  static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt; @@ -1129,10 +1137,10 @@ static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;
&gt; -       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; -               return (phys_addr_t) iova;
&gt; +       if (!domain-&gt;pgtbl.ops.iova_to_phys)
&gt; +               return 0;
&gt;
&gt; -       return 0;
&gt; +       return domain-&gt;pgtbl.ops.iova_to_phys(&amp;domain-&gt;pgtbl.ops, iova);
&gt;  }
&gt;
&gt;  /*
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 9140df71e17b..fe32a4eff14e 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -88,6 +88,7 @@ struct riscv_iommu_device {
&gt;
&gt;  struct riscv_iommu_domain {
&gt;         struct iommu_domain domain;
&gt; +       struct io_pgtable pgtbl;
&gt;
&gt;         struct list_head endpoints;
&gt;         struct mutex lock;
&gt; diff --git a/include/linux/io-pgtable.h b/include/linux/io-pgtable.h
&gt; index 1b7a44b35616..8dd9d3a28e3a 100644
&gt; --- a/include/linux/io-pgtable.h
&gt; +++ b/include/linux/io-pgtable.h
&gt; @@ -19,6 +19,7 @@ enum io_pgtable_fmt {
&gt;         AMD_IOMMU_V2,
&gt;         APPLE_DART,
&gt;         APPLE_DART2,
&gt; +       RISCV_IOMMU,
&gt;         IO_PGTABLE_NUM_FMTS,
&gt;  };
&gt;
&gt; @@ -258,5 +259,6 @@ extern struct io_pgtable_init_fns io_pgtable_arm_mali_lpae_init_fns;
&gt;  extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v1_init_fns;
&gt;  extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v2_init_fns;
&gt;  extern struct io_pgtable_init_fns io_pgtable_apple_dart_init_fns;
&gt; +extern struct io_pgtable_init_fns io_pgtable_riscv_init_fns;
&gt;
&gt;  #endif /* __IO_PGTABLE_H */
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m35e1f370635d089a8dde16e4c70b533d4b503ee0 id=e35e1f370635d089a8dde16e4c70b533d4b503ee0>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0qX0QuJRghAem-2q-raXqYOLdyaWyb7YfF9J9gazeo5Fw@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0qX0QuJRghAem-2q-raXqYOLdyaWyb7YfF9J9gazeo5Fw@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0qX0QuJRghAem-2q-raXqYOLdyaWyb7YfF9J9gazeo5Fw@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0qX0QuJRghAem-2q-raXqYOLdyaWyb7YfF9J9gazeo5Fw@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0qX0QuJRghAem-2q-raXqYOLdyaWyb7YfF9J9gazeo5Fw@mail.gmail.com/t/#u>nested</a>] <a href=#r35e1f370635d089a8dde16e4c70b533d4b503ee0>86+ messages in thread</a></pre><hr><pre><a href=#ec929b28389818fb366cddb7da7fa1c8aefd86240 id=mc929b28389818fb366cddb7da7fa1c8aefd86240>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-24 13:23           ` <a href=#m2f68d3d87e65ff461879a6fa2ab08e51464f5507>Zong Li</a>
<b>@ 2023-07-26  3:21             ` Baolu Lu</b>
  2023-07-26  4:26               ` <a href=#m5eb9ba5978916aa33090c12ea6b51d8c00bd37a5>Zong Li</a>
  <a href=#rc929b28389818fb366cddb7da7fa1c8aefd86240>0 siblings, 1 reply; 86+ messages in thread</a>
From: Baolu Lu @ 2023-07-26  3:21 UTC (<a href=https://lore.kernel.org/lkml/592edb17-7fa4-3b5b-2803-e8c50c322eee@linux.intel.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/592edb17-7fa4-3b5b-2803-e8c50c322eee@linux.intel.com/raw>raw</a>)
  To: Zong Li, Anup Patel
  Cc: baolu.lu, Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230726032156">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230726032156">linux-riscv</a>

On 2023/7/24 21:23, Zong Li wrote:
<span class=q>&gt;&gt;&gt;&gt;&gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt;&gt;&gt;&gt;&gt; IOMMU is in translation mode. To identify the devices that require
&gt;&gt;&gt;&gt;&gt; bypass mode by default, does it be sensible to add a property to
&gt;&gt;&gt;&gt;&gt; indicate this behavior?
&gt;&gt;&gt;&gt; Bypass mode for a device is a property of that device (similar to dma-coherent)
&gt;&gt;&gt;&gt; and not of the IOMMU. Other architectures (ARM and x86) never added such
&gt;&gt;&gt;&gt; a device property for bypass mode so I guess it is NOT ADVISABLE to do it.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; If this is REALLY required then we can do something similar to the QCOM
&gt;&gt;&gt;&gt; SMMU driver where they have a whitelist of devices which are allowed to
&gt;&gt;&gt;&gt; be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
&gt;&gt;&gt;&gt; compatible string and any device outside this whitelist is blocked by default.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt; I have considered that adding the property of bypass mode to that
&gt;&gt;&gt; device would be more appropriate. However, if we want to define this
&gt;&gt;&gt; property for the device, it might need to go through the generic IOMMU
&gt;&gt;&gt; dt-bindings, but I'm not sure if other IOMMU devices need this. I am
&gt;&gt;&gt; bringing up this topic here because I would like to explore if there
&gt;&gt;&gt; are any solutions on the IOMMU side, such as a property that indicates
&gt;&gt;&gt; the phandle of devices wishing to set bypass mode, somewhat similar to
&gt;&gt;&gt; the whitelist you mentioned earlier. Do you think we should address
&gt;&gt;&gt; this? After all, this is a case of RISC-V IOMMU supported.
&gt;&gt; Bypass mode is a common feature across IOMMUs. Other IOMMUs don't
&gt;&gt; have a special property for bypass mode at device-level or at IOMMU level,
&gt;&gt; which clearly indicates that defining a RISC-V specific property is not the
&gt;&gt; right way to go.
&gt;&gt;
&gt;&gt; The real question is how do we set IOMMU_DOMAIN_IDENTITY (i.e.
&gt;&gt; bypass/identity domain) as the default domain for certain devices ?
&gt;&gt;
&gt;&gt; One possible option is to implement def_domain_type() IOMMU operation
&gt;&gt; for RISC-V IOMMU which will return IOMMU_DOMAIN_IDENTITY for
&gt;&gt; certain devices based on compatible string matching (i.e. whitelist of
&gt;&gt; devices). As an example, refer qcom_smmu_def_domain_type()
&gt;&gt; of drivers/iommu/arm/arm-smmu/arm-smmu-qcom.c
&gt;&gt;
&gt; That is indeed one way to approach it, and we can modify the
&gt; compatible string when we want to change the mode. However, it would
&gt; be preferable to explore a more flexible approach to achieve this
&gt; goal. By doing so, we can avoid hard coding anything in the driver or
&gt; having to rebuild the kernel  whenever we want to change the mode for
&gt; certain devices. While I have considered extending a cell in the
&gt; 'iommus' property to indicate a device's desire to set bypass mode, it
&gt; doesn't comply with the iommu documentation and could lead to
&gt; ambiguous definitions.
</span>
Hard coding the matching strings in the iommu driver is definitely not a
preferable way. A feasible solution from current code's point of view is
that platform opt-in the device's special requirements through DT or
ACPI. And in the def_domain_type callback, let the iommu core know that,
hence it can allocate a right type of domain for the device.

Thoughts?

Best regards,
baolu

<a href=#mc929b28389818fb366cddb7da7fa1c8aefd86240 id=ec929b28389818fb366cddb7da7fa1c8aefd86240>^</a> <a href=https://lore.kernel.org/lkml/592edb17-7fa4-3b5b-2803-e8c50c322eee@linux.intel.com/>permalink</a> <a href=https://lore.kernel.org/lkml/592edb17-7fa4-3b5b-2803-e8c50c322eee@linux.intel.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/592edb17-7fa4-3b5b-2803-e8c50c322eee@linux.intel.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/592edb17-7fa4-3b5b-2803-e8c50c322eee@linux.intel.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/592edb17-7fa4-3b5b-2803-e8c50c322eee@linux.intel.com/t/#u>nested</a>] <a href=#rc929b28389818fb366cddb7da7fa1c8aefd86240>86+ messages in thread</a></pre><hr><pre><a href=#e5eb9ba5978916aa33090c12ea6b51d8c00bd37a5 id=m5eb9ba5978916aa33090c12ea6b51d8c00bd37a5>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-26  3:21             ` <a href=#mc929b28389818fb366cddb7da7fa1c8aefd86240>Baolu Lu</a>
<b>@ 2023-07-26  4:26               ` Zong Li</b>
  2023-07-26 12:17                 ` <a href=#ma6af771a2d7ce03a40ca3f822dc991cbf00147d3>Jason Gunthorpe</a>
  <a href=#r5eb9ba5978916aa33090c12ea6b51d8c00bd37a5>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-26  4:26 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0pS_=YxgrxSKbdfrFdGcBduzk3LTyC4vp_hqoJTbX3e0g@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0pS_=YxgrxSKbdfrFdGcBduzk3LTyC4vp_hqoJTbX3e0g@mail.gmail.com/raw">raw</a>)
  To: Baolu Lu
  Cc: Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230726042810">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230726042810">linux-riscv</a>

On Wed, Jul 26, 2023 at 11:21 AM Baolu Lu &lt;baolu.lu@linux.intel.com&gt; wrote:
<span class=q>&gt;
&gt; On 2023/7/24 21:23, Zong Li wrote:
&gt; &gt;&gt;&gt;&gt;&gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt; &gt;&gt;&gt;&gt;&gt; IOMMU is in translation mode. To identify the devices that require
&gt; &gt;&gt;&gt;&gt;&gt; bypass mode by default, does it be sensible to add a property to
&gt; &gt;&gt;&gt;&gt;&gt; indicate this behavior?
&gt; &gt;&gt;&gt;&gt; Bypass mode for a device is a property of that device (similar to dma-coherent)
&gt; &gt;&gt;&gt;&gt; and not of the IOMMU. Other architectures (ARM and x86) never added such
&gt; &gt;&gt;&gt;&gt; a device property for bypass mode so I guess it is NOT ADVISABLE to do it.
&gt; &gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt; If this is REALLY required then we can do something similar to the QCOM
&gt; &gt;&gt;&gt;&gt; SMMU driver where they have a whitelist of devices which are allowed to
&gt; &gt;&gt;&gt;&gt; be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
&gt; &gt;&gt;&gt;&gt; compatible string and any device outside this whitelist is blocked by default.
&gt; &gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt; I have considered that adding the property of bypass mode to that
&gt; &gt;&gt;&gt; device would be more appropriate. However, if we want to define this
&gt; &gt;&gt;&gt; property for the device, it might need to go through the generic IOMMU
&gt; &gt;&gt;&gt; dt-bindings, but I'm not sure if other IOMMU devices need this. I am
&gt; &gt;&gt;&gt; bringing up this topic here because I would like to explore if there
&gt; &gt;&gt;&gt; are any solutions on the IOMMU side, such as a property that indicates
&gt; &gt;&gt;&gt; the phandle of devices wishing to set bypass mode, somewhat similar to
&gt; &gt;&gt;&gt; the whitelist you mentioned earlier. Do you think we should address
&gt; &gt;&gt;&gt; this? After all, this is a case of RISC-V IOMMU supported.
&gt; &gt;&gt; Bypass mode is a common feature across IOMMUs. Other IOMMUs don't
&gt; &gt;&gt; have a special property for bypass mode at device-level or at IOMMU level,
&gt; &gt;&gt; which clearly indicates that defining a RISC-V specific property is not the
&gt; &gt;&gt; right way to go.
&gt; &gt;&gt;
&gt; &gt;&gt; The real question is how do we set IOMMU_DOMAIN_IDENTITY (i.e.
&gt; &gt;&gt; bypass/identity domain) as the default domain for certain devices ?
&gt; &gt;&gt;
&gt; &gt;&gt; One possible option is to implement def_domain_type() IOMMU operation
&gt; &gt;&gt; for RISC-V IOMMU which will return IOMMU_DOMAIN_IDENTITY for
&gt; &gt;&gt; certain devices based on compatible string matching (i.e. whitelist of
&gt; &gt;&gt; devices). As an example, refer qcom_smmu_def_domain_type()
&gt; &gt;&gt; of drivers/iommu/arm/arm-smmu/arm-smmu-qcom.c
&gt; &gt;&gt;
&gt; &gt; That is indeed one way to approach it, and we can modify the
&gt; &gt; compatible string when we want to change the mode. However, it would
&gt; &gt; be preferable to explore a more flexible approach to achieve this
&gt; &gt; goal. By doing so, we can avoid hard coding anything in the driver or
&gt; &gt; having to rebuild the kernel  whenever we want to change the mode for
&gt; &gt; certain devices. While I have considered extending a cell in the
&gt; &gt; 'iommus' property to indicate a device's desire to set bypass mode, it
&gt; &gt; doesn't comply with the iommu documentation and could lead to
&gt; &gt; ambiguous definitions.
&gt;
&gt; Hard coding the matching strings in the iommu driver is definitely not a
&gt; preferable way. A feasible solution from current code's point of view is
&gt; that platform opt-in the device's special requirements through DT or
&gt; ACPI. And in the def_domain_type callback, let the iommu core know that,
&gt; hence it can allocate a right type of domain for the device.
&gt;
&gt; Thoughts?
&gt;
</span>
It would be nice if we can deal with it at this time. As we discussed
earlier, we might need to consider how to indicate that, such as
putting a property in device side or iommu side, and whether we need
to define it in generic dt-binding instead of RISC-V specific
dt-binding.

<span class=q>&gt; Best regards,
&gt; baolu
</span>
<a href=#m5eb9ba5978916aa33090c12ea6b51d8c00bd37a5 id=e5eb9ba5978916aa33090c12ea6b51d8c00bd37a5>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0pS_=YxgrxSKbdfrFdGcBduzk3LTyC4vp_hqoJTbX3e0g@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0pS_=YxgrxSKbdfrFdGcBduzk3LTyC4vp_hqoJTbX3e0g@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0pS_=YxgrxSKbdfrFdGcBduzk3LTyC4vp_hqoJTbX3e0g@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0pS_=YxgrxSKbdfrFdGcBduzk3LTyC4vp_hqoJTbX3e0g@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0pS_=YxgrxSKbdfrFdGcBduzk3LTyC4vp_hqoJTbX3e0g@mail.gmail.com/t/#u">nested</a>] <a href=#r5eb9ba5978916aa33090c12ea6b51d8c00bd37a5>86+ messages in thread</a></pre><hr><pre><a href=#ea6af771a2d7ce03a40ca3f822dc991cbf00147d3 id=ma6af771a2d7ce03a40ca3f822dc991cbf00147d3>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-26  4:26               ` <a href=#m5eb9ba5978916aa33090c12ea6b51d8c00bd37a5>Zong Li</a>
<b>@ 2023-07-26 12:17                 ` Jason Gunthorpe</b>
  2023-07-27  2:42                   ` <a href=#mb9392a38decda68a70e4996544c2137d88821f96>Zong Li</a>
  <a href=#ra6af771a2d7ce03a40ca3f822dc991cbf00147d3>0 siblings, 1 reply; 86+ messages in thread</a>
From: Jason Gunthorpe @ 2023-07-26 12:17 UTC (<a href=https://lore.kernel.org/lkml/ZMEO1kNGfGjN6kZM@ziepe.ca/>permalink</a> / <a href=https://lore.kernel.org/lkml/ZMEO1kNGfGjN6kZM@ziepe.ca/raw>raw</a>)
  To: Zong Li
  Cc: Baolu Lu, Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230726121738">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230726121738">linux-riscv</a>

On Wed, Jul 26, 2023 at 12:26:14PM +0800, Zong Li wrote:
<span class=q>&gt; On Wed, Jul 26, 2023 at 11:21 AM Baolu Lu &lt;baolu.lu@linux.intel.com&gt; wrote:
&gt; &gt;
&gt; &gt; On 2023/7/24 21:23, Zong Li wrote:
&gt; &gt; &gt;&gt;&gt;&gt;&gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt; &gt; &gt;&gt;&gt;&gt;&gt; IOMMU is in translation mode. To identify the devices that require
&gt; &gt; &gt;&gt;&gt;&gt;&gt; bypass mode by default, does it be sensible to add a property to
&gt; &gt; &gt;&gt;&gt;&gt;&gt; indicate this behavior?
&gt; &gt; &gt;&gt;&gt;&gt; Bypass mode for a device is a property of that device (similar to dma-coherent)
&gt; &gt; &gt;&gt;&gt;&gt; and not of the IOMMU. Other architectures (ARM and x86) never added such
&gt; &gt; &gt;&gt;&gt;&gt; a device property for bypass mode so I guess it is NOT ADVISABLE to do it.
&gt; &gt; &gt;&gt;&gt;&gt;
&gt; &gt; &gt;&gt;&gt;&gt; If this is REALLY required then we can do something similar to the QCOM
&gt; &gt; &gt;&gt;&gt;&gt; SMMU driver where they have a whitelist of devices which are allowed to
&gt; &gt; &gt;&gt;&gt;&gt; be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
&gt; &gt; &gt;&gt;&gt;&gt; compatible string and any device outside this whitelist is
&gt; &gt; &gt;&gt;&gt;&gt; blocked by default.
</span>
I have a draft patch someplace that consolidated all this quirk
checking into the core code. Generally the expectation is that any
device behind an iommu is fully functional in all modes. The existing
quirks are for HW defects that make some devices not work properly. In
this case the right outcome seems to be effectively blocking them from
using the iommu.

So, you should explain a lot more what "require bypass mode" means in
the RISCV world and why any device would need it.

Jason

<a href=#ma6af771a2d7ce03a40ca3f822dc991cbf00147d3 id=ea6af771a2d7ce03a40ca3f822dc991cbf00147d3>^</a> <a href=https://lore.kernel.org/lkml/ZMEO1kNGfGjN6kZM@ziepe.ca/>permalink</a> <a href=https://lore.kernel.org/lkml/ZMEO1kNGfGjN6kZM@ziepe.ca/raw>raw</a> <a href=https://lore.kernel.org/lkml/ZMEO1kNGfGjN6kZM@ziepe.ca/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/ZMEO1kNGfGjN6kZM@ziepe.ca/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/ZMEO1kNGfGjN6kZM@ziepe.ca/t/#u>nested</a>] <a href=#ra6af771a2d7ce03a40ca3f822dc991cbf00147d3>86+ messages in thread</a></pre><hr><pre><a href=#eb9392a38decda68a70e4996544c2137d88821f96 id=mb9392a38decda68a70e4996544c2137d88821f96>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-26 12:17                 ` <a href=#ma6af771a2d7ce03a40ca3f822dc991cbf00147d3>Jason Gunthorpe</a>
<b>@ 2023-07-27  2:42                   ` Zong Li</b>
  2023-08-09 14:57                     ` <a href=#m2f7577e9b5cd357284c03e252264f511c553b0d9>Jason Gunthorpe</a>
  <a href=#rb9392a38decda68a70e4996544c2137d88821f96>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-27  2:42 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0qMWS_j0n_aUO8BVFSedYCjuMM=Z_tsnK05ZhG+Ob6pqw@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0qMWS_j0n_aUO8BVFSedYCjuMM=Z_tsnK05ZhG+Ob6pqw@mail.gmail.com/raw">raw</a>)
  To: Jason Gunthorpe
  Cc: Baolu Lu, Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230727024304">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230727024304">linux-riscv</a>

On Wed, Jul 26, 2023 at 8:17 PM Jason Gunthorpe &lt;jgg@ziepe.ca&gt; wrote:
<span class=q>&gt;
&gt; On Wed, Jul 26, 2023 at 12:26:14PM +0800, Zong Li wrote:
&gt; &gt; On Wed, Jul 26, 2023 at 11:21 AM Baolu Lu &lt;baolu.lu@linux.intel.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; On 2023/7/24 21:23, Zong Li wrote:
&gt; &gt; &gt; &gt;&gt;&gt;&gt;&gt; In RISC-V IOMMU, certain devices can be set to bypass mode when the
&gt; &gt; &gt; &gt;&gt;&gt;&gt;&gt; IOMMU is in translation mode. To identify the devices that require
&gt; &gt; &gt; &gt;&gt;&gt;&gt;&gt; bypass mode by default, does it be sensible to add a property to
&gt; &gt; &gt; &gt;&gt;&gt;&gt;&gt; indicate this behavior?
&gt; &gt; &gt; &gt;&gt;&gt;&gt; Bypass mode for a device is a property of that device (similar to dma-coherent)
&gt; &gt; &gt; &gt;&gt;&gt;&gt; and not of the IOMMU. Other architectures (ARM and x86) never added such
&gt; &gt; &gt; &gt;&gt;&gt;&gt; a device property for bypass mode so I guess it is NOT ADVISABLE to do it.
&gt; &gt; &gt; &gt;&gt;&gt;&gt;
&gt; &gt; &gt; &gt;&gt;&gt;&gt; If this is REALLY required then we can do something similar to the QCOM
&gt; &gt; &gt; &gt;&gt;&gt;&gt; SMMU driver where they have a whitelist of devices which are allowed to
&gt; &gt; &gt; &gt;&gt;&gt;&gt; be in bypass mode (i.e. IOMMU_DOMAIN_IDENTITY) based their device
&gt; &gt; &gt; &gt;&gt;&gt;&gt; compatible string and any device outside this whitelist is
&gt; &gt; &gt; &gt;&gt;&gt;&gt; blocked by default.
&gt;
&gt; I have a draft patch someplace that consolidated all this quirk
&gt; checking into the core code. Generally the expectation is that any
&gt; device behind an iommu is fully functional in all modes. The existing
&gt; quirks are for HW defects that make some devices not work properly. In
&gt; this case the right outcome seems to be effectively blocking them from
&gt; using the iommu.
&gt;
&gt; So, you should explain a lot more what "require bypass mode" means in
&gt; the RISCV world and why any device would need it.
</span>
Perhaps this question could be related to the scenarios in which
devices wish to be in bypass mode when the IOMMU is in translation
mode, and why IOMMU defines/supports this case. Currently, I could
envision a scenario where a device is already connected to the IOMMU
in hardware, but it is not functioning correctly, or there are
performance impacts. If modifying the hardware is not feasible, a
default configuration that allows bypass mode could be provided as a
solution. There might be other scenarios that I might have overlooked.
It seems to me since IOMMU supports this configuration, it would be
advantageous to have an approach to achieve it, and DT might be a
flexible way.

<span class=q>&gt;
&gt; Jason
</span>
<a href=#mb9392a38decda68a70e4996544c2137d88821f96 id=eb9392a38decda68a70e4996544c2137d88821f96>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0qMWS_j0n_aUO8BVFSedYCjuMM=Z_tsnK05ZhG+Ob6pqw@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0qMWS_j0n_aUO8BVFSedYCjuMM=Z_tsnK05ZhG+Ob6pqw@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0qMWS_j0n_aUO8BVFSedYCjuMM=Z_tsnK05ZhG+Ob6pqw@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0qMWS_j0n_aUO8BVFSedYCjuMM=Z_tsnK05ZhG+Ob6pqw@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0qMWS_j0n_aUO8BVFSedYCjuMM=Z_tsnK05ZhG+Ob6pqw@mail.gmail.com/t/#u">nested</a>] <a href=#rb9392a38decda68a70e4996544c2137d88821f96>86+ messages in thread</a></pre><hr><pre><a href=#e522f968d0909aad51fe7e480809ea548917990fa id=m522f968d0909aad51fe7e480809ea548917990fa>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
                     ` <a href=#r5c32a5e8f769114a8ba7611812fa02c944920207>(2 preceding siblings ...)</a>
  2023-07-20 12:31   ` <a href=#m5c32a5e8f769114a8ba7611812fa02c944920207>Baolu Lu</a>
<b>@ 2023-07-28  2:42   ` Zong Li</b>
  2023-08-02 20:15     ` <a href=#m6bea4b3cd6bb3324224d86b9abb254943fb6124a>Tomasz Jeznach</a>
  2023-08-03  0:18   ` <a href=#m428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>Jason Gunthorpe</a>
                     ` <a href=#r428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>(3 subsequent siblings)</a>
  <a href=#r522f968d0909aad51fe7e480809ea548917990fa>7 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-28  2:42 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0qRYvTffMnep-aQyTq2tMxbP-s_Lunc+cZ2Rio+BvAE=g@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0qRYvTffMnep-aQyTq2tMxbP-s_Lunc+cZ2Rio+BvAE=g@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230728024350">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230728024350">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; The patch introduces skeleton IOMMU device driver implementation as defined
&gt; by RISC-V IOMMU Architecture Specification, Version 1.0 [1], with minimal support
&gt; for pass-through mapping, basic initialization and bindings for platform and PCIe
&gt; hardware implementations.
&gt;
&gt; Series of patches following specification evolution has been reorganized to provide
&gt; functional separation of implemented blocks, compliant with ratified specification.
&gt;
&gt; This and following patch series includes code contributed by: Nick Kossifidis
&gt; &lt;mick@ics.forth.gr&gt; (iommu-platform device, number of specification clarification
&gt; and bugfixes and readability improvements), Sebastien Boeuf &lt;seb@rivosinc.com&gt; (page
&gt; table creation, ATS/PGR flow).
&gt;
&gt; Complete history can be found at the maintainer's repository branch [2].
&gt;
&gt; Device driver enables RISC-V 32/64 support for memory translation for DMA capable
&gt; PCI and platform devices, multilevel device directory table, process directory,
&gt; shared virtual address support, wired and message signaled interrupt for translation
&gt; I/O fault, page request interface and command processing.
&gt;
&gt; Matching RISCV-V IOMMU device emulation implementation is available for QEMU project,
&gt; along with educational device extensions for PASID ATS/PRI support [3].
&gt;
&gt; References:
&gt;  - [1] <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
&gt;  - [2] <a href=https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu</a>
&gt;  - [3] <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu</a>
&gt;
&gt; Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/Kconfig                |   1 +
&gt;  drivers/iommu/Makefile               |   2 +-
&gt;  drivers/iommu/riscv/Kconfig          |  22 +
&gt;  drivers/iommu/riscv/Makefile         |   1 +
&gt;  drivers/iommu/riscv/iommu-bits.h     | 704 +++++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu-pci.c      | 134 +++++
&gt;  drivers/iommu/riscv/iommu-platform.c |  94 ++++
&gt;  drivers/iommu/riscv/iommu.c          | 660 +++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu.h          | 115 +++++
&gt;  9 files changed, 1732 insertions(+), 1 deletion(-)
&gt;  create mode 100644 drivers/iommu/riscv/Kconfig
&gt;  create mode 100644 drivers/iommu/riscv/Makefile
&gt;  create mode 100644 drivers/iommu/riscv/iommu-bits.h
&gt;  create mode 100644 drivers/iommu/riscv/iommu-pci.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu-platform.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu.h
&gt;
&gt; diff --git a/drivers/iommu/Kconfig b/drivers/iommu/Kconfig
&gt; index 2b12b583ef4b..36fcc6fd5b4e 100644
&gt; --- a/drivers/iommu/Kconfig
&gt; +++ b/drivers/iommu/Kconfig
&gt; @@ -187,6 +187,7 @@ config MSM_IOMMU
&gt;  source "drivers/iommu/amd/Kconfig"
&gt;  source "drivers/iommu/intel/Kconfig"
&gt;  source "drivers/iommu/iommufd/Kconfig"
&gt; +source "drivers/iommu/riscv/Kconfig"
&gt;
&gt;  config IRQ_REMAP
&gt;         bool "Support for Interrupt Remapping"
&gt; diff --git a/drivers/iommu/Makefile b/drivers/iommu/Makefile
&gt; index 769e43d780ce..8f57110a9fb1 100644
&gt; --- a/drivers/iommu/Makefile
&gt; +++ b/drivers/iommu/Makefile
&gt; @@ -1,5 +1,5 @@
&gt;  # SPDX-License-Identifier: GPL-2.0
&gt; -obj-y += amd/ intel/ arm/ iommufd/
&gt; +obj-y += amd/ intel/ arm/ iommufd/ riscv/
&gt;  obj-$(CONFIG_IOMMU_API) += iommu.o
&gt;  obj-$(CONFIG_IOMMU_API) += iommu-traces.o
&gt;  obj-$(CONFIG_IOMMU_API) += iommu-sysfs.o
&gt; diff --git a/drivers/iommu/riscv/Kconfig b/drivers/iommu/riscv/Kconfig
&gt; new file mode 100644
&gt; index 000000000000..01d4043849d4
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/Kconfig
&gt; @@ -0,0 +1,22 @@
&gt; +# SPDX-License-Identifier: GPL-2.0-only
&gt; +# RISC-V IOMMU support
&gt; +
&gt; +config RISCV_IOMMU
&gt; +       bool "RISC-V IOMMU driver"
&gt; +       depends on RISCV
&gt; +       select IOMMU_API
&gt; +       select IOMMU_DMA
&gt; +       select IOMMU_SVA
&gt; +       select IOMMU_IOVA
&gt; +       select IOMMU_IO_PGTABLE
&gt; +       select IOASID
&gt; +       select PCI_MSI
&gt; +       select PCI_ATS
&gt; +       select PCI_PRI
&gt; +       select PCI_PASID
&gt; +       select MMU_NOTIFIER
&gt; +       help
&gt; +         Support for devices following RISC-V IOMMU specification.
&gt; +
&gt; +         If unsure, say N here.
&gt; +
&gt; diff --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
&gt; new file mode 100644
&gt; index 000000000000..38730c11e4a8
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/Makefile
&gt; @@ -0,0 +1 @@
&gt; +obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o
&gt; \ No newline at end of file
&gt; diff --git a/drivers/iommu/riscv/iommu-bits.h b/drivers/iommu/riscv/iommu-bits.h
&gt; new file mode 100644
&gt; index 000000000000..b2946793a73d
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-bits.h
&gt; @@ -0,0 +1,704 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + * Copyright © 2023 RISC-V IOMMU Task Group
&gt; + *
&gt; + * RISC-V Ziommu - Register Layout and Data Structures.
&gt; + *
&gt; + * Based on the 'RISC-V IOMMU Architecture Specification', Version 1.0
&gt; + * Published at  <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
&gt; + *
&gt; + */
&gt; +
&gt; +#ifndef _RISCV_IOMMU_BITS_H_
&gt; +#define _RISCV_IOMMU_BITS_H_
&gt; +
&gt; +#include &lt;linux/types.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +#include &lt;linux/bits.h&gt;
&gt; +
&gt; +/*
&gt; + * Chapter 5: Memory Mapped register interface
&gt; + */
&gt; +
&gt; +/* Common field positions */
&gt; +#define RISCV_IOMMU_PPN_FIELD          GENMASK_ULL(53, 10)
&gt; +#define RISCV_IOMMU_QUEUE_LOGSZ_FIELD  GENMASK_ULL(4, 0)
&gt; +#define RISCV_IOMMU_QUEUE_INDEX_FIELD  GENMASK_ULL(31, 0)
&gt; +#define RISCV_IOMMU_QUEUE_ENABLE       BIT(0)
&gt; +#define RISCV_IOMMU_QUEUE_INTR_ENABLE  BIT(1)
&gt; +#define RISCV_IOMMU_QUEUE_MEM_FAULT    BIT(8)
&gt; +#define RISCV_IOMMU_QUEUE_OVERFLOW     BIT(9)
&gt; +#define RISCV_IOMMU_QUEUE_ACTIVE       BIT(16)
&gt; +#define RISCV_IOMMU_QUEUE_BUSY         BIT(17)
&gt; +
&gt; +#define RISCV_IOMMU_ATP_PPN_FIELD      GENMASK_ULL(43, 0)
&gt; +#define RISCV_IOMMU_ATP_MODE_FIELD     GENMASK_ULL(63, 60)
&gt; +
&gt; +/* 5.3 IOMMU Capabilities (64bits) */
&gt; +#define RISCV_IOMMU_REG_CAP            0x0000
&gt; +#define RISCV_IOMMU_CAP_VERSION                GENMASK_ULL(7, 0)
&gt; +#define RISCV_IOMMU_CAP_S_SV32         BIT_ULL(8)
&gt; +#define RISCV_IOMMU_CAP_S_SV39         BIT_ULL(9)
&gt; +#define RISCV_IOMMU_CAP_S_SV48         BIT_ULL(10)
&gt; +#define RISCV_IOMMU_CAP_S_SV57         BIT_ULL(11)
&gt; +#define RISCV_IOMMU_CAP_SVPBMT         BIT_ULL(15)
&gt; +#define RISCV_IOMMU_CAP_G_SV32         BIT_ULL(16)
&gt; +#define RISCV_IOMMU_CAP_G_SV39         BIT_ULL(17)
&gt; +#define RISCV_IOMMU_CAP_G_SV48         BIT_ULL(18)
&gt; +#define RISCV_IOMMU_CAP_G_SV57         BIT_ULL(19)
&gt; +#define RISCV_IOMMU_CAP_MSI_FLAT       BIT_ULL(22)
&gt; +#define RISCV_IOMMU_CAP_MSI_MRIF       BIT_ULL(23)
&gt; +#define RISCV_IOMMU_CAP_AMO            BIT_ULL(24)
&gt; +#define RISCV_IOMMU_CAP_ATS            BIT_ULL(25)
&gt; +#define RISCV_IOMMU_CAP_T2GPA          BIT_ULL(26)
&gt; +#define RISCV_IOMMU_CAP_END            BIT_ULL(27)
&gt; +#define RISCV_IOMMU_CAP_IGS            GENMASK_ULL(29, 28)
&gt; +#define RISCV_IOMMU_CAP_HPM            BIT_ULL(30)
&gt; +#define RISCV_IOMMU_CAP_DBG            BIT_ULL(31)
&gt; +#define RISCV_IOMMU_CAP_PAS            GENMASK_ULL(37, 32)
&gt; +#define RISCV_IOMMU_CAP_PD8            BIT_ULL(38)
&gt; +#define RISCV_IOMMU_CAP_PD17           BIT_ULL(39)
&gt; +#define RISCV_IOMMU_CAP_PD20           BIT_ULL(40)
&gt; +
&gt; +#define RISCV_IOMMU_CAP_VERSION_VER_MASK       0xF0
&gt; +#define RISCV_IOMMU_CAP_VERSION_REV_MASK       0x0F
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_igs_settings - Interrupt Generation Support Settings
&gt; + * @RISCV_IOMMU_CAP_IGS_MSI: I/O MMU supports only MSI generation
&gt; + * @RISCV_IOMMU_CAP_IGS_WSI: I/O MMU supports only Wired-Signaled interrupt
&gt; + * @RISCV_IOMMU_CAP_IGS_BOTH: I/O MMU supports both MSI and WSI generation
&gt; + * @RISCV_IOMMU_CAP_IGS_RSRV: Reserved for standard use
&gt; + */
&gt; +enum riscv_iommu_igs_settings {
&gt; +       RISCV_IOMMU_CAP_IGS_MSI = 0,
&gt; +       RISCV_IOMMU_CAP_IGS_WSI = 1,
&gt; +       RISCV_IOMMU_CAP_IGS_BOTH = 2,
&gt; +       RISCV_IOMMU_CAP_IGS_RSRV = 3
&gt; +};
&gt; +
&gt; +/* 5.4 Features control register (32bits) */
&gt; +#define RISCV_IOMMU_REG_FCTL           0x0008
&gt; +#define RISCV_IOMMU_FCTL_BE            BIT(0)
&gt; +#define RISCV_IOMMU_FCTL_WSI           BIT(1)
&gt; +#define RISCV_IOMMU_FCTL_GXL           BIT(2)
&gt; +
&gt; +/* 5.5 Device-directory-table pointer (64bits) */
&gt; +#define RISCV_IOMMU_REG_DDTP           0x0010
&gt; +#define RISCV_IOMMU_DDTP_MODE          GENMASK_ULL(3, 0)
&gt; +#define RISCV_IOMMU_DDTP_BUSY          BIT_ULL(4)
&gt; +#define RISCV_IOMMU_DDTP_PPN           RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_ddtp_modes - I/O MMU translation modes
&gt; + * @RISCV_IOMMU_DDTP_MODE_OFF: No inbound transactions allowed
&gt; + * @RISCV_IOMMU_DDTP_MODE_BARE: Pass-through mode
&gt; + * @RISCV_IOMMU_DDTP_MODE_1LVL: One-level DDT
&gt; + * @RISCV_IOMMU_DDTP_MODE_2LVL: Two-level DDT
&gt; + * @RISCV_IOMMU_DDTP_MODE_3LVL: Three-level DDT
&gt; + */
&gt; +enum riscv_iommu_ddtp_modes {
&gt; +       RISCV_IOMMU_DDTP_MODE_OFF = 0,
&gt; +       RISCV_IOMMU_DDTP_MODE_BARE = 1,
&gt; +       RISCV_IOMMU_DDTP_MODE_1LVL = 2,
&gt; +       RISCV_IOMMU_DDTP_MODE_2LVL = 3,
&gt; +       RISCV_IOMMU_DDTP_MODE_3LVL = 4,
&gt; +       RISCV_IOMMU_DDTP_MODE_MAX = 4
&gt; +};
&gt; +
&gt; +/* 5.6 Command Queue Base (64bits) */
&gt; +#define RISCV_IOMMU_REG_CQB            0x0018
&gt; +#define RISCV_IOMMU_CQB_ENTRIES                RISCV_IOMMU_QUEUE_LOGSZ_FIELD
&gt; +#define RISCV_IOMMU_CQB_PPN            RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.7 Command Queue head (32bits) */
&gt; +#define RISCV_IOMMU_REG_CQH            0x0020
&gt; +#define RISCV_IOMMU_CQH_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.8 Command Queue tail (32bits) */
&gt; +#define RISCV_IOMMU_REG_CQT            0x0024
&gt; +#define RISCV_IOMMU_CQT_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.9 Fault Queue Base (64bits) */
&gt; +#define RISCV_IOMMU_REG_FQB            0x0028
&gt; +#define RISCV_IOMMU_FQB_ENTRIES                RISCV_IOMMU_QUEUE_LOGSZ_FIELD
&gt; +#define RISCV_IOMMU_FQB_PPN            RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.10 Fault Queue Head (32bits) */
&gt; +#define RISCV_IOMMU_REG_FQH            0x0030
&gt; +#define RISCV_IOMMU_FQH_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.11 Fault Queue tail (32bits) */
&gt; +#define RISCV_IOMMU_REG_FQT            0x0034
&gt; +#define RISCV_IOMMU_FQT_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.12 Page Request Queue base (64bits) */
&gt; +#define RISCV_IOMMU_REG_PQB            0x0038
&gt; +#define RISCV_IOMMU_PQB_ENTRIES                RISCV_IOMMU_QUEUE_LOGSZ_FIELD
&gt; +#define RISCV_IOMMU_PQB_PPN            RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.13 Page Request Queue head (32bits) */
&gt; +#define RISCV_IOMMU_REG_PQH            0x0040
&gt; +#define RISCV_IOMMU_PQH_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.14 Page Request Queue tail (32bits) */
&gt; +#define RISCV_IOMMU_REG_PQT            0x0044
&gt; +#define RISCV_IOMMU_PQT_INDEX_MASK     RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.15 Command Queue CSR (32bits) */
&gt; +#define RISCV_IOMMU_REG_CQCSR          0x0048
&gt; +#define RISCV_IOMMU_CQCSR_CQEN         RISCV_IOMMU_QUEUE_ENABLE
&gt; +#define RISCV_IOMMU_CQCSR_CIE          RISCV_IOMMU_QUEUE_INTR_ENABLE
&gt; +#define RISCV_IOMMU_CQCSR_CQMF         RISCV_IOMMU_QUEUE_MEM_FAULT
&gt; +#define RISCV_IOMMU_CQCSR_CMD_TO       BIT(9)
&gt; +#define RISCV_IOMMU_CQCSR_CMD_ILL      BIT(10)
&gt; +#define RISCV_IOMMU_CQCSR_FENCE_W_IP   BIT(11)
&gt; +#define RISCV_IOMMU_CQCSR_CQON         RISCV_IOMMU_QUEUE_ACTIVE
&gt; +#define RISCV_IOMMU_CQCSR_BUSY         RISCV_IOMMU_QUEUE_BUSY
&gt; +
&gt; +/* 5.16 Fault Queue CSR (32bits) */
&gt; +#define RISCV_IOMMU_REG_FQCSR          0x004C
&gt; +#define RISCV_IOMMU_FQCSR_FQEN         RISCV_IOMMU_QUEUE_ENABLE
&gt; +#define RISCV_IOMMU_FQCSR_FIE          RISCV_IOMMU_QUEUE_INTR_ENABLE
&gt; +#define RISCV_IOMMU_FQCSR_FQMF         RISCV_IOMMU_QUEUE_MEM_FAULT
&gt; +#define RISCV_IOMMU_FQCSR_FQOF         RISCV_IOMMU_QUEUE_OVERFLOW
&gt; +#define RISCV_IOMMU_FQCSR_FQON         RISCV_IOMMU_QUEUE_ACTIVE
&gt; +#define RISCV_IOMMU_FQCSR_BUSY         RISCV_IOMMU_QUEUE_BUSY
&gt; +
&gt; +/* 5.17 Page Request Queue CSR (32bits) */
&gt; +#define RISCV_IOMMU_REG_PQCSR          0x0050
&gt; +#define RISCV_IOMMU_PQCSR_PQEN         RISCV_IOMMU_QUEUE_ENABLE
&gt; +#define RISCV_IOMMU_PQCSR_PIE          RISCV_IOMMU_QUEUE_INTR_ENABLE
&gt; +#define RISCV_IOMMU_PQCSR_PQMF         RISCV_IOMMU_QUEUE_MEM_FAULT
&gt; +#define RISCV_IOMMU_PQCSR_PQOF         RISCV_IOMMU_QUEUE_OVERFLOW
&gt; +#define RISCV_IOMMU_PQCSR_PQON         RISCV_IOMMU_QUEUE_ACTIVE
&gt; +#define RISCV_IOMMU_PQCSR_BUSY         RISCV_IOMMU_QUEUE_BUSY
&gt; +
&gt; +/* 5.18 Interrupt Pending Status (32bits) */
&gt; +#define RISCV_IOMMU_REG_IPSR           0x0054
&gt; +
&gt; +#define RISCV_IOMMU_INTR_CQ            0
&gt; +#define RISCV_IOMMU_INTR_FQ            1
&gt; +#define RISCV_IOMMU_INTR_PM            2
&gt; +#define RISCV_IOMMU_INTR_PQ            3
&gt; +#define RISCV_IOMMU_INTR_COUNT         4
&gt; +
&gt; +#define RISCV_IOMMU_IPSR_CIP           BIT(RISCV_IOMMU_INTR_CQ)
&gt; +#define RISCV_IOMMU_IPSR_FIP           BIT(RISCV_IOMMU_INTR_FQ)
&gt; +#define RISCV_IOMMU_IPSR_PMIP          BIT(RISCV_IOMMU_INTR_PM)
&gt; +#define RISCV_IOMMU_IPSR_PIP           BIT(RISCV_IOMMU_INTR_PQ)
&gt; +
&gt; +/* 5.19 Performance monitoring counter overflow status (32bits) */
&gt; +#define RISCV_IOMMU_REG_IOCOUNTOVF     0x0058
&gt; +#define RISCV_IOMMU_IOCOUNTOVF_CY      BIT(0)
&gt; +#define RISCV_IOMMU_IOCOUNTOVF_HPM     GENMASK_ULL(31, 1)
&gt; +
&gt; +/* 5.20 Performance monitoring counter inhibits (32bits) */
&gt; +#define RISCV_IOMMU_REG_IOCOUNTINH     0x005C
&gt; +#define RISCV_IOMMU_IOCOUNTINH_CY      BIT(0)
&gt; +#define RISCV_IOMMU_IOCOUNTINH_HPM     GENMASK(31, 1)
&gt; +
&gt; +/* 5.21 Performance monitoring cycles counter (64bits) */
&gt; +#define RISCV_IOMMU_REG_IOHPMCYCLES     0x0060
&gt; +#define RISCV_IOMMU_IOHPMCYCLES_COUNTER        GENMASK_ULL(62, 0)
&gt; +#define RISCV_IOMMU_IOHPMCYCLES_OVF    BIT_ULL(63)
&gt; +
&gt; +/* 5.22 Performance monitoring event counters (31 * 64bits) */
&gt; +#define RISCV_IOMMU_REG_IOHPMCTR_BASE  0x0068
&gt; +#define RISCV_IOMMU_REG_IOHPMCTR(_n)   (RISCV_IOMMU_REG_IOHPMCTR_BASE + (_n * 0x8))
&gt; +
&gt; +/* 5.23 Performance monitoring event selectors (31 * 64bits) */
&gt; +#define RISCV_IOMMU_REG_IOHPMEVT_BASE  0x0160
&gt; +#define RISCV_IOMMU_REG_IOHPMEVT(_n)   (RISCV_IOMMU_REG_IOHPMEVT_BASE + (_n * 0x8))
&gt; +#define RISCV_IOMMU_IOHPMEVT_EVENT_ID  GENMASK_ULL(14, 0)
&gt; +#define RISCV_IOMMU_IOHPMEVT_DMASK     BIT_ULL(15)
&gt; +#define RISCV_IOMMU_IOHPMEVT_PID_PSCID GENMASK_ULL(35, 16)
&gt; +#define RISCV_IOMMU_IOHPMEVT_DID_GSCID GENMASK_ULL(59, 36)
&gt; +#define RISCV_IOMMU_IOHPMEVT_PV_PSCV   BIT_ULL(60)
&gt; +#define RISCV_IOMMU_IOHPMEVT_DV_GSCV   BIT_ULL(61)
&gt; +#define RISCV_IOMMU_IOHPMEVT_IDT       BIT_ULL(62)
&gt; +#define RISCV_IOMMU_IOHPMEVT_OF                BIT_ULL(63)
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_hpmevent_id - Performance-monitoring event identifier
&gt; + *
&gt; + * @RISCV_IOMMU_HPMEVENT_INVALID: Invalid event, do not count
&gt; + * @RISCV_IOMMU_HPMEVENT_URQ: Untranslated requests
&gt; + * @RISCV_IOMMU_HPMEVENT_TRQ: Translated requests
&gt; + * @RISCV_IOMMU_HPMEVENT_ATS_RQ: ATS translation requests
&gt; + * @RISCV_IOMMU_HPMEVENT_TLB_MISS: TLB misses
&gt; + * @RISCV_IOMMU_HPMEVENT_DD_WALK: Device directory walks
&gt; + * @RISCV_IOMMU_HPMEVENT_PD_WALK: Process directory walks
&gt; + * @RISCV_IOMMU_HPMEVENT_S_VS_WALKS: S/VS-Stage page table walks
&gt; + * @RISCV_IOMMU_HPMEVENT_G_WALKS: G-Stage page table walks
&gt; + * @RISCV_IOMMU_HPMEVENT_MAX: Value to denote maximum Event IDs
&gt; + */
&gt; +enum riscv_iommu_hpmevent_id {
&gt; +       RISCV_IOMMU_HPMEVENT_INVALID    = 0,
&gt; +       RISCV_IOMMU_HPMEVENT_URQ        = 1,
&gt; +       RISCV_IOMMU_HPMEVENT_TRQ        = 2,
&gt; +       RISCV_IOMMU_HPMEVENT_ATS_RQ     = 3,
&gt; +       RISCV_IOMMU_HPMEVENT_TLB_MISS   = 4,
&gt; +       RISCV_IOMMU_HPMEVENT_DD_WALK    = 5,
&gt; +       RISCV_IOMMU_HPMEVENT_PD_WALK    = 6,
&gt; +       RISCV_IOMMU_HPMEVENT_S_VS_WALKS = 7,
&gt; +       RISCV_IOMMU_HPMEVENT_G_WALKS    = 8,
&gt; +       RISCV_IOMMU_HPMEVENT_MAX        = 9
&gt; +};
&gt; +
&gt; +/* 5.24 Translation request IOVA (64bits) */
&gt; +#define RISCV_IOMMU_REG_TR_REQ_IOVA     0x0258
&gt; +#define RISCV_IOMMU_TR_REQ_IOVA_VPN    GENMASK_ULL(63, 12)
&gt; +
&gt; +/* 5.25 Translation request control (64bits) */
&gt; +#define RISCV_IOMMU_REG_TR_REQ_CTL     0x0260
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_GO_BUSY BIT_ULL(0)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_PRIV    BIT_ULL(1)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_EXE     BIT_ULL(2)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_NW      BIT_ULL(3)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_PID     GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_PV      BIT_ULL(32)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_DID     GENMASK_ULL(63, 40)
&gt; +
&gt; +/* 5.26 Translation request response (64bits) */
&gt; +#define RISCV_IOMMU_REG_TR_RESPONSE    0x0268
&gt; +#define RISCV_IOMMU_TR_RESPONSE_FAULT  BIT_ULL(0)
&gt; +#define RISCV_IOMMU_TR_RESPONSE_PBMT   GENMASK_ULL(8, 7)
&gt; +#define RISCV_IOMMU_TR_RESPONSE_SZ     BIT_ULL(9)
&gt; +#define RISCV_IOMMU_TR_RESPONSE_PPN    RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.27 Interrupt cause to vector (64bits) */
&gt; +#define RISCV_IOMMU_REG_IVEC           0x02F8
&gt; +#define RISCV_IOMMU_IVEC_CIV           GENMASK_ULL(3, 0)
&gt; +#define RISCV_IOMMU_IVEC_FIV           GENMASK_ULL(7, 4)
&gt; +#define RISCV_IOMMU_IVEC_PMIV          GENMASK_ULL(11, 8)
&gt; +#define RISCV_IOMMU_IVEC_PIV           GENMASK_ULL(15,12)
&gt; +
&gt; +/* 5.28 MSI Configuration table (32 * 64bits) */
&gt; +#define RISCV_IOMMU_REG_MSI_CONFIG     0x0300
&gt; +#define RISCV_IOMMU_REG_MSI_ADDR(_n)   (RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10))
&gt; +#define RISCV_IOMMU_MSI_ADDR           GENMASK_ULL(55, 2)
&gt; +#define RISCV_IOMMU_REG_MSI_DATA(_n)   (RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10) + 0x08)
&gt; +#define RISCV_IOMMU_MSI_DATA           GENMASK_ULL(31, 0)
&gt; +#define RISCV_IOMMU_REG_MSI_VEC_CTL(_n)        (RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10) + 0x0C)
&gt; +#define RISCV_IOMMU_MSI_VEC_CTL_M      BIT_ULL(0)
&gt; +
&gt; +#define RISCV_IOMMU_REG_SIZE   0x1000
&gt; +
&gt; +/*
&gt; + * Chapter 2: Data structures
&gt; + */
&gt; +
&gt; +/*
&gt; + * Device Directory Table macros for non-leaf nodes
&gt; + */
&gt; +#define RISCV_IOMMU_DDTE_VALID BIT_ULL(0)
&gt; +#define RISCV_IOMMU_DDTE_PPN   RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_dc - Device Context
&gt; + * @tc: Translation Control
&gt; + * @iohgatp: I/O Hypervisor guest address translation and protection
&gt; + *          (Second stage context)
&gt; + * @ta: Translation Attributes
&gt; + * @fsc: First stage context
&gt; + * @msiptpt: MSI page table pointer
&gt; + * @msi_addr_mask: MSI address mask
&gt; + * @msi_addr_pattern: MSI address pattern
&gt; + *
&gt; + * This structure is used for leaf nodes on the Device Directory Table,
&gt; + * in case RISCV_IOMMU_CAP_MSI_FLAT is not set, the bottom 4 fields are
&gt; + * not present and are skipped with pointer arithmetic to avoid
&gt; + * casting, check out riscv_iommu_get_dc().
&gt; + * See section 2.1 for more details
&gt; + */
&gt; +struct riscv_iommu_dc {
&gt; +       u64 tc;
&gt; +       u64 iohgatp;
&gt; +       u64 ta;
&gt; +       u64 fsc;
&gt; +       u64 msiptp;
&gt; +       u64 msi_addr_mask;
&gt; +       u64 msi_addr_pattern;
&gt; +       u64 _reserved;
&gt; +};
&gt; +
&gt; +/* Translation control fields */
&gt; +#define RISCV_IOMMU_DC_TC_V            BIT_ULL(0)
&gt; +#define RISCV_IOMMU_DC_TC_EN_ATS       BIT_ULL(1)
&gt; +#define RISCV_IOMMU_DC_TC_EN_PRI       BIT_ULL(2)
&gt; +#define RISCV_IOMMU_DC_TC_T2GPA                BIT_ULL(3)
&gt; +#define RISCV_IOMMU_DC_TC_DTF          BIT_ULL(4)
&gt; +#define RISCV_IOMMU_DC_TC_PDTV         BIT_ULL(5)
&gt; +#define RISCV_IOMMU_DC_TC_PRPR         BIT_ULL(6)
&gt; +#define RISCV_IOMMU_DC_TC_GADE         BIT_ULL(7)
&gt; +#define RISCV_IOMMU_DC_TC_SADE         BIT_ULL(8)
&gt; +#define RISCV_IOMMU_DC_TC_DPE          BIT_ULL(9)
&gt; +#define RISCV_IOMMU_DC_TC_SBE          BIT_ULL(10)
&gt; +#define RISCV_IOMMU_DC_TC_SXL          BIT_ULL(11)
&gt; +
&gt; +/* Second-stage (aka G-stage) context fields */
&gt; +#define RISCV_IOMMU_DC_IOHGATP_PPN     RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_DC_IOHGATP_GSCID   GENMASK_ULL(59, 44)
&gt; +#define RISCV_IOMMU_DC_IOHGATP_MODE    RISCV_IOMMU_ATP_MODE_FIELD
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_dc_iohgatp_modes - Guest address translation/protection modes
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_BARE: No translation/protection
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV32X4: Sv32x4 (2-bit extension of Sv32), when fctl.GXL == 1
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV39X4: Sv39x4 (2-bit extension of Sv39), when fctl.GXL == 0
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV48X4: Sv48x4 (2-bit extension of Sv48), when fctl.GXL == 0
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV57X4: Sv57x4 (2-bit extension of Sv57), when fctl.GXL == 0
&gt; + */
&gt; +enum riscv_iommu_dc_iohgatp_modes {
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_BARE = 0,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV32X4 = 8,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV39X4 = 8,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV48X4 = 9,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV57X4 = 10
&gt; +};
&gt; +
&gt; +/* Translation attributes fields */
&gt; +#define RISCV_IOMMU_DC_TA_PSCID                GENMASK_ULL(31,12)
&gt; +
&gt; +/* First-stage context fields */
&gt; +#define RISCV_IOMMU_DC_FSC_PPN         RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_DC_FSC_MODE                RISCV_IOMMU_ATP_MODE_FIELD
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_dc_fsc_atp_modes - First stage address translation/protection modes
&gt; + * @RISCV_IOMMU_DC_FSC_MODE_BARE: No translation/protection
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV32: Sv32, when dc.tc.SXL == 1
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV39: Sv39, when dc.tc.SXL == 0
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV48: Sv48, when dc.tc.SXL == 0
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV57: Sv57, when dc.tc.SXL == 0
&gt; + * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8: 1lvl PDT, 8bit process ids
&gt; + * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD17: 2lvl PDT, 17bit process ids
&gt; + * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD20: 3lvl PDT, 20bit process ids
&gt; + *
&gt; + * FSC holds IOSATP when RISCV_IOMMU_DC_TC_PDTV is 0 and PDTP otherwise.
&gt; + * IOSATP controls the first stage address translation (same as the satp register on
&gt; + * the RISC-V MMU), and PDTP holds the process directory table, used to select a
&gt; + * first stage page table based on a process id (for devices that support multiple
&gt; + * process ids).
&gt; + */
&gt; +enum riscv_iommu_dc_fsc_atp_modes {
&gt; +       RISCV_IOMMU_DC_FSC_MODE_BARE = 0,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV32 = 8,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV39 = 8,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV48 = 9,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV57 = 10,
&gt; +       RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8 = 1,
&gt; +       RISCV_IOMMU_DC_FSC_PDTP_MODE_PD17 = 2,
&gt; +       RISCV_IOMMU_DC_FSC_PDTP_MODE_PD20 = 3
&gt; +};
&gt; +
&gt; +/* MSI page table pointer */
&gt; +#define RISCV_IOMMU_DC_MSIPTP_PPN      RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_DC_MSIPTP_MODE     RISCV_IOMMU_ATP_MODE_FIELD
&gt; +#define RISCV_IOMMU_DC_MSIPTP_MODE_OFF 0
&gt; +#define RISCV_IOMMU_DC_MSIPTP_MODE_FLAT        1
&gt; +
&gt; +/* MSI address mask */
&gt; +#define RISCV_IOMMU_DC_MSI_ADDR_MASK   GENMASK_ULL(51, 0)
&gt; +
&gt; +/* MSI address pattern */
&gt; +#define RISCV_IOMMU_DC_MSI_PATTERN     GENMASK_ULL(51, 0)
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_pc - Process Context
&gt; + * @ta: Translation Attributes
&gt; + * @fsc: First stage context
&gt; + *
&gt; + * This structure is used for leaf nodes on the Process Directory Table
&gt; + * See section 2.3 for more details
&gt; + */
&gt; +struct riscv_iommu_pc {
&gt; +       u64 ta;
&gt; +       u64 fsc;
&gt; +};
&gt; +
&gt; +/* Translation attributes fields */
&gt; +#define RISCV_IOMMU_PC_TA_V    BIT_ULL(0)
&gt; +#define RISCV_IOMMU_PC_TA_ENS  BIT_ULL(1)
&gt; +#define RISCV_IOMMU_PC_TA_SUM  BIT_ULL(2)
&gt; +#define RISCV_IOMMU_PC_TA_PSCID        GENMASK_ULL(31, 12)
&gt; +
&gt; +/* First stage context fields */
&gt; +#define RISCV_IOMMU_PC_FSC_PPN RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_PC_FSC_MODE        RISCV_IOMMU_ATP_MODE_FIELD
&gt; +
&gt; +/*
&gt; + * Chapter 3: In-memory queue interface
&gt; + */
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_cmd - Generic I/O MMU command structure
&gt; + * @dword0: Includes the opcode and the function identifier
&gt; + * @dword1: Opcode specific data
&gt; + *
&gt; + * The commands are interpreted as two 64bit fields, where the first
&gt; + * 7bits of the first field are the opcode which also defines the
&gt; + * command's format, followed by a 3bit field that specifies the
&gt; + * function invoked by that command, and the rest is opcode-specific.
&gt; + * This is a generic struct which will be populated differently
&gt; + * according to each command. For more infos on the commands and
&gt; + * the command queue check section 3.1.
&gt; + */
&gt; +struct riscv_iommu_command {
&gt; +       u64 dword0;
&gt; +       u64 dword1;
&gt; +};
&gt; +
&gt; +/* Fields on dword0, common for all commands */
&gt; +#define RISCV_IOMMU_CMD_OPCODE GENMASK_ULL(6, 0)
&gt; +#define        RISCV_IOMMU_CMD_FUNC    GENMASK_ULL(9, 7)
&gt; +
&gt; +/* 3.1.1 I/O MMU Page-table cache invalidation */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_OPCODE                1
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA      0
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_FUNC_GVMA     1
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_AV            BIT_ULL(10)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_PSCID         GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_PSCV          BIT_ULL(32)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_GV            BIT_ULL(33)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_GSCID         GENMASK_ULL(59, 44)
&gt; +/* dword1 is the address, 4K-alligned and shifted to the right by
&gt; + * two bits. */
&gt; +
&gt; +/* 3.1.2 I/O MMU Command Queue Fences */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_OPCODE         2
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_FUNC_C         0
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_AV             BIT_ULL(10)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_WSI            BIT_ULL(11)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_PR             BIT_ULL(12)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_PW             BIT_ULL(13)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_DATA           GENMASK_ULL(63, 32)
&gt; +/* dword1 is the address, word-size alligned and shifted to the
&gt; + * right by two bits. */
&gt; +
&gt; +/* 3.1.3 I/O MMU Directory cache invalidation */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_IODIR_OPCODE           3
&gt; +#define RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT   0
&gt; +#define RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT   1
&gt; +#define RISCV_IOMMU_CMD_IODIR_PID              GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_CMD_IODIR_DV               BIT_ULL(33)
&gt; +#define RISCV_IOMMU_CMD_IODIR_DID              GENMASK_ULL(63, 40)
&gt; +/* dword1 is reserved for standard use */
&gt; +
&gt; +/* 3.1.4 I/O MMU PCIe ATS */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_ATS_OPCODE             4
&gt; +#define RISCV_IOMMU_CMD_ATS_FUNC_INVAL         0
&gt; +#define RISCV_IOMMU_CMD_ATS_FUNC_PRGR          1
&gt; +#define RISCV_IOMMU_CMD_ATS_PID                        GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_CMD_ATS_PV                 BIT_ULL(32)
&gt; +#define RISCV_IOMMU_CMD_ATS_DSV                        BIT_ULL(33)
&gt; +#define RISCV_IOMMU_CMD_ATS_RID                        GENMASK_ULL(55, 40)
&gt; +#define RISCV_IOMMU_CMD_ATS_DSEG               GENMASK_ULL(63, 56)
&gt; +/* dword1 is the ATS payload, two different payload types for INVAL and PRGR */
&gt; +
&gt; +/* ATS.INVAL payload*/
&gt; +#define RISCV_IOMMU_CMD_ATS_INVAL_G            BIT_ULL(0)
&gt; +/* Bits 1 - 10 are zeroed */
&gt; +#define RISCV_IOMMU_CMD_ATS_INVAL_S            BIT_ULL(11)
&gt; +#define RISCV_IOMMU_CMD_ATS_INVAL_UADDR                GENMASK_ULL(63, 12)
&gt; +
&gt; +/* ATS.PRGR payload */
&gt; +/* Bits 0 - 31 are zeroed */
&gt; +#define RISCV_IOMMU_CMD_ATS_PRGR_PRG_INDEX     GENMASK_ULL(40, 32)
&gt; +/* Bits 41 - 43 are zeroed */
&gt; +#define RISCV_IOMMU_CMD_ATS_PRGR_RESP_CODE     GENMASK_ULL(47, 44)
&gt; +#define RISCV_IOMMU_CMD_ATS_PRGR_DST_ID                GENMASK_ULL(63, 48)
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_fq_record - Fault/Event Queue Record
&gt; + * @hdr: Header, includes fault/event cause, PID/DID, transaction type etc
&gt; + * @_reserved: Low 32bits for custom use, high 32bits for standard use
&gt; + * @iotval: Transaction-type/cause specific format
&gt; + * @iotval2: Cause specific format
&gt; + *
&gt; + * The fault/event queue reports events and failures raised when
&gt; + * processing transactions. Each record is a 32byte structure where
&gt; + * the first dword has a fixed format for providing generic infos
&gt; + * regarding the fault/event, and two more dwords are there for
&gt; + * fault/event-specific information. For more details see section
&gt; + * 3.2.
&gt; + */
&gt; +struct riscv_iommu_fq_record {
&gt; +       u64 hdr;
&gt; +       u64 _reserved;
&gt; +       u64 iotval;
&gt; +       u64 iotval2;
&gt; +};
&gt; +
&gt; +/* Fields on header */
&gt; +#define RISCV_IOMMU_FQ_HDR_CAUSE       GENMASK_ULL(11, 0)
&gt; +#define RISCV_IOMMU_FQ_HDR_PID         GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_FQ_HDR_PV          BIT_ULL(32)
&gt; +#define RISCV_IOMMU_FQ_HDR_PRIV                BIT_ULL(33)
&gt; +#define RISCV_IOMMU_FQ_HDR_TTYPE       GENMASK_ULL(39, 34)
&gt; +#define RISCV_IOMMU_FQ_HDR_DID         GENMASK_ULL(63, 40)
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_fq_causes - Fault/event cause values
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT: Instruction access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_ADDR_MISALIGNED: Read address misaligned
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT: Read load fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_ADDR_MISALIGNED: Write/AMO address misaligned
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT: Write/AMO access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT_S: Instruction page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT_S: Read page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT_S: Write/AMO page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT_VS: Instruction guest page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT_VS: Read guest page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT_VS: Write/AMO guest page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DMA_DISABLED: All inbound transactions disallowed
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_LOAD_FAULT: DDT entry load access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_INVALID: DDT entry invalid
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_MISCONFIGURED: DDT entry misconfigured
&gt; + * @RISCV_IOMMU_FQ_CAUSE_TTYPE_BLOCKED: Transaction type disallowed
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_LOAD_FAULT: MSI PTE load access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_INVALID: MSI PTE invalid
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_MISCONFIGURED: MSI PTE misconfigured
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MRIF_FAULT: MRIF access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_LOAD_FAULT: PDT entry load access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_INVALID: PDT entry invalid
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_MISCONFIGURED: PDT entry misconfigured
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_CORRUPTED: DDT data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_CORRUPTED: PDT data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_PT_CORRUPTED: MSI page table data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MRIF_CORRUIPTED: MRIF data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INTERNAL_DP_ERROR: Internal data path error
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_WR_FAULT: IOMMU MSI write access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PT_CORRUPTED: First/second stage page table data corruption
&gt; + *
&gt; + * Values are on table 11 of the spec, encodings 275 - 2047 are reserved for standard
&gt; + * use, and 2048 - 4095 for custom use.
&gt; + */
&gt; +enum riscv_iommu_fq_causes {
&gt; +       RISCV_IOMMU_FQ_CAUSE_INST_FAULT = 1,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_ADDR_MISALIGNED = 4,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_FAULT = 5,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_ADDR_MISALIGNED = 6,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_FAULT = 7,
&gt; +       RISCV_IOMMU_FQ_CAUSE_INST_FAULT_S = 12,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_FAULT_S = 13,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_FAULT_S = 15,
&gt; +       RISCV_IOMMU_FQ_CAUSE_INST_FAULT_VS = 20,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_FAULT_VS = 21,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_FAULT_VS = 23,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DMA_DISABLED = 256,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_LOAD_FAULT = 257,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_INVALID = 258,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_MISCONFIGURED = 259,
&gt; +       RISCV_IOMMU_FQ_CAUSE_TTYPE_BLOCKED = 260,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_LOAD_FAULT = 261,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_INVALID = 262,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_MISCONFIGURED = 263,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MRIF_FAULT = 264,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_LOAD_FAULT = 265,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_INVALID = 266,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_MISCONFIGURED = 267,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_CORRUPTED = 268,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_CORRUPTED = 269,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_PT_CORRUPTED = 270,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MRIF_CORRUIPTED = 271,
&gt; +       RISCV_IOMMU_FQ_CAUSE_INTERNAL_DP_ERROR = 272,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_WR_FAULT = 273,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PT_CORRUPTED = 274
&gt; +};
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_fq_ttypes: Fault/event transaction types
&gt; + * @RISCV_IOMMU_FQ_TTYPE_NONE: None. Fault not caused by an inbound transaction.
&gt; + * @RISCV_IOMMU_FQ_TTYPE_UADDR_INST_FETCH: Instruction fetch from untranslated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_UADDR_RD: Read from untranslated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_UADDR_WR: Write/AMO to untranslated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_TADDR_INST_FETCH: Instruction fetch from translated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_TADDR_RD: Read from translated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_TADDR_WR: Write/AMO to translated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_PCIE_ATS_REQ: PCIe ATS translation request
&gt; + * @RISCV_IOMMU_FW_TTYPE_PCIE_MSG_REQ: PCIe message request
&gt; + *
&gt; + * Values are on table 12 of the spec, type 4 and 10 - 31 are reserved for standard use
&gt; + * and 31 - 63 for custom use.
&gt; + */
&gt; +enum riscv_iommu_fq_ttypes {
&gt; +       RISCV_IOMMU_FQ_TTYPE_NONE = 0,
&gt; +       RISCV_IOMMU_FQ_TTYPE_UADDR_INST_FETCH = 1,
&gt; +       RISCV_IOMMU_FQ_TTYPE_UADDR_RD = 2,
&gt; +       RISCV_IOMMU_FQ_TTYPE_UADDR_WR = 3,
&gt; +       RISCV_IOMMU_FQ_TTYPE_TADDR_INST_FETCH = 5,
&gt; +       RISCV_IOMMU_FQ_TTYPE_TADDR_RD = 6,
&gt; +       RISCV_IOMMU_FQ_TTYPE_TADDR_WR = 7,
&gt; +       RISCV_IOMMU_FQ_TTYPE_PCIE_ATS_REQ = 8,
&gt; +       RISCV_IOMMU_FW_TTYPE_PCIE_MSG_REQ = 9,
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_pq_record - PCIe Page Request record
&gt; + * @hdr: Header, includes PID, DID etc
&gt; + * @payload: Holds the page address, request group and permission bits
&gt; + *
&gt; + * For more infos on the PCIe Page Request queue see chapter 3.3.
&gt; + */
&gt; +struct riscv_iommu_pq_record {
&gt; +       u64 hdr;
&gt; +       u64 payload;
&gt; +};
&gt; +
&gt; +/* Header fields */
&gt; +#define RISCV_IOMMU_PREQ_HDR_PID       GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_PREQ_HDR_PV                BIT_ULL(32)
&gt; +#define RISCV_IOMMU_PREQ_HDR_PRIV      BIT_ULL(33)
&gt; +#define RISCV_IOMMU_PREQ_HDR_EXEC      BIT_ULL(34)
&gt; +#define RISCV_IOMMU_PREQ_HDR_DID       GENMASK_ULL(63, 40)
&gt; +
&gt; +/* Payload fields */
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_R     BIT_ULL(0)
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_W     BIT_ULL(1)
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_L     BIT_ULL(2)
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_M     GENMASK_ULL(2, 0)       /* Mask of RWL for convenience */
&gt; +#define RISCV_IOMMU_PREQ_PRG_INDEX     GENMASK_ULL(11, 3)
&gt; +#define RISCV_IOMMU_PREQ_UADDR         GENMASK_ULL(63, 12)
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_msi_pte - MSI Page Table Entry
&gt; + * @pte: MSI PTE
&gt; + * @mrif_info: Memory-resident interrupt file info
&gt; + *
&gt; + * The MSI Page Table is used for virtualizing MSIs, so that when
&gt; + * a device sends an MSI to a guest, the IOMMU can reroute it
&gt; + * by translating the MSI address, either to a guest interrupt file
&gt; + * or a memory resident interrupt file (MRIF). Note that this page table
&gt; + * is an array of MSI PTEs, not a multi-level pt, each entry
&gt; + * is a leaf entry. For more infos check out the the AIA spec, chapter 9.5.
&gt; + *
&gt; + * Also in basic mode the mrif_info field is ignored by the IOMMU and can
&gt; + * be used by software, any other reserved fields on pte must be zeroed-out
&gt; + * by software.
&gt; + */
&gt; +struct riscv_iommu_msi_pte {
&gt; +       u64 pte;
&gt; +       u64 mrif_info;
&gt; +};
&gt; +
&gt; +/* Fields on pte */
&gt; +#define RISCV_IOMMU_MSI_PTE_V          BIT_ULL(0)
&gt; +#define RISCV_IOMMU_MSI_PTE_M          GENMASK_ULL(2, 1)
&gt; +#define RISCV_IOMMU_MSI_PTE_MRIF_ADDR  GENMASK_ULL(53, 7)      /* When M == 1 (MRIF mode) */
&gt; +#define RISCV_IOMMU_MSI_PTE_PPN                RISCV_IOMMU_PPN_FIELD   /* When M == 3 (basic mode) */
&gt; +#define RISCV_IOMMU_MSI_PTE_C          BIT_ULL(63)
&gt; +
&gt; +/* Fields on mrif_info */
&gt; +#define RISCV_IOMMU_MSI_MRIF_NID       GENMASK_ULL(9, 0)
&gt; +#define RISCV_IOMMU_MSI_MRIF_NPPN      RISCV_IOMMU_PPN_FIELD
&gt; +#define RISCV_IOMMU_MSI_MRIF_NID_MSB   BIT_ULL(60)
&gt; +
&gt; +#endif /* _RISCV_IOMMU_BITS_H_ */
&gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; new file mode 100644
&gt; index 000000000000..c91f963d7a29
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; @@ -0,0 +1,134 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * RISCV IOMMU as a PCIe device
&gt; + *
&gt; + * Authors
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/compiler.h&gt;
&gt; +#include &lt;linux/pci.h&gt;
&gt; +#include &lt;linux/init.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +
&gt; +#include "iommu.h"
&gt; +
&gt; +/* Rivos Inc. assigned PCI Vendor and Device IDs */
&gt; +#ifndef PCI_VENDOR_ID_RIVOS
&gt; +#define PCI_VENDOR_ID_RIVOS             0x1efd
&gt; +#endif
&gt; +
&gt; +#ifndef PCI_DEVICE_ID_RIVOS_IOMMU
&gt; +#define PCI_DEVICE_ID_RIVOS_IOMMU       0xedf1
&gt; +#endif
&gt; +
&gt; +static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
&gt; +{
&gt; +       struct device *dev = &amp;pdev-&gt;dev;
&gt; +       struct riscv_iommu_device *iommu;
&gt; +       int ret;
&gt; +
&gt; +       ret = pci_enable_device_mem(pdev);
&gt; +       if (ret &lt; 0)
&gt; +               return ret;
&gt; +
&gt; +       ret = pci_request_mem_regions(pdev, KBUILD_MODNAME);
&gt; +       if (ret &lt; 0)
&gt; +               goto fail;
&gt; +
&gt; +       ret = -ENOMEM;
&gt; +
&gt; +       iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; +       if (!iommu)
&gt; +               goto fail;
&gt; +
&gt; +       if (!(pci_resource_flags(pdev, 0) &amp; IORESOURCE_MEM))
&gt; +               goto fail;
&gt; +
&gt; +       if (pci_resource_len(pdev, 0) &lt; RISCV_IOMMU_REG_SIZE)
&gt; +               goto fail;
&gt; +
&gt; +       iommu-&gt;reg_phys = pci_resource_start(pdev, 0);
&gt; +       if (!iommu-&gt;reg_phys)
&gt; +               goto fail;
&gt; +
&gt; +       iommu-&gt;reg = devm_ioremap(dev, iommu-&gt;reg_phys, RISCV_IOMMU_REG_SIZE);
&gt; +       if (!iommu-&gt;reg)
&gt; +               goto fail;
&gt; +
&gt; +       iommu-&gt;dev = dev;
&gt; +       dev_set_drvdata(dev, iommu);
&gt; +
&gt; +       dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
&gt; +       pci_set_master(pdev);
&gt; +
&gt; +       ret = riscv_iommu_init(iommu);
&gt; +       if (!ret)
&gt; +               return ret;
&gt; +
&gt; + fail:
&gt; +       pci_clear_master(pdev);
&gt; +       pci_release_regions(pdev);
&gt; +       pci_disable_device(pdev);
&gt; +       /* Note: devres_release_all() will release iommu and iommu-&gt;reg */
&gt; +       return ret;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_pci_remove(struct pci_dev *pdev)
&gt; +{
&gt; +       riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +       pci_clear_master(pdev);
&gt; +       pci_release_regions(pdev);
&gt; +       pci_disable_device(pdev);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_suspend(struct device *dev)
&gt; +{
&gt; +       dev_warn(dev, "RISC-V IOMMU PM not implemented");
&gt; +       return -ENODEV;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_resume(struct device *dev)
&gt; +{
&gt; +       dev_warn(dev, "RISC-V IOMMU PM not implemented");
&gt; +       return -ENODEV;
&gt; +}
&gt; +
&gt; +static DEFINE_SIMPLE_DEV_PM_OPS(riscv_iommu_pm_ops, riscv_iommu_suspend,
&gt; +                               riscv_iommu_resume);
&gt; +
&gt; +static const struct pci_device_id riscv_iommu_pci_tbl[] = {
&gt; +       {PCI_VENDOR_ID_RIVOS, PCI_DEVICE_ID_RIVOS_IOMMU,
&gt; +        PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0},
&gt; +       {0,}
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(pci, riscv_iommu_pci_tbl);
&gt; +
&gt; +static const struct of_device_id riscv_iommu_of_match[] = {
&gt; +       {.compatible = "riscv,pci-iommu",},
&gt; +       {},
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
&gt; +
&gt; +static struct pci_driver riscv_iommu_pci_driver = {
&gt; +       .name = KBUILD_MODNAME,
&gt; +       .id_table = riscv_iommu_pci_tbl,
&gt; +       .probe = riscv_iommu_pci_probe,
&gt; +       .remove = riscv_iommu_pci_remove,
&gt; +       .driver = {
&gt; +                  .pm = pm_sleep_ptr(&amp;riscv_iommu_pm_ops),
&gt; +                  .of_match_table = riscv_iommu_of_match,
&gt; +                  },
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_pci_driver, pci_register_driver, pci_unregister_driver);
&gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; new file mode 100644
&gt; index 000000000000..e4e8ca6711e7
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; @@ -0,0 +1,94 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * RISC-V IOMMU as a platform device
&gt; + *
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * Author: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/of_platform.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +
&gt; +#include "iommu-bits.h"
&gt; +#include "iommu.h"
&gt; +
&gt; +static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; +{
&gt; +       struct device *dev = &amp;pdev-&gt;dev;
&gt; +       struct riscv_iommu_device *iommu = NULL;
&gt; +       struct resource *res = NULL;
&gt; +       int ret = 0;
&gt; +
&gt; +       iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; +       if (!iommu)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       iommu-&gt;dev = dev;
&gt; +       dev_set_drvdata(dev, iommu);
&gt; +
&gt; +       res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
&gt; +       if (!res) {
&gt; +               dev_err(dev, "could not find resource for register region\n");
&gt; +               return -EINVAL;
&gt; +       }
&gt; +
&gt; +       iommu-&gt;reg = devm_platform_get_and_ioremap_resource(pdev, 0, &amp;res);
&gt; +       if (IS_ERR(iommu-&gt;reg)) {
&gt; +               ret = dev_err_probe(dev, PTR_ERR(iommu-&gt;reg),
&gt; +                                   "could not map register region\n");
&gt; +               goto fail;
&gt; +       };
&gt; +
&gt; +       iommu-&gt;reg_phys = res-&gt;start;
&gt; +
&gt; +       ret = -ENODEV;
&gt; +
&gt; +       /* Sanity check: Did we get the whole register space ? */
&gt; +       if ((res-&gt;end - res-&gt;start + 1) &lt; RISCV_IOMMU_REG_SIZE) {
&gt; +               dev_err(dev, "device region smaller than register file (0x%llx)\n",
&gt; +                       res-&gt;end - res-&gt;start);
&gt; +               goto fail;
&gt; +       }
</span>
Could we assume that DT should be responsible for specifying the right size?

<span class=q>&gt; +
&gt; +       dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; +
&gt; +       return riscv_iommu_init(iommu);
&gt; +
&gt; + fail:
&gt; +       /* Note: devres_release_all() will release iommu and iommu-&gt;reg */
&gt; +       return ret;
&gt; +};
&gt; +
&gt; +static void riscv_iommu_platform_remove(struct platform_device *pdev)
&gt; +{
&gt; +       riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +};
&gt; +
&gt; +static void riscv_iommu_platform_shutdown(struct platform_device *pdev)
&gt; +{
&gt; +       return;
&gt; +};
&gt; +
&gt; +static const struct of_device_id riscv_iommu_of_match[] = {
&gt; +       {.compatible = "riscv,iommu",},
&gt; +       {},
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
&gt; +
&gt; +static struct platform_driver riscv_iommu_platform_driver = {
&gt; +       .driver = {
&gt; +                  .name = "riscv,iommu",
&gt; +                  .of_match_table = riscv_iommu_of_match,
&gt; +                  .suppress_bind_attrs = true,
&gt; +                  },
&gt; +       .probe = riscv_iommu_platform_probe,
&gt; +       .remove_new = riscv_iommu_platform_remove,
&gt; +       .shutdown = riscv_iommu_platform_shutdown,
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_platform_driver, platform_driver_register,
&gt; +             platform_driver_unregister);
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; new file mode 100644
&gt; index 000000000000..8c236242e2cc
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -0,0 +1,660 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * IOMMU API for RISC-V architected Ziommu implementations.
&gt; + *
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * Authors
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
&gt; +
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/compiler.h&gt;
&gt; +#include &lt;linux/pci.h&gt;
&gt; +#include &lt;linux/pci-ats.h&gt;
&gt; +#include &lt;linux/init.h&gt;
&gt; +#include &lt;linux/completion.h&gt;
&gt; +#include &lt;linux/uaccess.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/irqdomain.h&gt;
&gt; +#include &lt;linux/platform_device.h&gt;
&gt; +#include &lt;linux/dma-map-ops.h&gt;
&gt; +#include &lt;asm/page.h&gt;
&gt; +
&gt; +#include "../dma-iommu.h"
&gt; +#include "../iommu-sva.h"
&gt; +#include "iommu.h"
&gt; +
&gt; +#include &lt;asm/csr.h&gt;
&gt; +#include &lt;asm/delay.h&gt;
&gt; +
&gt; +MODULE_DESCRIPTION("IOMMU driver for RISC-V architected Ziommu implementations");
&gt; +MODULE_AUTHOR("Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;");
&gt; +MODULE_AUTHOR("Nick Kossifidis &lt;mick@ics.forth.gr&gt;");
&gt; +MODULE_ALIAS("riscv-iommu");
&gt; +MODULE_LICENSE("GPL v2");
&gt; +
&gt; +/* Global IOMMU params. */
&gt; +static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt; +module_param(ddt_mode, int, 0644);
&gt; +MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt; +
&gt; +/* IOMMU PSCID allocation namespace. */
&gt; +#define RISCV_IOMMU_MAX_PSCID  (1U &lt;&lt; 20)
&gt; +static DEFINE_IDA(riscv_iommu_pscids);
&gt; +
&gt; +/* 1 second */
&gt; +#define RISCV_IOMMU_TIMEOUT    riscv_timebase
&gt; +
&gt; +/* RISC-V IOMMU PPN &lt;&gt; PHYS address conversions, PHYS &lt;=&gt; PPN[53:10] */
&gt; +#define phys_to_ppn(va)  (((va) &gt;&gt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 10))
&gt; +#define ppn_to_phys(pn)         (((pn) &lt;&lt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 12))
&gt; +
&gt; +#define iommu_domain_to_riscv(iommu_domain) \
&gt; +    container_of(iommu_domain, struct riscv_iommu_domain, domain)
&gt; +
&gt; +#define iommu_device_to_riscv(iommu_device) \
&gt; +    container_of(iommu_device, struct riscv_iommu, iommu)
&gt; +
&gt; +static const struct iommu_domain_ops riscv_iommu_domain_ops;
&gt; +static const struct iommu_ops riscv_iommu_ops;
&gt; +
&gt; +/*
&gt; + * Register device for IOMMU tracking.
&gt; + */
&gt; +static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_endpoint *ep, *rb_ep;
&gt; +       struct rb_node **new_node, *parent_node = NULL;
&gt; +
&gt; +       mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +       new_node = &amp;(iommu-&gt;eps.rb_node);
&gt; +       while (*new_node) {
&gt; +               rb_ep = rb_entry(*new_node, struct riscv_iommu_endpoint, node);
&gt; +               parent_node = *new_node;
&gt; +               if (rb_ep-&gt;devid &gt; ep-&gt;devid) {
&gt; +                       new_node = &amp;((*new_node)-&gt;rb_left);
&gt; +               } else if (rb_ep-&gt;devid &lt; ep-&gt;devid) {
&gt; +                       new_node = &amp;((*new_node)-&gt;rb_right);
&gt; +               } else {
&gt; +                       dev_warn(dev, "device %u already in the tree\n", ep-&gt;devid);
&gt; +                       break;
&gt; +               }
&gt; +       }
&gt; +
&gt; +       rb_link_node(&amp;ep-&gt;node, parent_node, new_node);
&gt; +       rb_insert_color(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; +
&gt; +       mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; +}
&gt; +
&gt; +/*
&gt; + * Endpoint management
&gt; + */
&gt; +
&gt; +static int riscv_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)
&gt; +{
&gt; +       return iommu_fwspec_add_ids(dev, args-&gt;args, 1);
&gt; +}
&gt; +
&gt; +static bool riscv_iommu_capable(struct device *dev, enum iommu_cap cap)
&gt; +{
&gt; +       switch (cap) {
&gt; +       case IOMMU_CAP_CACHE_COHERENCY:
&gt; +       case IOMMU_CAP_PRE_BOOT_PROTECTION:
&gt; +               return true;
&gt; +
&gt; +       default:
&gt; +               break;
&gt; +       }
&gt; +
&gt; +       return false;
&gt; +}
&gt; +
&gt; +static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_device *iommu;
&gt; +       struct riscv_iommu_endpoint *ep;
&gt; +       struct iommu_fwspec *fwspec;
&gt; +
&gt; +       fwspec = dev_iommu_fwspec_get(dev);
&gt; +       if (!fwspec || fwspec-&gt;ops != &amp;riscv_iommu_ops ||
&gt; +           !fwspec-&gt;iommu_fwnode || !fwspec-&gt;iommu_fwnode-&gt;dev)
&gt; +               return ERR_PTR(-ENODEV);
&gt; +
&gt; +       iommu = dev_get_drvdata(fwspec-&gt;iommu_fwnode-&gt;dev);
&gt; +       if (!iommu)
&gt; +               return ERR_PTR(-ENODEV);
&gt; +
&gt; +       if (dev_iommu_priv_get(dev))
&gt; +               return &amp;iommu-&gt;iommu;
&gt; +
&gt; +       ep = kzalloc(sizeof(*ep), GFP_KERNEL);
&gt; +       if (!ep)
&gt; +               return ERR_PTR(-ENOMEM);
&gt; +
&gt; +       mutex_init(&amp;ep-&gt;lock);
&gt; +       INIT_LIST_HEAD(&amp;ep-&gt;domain);
&gt; +
&gt; +       if (dev_is_pci(dev)) {
&gt; +               ep-&gt;devid = pci_dev_id(to_pci_dev(dev));
&gt; +               ep-&gt;domid = pci_domain_nr(to_pci_dev(dev)-&gt;bus);
&gt; +       } else {
&gt; +               /* TODO: Make this generic, for now hardcode domain id to 0 */
&gt; +               ep-&gt;devid = fwspec-&gt;ids[0];
&gt; +               ep-&gt;domid = 0;
&gt; +       }
&gt; +
&gt; +       ep-&gt;iommu = iommu;
&gt; +       ep-&gt;dev = dev;
&gt; +
&gt; +       dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt; +               ep-&gt;devid, ep-&gt;domid);
&gt; +
&gt; +       dev_iommu_priv_set(dev, ep);
&gt; +       riscv_iommu_add_device(iommu, dev);
&gt; +
&gt; +       return &amp;iommu-&gt;iommu;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_probe_finalize(struct device *dev)
&gt; +{
&gt; +       set_dma_ops(dev, NULL);
&gt; +       iommu_setup_dma_ops(dev, 0, U64_MAX);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_release_device(struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +       struct riscv_iommu_device *iommu = ep-&gt;iommu;
&gt; +
&gt; +       dev_info(dev, "device with devid %i released\n", ep-&gt;devid);
&gt; +
&gt; +       mutex_lock(&amp;ep-&gt;lock);
&gt; +       list_del(&amp;ep-&gt;domain);
&gt; +       mutex_unlock(&amp;ep-&gt;lock);
&gt; +
&gt; +       /* Remove endpoint from IOMMU tracking structures */
&gt; +       mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt; +       rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; +       mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       set_dma_ops(dev, NULL);
&gt; +       dev_iommu_priv_set(dev, NULL);
&gt; +
&gt; +       kfree(ep);
&gt; +}
&gt; +
&gt; +static struct iommu_group *riscv_iommu_device_group(struct device *dev)
&gt; +{
&gt; +       if (dev_is_pci(dev))
&gt; +               return pci_device_group(dev);
&gt; +       return generic_device_group(dev);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_get_resv_regions(struct device *dev, struct list_head *head)
&gt; +{
&gt; +       iommu_dma_get_resv_regions(dev, head);
&gt; +}
&gt; +
&gt; +/*
&gt; + * Domain management
&gt; + */
&gt; +
&gt; +static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain;
&gt; +
&gt; +       if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_BLOCKED)
&gt; +               return NULL;
&gt; +
&gt; +       domain = kzalloc(sizeof(*domain), GFP_KERNEL);
&gt; +       if (!domain)
&gt; +               return NULL;
&gt; +
&gt; +       mutex_init(&amp;domain-&gt;lock);
&gt; +       INIT_LIST_HEAD(&amp;domain-&gt;endpoints);
&gt; +
&gt; +       domain-&gt;domain.ops = &amp;riscv_iommu_domain_ops;
&gt; +       domain-&gt;mode = RISCV_IOMMU_DC_FSC_MODE_BARE;
&gt; +       domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt; +                                       RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
&gt; +
&gt; +       printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; +
</span>
Could it uses pr_xxx instead of printk?

<span class=q>&gt; +       return &amp;domain-&gt;domain;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (!list_empty(&amp;domain-&gt;endpoints)) {
&gt; +               pr_warn("IOMMU domain is not empty!\n");
&gt; +       }
&gt; +
&gt; +       if (domain-&gt;pgd_root)
&gt; +               free_pages((unsigned long)domain-&gt;pgd_root, 0);
&gt; +
&gt; +       if ((int)domain-&gt;pscid &gt; 0)
&gt; +               ida_free(&amp;riscv_iommu_pscids, domain-&gt;pscid);
&gt; +
&gt; +       printk("domain free %u\n", domain-&gt;pscid);
&gt; +
</span>
Could it uses pr_xxx instead of printk?

<span class=q>&gt; +       kfree(domain);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt; +                                      struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       struct iommu_domain_geometry *geometry;
&gt; +
&gt; +       /* Domain assigned to another iommu */
&gt; +       if (domain-&gt;iommu &amp;&amp; domain-&gt;iommu != iommu)
&gt; +               return -EINVAL;
&gt; +       /* Domain already initialized */
&gt; +       else if (domain-&gt;iommu)
&gt; +               return 0;
&gt; +
&gt; +       /*
&gt; +        * TODO: Before using VA_BITS and satp_mode here, verify they
&gt; +        * are supported by the iommu, through the capabilities register.
&gt; +        */
&gt; +
&gt; +       geometry = &amp;domain-&gt;domain.geometry;
&gt; +
&gt; +       /*
&gt; +        * Note: RISC-V Privilege spec mandates that virtual addresses
&gt; +        * need to be sign-extended, so if (VA_BITS - 1) is set, all
&gt; +        * bits &gt;= VA_BITS need to also be set or else we'll get a
&gt; +        * page fault. However the code that creates the mappings
&gt; +        * above us (e.g. iommu_dma_alloc_iova()) won't do that for us
&gt; +        * for now, so we'll end up with invalid virtual addresses
&gt; +        * to map. As a workaround until we get this sorted out
&gt; +        * limit the available virtual addresses to VA_BITS - 1.
&gt; +        */
&gt; +       geometry-&gt;aperture_start = 0;
&gt; +       geometry-&gt;aperture_end = DMA_BIT_MASK(VA_BITS - 1);
&gt; +       geometry-&gt;force_aperture = true;
&gt; +
&gt; +       domain-&gt;iommu = iommu;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return 0;
&gt; +
&gt; +       /* TODO: Fix this for RV32 */
&gt; +       domain-&gt;mode = satp_mode &gt;&gt; 60;
&gt; +       domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO, 0);
&gt; +
&gt; +       if (!domain-&gt;pgd_root)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +       int ret;
&gt; +
&gt; +       /* PSCID not valid */
&gt; +       if ((int)domain-&gt;pscid &lt; 0)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       mutex_lock(&amp;domain-&gt;lock);
&gt; +       mutex_lock(&amp;ep-&gt;lock);
&gt; +
&gt; +       if (!list_empty(&amp;ep-&gt;domain)) {
&gt; +               dev_warn(dev, "endpoint already attached to a domain. dropping\n");
&gt; +               list_del_init(&amp;ep-&gt;domain);
&gt; +       }
&gt; +
&gt; +       /* allocate root pages, initialize io-pgtable ops, etc. */
&gt; +       ret = riscv_iommu_domain_finalize(domain, ep-&gt;iommu);
&gt; +       if (ret &lt; 0) {
&gt; +               dev_err(dev, "can not finalize domain: %d\n", ret);
&gt; +               mutex_unlock(&amp;ep-&gt;lock);
&gt; +               mutex_unlock(&amp;domain-&gt;lock);
&gt; +               return ret;
&gt; +       }
&gt; +
&gt; +       if (ep-&gt;iommu-&gt;ddt_mode != RISCV_IOMMU_DDTP_MODE_BARE ||
&gt; +           domain-&gt;domain.type != IOMMU_DOMAIN_IDENTITY) {
&gt; +               dev_warn(dev, "domain type %d not supported\n",
&gt; +                   domain-&gt;domain.type);
&gt; +               return -ENODEV;
&gt; +       }
&gt; +
&gt; +       list_add_tail(&amp;ep-&gt;domain, &amp;domain-&gt;endpoints);
&gt; +       mutex_unlock(&amp;ep-&gt;lock);
&gt; +       mutex_unlock(&amp;domain-&gt;lock);
&gt; +
&gt; +       dev_info(dev, "domain type %d attached w/ PSCID %u\n",
&gt; +           domain-&gt;domain.type, domain-&gt;pscid);
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt; +                                         unsigned long *start, unsigned long *end,
&gt; +                                         size_t *pgsize)
&gt; +{
&gt; +       /* Command interface not implemented */
&gt; +}
&gt; +
&gt; +static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; +{
&gt; +       riscv_iommu_flush_iotlb_range(iommu_domain, NULL, NULL, NULL);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_iotlb_sync(struct iommu_domain *iommu_domain,
&gt; +                                  struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +       riscv_iommu_flush_iotlb_range(iommu_domain, &amp;gather-&gt;start, &amp;gather-&gt;end,
&gt; +                                     &amp;gather-&gt;pgsize);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_iotlb_sync_map(struct iommu_domain *iommu_domain,
&gt; +                                      unsigned long iova, size_t size)
&gt; +{
&gt; +       unsigned long end = iova + size - 1;
&gt; +       /*
&gt; +        * Given we don't know the page size used by this range, we assume the
&gt; +        * smallest page size to ensure all possible entries are flushed from
&gt; +        * the IOATC.
&gt; +        */
&gt; +       size_t pgsize = PAGE_SIZE;
&gt; +       riscv_iommu_flush_iotlb_range(iommu_domain, &amp;iova, &amp;end, &amp;pgsize);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
&gt; +                                unsigned long iova, phys_addr_t phys,
&gt; +                                size_t pgsize, size_t pgcount, int prot,
&gt; +                                gfp_t gfp, size_t *mapped)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; +               *mapped = pgsize * pgcount;
&gt; +               return 0;
&gt; +       }
&gt; +
&gt; +       return -ENODEV;
&gt; +}
&gt; +
&gt; +static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt; +                                     unsigned long iova, size_t pgsize,
&gt; +                                     size_t pgcount, struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return pgsize * pgcount;
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt; +                                           dma_addr_t iova)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return (phys_addr_t) iova;
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Translation mode setup
&gt; + */
&gt; +
&gt; +static u64 riscv_iommu_get_ddtp(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       u64 ddtp;
&gt; +       cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
&gt; +
&gt; +       /* Wait for DDTP.BUSY to be cleared and return latest value */
&gt; +       do {
&gt; +               ddtp = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_DDTP);
&gt; +               if (!(ddtp &amp; RISCV_IOMMU_DDTP_BUSY))
&gt; +                       break;
&gt; +               cpu_relax();
&gt; +       } while (get_cycles() &lt; end_cycles);
&gt; +
&gt; +       return ddtp;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_ddt_cleanup(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       /* TODO: teardown whole device directory tree. */
&gt; +       if (iommu-&gt;ddtp) {
&gt; +               if (iommu-&gt;ddtp_in_iomem) {
&gt; +                       iounmap((void *)iommu-&gt;ddtp);
&gt; +               } else
&gt; +                       free_page(iommu-&gt;ddtp);
&gt; +               iommu-&gt;ddtp = 0;
&gt; +       }
&gt; +}
&gt; +
&gt; +static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned requested_mode)
&gt; +{
&gt; +       struct device *dev = iommu-&gt;dev;
&gt; +       u64 ddtp = 0;
&gt; +       u64 ddtp_paddr = 0;
&gt; +       unsigned mode = requested_mode;
&gt; +       unsigned mode_readback = 0;
&gt; +
&gt; +       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +       if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY)
&gt; +               return -EBUSY;
&gt; +
&gt; +       /* Disallow state transtion from xLVL to xLVL. */
&gt; +       switch (FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp)) {
&gt; +       case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; +       case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; +               break;
&gt; +       default:
&gt; +               if ((mode != RISCV_IOMMU_DDTP_MODE_BARE)
&gt; +                   &amp;&amp; (mode != RISCV_IOMMU_DDTP_MODE_OFF))
&gt; +                       return -EINVAL;
&gt; +               break;
&gt; +       }
&gt; +
&gt; + retry:
</span>
We need to consider the `iommu.passthrough` before we set up the mode
in switch case, something like

if (iommu_default_passthrough()) {
        /* set ddtp to bare mode */
}

<span class=q>&gt; +       switch (mode) {
&gt; +       case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; +       case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; +               riscv_iommu_ddt_cleanup(iommu);
&gt; +               ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode);
&gt; +               break;
&gt; +       case RISCV_IOMMU_DDTP_MODE_1LVL:
&gt; +       case RISCV_IOMMU_DDTP_MODE_2LVL:
&gt; +       case RISCV_IOMMU_DDTP_MODE_3LVL:
&gt; +               if (!iommu-&gt;ddtp) {
&gt; +                       /*
&gt; +                        * We haven't initialized ddtp yet, since it's WARL make
&gt; +                        * sure that we don't have a hardwired PPN field there
&gt; +                        * that points to i/o memory instead.
&gt; +                        */
&gt; +                       riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, 0);
&gt; +                       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +                       ddtp_paddr = ppn_to_phys(ddtp);
&gt; +                       if (ddtp_paddr) {
&gt; +                               dev_warn(dev, "ddtp at 0x%llx\n", ddtp_paddr);
&gt; +                               iommu-&gt;ddtp =
&gt; +                                   (unsigned long)ioremap(ddtp_paddr, PAGE_SIZE);
&gt; +                               iommu-&gt;ddtp_in_iomem = true;
&gt; +                       } else {
&gt; +                               iommu-&gt;ddtp = get_zeroed_page(GFP_KERNEL);
&gt; +                       }
&gt; +               }
&gt; +               if (!iommu-&gt;ddtp)
&gt; +                       return -ENOMEM;
&gt; +
&gt; +               ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode) |
&gt; +                   phys_to_ppn(__pa(iommu-&gt;ddtp));
&gt; +
&gt; +               break;
&gt; +       default:
&gt; +               return -EINVAL;
&gt; +       }
&gt; +
&gt; +       riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, ddtp);
&gt; +       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +       if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY) {
&gt; +               dev_warn(dev, "timeout when setting ddtp (ddt mode: %i)\n", mode);
&gt; +               return -EBUSY;
&gt; +       }
&gt; +
&gt; +       mode_readback = FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp);
&gt; +       dev_info(dev, "mode_readback: %i, mode: %i\n", mode_readback, mode);
&gt; +       if (mode_readback != mode) {
&gt; +               /*
&gt; +                * Mode field is WARL, an I/O MMU may support a subset of
&gt; +                * directory table levels in which case if we tried to set
&gt; +                * an unsupported number of levels we'll readback either
&gt; +                * a valid xLVL or off/bare. If we got off/bare, try again
&gt; +                * with a smaller xLVL.
&gt; +                */
&gt; +               if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
&gt; +                   mode &gt; RISCV_IOMMU_DDTP_MODE_1LVL) {
&gt; +                       mode--;
&gt; +                       goto retry;
&gt; +               }
&gt; +
&gt; +               /*
&gt; +                * We tried all supported xLVL modes and still got off/bare instead,
&gt; +                * an I/O MMU must support at least one supported xLVL mode so something
&gt; +                * went very wrong.
&gt; +                */
&gt; +               if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
&gt; +                   mode == RISCV_IOMMU_DDTP_MODE_1LVL)
&gt; +                       goto fail;
&gt; +
&gt; +               /*
&gt; +                * We tried setting off or bare and got something else back, something
&gt; +                * went very wrong since off/bare is always legal.
&gt; +                */
&gt; +               if (mode &lt; RISCV_IOMMU_DDTP_MODE_1LVL)
&gt; +                       goto fail;
&gt; +
&gt; +               /*
&gt; +                * We tried setting an xLVL mode but got another xLVL mode that
&gt; +                * we don't support (e.g. a custom one).
&gt; +                */
&gt; +               if (mode_readback &gt; RISCV_IOMMU_DDTP_MODE_MAX)
&gt; +                       goto fail;
&gt; +
&gt; +               /* We tried setting an xLVL mode but got another supported xLVL mode */
&gt; +               mode = mode_readback;
&gt; +       }
&gt; +
&gt; +       if (mode != requested_mode)
&gt; +               dev_warn(dev, "unsupported DDT mode requested (%i), using %i instead\n",
&gt; +                        requested_mode, mode);
&gt; +
&gt; +       iommu-&gt;ddt_mode = mode;
&gt; +       dev_info(dev, "ddt_mode: %i\n", iommu-&gt;ddt_mode);
&gt; +       return 0;
&gt; +
&gt; + fail:
&gt; +       dev_err(dev, "failed to set DDT mode, tried: %i and got %i\n", mode,
&gt; +               mode_readback);
&gt; +       riscv_iommu_ddt_cleanup(iommu);
&gt; +       return -EINVAL;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Common I/O MMU driver probe/teardown
&gt; + */
&gt; +
&gt; +static const struct iommu_domain_ops riscv_iommu_domain_ops = {
&gt; +       .free = riscv_iommu_domain_free,
&gt; +       .attach_dev = riscv_iommu_attach_dev,
&gt; +       .map_pages = riscv_iommu_map_pages,
&gt; +       .unmap_pages = riscv_iommu_unmap_pages,
&gt; +       .iova_to_phys = riscv_iommu_iova_to_phys,
&gt; +       .iotlb_sync = riscv_iommu_iotlb_sync,
&gt; +       .iotlb_sync_map = riscv_iommu_iotlb_sync_map,
&gt; +       .flush_iotlb_all = riscv_iommu_flush_iotlb_all,
&gt; +};
&gt; +
&gt; +static const struct iommu_ops riscv_iommu_ops = {
&gt; +       .owner = THIS_MODULE,
&gt; +       .pgsize_bitmap = SZ_4K | SZ_2M | SZ_512M,
&gt; +       .capable = riscv_iommu_capable,
&gt; +       .domain_alloc = riscv_iommu_domain_alloc,
&gt; +       .probe_device = riscv_iommu_probe_device,
&gt; +       .probe_finalize = riscv_iommu_probe_finalize,
&gt; +       .release_device = riscv_iommu_release_device,
&gt; +       .device_group = riscv_iommu_device_group,
&gt; +       .get_resv_regions = riscv_iommu_get_resv_regions,
&gt; +       .of_xlate = riscv_iommu_of_xlate,
&gt; +       .default_domain_ops = &amp;riscv_iommu_domain_ops,
&gt; +};
&gt; +
&gt; +void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       iommu_device_unregister(&amp;iommu-&gt;iommu);
&gt; +       riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +}
&gt; +
&gt; +int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       struct device *dev = iommu-&gt;dev;
&gt; +       u32 fctl = 0;
&gt; +       int ret;
&gt; +
&gt; +       iommu-&gt;eps = RB_ROOT;
&gt; +
&gt; +       fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; +
&gt; +#ifdef CONFIG_CPU_BIG_ENDIAN
&gt; +       if (!(cap &amp; RISCV_IOMMU_CAP_END)) {
&gt; +               dev_err(dev, "IOMMU doesn't support Big Endian\n");
&gt; +               return -EIO;
&gt; +       } else if (!(fctl &amp; RISCV_IOMMU_FCTL_BE)) {
&gt; +               fctl |= FIELD_PREP(RISCV_IOMMU_FCTL_BE, 1);
&gt; +               riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; +       }
&gt; +#endif
&gt; +
&gt; +       /* Clear any pending interrupt flag. */
&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt; +                          RISCV_IOMMU_IPSR_CIP |
&gt; +                          RISCV_IOMMU_IPSR_FIP |
&gt; +                          RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt; +       spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt; +       mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt; +
&gt; +       if (ret) {
&gt; +               dev_err(dev, "cannot enable iommu device (%d)\n", ret);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       ret = iommu_device_register(&amp;iommu-&gt;iommu, &amp;riscv_iommu_ops, dev);
&gt; +       if (ret) {
&gt; +               dev_err(dev, "cannot register iommu interface (%d)\n", ret);
&gt; +               iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       return 0;
&gt; + fail:
&gt; +       riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +       return ret;
&gt; +}
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; new file mode 100644
&gt; index 000000000000..7baefd3630b3
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -0,0 +1,115 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * RISC-V Ziommu - IOMMU Interface Specification.
&gt; + *
&gt; + * Authors
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#ifndef _RISCV_IOMMU_H_
&gt; +#define _RISCV_IOMMU_H_
&gt; +
&gt; +#include &lt;linux/types.h&gt;
&gt; +#include &lt;linux/iova.h&gt;
&gt; +#include &lt;linux/io.h&gt;
&gt; +#include &lt;linux/idr.h&gt;
&gt; +#include &lt;linux/list.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/io-pgtable.h&gt;
&gt; +
&gt; +#include "iommu-bits.h"
&gt; +
&gt; +#define IOMMU_PAGE_SIZE_4K     BIT_ULL(12)
&gt; +#define IOMMU_PAGE_SIZE_2M     BIT_ULL(21)
&gt; +#define IOMMU_PAGE_SIZE_1G     BIT_ULL(30)
&gt; +#define IOMMU_PAGE_SIZE_512G   BIT_ULL(39)
&gt; +
&gt; +struct riscv_iommu_device {
&gt; +       struct iommu_device iommu;      /* iommu core interface */
&gt; +       struct device *dev;             /* iommu hardware */
&gt; +
&gt; +       /* hardware control register space */
&gt; +       void __iomem *reg;
&gt; +       resource_size_t reg_phys;
&gt; +
&gt; +       /* IRQs for the various queues */
&gt; +       int irq_cmdq;
&gt; +       int irq_fltq;
&gt; +       int irq_pm;
&gt; +       int irq_priq;
&gt; +
&gt; +       /* supported and enabled hardware capabilities */
&gt; +       u64 cap;
&gt; +
&gt; +       /* global lock, to be removed */
&gt; +       spinlock_t cq_lock;
&gt; +
&gt; +       /* device directory table root pointer and mode */
&gt; +       unsigned long ddtp;
&gt; +       unsigned ddt_mode;
&gt; +       bool ddtp_in_iomem;
&gt; +
&gt; +       /* Connected end-points */
&gt; +       struct rb_root eps;
&gt; +       struct mutex eps_mutex;
&gt; +};
&gt; +
&gt; +struct riscv_iommu_domain {
&gt; +       struct iommu_domain domain;
&gt; +
&gt; +       struct list_head endpoints;
&gt; +       struct mutex lock;
&gt; +       struct riscv_iommu_device *iommu;
&gt; +
&gt; +       unsigned mode;          /* RIO_ATP_MODE_* enum */
&gt; +       unsigned pscid;         /* RISC-V IOMMU PSCID */
&gt; +
&gt; +       pgd_t *pgd_root;        /* page table root pointer */
&gt; +};
&gt; +
&gt; +/* Private dev_iommu_priv object, device-domain relationship. */
&gt; +struct riscv_iommu_endpoint {
&gt; +       struct device *dev;                     /* platform or PCI endpoint device */
&gt; +       unsigned devid;                         /* PCI bus:device:function number */
&gt; +       unsigned domid;                         /* PCI domain number, segment */
&gt; +       struct rb_node node;                    /* device tracking node (lookup by devid) */
&gt; +       struct riscv_iommu_device *iommu;       /* parent iommu device */
&gt; +
&gt; +       struct mutex lock;
&gt; +       struct list_head domain;                /* endpoint attached managed domain */
&gt; +};
&gt; +
&gt; +/* Helper functions and macros */
&gt; +
&gt; +static inline u32 riscv_iommu_readl(struct riscv_iommu_device *iommu,
&gt; +                                   unsigned offset)
&gt; +{
&gt; +       return readl_relaxed(iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_writel(struct riscv_iommu_device *iommu,
&gt; +                                     unsigned offset, u32 val)
&gt; +{
&gt; +       writel_relaxed(val, iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +static inline u64 riscv_iommu_readq(struct riscv_iommu_device *iommu,
&gt; +                                   unsigned offset)
&gt; +{
&gt; +       return readq_relaxed(iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_writeq(struct riscv_iommu_device *iommu,
&gt; +                                     unsigned offset, u64 val)
&gt; +{
&gt; +       writeq_relaxed(val, iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +int riscv_iommu_init(struct riscv_iommu_device *iommu);
&gt; +void riscv_iommu_remove(struct riscv_iommu_device *iommu);
&gt; +
&gt; +#endif
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m522f968d0909aad51fe7e480809ea548917990fa id=e522f968d0909aad51fe7e480809ea548917990fa>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0qRYvTffMnep-aQyTq2tMxbP-s_Lunc+cZ2Rio+BvAE=g@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0qRYvTffMnep-aQyTq2tMxbP-s_Lunc+cZ2Rio+BvAE=g@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0qRYvTffMnep-aQyTq2tMxbP-s_Lunc+cZ2Rio+BvAE=g@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0qRYvTffMnep-aQyTq2tMxbP-s_Lunc+cZ2Rio+BvAE=g@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0qRYvTffMnep-aQyTq2tMxbP-s_Lunc+cZ2Rio+BvAE=g@mail.gmail.com/t/#u">nested</a>] <a href=#r522f968d0909aad51fe7e480809ea548917990fa>86+ messages in thread</a></pre><hr><pre><a href=#e2c22e456fe699f9bda99e7579498d35ce7c66c0b id=m2c22e456fe699f9bda99e7579498d35ce7c66c0b>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-24  9:47       ` <a href=#ma907ef87338b36d71e27c34ee0ef394c7f908811>Zong Li</a>
<b>@ 2023-07-28  5:18         ` Tomasz Jeznach</b>
  2023-07-28  8:48           ` <a href=#m61bdf97d5005e12a7fb847e1df93032acf19cd36>Zong Li</a>
  <a href=#r2c22e456fe699f9bda99e7579498d35ce7c66c0b>0 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-07-28  5:18 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u6TaQ2PLcKRuSpcqh4Q5qUriimSZ1hmmy=37R2378NCUA@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u6TaQ2PLcKRuSpcqh4Q5qUriimSZ1hmmy=37R2378NCUA@mail.gmail.com/raw">raw</a>)
  To: Zong Li
  Cc: Nick Kossifidis, Anup Patel, Albert Ou, linux, Will Deacon,
	Joerg Roedel, <a href="https://lore.kernel.org/lkml/?t=20230728051911">linux-kernel</a>, Sebastien Boeuf, iommu,
	Palmer Dabbelt, Paul Walmsley, <a href="https://lore.kernel.org/linux-riscv/?t=20230728051911">linux-riscv</a>, Robin Murphy

On Mon, Jul 24, 2023 at 11:47 AM Zong Li &lt;zong.li@sifive.com&gt; wrote:
<span class=q>&gt;
&gt; On Fri, Jul 21, 2023 at 2:00 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Wed, Jul 19, 2023 at 8:12 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; Hello Tomasz,
&gt; &gt; &gt;
&gt; &gt; &gt; On 7/19/23 22:33, Tomasz Jeznach wrote:
&gt; &gt; &gt; &gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; The description doesn't match the subject nor the patch content (we
&gt; &gt; &gt; don't jus enable interrupts, we also init the queues).
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; +     /* Parse Queue lengts */
&gt; &gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; &gt; +             dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; &gt; +             dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; &gt; +             dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt;       dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; We need to add those to the device tree binding doc (or throw them away,
&gt; &gt; &gt; I thought it would be better to have them as part of the device
&gt; &gt; &gt; desciption than a module parameter).
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; We can add them as an optional fields to DT.
&gt; &gt; Alternatively, I've been looking into an option to auto-scale CQ/PQ
&gt; &gt; based on number of attached devices, but this gets trickier for
&gt; &gt; hot-pluggable systems. I've added module parameters as a bare-minimum,
&gt; &gt; but still looking for better solutions.
&gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; &gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; +     case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; &gt; &gt; &gt; +             q = &amp;iommu-&gt;priq;
&gt; &gt; &gt; &gt; +             q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; &gt; &gt; &gt; +             count = iommu-&gt;priq_len;
&gt; &gt; &gt; &gt; +             irq = iommu-&gt;irq_priq;
&gt; &gt; &gt; &gt; +             irq_check = riscv_iommu_priq_irq_check;
&gt; &gt; &gt; &gt; +             irq_process = riscv_iommu_priq_process;
&gt; &gt; &gt; &gt; +             q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; &gt; &gt; &gt; +             q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; &gt; &gt; &gt; +             name = "priq";
&gt; &gt; &gt; &gt; +             break;
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; It makes more sense to add the code for the page request queue in the
&gt; &gt; &gt; patch that adds ATS/PRI support IMHO. This comment also applies to its
&gt; &gt; &gt; interrupt handlers below.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; ack. will do.
&gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; &gt; +                                               u64 addr)
&gt; &gt; &gt; &gt; +{
&gt; &gt; &gt; &gt; +     cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; &gt; &gt; &gt; +     cmd-&gt;dword1 = addr;
&gt; &gt; &gt; &gt; +}
&gt; &gt; &gt; &gt; +
&gt; &gt; &gt;
&gt; &gt; &gt; This needs to be (addr &gt;&gt; 2) to match the spec, same as in the iofence
&gt; &gt; &gt; command.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; oops. Thanks!
&gt; &gt;
&gt;
&gt; I think it should be (addr &gt;&gt; 12) according to the spec.
&gt;
</span>
My reading of the spec '3.1.1. IOMMU Page-Table cache invalidation commands'
is that it is a 4k page aligned address packed at dword1[61:10], so
effectively shifted by 2 bits.

regards,
- Tomasz

<span class=q>&gt; &gt; &gt; Regards,
&gt; &gt; &gt; Nick
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; regards,
&gt; &gt; - Tomasz
&gt; &gt;
&gt; &gt; _______________________________________________
&gt; &gt; linux-riscv mailing list
&gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m2c22e456fe699f9bda99e7579498d35ce7c66c0b id=e2c22e456fe699f9bda99e7579498d35ce7c66c0b>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6TaQ2PLcKRuSpcqh4Q5qUriimSZ1hmmy=37R2378NCUA@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6TaQ2PLcKRuSpcqh4Q5qUriimSZ1hmmy=37R2378NCUA@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6TaQ2PLcKRuSpcqh4Q5qUriimSZ1hmmy=37R2378NCUA@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u6TaQ2PLcKRuSpcqh4Q5qUriimSZ1hmmy=37R2378NCUA@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u6TaQ2PLcKRuSpcqh4Q5qUriimSZ1hmmy=37R2378NCUA@mail.gmail.com/t/#u">nested</a>] <a href=#r2c22e456fe699f9bda99e7579498d35ce7c66c0b>86+ messages in thread</a></pre><hr><pre><a href=#e61bdf97d5005e12a7fb847e1df93032acf19cd36 id=m61bdf97d5005e12a7fb847e1df93032acf19cd36>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-28  5:18         ` <a href=#m2c22e456fe699f9bda99e7579498d35ce7c66c0b>Tomasz Jeznach</a>
<b>@ 2023-07-28  8:48           ` Zong Li</b>
  <a href=#r61bdf97d5005e12a7fb847e1df93032acf19cd36>0 siblings, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-07-28  8:48 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0o40cFhVzk=eMuEXrjccSjTuTtdyu5L23bFDpzH5iPdkQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0o40cFhVzk=eMuEXrjccSjTuTtdyu5L23bFDpzH5iPdkQ@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Nick Kossifidis, Anup Patel, Albert Ou, linux, Will Deacon,
	Joerg Roedel, <a href="https://lore.kernel.org/lkml/?t=20230728085030">linux-kernel</a>, Sebastien Boeuf, iommu,
	Palmer Dabbelt, Paul Walmsley, <a href="https://lore.kernel.org/linux-riscv/?t=20230728085030">linux-riscv</a>, Robin Murphy

On Fri, Jul 28, 2023 at 1:19 PM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; On Mon, Jul 24, 2023 at 11:47 AM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Fri, Jul 21, 2023 at 2:00 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; On Wed, Jul 19, 2023 at 8:12 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Hello Tomasz,
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; On 7/19/23 22:33, Tomasz Jeznach wrote:
&gt; &gt; &gt; &gt; &gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; The description doesn't match the subject nor the patch content (we
&gt; &gt; &gt; &gt; don't jus enable interrupts, we also init the queues).
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; +     /* Parse Queue lengts */
&gt; &gt; &gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt; &gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; &gt; &gt; +             dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt; &gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; &gt; &gt; +             dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt; +     ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt; &gt; &gt; &gt; +     if (!ret)
&gt; &gt; &gt; &gt; &gt; +             dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt; &gt;       dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; We need to add those to the device tree binding doc (or throw them away,
&gt; &gt; &gt; &gt; I thought it would be better to have them as part of the device
&gt; &gt; &gt; &gt; desciption than a module parameter).
&gt; &gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; We can add them as an optional fields to DT.
&gt; &gt; &gt; Alternatively, I've been looking into an option to auto-scale CQ/PQ
&gt; &gt; &gt; based on number of attached devices, but this gets trickier for
&gt; &gt; &gt; hot-pluggable systems. I've added module parameters as a bare-minimum,
&gt; &gt; &gt; but still looking for better solutions.
&gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; &gt; &gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; +     case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; &gt; &gt; &gt; &gt; +             q = &amp;iommu-&gt;priq;
&gt; &gt; &gt; &gt; &gt; +             q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; &gt; &gt; &gt; &gt; +             count = iommu-&gt;priq_len;
&gt; &gt; &gt; &gt; &gt; +             irq = iommu-&gt;irq_priq;
&gt; &gt; &gt; &gt; &gt; +             irq_check = riscv_iommu_priq_irq_check;
&gt; &gt; &gt; &gt; &gt; +             irq_process = riscv_iommu_priq_process;
&gt; &gt; &gt; &gt; &gt; +             q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; &gt; &gt; &gt; &gt; +             q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; &gt; &gt; &gt; &gt; +             name = "priq";
&gt; &gt; &gt; &gt; &gt; +             break;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; It makes more sense to add the code for the page request queue in the
&gt; &gt; &gt; &gt; patch that adds ATS/PRI support IMHO. This comment also applies to its
&gt; &gt; &gt; &gt; interrupt handlers below.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; ack. will do.
&gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; &gt; &gt; +                                               u64 addr)
&gt; &gt; &gt; &gt; &gt; +{
&gt; &gt; &gt; &gt; &gt; +     cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; &gt; &gt; &gt; &gt; +     cmd-&gt;dword1 = addr;
&gt; &gt; &gt; &gt; &gt; +}
&gt; &gt; &gt; &gt; &gt; +
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; This needs to be (addr &gt;&gt; 2) to match the spec, same as in the iofence
&gt; &gt; &gt; &gt; command.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; oops. Thanks!
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; I think it should be (addr &gt;&gt; 12) according to the spec.
&gt; &gt;
&gt;
&gt; My reading of the spec '3.1.1. IOMMU Page-Table cache invalidation commands'
&gt; is that it is a 4k page aligned address packed at dword1[61:10], so
&gt; effectively shifted by 2 bits.
</span>
Thanks for your clarifying. Just an opinion, perhaps you can use
'FIELD_PREP()' on it as well, it might be clearer.

<span class=q>&gt;
&gt; regards,
&gt; - Tomasz
&gt;
&gt; &gt; &gt; &gt; Regards,
&gt; &gt; &gt; &gt; Nick
&gt; &gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; regards,
&gt; &gt; &gt; - Tomasz
&gt; &gt; &gt;
&gt; &gt; &gt; _______________________________________________
&gt; &gt; &gt; linux-riscv mailing list
&gt; &gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m61bdf97d5005e12a7fb847e1df93032acf19cd36 id=e61bdf97d5005e12a7fb847e1df93032acf19cd36>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0o40cFhVzk=eMuEXrjccSjTuTtdyu5L23bFDpzH5iPdkQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0o40cFhVzk=eMuEXrjccSjTuTtdyu5L23bFDpzH5iPdkQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0o40cFhVzk=eMuEXrjccSjTuTtdyu5L23bFDpzH5iPdkQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0o40cFhVzk=eMuEXrjccSjTuTtdyu5L23bFDpzH5iPdkQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0o40cFhVzk=eMuEXrjccSjTuTtdyu5L23bFDpzH5iPdkQ@mail.gmail.com/t/#u">nested</a>] <a href=#r61bdf97d5005e12a7fb847e1df93032acf19cd36>86+ messages in thread</a></pre><hr><pre><a href=#e47475dde350a53202c60665ebadd89162dc278d8 id=m47475dde350a53202c60665ebadd89162dc278d8>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-19 19:33 ` <a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</a> Tomasz Jeznach
  2023-07-20  3:11   ` <a href=#me036e876659d5bad1074323224ed7dc70b2e49db>Nick Kossifidis</a>
  2023-07-20 13:08   ` <a href=#m1715001bd807613c4ae6715e3679cf47b74e2a60>Baolu Lu</a>
<b>@ 2023-07-29 12:58   ` Zong Li</b>
  2023-07-31  9:32     ` <a href=#me232eb871eb83c17c7ddecbc7cf02ed18dff1d71>Nick Kossifidis</a>
  2023-08-02 20:50     ` <a href=#m407eda026cd986eb75d1fc2a13fa9e272c24019b>Tomasz Jeznach</a>
  2023-08-16 18:49   ` <a href=#mf18bd90d921132d02c05d7d5894300a045bab960>Robin Murphy</a>
  <a href=#r47475dde350a53202c60665ebadd89162dc278d8>3 siblings, 2 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-07-29 12:58 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0pm+1yXuvUGudwNtvNHWV3FytH4VfCnq7_Ws=t-MZP_kQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0pm+1yXuvUGudwNtvNHWV3FytH4VfCnq7_Ws=t-MZP_kQ@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230729125844">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230729125844">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt;
&gt; Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/riscv/iommu-pci.c      |  72 ++++
&gt;  drivers/iommu/riscv/iommu-platform.c |  66 +++
&gt;  drivers/iommu/riscv/iommu.c          | 604 ++++++++++++++++++++++++++-
&gt;  drivers/iommu/riscv/iommu.h          |  28 ++
&gt;  4 files changed, 769 insertions(+), 1 deletion(-)
&gt;
&gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; index c91f963d7a29..9ea0647f7b92 100644
&gt; --- a/drivers/iommu/riscv/iommu-pci.c
&gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; @@ -34,6 +34,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt;  {
&gt;         struct device *dev = &amp;pdev-&gt;dev;
&gt;         struct riscv_iommu_device *iommu;
&gt; +       u64 icvec;
&gt;         int ret;
&gt;
&gt;         ret = pci_enable_device_mem(pdev);
&gt; @@ -67,14 +68,84 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt;         iommu-&gt;dev = dev;
&gt;         dev_set_drvdata(dev, iommu);
&gt;
&gt; +       /* Check device reported capabilities. */
&gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; +
&gt; +       /* The PCI driver only uses MSIs, make sure the IOMMU supports this */
&gt; +       switch (FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap)) {
&gt; +       case RISCV_IOMMU_CAP_IGS_MSI:
&gt; +       case RISCV_IOMMU_CAP_IGS_BOTH:
&gt; +               break;
&gt; +       default:
&gt; +               dev_err(dev, "unable to use message-signaled interrupts\n");
&gt; +               ret = -ENODEV;
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt;         dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
&gt;         pci_set_master(pdev);
&gt;
&gt; +       /* Allocate and assign IRQ vectors for the various events */
&gt; +       ret = pci_alloc_irq_vectors(pdev, 1, RISCV_IOMMU_INTR_COUNT, PCI_IRQ_MSIX);
&gt; +       if (ret &lt; 0) {
&gt; +               dev_err(dev, "unable to allocate irq vectors\n");
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       ret = -ENODEV;
&gt; +
&gt; +       iommu-&gt;irq_cmdq = msi_get_virq(dev, RISCV_IOMMU_INTR_CQ);
&gt; +       if (!iommu-&gt;irq_cmdq) {
&gt; +               dev_warn(dev, "no MSI vector %d for the command queue\n",
&gt; +                        RISCV_IOMMU_INTR_CQ);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       iommu-&gt;irq_fltq = msi_get_virq(dev, RISCV_IOMMU_INTR_FQ);
&gt; +       if (!iommu-&gt;irq_fltq) {
&gt; +               dev_warn(dev, "no MSI vector %d for the fault/event queue\n",
&gt; +                        RISCV_IOMMU_INTR_FQ);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; +               iommu-&gt;irq_pm = msi_get_virq(dev, RISCV_IOMMU_INTR_PM);
&gt; +               if (!iommu-&gt;irq_pm) {
&gt; +                       dev_warn(dev,
&gt; +                                "no MSI vector %d for performance monitoring\n",
&gt; +                                RISCV_IOMMU_INTR_PM);
&gt; +                       goto fail;
&gt; +               }
&gt; +       }
&gt; +
&gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; +               iommu-&gt;irq_priq = msi_get_virq(dev, RISCV_IOMMU_INTR_PQ);
&gt; +               if (!iommu-&gt;irq_priq) {
&gt; +                       dev_warn(dev,
&gt; +                                "no MSI vector %d for page-request queue\n",
&gt; +                                RISCV_IOMMU_INTR_PQ);
&gt; +                       goto fail;
&gt; +               }
&gt; +       }
&gt; +
&gt; +       /* Set simple 1:1 mapping for MSI vectors */
&gt; +       icvec = FIELD_PREP(RISCV_IOMMU_IVEC_CIV, RISCV_IOMMU_INTR_CQ) |
&gt; +           FIELD_PREP(RISCV_IOMMU_IVEC_FIV, RISCV_IOMMU_INTR_FQ);
&gt; +
&gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM)
&gt; +               icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PMIV, RISCV_IOMMU_INTR_PM);
&gt; +
&gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS)
&gt; +               icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PIV, RISCV_IOMMU_INTR_PQ);
&gt; +
&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IVEC, icvec);
&gt; +
&gt;         ret = riscv_iommu_init(iommu);
&gt;         if (!ret)
&gt;                 return ret;
&gt;
&gt;   fail:
&gt; +       pci_free_irq_vectors(pdev);
&gt;         pci_clear_master(pdev);
&gt;         pci_release_regions(pdev);
&gt;         pci_disable_device(pdev);
&gt; @@ -85,6 +156,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt;  static void riscv_iommu_pci_remove(struct pci_dev *pdev)
&gt;  {
&gt;         riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +       pci_free_irq_vectors(pdev);
&gt;         pci_clear_master(pdev);
&gt;         pci_release_regions(pdev);
&gt;         pci_disable_device(pdev);
&gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; index e4e8ca6711e7..35935d3c7ef4 100644
&gt; --- a/drivers/iommu/riscv/iommu-platform.c
&gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; @@ -20,6 +20,8 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt;         struct device *dev = &amp;pdev-&gt;dev;
&gt;         struct riscv_iommu_device *iommu = NULL;
&gt;         struct resource *res = NULL;
&gt; +       u32 fctl = 0;
&gt; +       int irq = 0;
&gt;         int ret = 0;
&gt;
&gt;         iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; @@ -53,6 +55,70 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt;                 goto fail;
&gt;         }
&gt;
&gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; +
&gt; +       /* For now we only support WSIs until we have AIA support */
</span>
I'm not completely understand AIA support here, because I saw the pci
case uses the MSI, and kernel seems to have the AIA implementation.
Could you please elaborate it?

<span class=q>&gt; +       ret = FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap);
&gt; +       if (ret == RISCV_IOMMU_CAP_IGS_MSI) {
&gt; +               dev_err(dev, "IOMMU only supports MSIs\n");
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       /* Parse IRQ assignment */
&gt; +       irq = platform_get_irq_byname_optional(pdev, "cmdq");
&gt; +       if (irq &gt; 0)
&gt; +               iommu-&gt;irq_cmdq = irq;
&gt; +       else {
&gt; +               dev_err(dev, "no IRQ provided for the command queue\n");
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       irq = platform_get_irq_byname_optional(pdev, "fltq");
&gt; +       if (irq &gt; 0)
&gt; +               iommu-&gt;irq_fltq = irq;
&gt; +       else {
&gt; +               dev_err(dev, "no IRQ provided for the fault/event queue\n");
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; +               irq = platform_get_irq_byname_optional(pdev, "pm");
&gt; +               if (irq &gt; 0)
&gt; +                       iommu-&gt;irq_pm = irq;
&gt; +               else {
&gt; +                       dev_err(dev, "no IRQ provided for performance monitoring\n");
&gt; +                       goto fail;
&gt; +               }
&gt; +       }
&gt; +
&gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; +               irq = platform_get_irq_byname_optional(pdev, "priq");
&gt; +               if (irq &gt; 0)
&gt; +                       iommu-&gt;irq_priq = irq;
&gt; +               else {
&gt; +                       dev_err(dev, "no IRQ provided for the page-request queue\n");
&gt; +                       goto fail;
&gt; +               }
&gt; +       }
</span>
Should we define the "interrupt-names" in dt-bindings?

<span class=q>&gt; +
&gt; +       /* Make sure fctl.WSI is set */
&gt; +       fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; +       fctl |= RISCV_IOMMU_FCTL_WSI;
&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; +
&gt; +       /* Parse Queue lengts */
&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; +       if (!ret)
&gt; +               dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; +
&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; +       if (!ret)
&gt; +               dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; +
&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; +       if (!ret)
&gt; +               dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; +
&gt;         dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt;
&gt;         return riscv_iommu_init(iommu);
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 31dc3c458e13..5c4cf9875302 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -45,6 +45,18 @@ static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt;  module_param(ddt_mode, int, 0644);
&gt;  MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt;
&gt; +static int cmdq_length = 1024;
&gt; +module_param(cmdq_length, int, 0644);
&gt; +MODULE_PARM_DESC(cmdq_length, "Command queue length.");
&gt; +
&gt; +static int fltq_length = 1024;
&gt; +module_param(fltq_length, int, 0644);
&gt; +MODULE_PARM_DESC(fltq_length, "Fault queue length.");
&gt; +
&gt; +static int priq_length = 1024;
&gt; +module_param(priq_length, int, 0644);
&gt; +MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
&gt; +
&gt;  /* IOMMU PSCID allocation namespace. */
&gt;  #define RISCV_IOMMU_MAX_PSCID  (1U &lt;&lt; 20)
&gt;  static DEFINE_IDA(riscv_iommu_pscids);
&gt; @@ -65,6 +77,497 @@ static DEFINE_IDA(riscv_iommu_pscids);
&gt;  static const struct iommu_domain_ops riscv_iommu_domain_ops;
&gt;  static const struct iommu_ops riscv_iommu_ops;
&gt;
&gt; +/*
&gt; + * Common queue management routines
&gt; + */
&gt; +
&gt; +/* Note: offsets are the same for all queues */
&gt; +#define Q_HEAD(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQH - RISCV_IOMMU_REG_CQB))
&gt; +#define Q_TAIL(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQT - RISCV_IOMMU_REG_CQB))
&gt; +
&gt; +static unsigned riscv_iommu_queue_consume(struct riscv_iommu_device *iommu,
&gt; +                                         struct riscv_iommu_queue *q, unsigned *ready)
&gt; +{
&gt; +       u32 tail = riscv_iommu_readl(iommu, Q_TAIL(q));
&gt; +       *ready = q-&gt;lui;
&gt; +
&gt; +       BUG_ON(q-&gt;cnt &lt;= tail);
&gt; +       if (q-&gt;lui &lt;= tail)
&gt; +               return tail - q-&gt;lui;
&gt; +       return q-&gt;cnt - q-&gt;lui;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_queue_release(struct riscv_iommu_device *iommu,
&gt; +                                     struct riscv_iommu_queue *q, unsigned count)
&gt; +{
&gt; +       q-&gt;lui = (q-&gt;lui + count) &amp; (q-&gt;cnt - 1);
&gt; +       riscv_iommu_writel(iommu, Q_HEAD(q), q-&gt;lui);
&gt; +}
&gt; +
&gt; +static u32 riscv_iommu_queue_ctrl(struct riscv_iommu_device *iommu,
&gt; +                                 struct riscv_iommu_queue *q, u32 val)
&gt; +{
&gt; +       cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
&gt; +
&gt; +       riscv_iommu_writel(iommu, q-&gt;qcr, val);
&gt; +       do {
&gt; +               val = riscv_iommu_readl(iommu, q-&gt;qcr);
&gt; +               if (!(val &amp; RISCV_IOMMU_QUEUE_BUSY))
&gt; +                       break;
&gt; +               cpu_relax();
&gt; +       } while (get_cycles() &lt; end_cycles);
&gt; +
&gt; +       return val;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_queue_free(struct riscv_iommu_device *iommu,
&gt; +                                  struct riscv_iommu_queue *q)
&gt; +{
&gt; +       size_t size = q-&gt;len * q-&gt;cnt;
&gt; +
&gt; +       riscv_iommu_queue_ctrl(iommu, q, 0);
&gt; +
&gt; +       if (q-&gt;base) {
&gt; +               if (q-&gt;in_iomem)
&gt; +                       iounmap(q-&gt;base);
&gt; +               else
&gt; +                       dmam_free_coherent(iommu-&gt;dev, size, q-&gt;base, q-&gt;base_dma);
&gt; +       }
&gt; +       if (q-&gt;irq)
&gt; +               free_irq(q-&gt;irq, q);
&gt; +}
&gt; +
&gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; +
&gt; +static int riscv_iommu_queue_init(struct riscv_iommu_device *iommu, int queue_id)
&gt; +{
&gt; +       struct device *dev = iommu-&gt;dev;
&gt; +       struct riscv_iommu_queue *q = NULL;
&gt; +       size_t queue_size = 0;
&gt; +       irq_handler_t irq_check;
&gt; +       irq_handler_t irq_process;
&gt; +       const char *name;
&gt; +       int count = 0;
&gt; +       int irq = 0;
&gt; +       unsigned order = 0;
&gt; +       u64 qbr_val = 0;
&gt; +       u64 qbr_readback = 0;
&gt; +       u64 qbr_paddr = 0;
&gt; +       int ret = 0;
&gt; +
&gt; +       switch (queue_id) {
&gt; +       case RISCV_IOMMU_COMMAND_QUEUE:
&gt; +               q = &amp;iommu-&gt;cmdq;
&gt; +               q-&gt;len = sizeof(struct riscv_iommu_command);
&gt; +               count = iommu-&gt;cmdq_len;
&gt; +               irq = iommu-&gt;irq_cmdq;
&gt; +               irq_check = riscv_iommu_cmdq_irq_check;
&gt; +               irq_process = riscv_iommu_cmdq_process;
&gt; +               q-&gt;qbr = RISCV_IOMMU_REG_CQB;
&gt; +               q-&gt;qcr = RISCV_IOMMU_REG_CQCSR;
&gt; +               name = "cmdq";
&gt; +               break;
&gt; +       case RISCV_IOMMU_FAULT_QUEUE:
&gt; +               q = &amp;iommu-&gt;fltq;
&gt; +               q-&gt;len = sizeof(struct riscv_iommu_fq_record);
&gt; +               count = iommu-&gt;fltq_len;
&gt; +               irq = iommu-&gt;irq_fltq;
&gt; +               irq_check = riscv_iommu_fltq_irq_check;
&gt; +               irq_process = riscv_iommu_fltq_process;
&gt; +               q-&gt;qbr = RISCV_IOMMU_REG_FQB;
&gt; +               q-&gt;qcr = RISCV_IOMMU_REG_FQCSR;
&gt; +               name = "fltq";
&gt; +               break;
&gt; +       case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; +               q = &amp;iommu-&gt;priq;
&gt; +               q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; +               count = iommu-&gt;priq_len;
&gt; +               irq = iommu-&gt;irq_priq;
&gt; +               irq_check = riscv_iommu_priq_irq_check;
&gt; +               irq_process = riscv_iommu_priq_process;
&gt; +               q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; +               q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; +               name = "priq";
&gt; +               break;
&gt; +       default:
&gt; +               dev_err(dev, "invalid queue interrupt index in queue_init!\n");
&gt; +               return -EINVAL;
&gt; +       }
&gt; +
&gt; +       /* Polling not implemented */
&gt; +       if (!irq)
&gt; +               return -ENODEV;
&gt; +
&gt; +       /* Allocate queue in memory and set the base register */
&gt; +       order = ilog2(count);
&gt; +       do {
&gt; +               queue_size = q-&gt;len * (1ULL &lt;&lt; order);
&gt; +               q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
&gt; +               if (q-&gt;base || queue_size &lt; PAGE_SIZE)
&gt; +                       break;
&gt; +
&gt; +               order--;
&gt; +       } while (1);
&gt; +
&gt; +       if (!q-&gt;base) {
&gt; +               dev_err(dev, "failed to allocate %s queue (cnt: %u)\n", name, count);
&gt; +               return -ENOMEM;
&gt; +       }
&gt; +
&gt; +       q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; +
&gt; +       qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; +           FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; +
&gt; +       riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; +
&gt; +       /*
&gt; +        * Queue base registers are WARL, so it's possible that whatever we wrote
&gt; +        * there was illegal/not supported by the hw in which case we need to make
&gt; +        * sure we set a supported PPN and/or queue size.
&gt; +        */
&gt; +       qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; +       if (qbr_readback == qbr_val)
&gt; +               goto irq;
&gt; +
&gt; +       dmam_free_coherent(dev, queue_size, q-&gt;base, q-&gt;base_dma);
&gt; +
&gt; +       /* Get supported queue size */
&gt; +       order = FIELD_GET(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, qbr_readback) + 1;
&gt; +       q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; +       queue_size = q-&gt;len * q-&gt;cnt;
&gt; +
&gt; +       /*
&gt; +        * In case we also failed to set PPN, it means the field is hardcoded and the
&gt; +        * queue resides in I/O memory instead, so get its physical address and
&gt; +        * ioremap it.
&gt; +        */
&gt; +       qbr_paddr = ppn_to_phys(qbr_readback);
&gt; +       if (qbr_paddr != q-&gt;base_dma) {
&gt; +               dev_info(dev,
&gt; +                        "hardcoded ppn in %s base register, using io memory for the queue\n",
&gt; +                        name);
&gt; +               dev_info(dev, "queue length for %s set to %i\n", name, q-&gt;cnt);
&gt; +               q-&gt;in_iomem = true;
&gt; +               q-&gt;base = ioremap(qbr_paddr, queue_size);
&gt; +               if (!q-&gt;base) {
&gt; +                       dev_err(dev, "failed to map %s queue (cnt: %u)\n", name, q-&gt;cnt);
&gt; +                       return -ENOMEM;
&gt; +               }
&gt; +               q-&gt;base_dma = qbr_paddr;
&gt; +       } else {
&gt; +               /*
&gt; +                * We only failed to set the queue size, re-try to allocate memory with
&gt; +                * the queue size supported by the hw.
&gt; +                */
&gt; +               dev_info(dev, "hardcoded queue size in %s base register\n", name);
&gt; +               dev_info(dev, "retrying with queue length: %i\n", q-&gt;cnt);
&gt; +               q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
&gt; +               if (!q-&gt;base) {
&gt; +                       dev_err(dev, "failed to allocate %s queue (cnt: %u)\n",
&gt; +                               name, q-&gt;cnt);
&gt; +                       return -ENOMEM;
&gt; +               }
&gt; +       }
&gt; +
&gt; +       qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; +           FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; +       riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; +
&gt; +       /* Final check to make sure hw accepted our write */
&gt; +       qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; +       if (qbr_readback != qbr_val) {
&gt; +               dev_err(dev, "failed to set base register for %s\n", name);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; + irq:
&gt; +       if (request_threaded_irq(irq, irq_check, irq_process, IRQF_ONESHOT | IRQF_SHARED,
&gt; +                                dev_name(dev), q)) {
&gt; +               dev_err(dev, "fail to request irq %d for %s\n", irq, name);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       q-&gt;irq = irq;
&gt; +
&gt; +       /* Note: All RIO_xQ_EN/IE fields are in the same offsets */
&gt; +       ret =
&gt; +           riscv_iommu_queue_ctrl(iommu, q,
&gt; +                                  RISCV_IOMMU_QUEUE_ENABLE |
&gt; +                                  RISCV_IOMMU_QUEUE_INTR_ENABLE);
&gt; +       if (ret &amp; RISCV_IOMMU_QUEUE_BUSY) {
&gt; +               dev_err(dev, "%s init timeout\n", name);
&gt; +               ret = -EBUSY;
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       return 0;
&gt; +
&gt; + fail:
&gt; +       riscv_iommu_queue_free(iommu, q);
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +/*
&gt; + * I/O MMU Command queue chapter 3.1
&gt; + */
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_vma(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +       cmd-&gt;dword0 =
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_OPCODE,
&gt; +                      RISCV_IOMMU_CMD_IOTINVAL_OPCODE) | FIELD_PREP(RISCV_IOMMU_CMD_FUNC,
&gt; +                                                                    RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA);
&gt; +       cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; +                                                 u64 addr)
&gt; +{
&gt; +       cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; +       cmd-&gt;dword1 = addr;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_set_pscid(struct riscv_iommu_command *cmd,
&gt; +                                                  unsigned pscid)
&gt; +{
&gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_PSCID, pscid) |
&gt; +           RISCV_IOMMU_CMD_IOTINVAL_PSCV;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_set_gscid(struct riscv_iommu_command *cmd,
&gt; +                                                  unsigned gscid)
&gt; +{
&gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_GSCID, gscid) |
&gt; +           RISCV_IOMMU_CMD_IOTINVAL_GV;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iofence(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C);
&gt; +       cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iofence_set_av(struct riscv_iommu_command *cmd,
&gt; +                                                 u64 addr, u32 data)
&gt; +{
&gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_IOFENCE_DATA, data) | RISCV_IOMMU_CMD_IOFENCE_AV;
&gt; +       cmd-&gt;dword1 = (addr &gt;&gt; 2);
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iodir_inval_ddt(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT);
&gt; +       cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iodir_inval_pdt(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT);
&gt; +       cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iodir_set_did(struct riscv_iommu_command *cmd,
&gt; +                                                unsigned devid)
&gt; +{
&gt; +       cmd-&gt;dword0 |=
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_IODIR_DID, devid) | RISCV_IOMMU_CMD_IODIR_DV;
&gt; +}
&gt; +
&gt; +/* TODO: Convert into lock-less MPSC implementation. */
&gt; +static bool riscv_iommu_post_sync(struct riscv_iommu_device *iommu,
&gt; +                                 struct riscv_iommu_command *cmd, bool sync)
&gt; +{
&gt; +       u32 head, tail, next, last;
&gt; +       unsigned long flags;
&gt; +
&gt; +       spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; +       head = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +       tail = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +       last = iommu-&gt;cmdq.lui;
&gt; +       if (tail != last) {
&gt; +               spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; +               /*
&gt; +                * FIXME: This is a workaround for dropped MMIO writes/reads on QEMU platform.
&gt; +                *        While debugging of the problem is still ongoing, this provides
&gt; +                *        a simple impolementation of try-again policy.
&gt; +                *        Will be changed to lock-less algorithm in the feature.
&gt; +                */
&gt; +               dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (1st)\n", last, tail);
&gt; +               spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; +               tail =
&gt; +                   riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +               last = iommu-&gt;cmdq.lui;
&gt; +               if (tail != last) {
&gt; +                       spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; +                       dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (2nd)\n", last, tail);
&gt; +                       spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; +               }
&gt; +       }
&gt; +
&gt; +       next = (last + 1) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +       if (next != head) {
&gt; +               struct riscv_iommu_command *ptr = iommu-&gt;cmdq.base;
&gt; +               ptr[last] = *cmd;
&gt; +               wmb();
&gt; +               riscv_iommu_writel(iommu, RISCV_IOMMU_REG_CQT, next);
&gt; +               iommu-&gt;cmdq.lui = next;
&gt; +       }
&gt; +
&gt; +       spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; +
&gt; +       if (sync &amp;&amp; head != next) {
&gt; +               cycles_t start_time = get_cycles();
&gt; +               while (1) {
&gt; +                       last = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp;
&gt; +                           (iommu-&gt;cmdq.cnt - 1);
&gt; +                       if (head &lt; next &amp;&amp; last &gt;= next)
&gt; +                               break;
&gt; +                       if (head &gt; next &amp;&amp; last &lt; head &amp;&amp; last &gt;= next)
&gt; +                               break;
&gt; +                       if (RISCV_IOMMU_TIMEOUT &lt; (get_cycles() - start_time)) {
</span>
This condition will be imprecise, because here is not in irq disabled
context, it will be scheduled out or preempted. When we come back
here, it might be over 1 second, but the IOFENCE is actually
completed.

<span class=q>&gt; +                               dev_err(iommu-&gt;dev, "IOFENCE TIMEOUT\n");
&gt; +                               return false;
&gt; +                       }
&gt; +                       cpu_relax();
&gt; +               }
&gt; +       }
&gt; +
&gt; +       return next != head;
&gt; +}
&gt; +
&gt; +static bool riscv_iommu_post(struct riscv_iommu_device *iommu,
&gt; +                            struct riscv_iommu_command *cmd)
&gt; +{
&gt; +       return riscv_iommu_post_sync(iommu, cmd, false);
&gt; +}
&gt; +
&gt; +static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       struct riscv_iommu_command cmd;
&gt; +       riscv_iommu_cmd_iofence(&amp;cmd);
&gt; +       return riscv_iommu_post_sync(iommu, &amp;cmd, true);
&gt; +}
&gt; +
&gt; +/* Command queue primary interrupt handler */
&gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data)
&gt; +{
&gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +       struct riscv_iommu_device *iommu =
&gt; +           container_of(q, struct riscv_iommu_device, cmdq);
&gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_CIP)
&gt; +               return IRQ_WAKE_THREAD;
&gt; +       return IRQ_NONE;
&gt; +}
&gt; +
&gt; +/* Command queue interrupt hanlder thread function */
&gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data)
&gt; +{
&gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +       struct riscv_iommu_device *iommu;
&gt; +       unsigned ctrl;
&gt; +
&gt; +       iommu = container_of(q, struct riscv_iommu_device, cmdq);
&gt; +
&gt; +       /* Error reporting, clear error reports if any. */
&gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQCSR);
&gt; +       if (ctrl &amp; (RISCV_IOMMU_CQCSR_CQMF |
&gt; +                   RISCV_IOMMU_CQCSR_CMD_TO | RISCV_IOMMU_CQCSR_CMD_ILL)) {
&gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;cmdq, ctrl);
&gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; +                                    "Command queue error: fault: %d tout: %d err: %d\n",
&gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CQMF),
&gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_TO),
&gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_ILL));
</span>
We need to handle the error by either adjusting the tail to remove the
failed command or fixing the failed command itself. Otherwise, the
failed command will keep in the queue and IOMMU will try to execute
it. I guess the first option might be easier to implement.

<span class=q>&gt; +       }
&gt; +
&gt; +       /* Clear fault interrupt pending. */
&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_CIP);
&gt; +
&gt; +       return IRQ_HANDLED;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Fault/event queue, chapter 3.2
&gt; + */
&gt; +
&gt; +static void riscv_iommu_fault_report(struct riscv_iommu_device *iommu,
&gt; +                                    struct riscv_iommu_fq_record *event)
&gt; +{
&gt; +       unsigned err, devid;
&gt; +
&gt; +       err = FIELD_GET(RISCV_IOMMU_FQ_HDR_CAUSE, event-&gt;hdr);
&gt; +       devid = FIELD_GET(RISCV_IOMMU_FQ_HDR_DID, event-&gt;hdr);
&gt; +
&gt; +       dev_warn_ratelimited(iommu-&gt;dev,
&gt; +                            "Fault %d devid: %d" " iotval: %llx iotval2: %llx\n", err,
&gt; +                            devid, event-&gt;iotval, event-&gt;iotval2);
&gt; +}
&gt; +
&gt; +/* Fault/event queue primary interrupt handler */
&gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data)
&gt; +{
&gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +       struct riscv_iommu_device *iommu =
&gt; +           container_of(q, struct riscv_iommu_device, fltq);
&gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_FIP)
&gt; +               return IRQ_WAKE_THREAD;
&gt; +       return IRQ_NONE;
&gt; +}
&gt; +
&gt; +/* Fault queue interrupt hanlder thread function */
&gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data)
&gt; +{
&gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +       struct riscv_iommu_device *iommu;
&gt; +       struct riscv_iommu_fq_record *events;
&gt; +       unsigned cnt, len, idx, ctrl;
&gt; +
&gt; +       iommu = container_of(q, struct riscv_iommu_device, fltq);
&gt; +       events = (struct riscv_iommu_fq_record *)q-&gt;base;
&gt; +
&gt; +       /* Error reporting, clear error reports if any. */
&gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FQCSR);
&gt; +       if (ctrl &amp; (RISCV_IOMMU_FQCSR_FQMF | RISCV_IOMMU_FQCSR_FQOF)) {
&gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;fltq, ctrl);
&gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; +                                    "Fault queue error: fault: %d full: %d\n",
&gt; +                                    !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQMF),
&gt; +                                    !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQOF));
&gt; +       }
&gt; +
&gt; +       /* Clear fault interrupt pending. */
&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_FIP);
&gt; +
&gt; +       /* Report fault events. */
&gt; +       do {
&gt; +               cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; +               if (!cnt)
&gt; +                       break;
&gt; +               for (len = 0; len &lt; cnt; idx++, len++)
&gt; +                       riscv_iommu_fault_report(iommu, &amp;events[idx]);
&gt; +               riscv_iommu_queue_release(iommu, q, cnt);
&gt; +       } while (1);
&gt; +
&gt; +       return IRQ_HANDLED;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Page request queue, chapter 3.3
&gt; + */
&gt; +
&gt;  /*
&gt;   * Register device for IOMMU tracking.
&gt;   */
&gt; @@ -97,6 +600,54 @@ static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct devi
&gt;         mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt;  }
&gt;
&gt; +/* Page request interface queue primary interrupt handler */
&gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data)
&gt; +{
&gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +       struct riscv_iommu_device *iommu =
&gt; +           container_of(q, struct riscv_iommu_device, priq);
&gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_PIP)
&gt; +               return IRQ_WAKE_THREAD;
&gt; +       return IRQ_NONE;
&gt; +}
&gt; +
&gt; +/* Page request interface queue interrupt hanlder thread function */
&gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt; +{
&gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +       struct riscv_iommu_device *iommu;
&gt; +       struct riscv_iommu_pq_record *requests;
&gt; +       unsigned cnt, idx, ctrl;
&gt; +
&gt; +       iommu = container_of(q, struct riscv_iommu_device, priq);
&gt; +       requests = (struct riscv_iommu_pq_record *)q-&gt;base;
&gt; +
&gt; +       /* Error reporting, clear error reports if any. */
&gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_PQCSR);
&gt; +       if (ctrl &amp; (RISCV_IOMMU_PQCSR_PQMF | RISCV_IOMMU_PQCSR_PQOF)) {
&gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;priq, ctrl);
&gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; +                                    "Page request queue error: fault: %d full: %d\n",
&gt; +                                    !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQMF),
&gt; +                                    !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQOF));
&gt; +       }
&gt; +
&gt; +       /* Clear page request interrupt pending. */
&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_PIP);
&gt; +
&gt; +       /* Process page requests. */
&gt; +       do {
&gt; +               cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; +               if (!cnt)
&gt; +                       break;
&gt; +               dev_warn(iommu-&gt;dev, "unexpected %u page requests\n", cnt);
&gt; +               riscv_iommu_queue_release(iommu, q, cnt);
&gt; +       } while (1);
&gt; +
&gt; +       return IRQ_HANDLED;
&gt; +}
&gt; +
&gt;  /*
&gt;   * Endpoint management
&gt;   */
&gt; @@ -350,7 +901,29 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt;                                           unsigned long *start, unsigned long *end,
&gt;                                           size_t *pgsize)
&gt;  {
&gt; -       /* Command interface not implemented */
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +       struct riscv_iommu_command cmd;
&gt; +       unsigned long iova;
&gt; +
&gt; +       if (domain-&gt;mode == RISCV_IOMMU_DC_FSC_MODE_BARE)
&gt; +               return;
&gt; +
&gt; +       /* Domain not attached to an IOMMU! */
&gt; +       BUG_ON(!domain-&gt;iommu);
&gt; +
&gt; +       riscv_iommu_cmd_inval_vma(&amp;cmd);
&gt; +       riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
&gt; +
&gt; +       if (start &amp;&amp; end &amp;&amp; pgsize) {
&gt; +               /* Cover only the range that is needed */
&gt; +               for (iova = *start; iova &lt;= *end; iova += *pgsize) {
&gt; +                       riscv_iommu_cmd_inval_set_addr(&amp;cmd, iova);
&gt; +                       riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +               }
&gt; +       } else {
&gt; +               riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +       }
&gt; +       riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt;  }
&gt;
&gt;  static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; @@ -610,6 +1183,9 @@ void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt;         iommu_device_unregister(&amp;iommu-&gt;iommu);
&gt;         iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
&gt;         riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt;  }
&gt;
&gt;  int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; @@ -632,6 +1208,16 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;         }
&gt;  #endif
&gt;
&gt; +       /*
&gt; +        * Assign queue lengths from module parameters if not already
&gt; +        * set on the device tree.
&gt; +        */
&gt; +       if (!iommu-&gt;cmdq_len)
&gt; +               iommu-&gt;cmdq_len = cmdq_length;
&gt; +       if (!iommu-&gt;fltq_len)
&gt; +               iommu-&gt;fltq_len = fltq_length;
&gt; +       if (!iommu-&gt;priq_len)
&gt; +               iommu-&gt;priq_len = priq_length;
&gt;         /* Clear any pending interrupt flag. */
&gt;         riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt;                            RISCV_IOMMU_IPSR_CIP |
&gt; @@ -639,7 +1225,20 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;                            RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt;         spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt;         mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_COMMAND_QUEUE);
&gt; +       if (ret)
&gt; +               goto fail;
&gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_FAULT_QUEUE);
&gt; +       if (ret)
&gt; +               goto fail;
&gt; +       if (!(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS))
&gt; +               goto no_ats;
&gt; +
&gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_PAGE_REQUEST_QUEUE);
&gt; +       if (ret)
&gt; +               goto fail;
&gt;
&gt; + no_ats:
&gt;         ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt;
&gt;         if (ret) {
&gt; @@ -663,5 +1262,8 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;         return 0;
&gt;   fail:
&gt;         riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt;         return ret;
&gt;  }
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 7dc9baa59a50..04148a2a8ffd 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -28,6 +28,24 @@
&gt;  #define IOMMU_PAGE_SIZE_1G     BIT_ULL(30)
&gt;  #define IOMMU_PAGE_SIZE_512G   BIT_ULL(39)
&gt;
&gt; +struct riscv_iommu_queue {
&gt; +       dma_addr_t base_dma;    /* ring buffer bus address */
&gt; +       void *base;             /* ring buffer pointer */
&gt; +       size_t len;             /* single item length */
&gt; +       u32 cnt;                /* items count */
&gt; +       u32 lui;                /* last used index, consumer/producer share */
&gt; +       unsigned qbr;           /* queue base register offset */
&gt; +       unsigned qcr;           /* queue control and status register offset */
&gt; +       int irq;                /* registered interrupt number */
&gt; +       bool in_iomem;          /* indicates queue data are in I/O memory  */
&gt; +};
&gt; +
&gt; +enum riscv_queue_ids {
&gt; +       RISCV_IOMMU_COMMAND_QUEUE       = 0,
&gt; +       RISCV_IOMMU_FAULT_QUEUE         = 1,
&gt; +       RISCV_IOMMU_PAGE_REQUEST_QUEUE  = 2
&gt; +};
&gt; +
&gt;  struct riscv_iommu_device {
&gt;         struct iommu_device iommu;      /* iommu core interface */
&gt;         struct device *dev;             /* iommu hardware */
&gt; @@ -42,6 +60,11 @@ struct riscv_iommu_device {
&gt;         int irq_pm;
&gt;         int irq_priq;
&gt;
&gt; +       /* Queue lengths */
&gt; +       int cmdq_len;
&gt; +       int fltq_len;
&gt; +       int priq_len;
&gt; +
&gt;         /* supported and enabled hardware capabilities */
&gt;         u64 cap;
&gt;
&gt; @@ -53,6 +76,11 @@ struct riscv_iommu_device {
&gt;         unsigned ddt_mode;
&gt;         bool ddtp_in_iomem;
&gt;
&gt; +       /* hardware queues */
&gt; +       struct riscv_iommu_queue cmdq;
&gt; +       struct riscv_iommu_queue fltq;
&gt; +       struct riscv_iommu_queue priq;
&gt; +
&gt;         /* Connected end-points */
&gt;         struct rb_root eps;
&gt;         struct mutex eps_mutex;
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m47475dde350a53202c60665ebadd89162dc278d8 id=e47475dde350a53202c60665ebadd89162dc278d8>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0pm+1yXuvUGudwNtvNHWV3FytH4VfCnq7_Ws=t-MZP_kQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0pm+1yXuvUGudwNtvNHWV3FytH4VfCnq7_Ws=t-MZP_kQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0pm+1yXuvUGudwNtvNHWV3FytH4VfCnq7_Ws=t-MZP_kQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0pm+1yXuvUGudwNtvNHWV3FytH4VfCnq7_Ws=t-MZP_kQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0pm+1yXuvUGudwNtvNHWV3FytH4VfCnq7_Ws=t-MZP_kQ@mail.gmail.com/t/#u">nested</a>] <a href=#r47475dde350a53202c60665ebadd89162dc278d8>86+ messages in thread</a></pre><hr><pre><a href=#e525805e3cb4b98064a03306b5a208399736c02b0 id=m525805e3cb4b98064a03306b5a208399736c02b0>*</a> <b>Re: [PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</b>
  2023-07-19 19:33 ` <a href=#m50b13653960cd6e88a7efb588257ac568bffb87b>[PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</a> Tomasz Jeznach
  2023-07-25 13:13   ` <a href=#m35e1f370635d089a8dde16e4c70b533d4b503ee0>Zong Li</a>
<b>@ 2023-07-31  7:19   ` Zong Li</b>
  2023-08-16 21:04   ` <a href=#m4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259>Robin Murphy</a>
  <a href=#r525805e3cb4b98064a03306b5a208399736c02b0>2 siblings, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-07-31  7:19 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0pb-4y9rOoMwqSgyf-RUQAAp5J8iOheG=Nbo71vCtns7g@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0pb-4y9rOoMwqSgyf-RUQAAp5J8iOheG=Nbo71vCtns7g@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230731072351">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230731072351">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; Introduces I/O page level translation services, with 4K, 2M, 1G page
&gt; size support and enables page level iommu_map/unmap domain interfaces.
&gt;
&gt; Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/io-pgtable.c       |   3 +
&gt;  drivers/iommu/riscv/Makefile     |   2 +-
&gt;  drivers/iommu/riscv/io_pgtable.c | 266 +++++++++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu.c      |  40 +++--
&gt;  drivers/iommu/riscv/iommu.h      |   1 +
&gt;  include/linux/io-pgtable.h       |   2 +
&gt;  6 files changed, 297 insertions(+), 17 deletions(-)
&gt;  create mode 100644 drivers/iommu/riscv/io_pgtable.c
&gt;
&gt; diff --git a/drivers/iommu/io-pgtable.c b/drivers/iommu/io-pgtable.c
&gt; index b843fcd365d2..c4807175934f 100644
&gt; --- a/drivers/iommu/io-pgtable.c
&gt; +++ b/drivers/iommu/io-pgtable.c
&gt; @@ -32,6 +32,9 @@ io_pgtable_init_table[IO_PGTABLE_NUM_FMTS] = {
&gt;         [AMD_IOMMU_V1] = &amp;io_pgtable_amd_iommu_v1_init_fns,
&gt;         [AMD_IOMMU_V2] = &amp;io_pgtable_amd_iommu_v2_init_fns,
&gt;  #endif
&gt; +#ifdef CONFIG_RISCV_IOMMU
&gt; +       [RISCV_IOMMU] = &amp;io_pgtable_riscv_init_fns,
&gt; +#endif
&gt;  };
&gt;
&gt;  struct io_pgtable_ops *alloc_io_pgtable_ops(enum io_pgtable_fmt fmt,
&gt; diff --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
&gt; index 9523eb053cfc..13af452c3052 100644
&gt; --- a/drivers/iommu/riscv/Makefile
&gt; +++ b/drivers/iommu/riscv/Makefile
&gt; @@ -1 +1 @@
&gt; -obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o
&gt; \ No newline at end of file
&gt; +obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o io_pgtable.o
&gt; diff --git a/drivers/iommu/riscv/io_pgtable.c b/drivers/iommu/riscv/io_pgtable.c
&gt; new file mode 100644
&gt; index 000000000000..b6e603e6726e
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/io_pgtable.c
&gt; @@ -0,0 +1,266 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + *
&gt; + * RISC-V IOMMU page table allocator.
&gt; + *
&gt; + * Authors:
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/atomic.h&gt;
&gt; +#include &lt;linux/bitops.h&gt;
&gt; +#include &lt;linux/io-pgtable.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/sizes.h&gt;
&gt; +#include &lt;linux/slab.h&gt;
&gt; +#include &lt;linux/types.h&gt;
&gt; +#include &lt;linux/dma-mapping.h&gt;
&gt; +
&gt; +#include "iommu.h"
&gt; +
&gt; +#define io_pgtable_to_domain(x) \
&gt; +       container_of((x), struct riscv_iommu_domain, pgtbl)
&gt; +
&gt; +#define io_pgtable_ops_to_domain(x) \
&gt; +       io_pgtable_to_domain(container_of((x), struct io_pgtable, ops))
&gt; +
&gt; +static inline size_t get_page_size(size_t size)
&gt; +{
&gt; +       if (size &gt;= IOMMU_PAGE_SIZE_512G)
&gt; +               return IOMMU_PAGE_SIZE_512G;
&gt; +
&gt; +       if (size &gt;= IOMMU_PAGE_SIZE_1G)
&gt; +               return IOMMU_PAGE_SIZE_1G;
&gt; +
&gt; +       if (size &gt;= IOMMU_PAGE_SIZE_2M)
&gt; +               return IOMMU_PAGE_SIZE_2M;
&gt; +
&gt; +       return IOMMU_PAGE_SIZE_4K;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_pt_walk_free(pmd_t * ptp, unsigned shift, bool root)
&gt; +{
&gt; +       pmd_t *pte, *pt_base;
&gt; +       int i;
&gt; +
&gt; +       if (shift == PAGE_SHIFT)
&gt; +               return;
&gt; +
&gt; +       if (root)
&gt; +               pt_base = ptp;
&gt; +       else
&gt; +               pt_base =
&gt; +                   (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp)));
&gt; +
&gt; +       /* Recursively free all sub page table pages */
&gt; +       for (i = 0; i &lt; PTRS_PER_PMD; i++) {
&gt; +               pte = pt_base + i;
&gt; +               if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
&gt; +                       riscv_iommu_pt_walk_free(pte, shift - 9, false);
&gt; +       }
&gt; +
&gt; +       /* Now free the current page table page */
&gt; +       if (!root &amp;&amp; pmd_present(*pt_base))
&gt; +               free_page((unsigned long)pt_base);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_free_pgtable(struct io_pgtable *iop)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_to_domain(iop);
&gt; +       riscv_iommu_pt_walk_free((pmd_t *) domain-&gt;pgd_root, PGDIR_SHIFT, true);
&gt; +}
&gt; +
&gt; +static pte_t *riscv_iommu_pt_walk_alloc(pmd_t * ptp, unsigned long iova,
&gt; +                                       unsigned shift, bool root,
&gt; +                                       size_t pgsize,
&gt; +                                       unsigned long (*pd_alloc)(gfp_t),
&gt; +                                       gfp_t gfp)
&gt; +{
&gt; +       pmd_t *pte;
&gt; +       unsigned long pfn;
&gt; +
&gt; +       if (root)
&gt; +               pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +       else
&gt; +               pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
&gt; +                   ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +
&gt; +       if ((1ULL &lt;&lt; shift) &lt;= pgsize) {
&gt; +               if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
&gt; +                       riscv_iommu_pt_walk_free(pte, shift - 9, false);
&gt; +               return (pte_t *) pte;
&gt; +       }
&gt; +
&gt; +       if (pmd_none(*pte)) {
&gt; +               pfn = pd_alloc ? virt_to_pfn(pd_alloc(gfp)) : 0;
&gt; +               if (!pfn)
&gt; +                       return NULL;
&gt; +               set_pmd(pte, __pmd((pfn &lt;&lt; _PAGE_PFN_SHIFT) | _PAGE_TABLE));
&gt; +       }
&gt; +
&gt; +       return riscv_iommu_pt_walk_alloc(pte, iova, shift - 9, false,
&gt; +                                        pgsize, pd_alloc, gfp);
&gt; +}
&gt; +
&gt; +static pte_t *riscv_iommu_pt_walk_fetch(pmd_t * ptp,
&gt; +                                       unsigned long iova, unsigned shift,
&gt; +                                       bool root)
&gt; +{
&gt; +       pmd_t *pte;
&gt; +
&gt; +       if (root)
&gt; +               pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +       else
&gt; +               pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
&gt; +                   ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +
&gt; +       if (pmd_leaf(*pte))
&gt; +               return (pte_t *) pte;
&gt; +       else if (pmd_none(*pte))
&gt; +               return NULL;
&gt; +       else if (shift == PAGE_SHIFT)
&gt; +               return NULL;
&gt; +
&gt; +       return riscv_iommu_pt_walk_fetch(pte, iova, shift - 9, false);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_map_pages(struct io_pgtable_ops *ops,
&gt; +                                unsigned long iova, phys_addr_t phys,
&gt; +                                size_t pgsize, size_t pgcount, int prot,
&gt; +                                gfp_t gfp, size_t *mapped)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +       size_t size = 0;
&gt; +       size_t page_size = get_page_size(pgsize);
&gt; +       pte_t *pte;
&gt; +       pte_t pte_val;
&gt; +       pgprot_t pte_prot;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_BLOCKED)
&gt; +               return -ENODEV;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; +               *mapped = pgsize * pgcount;
&gt; +               return 0;
&gt; +       }
&gt; +
&gt; +       pte_prot = (prot &amp; IOMMU_WRITE) ?
&gt; +           __pgprot(_PAGE_BASE | _PAGE_READ | _PAGE_WRITE | _PAGE_DIRTY) :
&gt; +           __pgprot(_PAGE_BASE | _PAGE_READ);
&gt; +
&gt; +       while (pgcount--) {
&gt; +               pte =
&gt; +                   riscv_iommu_pt_walk_alloc((pmd_t *) domain-&gt;pgd_root, iova,
&gt; +                                             PGDIR_SHIFT, true, page_size,
&gt; +                                             get_zeroed_page, gfp);
&gt; +               if (!pte) {
&gt; +                       *mapped = size;
&gt; +                       return -ENOMEM;
&gt; +               }
&gt; +
&gt; +               pte_val = pfn_pte(phys_to_pfn(phys), pte_prot);
&gt; +
&gt; +               set_pte(pte, pte_val);
&gt; +
&gt; +               size += page_size;
&gt; +               iova += page_size;
&gt; +               phys += page_size;
&gt; +       }
&gt; +
&gt; +       *mapped = size;
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static size_t riscv_iommu_unmap_pages(struct io_pgtable_ops *ops,
&gt; +                                     unsigned long iova, size_t pgsize,
&gt; +                                     size_t pgcount,
&gt; +                                     struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +       size_t size = 0;
&gt; +       size_t page_size = get_page_size(pgsize);
&gt; +       pte_t *pte;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return pgsize * pgcount;
&gt; +
&gt; +       while (pgcount--) {
&gt; +               pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
&gt; +                                               iova, PGDIR_SHIFT, true);
&gt; +               if (!pte)
&gt; +                       return size;
&gt; +
&gt; +               set_pte(pte, __pte(0));
&gt; +
&gt; +               iommu_iotlb_gather_add_page(&amp;domain-&gt;domain, gather, iova,
&gt; +                                           pgsize);
&gt; +
&gt; +               size += page_size;
&gt; +               iova += page_size;
&gt; +       }
&gt; +
&gt; +       return size;
&gt; +}
&gt; +
&gt; +static phys_addr_t riscv_iommu_iova_to_phys(struct io_pgtable_ops *ops,
&gt; +                                           unsigned long iova)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +       pte_t *pte;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return (phys_addr_t) iova;
&gt; +
&gt; +       pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
&gt; +                                       iova, PGDIR_SHIFT, true);
&gt; +       if (!pte || !pte_present(*pte))
&gt; +               return 0;
&gt; +
&gt; +       return (pfn_to_phys(pte_pfn(*pte)) | (iova &amp; PAGE_MASK));
</span>
As I mentioned in last mail, it should be (iova &amp; ~PAGE_MASK) for
getting low 12 bits.

<span class=q>&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_inv_all(void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_inv_walk(unsigned long iova, size_t size,
&gt; +                                    size_t granule, void *cookie)
&gt; +{
&gt; +}
&gt; +
</span>
What could we do in these callbacks? Perhaps send the IOTINVAL command to IOMMU?

<span class=q>&gt; +static void riscv_iommu_tlb_add_page(struct iommu_iotlb_gather *gather,
&gt; +                                    unsigned long iova, size_t granule,
&gt; +                                    void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static const struct iommu_flush_ops riscv_iommu_flush_ops = {
&gt; +       .tlb_flush_all = riscv_iommu_tlb_inv_all,
&gt; +       .tlb_flush_walk = riscv_iommu_tlb_inv_walk,
&gt; +       .tlb_add_page = riscv_iommu_tlb_add_page,
&gt; +};
&gt; +
&gt; +/* NOTE: cfg should point to riscv_iommu_domain structure member pgtbl.cfg */
&gt; +static struct io_pgtable *riscv_iommu_alloc_pgtable(struct io_pgtable_cfg *cfg,
&gt; +                                                   void *cookie)
&gt; +{
&gt; +       struct io_pgtable *iop = container_of(cfg, struct io_pgtable, cfg);
&gt; +
&gt; +       cfg-&gt;pgsize_bitmap = SZ_4K | SZ_2M | SZ_1G;
&gt; +       cfg-&gt;ias = 57;          // va mode, SvXX -&gt; ias
&gt; +       cfg-&gt;oas = 57;          // pa mode, or SvXX+4 -&gt; oas
</span>
Is it possible that use VA_BITS instead of this magic number?

<span class=q>&gt; +       cfg-&gt;tlb = &amp;riscv_iommu_flush_ops;
&gt; +
&gt; +       iop-&gt;ops.map_pages = riscv_iommu_map_pages;
&gt; +       iop-&gt;ops.unmap_pages = riscv_iommu_unmap_pages;
&gt; +       iop-&gt;ops.iova_to_phys = riscv_iommu_iova_to_phys;
&gt; +
&gt; +       return iop;
&gt; +}
&gt; +
&gt; +struct io_pgtable_init_fns io_pgtable_riscv_init_fns = {
&gt; +       .alloc = riscv_iommu_alloc_pgtable,
&gt; +       .free = riscv_iommu_free_pgtable,
&gt; +};
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 9ee7d2b222b5..2ef6952a2109 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -807,7 +807,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;         /* Initial DC pointer can be NULL if IOMMU is configured in OFF or BARE mode */
&gt;         ep-&gt;dc = riscv_iommu_get_dc(iommu, ep-&gt;devid);
&gt;
&gt; -       dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt; +       dev_dbg(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt;                 ep-&gt;devid, ep-&gt;domid);
&gt;
&gt;         dev_iommu_priv_set(dev, ep);
&gt; @@ -874,7 +874,10 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;  {
&gt;         struct riscv_iommu_domain *domain;
&gt;
&gt; -       if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; +       if (type != IOMMU_DOMAIN_DMA &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_DMA_FQ &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_UNMANAGED &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt;             type != IOMMU_DOMAIN_BLOCKED)
&gt;                 return NULL;
&gt;
&gt; @@ -890,7 +893,7 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;         domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt;                                         RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
&gt;
&gt; -       printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; +       printk("domain alloc %u\n", domain-&gt;pscid);
&gt;
&gt;         return &amp;domain-&gt;domain;
&gt;  }
&gt; @@ -903,6 +906,9 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;                 pr_warn("IOMMU domain is not empty!\n");
&gt;         }
&gt;
&gt; +       if (domain-&gt;pgtbl.cookie)
&gt; +               free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
&gt; +
&gt;         if (domain-&gt;pgd_root)
&gt;                 free_pages((unsigned long)domain-&gt;pgd_root, 0);
&gt;
&gt; @@ -959,6 +965,9 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt;         if (!domain-&gt;pgd_root)
&gt;                 return -ENOMEM;
&gt;
&gt; +       if (!alloc_io_pgtable_ops(RISCV_IOMMU, &amp;domain-&gt;pgtbl.cfg, domain))
&gt; +               return -ENOMEM;
&gt; +
&gt;         return 0;
&gt;  }
&gt;
&gt; @@ -1006,9 +1015,8 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;                 return 0;
&gt;         }
&gt;
&gt; -       if (!dc) {
&gt; +       if (!dc)
&gt;                 return -ENODEV;
&gt; -       }
&gt;
&gt;         /*
&gt;          * S-Stage translation table. G-Stage remains unmodified (BARE).
&gt; @@ -1104,12 +1112,11 @@ static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;
&gt; -       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; -               *mapped = pgsize * pgcount;
&gt; -               return 0;
&gt; -       }
&gt; +       if (!domain-&gt;pgtbl.ops.map_pages)
&gt; +               return -ENODEV;
&gt;
&gt; -       return -ENODEV;
&gt; +       return domain-&gt;pgtbl.ops.map_pages(&amp;domain-&gt;pgtbl.ops, iova, phys,
&gt; +                                          pgsize, pgcount, prot, gfp, mapped);
&gt;  }
&gt;
&gt;  static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt; @@ -1118,10 +1125,11 @@ static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;
&gt; -       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; -               return pgsize * pgcount;
&gt; +       if (!domain-&gt;pgtbl.ops.unmap_pages)
&gt; +               return 0;
&gt;
&gt; -       return 0;
&gt; +       return domain-&gt;pgtbl.ops.unmap_pages(&amp;domain-&gt;pgtbl.ops, iova, pgsize,
&gt; +                                            pgcount, gather);
&gt;  }
&gt;
&gt;  static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt; @@ -1129,10 +1137,10 @@ static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;
&gt; -       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; -               return (phys_addr_t) iova;
&gt; +       if (!domain-&gt;pgtbl.ops.iova_to_phys)
&gt; +               return 0;
&gt;
&gt; -       return 0;
&gt; +       return domain-&gt;pgtbl.ops.iova_to_phys(&amp;domain-&gt;pgtbl.ops, iova);
&gt;  }
&gt;
&gt;  /*
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 9140df71e17b..fe32a4eff14e 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -88,6 +88,7 @@ struct riscv_iommu_device {
&gt;
&gt;  struct riscv_iommu_domain {
&gt;         struct iommu_domain domain;
&gt; +       struct io_pgtable pgtbl;
&gt;
&gt;         struct list_head endpoints;
&gt;         struct mutex lock;
&gt; diff --git a/include/linux/io-pgtable.h b/include/linux/io-pgtable.h
&gt; index 1b7a44b35616..8dd9d3a28e3a 100644
&gt; --- a/include/linux/io-pgtable.h
&gt; +++ b/include/linux/io-pgtable.h
&gt; @@ -19,6 +19,7 @@ enum io_pgtable_fmt {
&gt;         AMD_IOMMU_V2,
&gt;         APPLE_DART,
&gt;         APPLE_DART2,
&gt; +       RISCV_IOMMU,
&gt;         IO_PGTABLE_NUM_FMTS,
&gt;  };
&gt;
&gt; @@ -258,5 +259,6 @@ extern struct io_pgtable_init_fns io_pgtable_arm_mali_lpae_init_fns;
&gt;  extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v1_init_fns;
&gt;  extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v2_init_fns;
&gt;  extern struct io_pgtable_init_fns io_pgtable_apple_dart_init_fns;
&gt; +extern struct io_pgtable_init_fns io_pgtable_riscv_init_fns;
&gt;
&gt;  #endif /* __IO_PGTABLE_H */
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m525805e3cb4b98064a03306b5a208399736c02b0 id=e525805e3cb4b98064a03306b5a208399736c02b0>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0pb-4y9rOoMwqSgyf-RUQAAp5J8iOheG=Nbo71vCtns7g@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0pb-4y9rOoMwqSgyf-RUQAAp5J8iOheG=Nbo71vCtns7g@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0pb-4y9rOoMwqSgyf-RUQAAp5J8iOheG=Nbo71vCtns7g@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0pb-4y9rOoMwqSgyf-RUQAAp5J8iOheG=Nbo71vCtns7g@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0pb-4y9rOoMwqSgyf-RUQAAp5J8iOheG=Nbo71vCtns7g@mail.gmail.com/t/#u">nested</a>] <a href=#r525805e3cb4b98064a03306b5a208399736c02b0>86+ messages in thread</a></pre><hr><pre><a href=#e50f9bd691aa7ab3a5a8b02029fa5678c52ad628d id=m50f9bd691aa7ab3a5a8b02029fa5678c52ad628d>*</a> <b>Re: [PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</b>
  2023-07-19 19:33 ` <a href=#m2774c76ea4a5513d985e6c918e66c1e3730ad342>[PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</a> Tomasz Jeznach
<b>@ 2023-07-31  8:02   ` Zong Li</b>
  2023-08-16 21:43   ` <a href=#mf231abf8c9cfd6ea2015f815834751c8c88eb136>Robin Murphy</a>
  <a href=#r50f9bd691aa7ab3a5a8b02029fa5678c52ad628d>1 sibling, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-07-31  8:02 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0oSiv7UV+nmZppA0_oZCevEEt2UsNTz6WE3gtcCpExYqw@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0oSiv7UV+nmZppA0_oZCevEEt2UsNTz6WE3gtcCpExYqw@mail.gmail.com/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230731080438">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230731080438">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; This change provides basic identity mapping support to
&gt; excercise MSI_FLAT hardware capability.
&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/riscv/iommu.c | 81 +++++++++++++++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu.h |  3 ++
&gt;  2 files changed, 84 insertions(+)
&gt;
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 6042c35be3ca..7b3e3e135cf6 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -61,6 +61,9 @@ MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
&gt;  #define RISCV_IOMMU_MAX_PSCID  (1U &lt;&lt; 20)
&gt;  static DEFINE_IDA(riscv_iommu_pscids);
&gt;
&gt; +/* TODO: Enable MSI remapping */
&gt; +#define RISCV_IMSIC_BASE       0x28000000
</span>
I'm not sure if it is appropriate to hard code the base address of
peripheral in source code, it might be depends on the layout of each
target.

<span class=q>&gt; +
&gt;  /* 1 second */
&gt;  #define RISCV_IOMMU_TIMEOUT    riscv_timebase
&gt;
&gt; @@ -932,6 +935,72 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt;   * Endpoint management
&gt;   */
&gt;
&gt; +static int riscv_iommu_enable_ir(struct riscv_iommu_endpoint *ep)
&gt; +{
&gt; +       struct riscv_iommu_device *iommu = ep-&gt;iommu;
&gt; +       struct iommu_resv_region *entry;
&gt; +       struct irq_domain *msi_domain;
&gt; +       u64 val;
&gt; +       int i;
&gt; +
&gt; +       /* Initialize MSI remapping */
&gt; +       if (!ep-&gt;dc || !(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_MSI_FLAT))
&gt; +               return 0;
&gt; +
&gt; +       ep-&gt;msi_root = (struct riscv_iommu_msi_pte *)get_zeroed_page(GFP_KERNEL);
&gt; +       if (!ep-&gt;msi_root)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       for (i = 0; i &lt; 256; i++) {
&gt; +               ep-&gt;msi_root[i].pte = RISCV_IOMMU_MSI_PTE_V |
&gt; +                   FIELD_PREP(RISCV_IOMMU_MSI_PTE_M, 3) |
&gt; +                   phys_to_ppn(RISCV_IMSIC_BASE + i * PAGE_SIZE);
&gt; +       }
&gt; +
&gt; +       entry = iommu_alloc_resv_region(RISCV_IMSIC_BASE, PAGE_SIZE * 256, 0,
&gt; +                                       IOMMU_RESV_SW_MSI, GFP_KERNEL);
&gt; +       if (entry)
&gt; +               list_add_tail(&amp;entry-&gt;list, &amp;ep-&gt;regions);
&gt; +
&gt; +       val = virt_to_pfn(ep-&gt;msi_root) |
&gt; +           FIELD_PREP(RISCV_IOMMU_DC_MSIPTP_MODE, RISCV_IOMMU_DC_MSIPTP_MODE_FLAT);
&gt; +       ep-&gt;dc-&gt;msiptp = cpu_to_le64(val);
&gt; +
&gt; +       /* Single page of MSIPTP, 256 IMSIC files */
&gt; +       ep-&gt;dc-&gt;msi_addr_mask = cpu_to_le64(255);
&gt; +       ep-&gt;dc-&gt;msi_addr_pattern = cpu_to_le64(RISCV_IMSIC_BASE &gt;&gt; 12);
&gt; +       wmb();
&gt; +
&gt; +       /* set msi domain for the device as isolated. hack. */
&gt; +       msi_domain = dev_get_msi_domain(ep-&gt;dev);
&gt; +       if (msi_domain) {
&gt; +               msi_domain-&gt;flags |= IRQ_DOMAIN_FLAG_ISOLATED_MSI;
&gt; +       }
&gt; +
&gt; +       dev_dbg(ep-&gt;dev, "RV-IR enabled\n");
&gt; +
&gt; +       ep-&gt;ir_enabled = true;
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_disable_ir(struct riscv_iommu_endpoint *ep)
&gt; +{
&gt; +       if (!ep-&gt;ir_enabled)
&gt; +               return;
&gt; +
&gt; +       ep-&gt;dc-&gt;msi_addr_pattern = 0ULL;
&gt; +       ep-&gt;dc-&gt;msi_addr_mask = 0ULL;
&gt; +       ep-&gt;dc-&gt;msiptp = 0ULL;
&gt; +       wmb();
&gt; +
&gt; +       dev_dbg(ep-&gt;dev, "RV-IR disabled\n");
&gt; +
&gt; +       free_pages((unsigned long)ep-&gt;msi_root, 0);
&gt; +       ep-&gt;msi_root = NULL;
&gt; +       ep-&gt;ir_enabled = false;
&gt; +}
&gt; +
&gt;  /* Endpoint features/capabilities */
&gt;  static void riscv_iommu_disable_ep(struct riscv_iommu_endpoint *ep)
&gt;  {
&gt; @@ -1226,6 +1295,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;
&gt;         mutex_init(&amp;ep-&gt;lock);
&gt;         INIT_LIST_HEAD(&amp;ep-&gt;domain);
&gt; +       INIT_LIST_HEAD(&amp;ep-&gt;regions);
&gt;
&gt;         if (dev_is_pci(dev)) {
&gt;                 ep-&gt;devid = pci_dev_id(to_pci_dev(dev));
&gt; @@ -1248,6 +1318,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;         dev_iommu_priv_set(dev, ep);
&gt;         riscv_iommu_add_device(iommu, dev);
&gt;         riscv_iommu_enable_ep(ep);
&gt; +       riscv_iommu_enable_ir(ep);
&gt;
&gt;         return &amp;iommu-&gt;iommu;
&gt;  }
&gt; @@ -1279,6 +1350,7 @@ static void riscv_iommu_release_device(struct device *dev)
&gt;                 riscv_iommu_iodir_inv_devid(iommu, ep-&gt;devid);
&gt;         }
&gt;
&gt; +       riscv_iommu_disable_ir(ep);
&gt;         riscv_iommu_disable_ep(ep);
&gt;
&gt;         /* Remove endpoint from IOMMU tracking structures */
&gt; @@ -1301,6 +1373,15 @@ static struct iommu_group *riscv_iommu_device_group(struct device *dev)
&gt;
&gt;  static void riscv_iommu_get_resv_regions(struct device *dev, struct list_head *head)
&gt;  {
&gt; +       struct iommu_resv_region *entry, *new_entry;
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +       list_for_each_entry(entry, &amp;ep-&gt;regions, list) {
&gt; +               new_entry = kmemdup(entry, sizeof(*entry), GFP_KERNEL);
&gt; +               if (new_entry)
&gt; +                       list_add_tail(&amp;new_entry-&gt;list, head);
&gt; +       }
&gt; +
&gt;         iommu_dma_get_resv_regions(dev, head);
&gt;  }
&gt;
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 83e8d00fd0f8..55418a1144fb 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -117,14 +117,17 @@ struct riscv_iommu_endpoint {
&gt;         struct riscv_iommu_dc *dc;              /* device context pointer */
&gt;         struct riscv_iommu_pc *pc;              /* process context root, valid if pasid_enabled is true */
&gt;         struct riscv_iommu_device *iommu;       /* parent iommu device */
&gt; +       struct riscv_iommu_msi_pte *msi_root;   /* interrupt re-mapping */
&gt;
&gt;         struct mutex lock;
&gt;         struct list_head domain;                /* endpoint attached managed domain */
&gt; +       struct list_head regions;               /* reserved regions, interrupt remapping window */
&gt;
&gt;         /* end point info bits */
&gt;         unsigned pasid_bits;
&gt;         unsigned pasid_feat;
&gt;         bool pasid_enabled;
&gt; +       bool ir_enabled;
&gt;  };
&gt;
&gt;  /* Helper functions and macros */
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m50f9bd691aa7ab3a5a8b02029fa5678c52ad628d id=e50f9bd691aa7ab3a5a8b02029fa5678c52ad628d>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0oSiv7UV+nmZppA0_oZCevEEt2UsNTz6WE3gtcCpExYqw@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0oSiv7UV+nmZppA0_oZCevEEt2UsNTz6WE3gtcCpExYqw@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0oSiv7UV+nmZppA0_oZCevEEt2UsNTz6WE3gtcCpExYqw@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0oSiv7UV+nmZppA0_oZCevEEt2UsNTz6WE3gtcCpExYqw@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0oSiv7UV+nmZppA0_oZCevEEt2UsNTz6WE3gtcCpExYqw@mail.gmail.com/t/#u>nested</a>] <a href=#r50f9bd691aa7ab3a5a8b02029fa5678c52ad628d>86+ messages in thread</a></pre><hr><pre><a href=#e1a63028351b0e86a470c474db2d582acd5369901 id=m1a63028351b0e86a470c474db2d582acd5369901>*</a> <b>Re: [PATCH 11/11] RISC-V: drivers/iommu/riscv: Add G-Stage translation support</b>
  2023-07-19 19:33 ` <a href=#m6edef0662c8a8cd238cf3fa0929af7d0305c10f5>[PATCH 11/11] RISC-V: drivers/iommu/riscv: Add G-Stage translation support</a> Tomasz Jeznach
<b>@ 2023-07-31  8:12   ` Zong Li</b>
  2023-08-16 21:13   ` <a href=#m0c898cce80d8dc67ea1c5e12243227adb68db208>Robin Murphy</a>
  <a href=#r1a63028351b0e86a470c474db2d582acd5369901>1 sibling, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-07-31  8:12 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0q9bMm4m6AJ=3uy81+GsQ+bav+TLbdB-oTBu-wu+f5beQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0q9bMm4m6AJ=3uy81+GsQ+bav+TLbdB-oTBu-wu+f5beQ@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230731081449">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230731081449">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; This change introduces 2nd stage translation configuration
&gt; support, enabling nested translation for IOMMU hardware.
&gt; Pending integration with VMM IOMMUFD interfaces to manage
&gt; 1st stage translation and IOMMU virtialization interfaces.
&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/riscv/iommu.c | 58 ++++++++++++++++++++++++++++---------
&gt;  drivers/iommu/riscv/iommu.h |  3 +-
&gt;  2 files changed, 46 insertions(+), 15 deletions(-)
&gt;
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 7b3e3e135cf6..3ca2f0194d3c 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -1418,6 +1418,19 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;         return &amp;domain-&gt;domain;
&gt;  }
&gt;
&gt; +/* mark domain as second-stage translation */
&gt; +static int riscv_iommu_enable_nesting(struct iommu_domain *iommu_domain)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       mutex_lock(&amp;domain-&gt;lock);
&gt; +       if (list_empty(&amp;domain-&gt;endpoints))
&gt; +               domain-&gt;g_stage = true;
&gt; +       mutex_unlock(&amp;domain-&gt;lock);
&gt; +
&gt; +       return domain-&gt;g_stage ? 0 : -EBUSY;
&gt; +}
&gt; +
&gt;  static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; @@ -1433,7 +1446,7 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;                 free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
&gt;
&gt;         if (domain-&gt;pgd_root)
&gt; -               free_pages((unsigned long)domain-&gt;pgd_root, 0);
&gt; +               free_pages((unsigned long)domain-&gt;pgd_root, domain-&gt;g_stage ? 2 : 0);
&gt;
&gt;         if ((int)domain-&gt;pscid &gt; 0)
&gt;                 ida_free(&amp;riscv_iommu_pscids, domain-&gt;pscid);
&gt; @@ -1483,7 +1496,8 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt;
&gt;         /* TODO: Fix this for RV32 */
&gt;         domain-&gt;mode = satp_mode &gt;&gt; 60;
&gt; -       domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO, 0);
&gt; +       domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO,
&gt; +                                                     domain-&gt;g_stage ? 2 : 0);
&gt;
&gt;         if (!domain-&gt;pgd_root)
&gt;                 return -ENOMEM;
&gt; @@ -1499,6 +1513,8 @@ static u64 riscv_iommu_domain_atp(struct riscv_iommu_domain *domain)
&gt;         u64 atp = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, domain-&gt;mode);
&gt;         if (domain-&gt;mode != RISCV_IOMMU_DC_FSC_MODE_BARE)
&gt;                 atp |= FIELD_PREP(RISCV_IOMMU_DC_FSC_PPN, virt_to_pfn(domain-&gt;pgd_root));
&gt; +       if (domain-&gt;g_stage)
&gt; +               atp |= FIELD_PREP(RISCV_IOMMU_DC_IOHGATP_GSCID, domain-&gt;pscid);
&gt;         return atp;
&gt;  }
&gt;
&gt; @@ -1541,20 +1557,30 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;         if (!dc)
&gt;                 return -ENODEV;
&gt;
&gt; -       /*
&gt; -        * S-Stage translation table. G-Stage remains unmodified (BARE).
&gt; -        */
&gt; -       val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt; -
&gt; -       if (ep-&gt;pasid_enabled) {
&gt; -               ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
&gt; -               ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +       if (domain-&gt;g_stage) {
&gt; +               /*
&gt; +                * Enable G-Stage translation with initial pass-through mode
&gt; +                * for S-Stage. VMM is responsible for more restrictive
&gt; +                * guest VA translation scheme configuration.
&gt; +                */
&gt;                 dc-&gt;ta = 0;
&gt; -               dc-&gt;fsc = cpu_to_le64(virt_to_pfn(ep-&gt;pc) |
&gt; -                   FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8));
&gt; +               dc-&gt;fsc = 0ULL; /* RISCV_IOMMU_DC_FSC_MODE_BARE */ ;
&gt; +               dc-&gt;iohgatp = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt;         } else {
&gt; -               dc-&gt;ta = cpu_to_le64(val);
&gt; -               dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +               /* S-Stage translation table. G-Stage remains unmodified. */
&gt; +               if (ep-&gt;pasid_enabled) {
&gt; +                       val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt; +                       ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
&gt; +                       ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +                       dc-&gt;ta = 0;
&gt; +                       val = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE,
&gt; +                                         RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8);
&gt; +                       dc-&gt;fsc = cpu_to_le64(val | virt_to_pfn(ep-&gt;pc));
&gt; +               } else {
&gt; +                       val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt; +                       dc-&gt;ta = cpu_to_le64(val);
&gt; +                       dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +               }
&gt;         }
&gt;
&gt;         wmb();
&gt; @@ -1599,6 +1625,9 @@ static int riscv_iommu_set_dev_pasid(struct iommu_domain *iommu_domain,
&gt;         if (!iommu_domain || !iommu_domain-&gt;mm)
&gt;                 return -EINVAL;
&gt;
&gt; +       if (domain-&gt;g_stage)
&gt; +               return -EINVAL;
&gt; +
&gt;         /* Driver uses TC.DPE mode, PASID #0 is incorrect. */
&gt;         if (pasid == 0)
&gt;                 return -EINVAL;
&gt; @@ -1969,6 +1998,7 @@ static const struct iommu_domain_ops riscv_iommu_domain_ops = {
&gt;         .iotlb_sync = riscv_iommu_iotlb_sync,
&gt;         .iotlb_sync_map = riscv_iommu_iotlb_sync_map,
&gt;         .flush_iotlb_all = riscv_iommu_flush_iotlb_all,
&gt; +       .enable_nesting = riscv_iommu_enable_nesting,
&gt;  };
&gt;
</span>
I don't see the GVMA invalidate command, I guess we need do something
likes that in 'riscv_iommu_mm_invalidate'

<span class=q>&gt;  static const struct iommu_ops riscv_iommu_ops = {
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 55418a1144fb..55e5aafea5bc 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -102,8 +102,9 @@ struct riscv_iommu_domain {
&gt;         struct riscv_iommu_device *iommu;
&gt;
&gt;         unsigned mode;          /* RIO_ATP_MODE_* enum */
&gt; -       unsigned pscid;         /* RISC-V IOMMU PSCID */
&gt; +       unsigned pscid;         /* RISC-V IOMMU PSCID / GSCID */
&gt;         ioasid_t pasid;         /* IOMMU_DOMAIN_SVA: Cached PASID */
&gt; +       bool g_stage;           /* 2nd stage translation domain */
&gt;
&gt;         pgd_t *pgd_root;        /* page table root pointer */
&gt;  };
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#m1a63028351b0e86a470c474db2d582acd5369901 id=e1a63028351b0e86a470c474db2d582acd5369901>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0q9bMm4m6AJ=3uy81+GsQ+bav+TLbdB-oTBu-wu+f5beQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0q9bMm4m6AJ=3uy81+GsQ+bav+TLbdB-oTBu-wu+f5beQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0q9bMm4m6AJ=3uy81+GsQ+bav+TLbdB-oTBu-wu+f5beQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0q9bMm4m6AJ=3uy81+GsQ+bav+TLbdB-oTBu-wu+f5beQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0q9bMm4m6AJ=3uy81+GsQ+bav+TLbdB-oTBu-wu+f5beQ@mail.gmail.com/t/#u">nested</a>] <a href=#r1a63028351b0e86a470c474db2d582acd5369901>86+ messages in thread</a></pre><hr><pre><a href=#edc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7 id=mdc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7>*</a> <b>Re: [PATCH 09/11] RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support.</b>
  2023-07-19 19:33 ` <a href=#mdc9e0e502299442d2ebce9ef9d4f317c16f89a05>[PATCH 09/11] RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support</a> Tomasz Jeznach
<b>@ 2023-07-31  9:04   ` Zong Li</b>
  <a href=#rdc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7>0 siblings, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-07-31  9:04 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0r1WDRc6fkgUkxJJnxKRuABvK6rdnLoZy7DngYVxV8gpA@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0r1WDRc6fkgUkxJJnxKRuABvK6rdnLoZy7DngYVxV8gpA@mail.gmail.com/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230731090549">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230731090549">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:35 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; Introduces SVA (Shared Virtual Address) for RISC-V IOMMU, with
&gt; ATS/PRI services for capable devices.
&gt;
&gt; Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/riscv/iommu.c | 601 +++++++++++++++++++++++++++++++++++-
&gt;  drivers/iommu/riscv/iommu.h |  14 +
&gt;  2 files changed, 610 insertions(+), 5 deletions(-)
&gt;
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 2ef6952a2109..6042c35be3ca 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -384,6 +384,89 @@ static inline void riscv_iommu_cmd_iodir_set_did(struct riscv_iommu_command *cmd
&gt;             FIELD_PREP(RISCV_IOMMU_CMD_IODIR_DID, devid) | RISCV_IOMMU_CMD_IODIR_DV;
&gt;  }
&gt;
&gt; +static inline void riscv_iommu_cmd_iodir_set_pid(struct riscv_iommu_command *cmd,
&gt; +                                                unsigned pasid)
&gt; +{
&gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IODIR_PID, pasid);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_cmd_ats_inval(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_ATS_OPCODE) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_ATS_FUNC_INVAL);
&gt; +       cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_ats_prgr(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_ATS_OPCODE) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_ATS_FUNC_PRGR);
&gt; +       cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_cmd_ats_set_rid(struct riscv_iommu_command *cmd, u32 rid)
&gt; +{
&gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_ATS_RID, rid);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_cmd_ats_set_pid(struct riscv_iommu_command *cmd, u32 pid)
&gt; +{
&gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_ATS_PID, pid) | RISCV_IOMMU_CMD_ATS_PV;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_cmd_ats_set_dseg(struct riscv_iommu_command *cmd, u8 seg)
&gt; +{
&gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_ATS_DSEG, seg) | RISCV_IOMMU_CMD_ATS_DSV;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_cmd_ats_set_payload(struct riscv_iommu_command *cmd, u64 payload)
&gt; +{
&gt; +       cmd-&gt;dword1 = payload;
&gt; +}
&gt; +
&gt; +/* Prepare the ATS invalidation payload */
&gt; +static unsigned long riscv_iommu_ats_inval_payload(unsigned long start,
&gt; +                                                  unsigned long end, bool global_inv)
&gt; +{
&gt; +       size_t len = end - start + 1;
&gt; +       unsigned long payload = 0;
&gt; +
&gt; +       /*
&gt; +        * PCI Express specification
&gt; +        * Section 10.2.3.2 Translation Range Size (S) Field
&gt; +        */
&gt; +       if (len &lt; PAGE_SIZE)
&gt; +               len = PAGE_SIZE;
&gt; +       else
&gt; +               len = __roundup_pow_of_two(len);
&gt; +
&gt; +       payload = (start &amp; ~(len - 1)) | (((len - 1) &gt;&gt; 12) &lt;&lt; 11);
&gt; +
&gt; +       if (global_inv)
&gt; +               payload |= RISCV_IOMMU_CMD_ATS_INVAL_G;
&gt; +
&gt; +       return payload;
&gt; +}
&gt; +
&gt; +/* Prepare the ATS invalidation payload for all translations to be invalidated. */
&gt; +static unsigned long riscv_iommu_ats_inval_all_payload(bool global_inv)
&gt; +{
&gt; +       unsigned long payload = GENMASK_ULL(62, 11);
&gt; +
&gt; +       if (global_inv)
&gt; +               payload |= RISCV_IOMMU_CMD_ATS_INVAL_G;
&gt; +
&gt; +       return payload;
&gt; +}
&gt; +
&gt; +/* Prepare the ATS "Page Request Group Response" payload */
&gt; +static unsigned long riscv_iommu_ats_prgr_payload(u16 dest_id, u8 resp_code, u16 grp_idx)
&gt; +{
&gt; +       return FIELD_PREP(RISCV_IOMMU_CMD_ATS_PRGR_DST_ID, dest_id) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_ATS_PRGR_RESP_CODE, resp_code) |
&gt; +           FIELD_PREP(RISCV_IOMMU_CMD_ATS_PRGR_PRG_INDEX, grp_idx);
&gt; +}
&gt; +
&gt;  /* TODO: Convert into lock-less MPSC implementation. */
&gt;  static bool riscv_iommu_post_sync(struct riscv_iommu_device *iommu,
&gt;                                   struct riscv_iommu_command *cmd, bool sync)
&gt; @@ -460,6 +543,16 @@ static bool riscv_iommu_iodir_inv_devid(struct riscv_iommu_device *iommu, unsign
&gt;         return riscv_iommu_post(iommu, &amp;cmd);
&gt;  }
&gt;
&gt; +static bool riscv_iommu_iodir_inv_pasid(struct riscv_iommu_device *iommu,
&gt; +                                       unsigned devid, unsigned pasid)
&gt; +{
&gt; +       struct riscv_iommu_command cmd;
&gt; +       riscv_iommu_cmd_iodir_inval_pdt(&amp;cmd);
&gt; +       riscv_iommu_cmd_iodir_set_did(&amp;cmd, devid);
&gt; +       riscv_iommu_cmd_iodir_set_pid(&amp;cmd, pasid);
&gt; +       return riscv_iommu_post(iommu, &amp;cmd);
&gt; +}
&gt; +
&gt;  static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
&gt;  {
&gt;         struct riscv_iommu_command cmd;
&gt; @@ -467,6 +560,62 @@ static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
&gt;         return riscv_iommu_post_sync(iommu, &amp;cmd, true);
&gt;  }
&gt;
&gt; +static void riscv_iommu_mm_invalidate(struct mmu_notifier *mn,
&gt; +                                     struct mm_struct *mm, unsigned long start,
&gt; +                                     unsigned long end)
&gt; +{
&gt; +       struct riscv_iommu_command cmd;
&gt; +       struct riscv_iommu_endpoint *endpoint;
&gt; +       struct riscv_iommu_domain *domain =
&gt; +           container_of(mn, struct riscv_iommu_domain, mn);
&gt; +       unsigned long iova;
&gt; +       /*
&gt; +        * The mm_types defines vm_end as the first byte after the end address,
&gt; +        * different from IOMMU subsystem using the last address of an address
&gt; +        * range. So do a simple translation here by updating what end means.
&gt; +        */
&gt; +       unsigned long payload = riscv_iommu_ats_inval_payload(start, end - 1, true);
&gt; +
&gt; +       riscv_iommu_cmd_inval_vma(&amp;cmd);
&gt; +       riscv_iommu_cmd_inval_set_gscid(&amp;cmd, 0);
&gt; +       riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
&gt; +       if (end &gt; start) {
&gt; +               /* Cover only the range that is needed */
&gt; +               for (iova = start; iova &lt; end; iova += PAGE_SIZE) {
&gt; +                       riscv_iommu_cmd_inval_set_addr(&amp;cmd, iova);
&gt; +                       riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +               }
&gt; +       } else {
&gt; +               riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +       }
&gt; +
&gt; +       riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt; +
&gt; +       /* ATS invalidation for every device and for specific translation range. */
&gt; +       list_for_each_entry(endpoint, &amp;domain-&gt;endpoints, domain) {
&gt; +               if (!endpoint-&gt;pasid_enabled)
&gt; +                       continue;
&gt; +
&gt; +               riscv_iommu_cmd_ats_inval(&amp;cmd);
&gt; +               riscv_iommu_cmd_ats_set_dseg(&amp;cmd, endpoint-&gt;domid);
&gt; +               riscv_iommu_cmd_ats_set_rid(&amp;cmd, endpoint-&gt;devid);
&gt; +               riscv_iommu_cmd_ats_set_pid(&amp;cmd, domain-&gt;pasid);
&gt; +               riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
&gt; +               riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +       }
&gt; +       riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_mm_release(struct mmu_notifier *mn, struct mm_struct *mm)
&gt; +{
&gt; +       /* TODO: removed from notifier, cleanup PSCID mapping, flush IOTLB */
&gt; +}
&gt; +
&gt; +static const struct mmu_notifier_ops riscv_iommu_mmuops = {
&gt; +       .release = riscv_iommu_mm_release,
&gt; +       .invalidate_range = riscv_iommu_mm_invalidate,
&gt; +};
&gt; +
&gt;  /* Command queue primary interrupt handler */
&gt;  static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data)
&gt;  {
&gt; @@ -608,6 +757,128 @@ static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct devi
&gt;         mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt;  }
&gt;
&gt; +/*
&gt; + * Get device reference based on device identifier (requester id).
&gt; + * Decrement reference count with put_device() call.
&gt; + */
&gt; +static struct device *riscv_iommu_get_device(struct riscv_iommu_device *iommu,
&gt; +                                            unsigned devid)
&gt; +{
&gt; +       struct rb_node *node;
&gt; +       struct riscv_iommu_endpoint *ep;
&gt; +       struct device *dev = NULL;
&gt; +
&gt; +       mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       node = iommu-&gt;eps.rb_node;
&gt; +       while (node &amp;&amp; !dev) {
&gt; +               ep = rb_entry(node, struct riscv_iommu_endpoint, node);
&gt; +               if (ep-&gt;devid &lt; devid)
&gt; +                       node = node-&gt;rb_right;
&gt; +               else if (ep-&gt;devid &gt; devid)
&gt; +                       node = node-&gt;rb_left;
&gt; +               else
&gt; +                       dev = get_device(ep-&gt;dev);
&gt; +       }
&gt; +
&gt; +       mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       return dev;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_ats_prgr(struct device *dev, struct iommu_page_response *msg)
&gt; +{
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +       struct riscv_iommu_command cmd;
&gt; +       u8 resp_code;
&gt; +       unsigned long payload;
&gt; +
&gt; +       switch (msg-&gt;code) {
&gt; +       case IOMMU_PAGE_RESP_SUCCESS:
&gt; +               resp_code = 0b0000;
&gt; +               break;
&gt; +       case IOMMU_PAGE_RESP_INVALID:
&gt; +               resp_code = 0b0001;
&gt; +               break;
&gt; +       case IOMMU_PAGE_RESP_FAILURE:
&gt; +               resp_code = 0b1111;
&gt; +               break;
&gt; +       }
&gt; +       payload = riscv_iommu_ats_prgr_payload(ep-&gt;devid, resp_code, msg-&gt;grpid);
&gt; +
&gt; +       /* ATS Page Request Group Response */
&gt; +       riscv_iommu_cmd_ats_prgr(&amp;cmd);
&gt; +       riscv_iommu_cmd_ats_set_dseg(&amp;cmd, ep-&gt;domid);
&gt; +       riscv_iommu_cmd_ats_set_rid(&amp;cmd, ep-&gt;devid);
&gt; +       if (msg-&gt;flags &amp; IOMMU_PAGE_RESP_PASID_VALID)
&gt; +               riscv_iommu_cmd_ats_set_pid(&amp;cmd, msg-&gt;pasid);
&gt; +       riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
&gt; +       riscv_iommu_post(ep-&gt;iommu, &amp;cmd);
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_page_request(struct riscv_iommu_device *iommu,
&gt; +                                    struct riscv_iommu_pq_record *req)
&gt; +{
&gt; +       struct iommu_fault_event event = { 0 };
&gt; +       struct iommu_fault_page_request *prm = &amp;event.fault.prm;
&gt; +       int ret;
&gt; +       struct device *dev;
&gt; +       unsigned devid = FIELD_GET(RISCV_IOMMU_PREQ_HDR_DID, req-&gt;hdr);
&gt; +
&gt; +       /* Ignore PGR Stop marker. */
&gt; +       if ((req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_M) == RISCV_IOMMU_PREQ_PAYLOAD_L)
&gt; +               return;
&gt; +
&gt; +       dev = riscv_iommu_get_device(iommu, devid);
&gt; +       if (!dev) {
&gt; +               /* TODO: Handle invalid page request */
&gt; +               return;
&gt; +       }
&gt; +
&gt; +       event.fault.type = IOMMU_FAULT_PAGE_REQ;
&gt; +
&gt; +       if (req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_L)
&gt; +               prm-&gt;flags |= IOMMU_FAULT_PAGE_REQUEST_LAST_PAGE;
&gt; +       if (req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_W)
&gt; +               prm-&gt;perm |= IOMMU_FAULT_PERM_WRITE;
&gt; +       if (req-&gt;payload &amp; RISCV_IOMMU_PREQ_PAYLOAD_R)
&gt; +               prm-&gt;perm |= IOMMU_FAULT_PERM_READ;
&gt; +
&gt; +       prm-&gt;grpid = FIELD_GET(RISCV_IOMMU_PREQ_PRG_INDEX, req-&gt;payload);
&gt; +       prm-&gt;addr = FIELD_GET(RISCV_IOMMU_PREQ_UADDR, req-&gt;payload) &lt;&lt; PAGE_SHIFT;
&gt; +
&gt; +       if (req-&gt;hdr &amp; RISCV_IOMMU_PREQ_HDR_PV) {
&gt; +               prm-&gt;flags |= IOMMU_FAULT_PAGE_REQUEST_PASID_VALID;
&gt; +               /* TODO: where to find this bit */
&gt; +               prm-&gt;flags |= IOMMU_FAULT_PAGE_RESPONSE_NEEDS_PASID;
&gt; +               prm-&gt;pasid = FIELD_GET(RISCV_IOMMU_PREQ_HDR_PID, req-&gt;hdr);
&gt; +       }
&gt; +
&gt; +       ret = iommu_report_device_fault(dev, &amp;event);
&gt; +       if (ret) {
&gt; +               struct iommu_page_response resp = {
&gt; +                       .grpid = prm-&gt;grpid,
&gt; +                       .code = IOMMU_PAGE_RESP_FAILURE,
&gt; +               };
&gt; +               if (prm-&gt;flags &amp; IOMMU_FAULT_PAGE_RESPONSE_NEEDS_PASID) {
&gt; +                       resp.flags |= IOMMU_PAGE_RESP_PASID_VALID;
&gt; +                       resp.pasid = prm-&gt;pasid;
&gt; +               }
&gt; +               riscv_iommu_ats_prgr(dev, &amp;resp);
&gt; +       }
&gt; +
&gt; +       put_device(dev);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_page_response(struct device *dev,
&gt; +                                    struct iommu_fault_event *evt,
&gt; +                                    struct iommu_page_response *msg)
&gt; +{
&gt; +       return riscv_iommu_ats_prgr(dev, msg);
&gt; +}
&gt; +
&gt;  /* Page request interface queue primary interrupt handler */
&gt;  static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data)
&gt;  {
&gt; @@ -626,7 +897,7 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt;         struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt;         struct riscv_iommu_device *iommu;
&gt;         struct riscv_iommu_pq_record *requests;
&gt; -       unsigned cnt, idx, ctrl;
&gt; +       unsigned cnt, len, idx, ctrl;
&gt;
&gt;         iommu = container_of(q, struct riscv_iommu_device, priq);
&gt;         requests = (struct riscv_iommu_pq_record *)q-&gt;base;
&gt; @@ -649,7 +920,8 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt;                 cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt;                 if (!cnt)
&gt;                         break;
&gt; -               dev_warn(iommu-&gt;dev, "unexpected %u page requests\n", cnt);
&gt; +               for (len = 0; len &lt; cnt; idx++, len++)
&gt; +                       riscv_iommu_page_request(iommu, &amp;requests[idx]);
&gt;                 riscv_iommu_queue_release(iommu, q, cnt);
&gt;         } while (1);
&gt;
&gt; @@ -660,6 +932,169 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt;   * Endpoint management
&gt;   */
&gt;
&gt; +/* Endpoint features/capabilities */
&gt; +static void riscv_iommu_disable_ep(struct riscv_iommu_endpoint *ep)
&gt; +{
&gt; +       struct pci_dev *pdev;
&gt; +
&gt; +       if (!dev_is_pci(ep-&gt;dev))
&gt; +               return;
&gt; +
&gt; +       pdev = to_pci_dev(ep-&gt;dev);
&gt; +
&gt; +       if (ep-&gt;pasid_enabled) {
&gt; +               pci_disable_ats(pdev);
&gt; +               pci_disable_pri(pdev);
&gt; +               pci_disable_pasid(pdev);
&gt; +               ep-&gt;pasid_enabled = false;
&gt; +       }
&gt; +}
&gt; +
&gt; +static void riscv_iommu_enable_ep(struct riscv_iommu_endpoint *ep)
&gt; +{
&gt; +       int rc, feat, num;
&gt; +       struct pci_dev *pdev;
&gt; +       struct device *dev = ep-&gt;dev;
&gt; +
&gt; +       if (!dev_is_pci(dev))
&gt; +               return;
&gt; +
&gt; +       if (!ep-&gt;iommu-&gt;iommu.max_pasids)
&gt; +               return;
&gt; +
&gt; +       pdev = to_pci_dev(dev);
&gt; +
&gt; +       if (!pci_ats_supported(pdev))
&gt; +               return;
&gt; +
&gt; +       if (!pci_pri_supported(pdev))
&gt; +               return;
&gt; +
&gt; +       feat = pci_pasid_features(pdev);
&gt; +       if (feat &lt; 0)
&gt; +               return;
&gt; +
&gt; +       num = pci_max_pasids(pdev);
&gt; +       if (!num) {
&gt; +               dev_warn(dev, "Can't enable PASID (num: %d)\n", num);
&gt; +               return;
&gt; +       }
&gt; +
&gt; +       if (num &gt; ep-&gt;iommu-&gt;iommu.max_pasids)
&gt; +               num = ep-&gt;iommu-&gt;iommu.max_pasids;
&gt; +
&gt; +       rc = pci_enable_pasid(pdev, feat);
&gt; +       if (rc) {
&gt; +               dev_warn(dev, "Can't enable PASID (rc: %d)\n", rc);
&gt; +               return;
&gt; +       }
&gt; +
&gt; +       rc = pci_reset_pri(pdev);
&gt; +       if (rc) {
&gt; +               dev_warn(dev, "Can't reset PRI (rc: %d)\n", rc);
&gt; +               pci_disable_pasid(pdev);
&gt; +               return;
&gt; +       }
&gt; +
&gt; +       /* TODO: Get supported PRI queue length, hard-code to 32 entries */
&gt; +       rc = pci_enable_pri(pdev, 32);
&gt; +       if (rc) {
&gt; +               dev_warn(dev, "Can't enable PRI (rc: %d)\n", rc);
&gt; +               pci_disable_pasid(pdev);
&gt; +               return;
&gt; +       }
&gt; +
&gt; +       rc = pci_enable_ats(pdev, PAGE_SHIFT);
&gt; +       if (rc) {
&gt; +               dev_warn(dev, "Can't enable ATS (rc: %d)\n", rc);
&gt; +               pci_disable_pri(pdev);
&gt; +               pci_disable_pasid(pdev);
&gt; +               return;
&gt; +       }
&gt; +
&gt; +       ep-&gt;pc = (struct riscv_iommu_pc *)get_zeroed_page(GFP_KERNEL);
&gt; +       if (!ep-&gt;pc) {
&gt; +               pci_disable_ats(pdev);
&gt; +               pci_disable_pri(pdev);
&gt; +               pci_disable_pasid(pdev);
&gt; +               return;
&gt; +       }
&gt; +
&gt; +       ep-&gt;pasid_enabled = true;
&gt; +       ep-&gt;pasid_feat = feat;
&gt; +       ep-&gt;pasid_bits = ilog2(num);
&gt; +
&gt; +       dev_dbg(ep-&gt;dev, "PASID/ATS support enabled, %d bits\n", ep-&gt;pasid_bits);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_enable_sva(struct device *dev)
&gt; +{
&gt; +       int ret;
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +       if (!ep || !ep-&gt;iommu || !ep-&gt;iommu-&gt;pq_work)
&gt; +               return -EINVAL;
&gt; +
&gt; +       if (!ep-&gt;pasid_enabled)
&gt; +               return -ENODEV;
&gt; +
&gt; +       ret = iopf_queue_add_device(ep-&gt;iommu-&gt;pq_work, dev);
&gt; +       if (ret)
&gt; +               return ret;
&gt; +
&gt; +       return iommu_register_device_fault_handler(dev, iommu_queue_iopf, dev);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_disable_sva(struct device *dev)
&gt; +{
&gt; +       int ret;
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +       ret = iommu_unregister_device_fault_handler(dev);
&gt; +       if (!ret)
&gt; +               ret = iopf_queue_remove_device(ep-&gt;iommu-&gt;pq_work, dev);
&gt; +
&gt; +       return ret;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_enable_iopf(struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +       if (ep &amp;&amp; ep-&gt;pasid_enabled)
&gt; +               return 0;
&gt; +
&gt; +       return -EINVAL;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_dev_enable_feat(struct device *dev, enum iommu_dev_features feat)
&gt; +{
&gt; +       switch (feat) {
&gt; +       case IOMMU_DEV_FEAT_IOPF:
&gt; +               return riscv_iommu_enable_iopf(dev);
&gt; +
&gt; +       case IOMMU_DEV_FEAT_SVA:
&gt; +               return riscv_iommu_enable_sva(dev);
&gt; +
&gt; +       default:
&gt; +               return -ENODEV;
&gt; +       }
&gt; +}
&gt; +
&gt; +static int riscv_iommu_dev_disable_feat(struct device *dev, enum iommu_dev_features feat)
&gt; +{
&gt; +       switch (feat) {
&gt; +       case IOMMU_DEV_FEAT_IOPF:
&gt; +               return 0;
&gt; +
&gt; +       case IOMMU_DEV_FEAT_SVA:
&gt; +               return riscv_iommu_disable_sva(dev);
&gt; +
&gt; +       default:
&gt; +               return -ENODEV;
&gt; +       }
&gt; +}
&gt; +
&gt;  static int riscv_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)
&gt;  {
&gt;         return iommu_fwspec_add_ids(dev, args-&gt;args, 1);
&gt; @@ -812,6 +1247,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;
&gt;         dev_iommu_priv_set(dev, ep);
&gt;         riscv_iommu_add_device(iommu, dev);
&gt; +       riscv_iommu_enable_ep(ep);
&gt;
&gt;         return &amp;iommu-&gt;iommu;
&gt;  }
&gt; @@ -843,6 +1279,8 @@ static void riscv_iommu_release_device(struct device *dev)
&gt;                 riscv_iommu_iodir_inv_devid(iommu, ep-&gt;devid);
&gt;         }
&gt;
&gt; +       riscv_iommu_disable_ep(ep);
&gt; +
&gt;         /* Remove endpoint from IOMMU tracking structures */
&gt;         mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt;         rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; @@ -878,7 +1316,8 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;             type != IOMMU_DOMAIN_DMA_FQ &amp;&amp;
&gt;             type != IOMMU_DOMAIN_UNMANAGED &amp;&amp;
&gt;             type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; -           type != IOMMU_DOMAIN_BLOCKED)
&gt; +           type != IOMMU_DOMAIN_BLOCKED &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_SVA)
&gt;                 return NULL;
&gt;
&gt;         domain = kzalloc(sizeof(*domain), GFP_KERNEL);
&gt; @@ -906,6 +1345,9 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;                 pr_warn("IOMMU domain is not empty!\n");
&gt;         }
&gt;
&gt; +       if (domain-&gt;mn.ops &amp;&amp; iommu_domain-&gt;mm)
&gt; +               mmu_notifier_unregister(&amp;domain-&gt;mn, iommu_domain-&gt;mm);
&gt; +
&gt;         if (domain-&gt;pgtbl.cookie)
&gt;                 free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
&gt;
&gt; @@ -1023,14 +1465,29 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;          */
&gt;         val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt;
&gt; -       dc-&gt;ta = cpu_to_le64(val);
&gt; -       dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +       if (ep-&gt;pasid_enabled) {
&gt; +               ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
&gt; +               ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +               dc-&gt;ta = 0;
&gt; +               dc-&gt;fsc = cpu_to_le64(virt_to_pfn(ep-&gt;pc) |
&gt; +                   FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8));
</span>
Could I know why we determinate to use PD8 directly? Rather than PD17 or PD20.

<span class=q>&gt; +       } else {
&gt; +               dc-&gt;ta = cpu_to_le64(val);
&gt; +               dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +       }
&gt;
&gt;         wmb();
&gt;
&gt;         /* Mark device context as valid, synchronise device context cache. */
&gt;         val = RISCV_IOMMU_DC_TC_V;
&gt;
&gt; +       if (ep-&gt;pasid_enabled) {
&gt; +               val |= RISCV_IOMMU_DC_TC_EN_ATS |
&gt; +                      RISCV_IOMMU_DC_TC_EN_PRI |
&gt; +                      RISCV_IOMMU_DC_TC_DPE |
&gt; +                      RISCV_IOMMU_DC_TC_PDTV;
&gt; +       }
&gt; +
&gt;         if (ep-&gt;iommu-&gt;cap &amp; RISCV_IOMMU_CAP_AMO) {
&gt;                 val |= RISCV_IOMMU_DC_TC_GADE |
&gt;                        RISCV_IOMMU_DC_TC_SADE;
&gt; @@ -1051,13 +1508,107 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;         return 0;
&gt;  }
&gt;
&gt; +static int riscv_iommu_set_dev_pasid(struct iommu_domain *iommu_domain,
&gt; +                                    struct device *dev, ioasid_t pasid)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +       u64 ta, fsc;
&gt; +
&gt; +       if (!iommu_domain || !iommu_domain-&gt;mm)
&gt; +               return -EINVAL;
&gt; +
&gt; +       /* Driver uses TC.DPE mode, PASID #0 is incorrect. */
&gt; +       if (pasid == 0)
&gt; +               return -EINVAL;
&gt; +
&gt; +       /* Incorrect domain identifier */
&gt; +       if ((int)domain-&gt;pscid &lt; 0)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       /* Process Context table should be set for pasid enabled endpoints. */
&gt; +       if (!ep || !ep-&gt;pasid_enabled || !ep-&gt;dc || !ep-&gt;pc)
&gt; +               return -ENODEV;
&gt; +
&gt; +       domain-&gt;pasid = pasid;
&gt; +       domain-&gt;iommu = ep-&gt;iommu;
&gt; +       domain-&gt;mn.ops = &amp;riscv_iommu_mmuops;
&gt; +
&gt; +       /* register mm notifier */
&gt; +       if (mmu_notifier_register(&amp;domain-&gt;mn, iommu_domain-&gt;mm))
&gt; +               return -ENODEV;
&gt; +
&gt; +       /* TODO: get SXL value for the process, use 32 bit or SATP mode */
&gt; +       fsc = virt_to_pfn(iommu_domain-&gt;mm-&gt;pgd) | satp_mode;
&gt; +       ta = RISCV_IOMMU_PC_TA_V | FIELD_PREP(RISCV_IOMMU_PC_TA_PSCID, domain-&gt;pscid);
&gt; +
&gt; +       fsc = le64_to_cpu(xchg_relaxed(&amp;(ep-&gt;pc[pasid].fsc), cpu_to_le64(fsc)));
&gt; +       ta = le64_to_cpu(xchg_relaxed(&amp;(ep-&gt;pc[pasid].ta), cpu_to_le64(ta)));
&gt; +
&gt; +       wmb();
&gt; +
&gt; +       if (ta &amp; RISCV_IOMMU_PC_TA_V) {
&gt; +               riscv_iommu_iodir_inv_pasid(ep-&gt;iommu, ep-&gt;devid, pasid);
&gt; +               riscv_iommu_iofence_sync(ep-&gt;iommu);
&gt; +       }
&gt; +
&gt; +       dev_info(dev, "domain type %d attached w/ PSCID %u PASID %u\n",
&gt; +           domain-&gt;domain.type, domain-&gt;pscid, domain-&gt;pasid);
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_remove_dev_pasid(struct device *dev, ioasid_t pasid)
&gt; +{
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +       struct riscv_iommu_command cmd;
&gt; +       unsigned long payload = riscv_iommu_ats_inval_all_payload(false);
&gt; +       u64 ta;
&gt; +
&gt; +       /* invalidate TA.V */
&gt; +       ta = le64_to_cpu(xchg_relaxed(&amp;(ep-&gt;pc[pasid].ta), 0));
&gt; +
&gt; +       wmb();
&gt; +
&gt; +       dev_info(dev, "domain removed w/ PSCID %u PASID %u\n",
&gt; +           (unsigned)FIELD_GET(RISCV_IOMMU_PC_TA_PSCID, ta), pasid);
&gt; +
&gt; +       /* 1. invalidate PDT entry */
&gt; +       riscv_iommu_iodir_inv_pasid(ep-&gt;iommu, ep-&gt;devid, pasid);
&gt; +
&gt; +       /* 2. invalidate all matching IOATC entries (if PASID was valid) */
&gt; +       if (ta &amp; RISCV_IOMMU_PC_TA_V) {
&gt; +               riscv_iommu_cmd_inval_vma(&amp;cmd);
&gt; +               riscv_iommu_cmd_inval_set_gscid(&amp;cmd, 0);
&gt; +               riscv_iommu_cmd_inval_set_pscid(&amp;cmd,
&gt; +                   FIELD_GET(RISCV_IOMMU_PC_TA_PSCID, ta));
&gt; +               riscv_iommu_post(ep-&gt;iommu, &amp;cmd);
&gt; +       }
&gt; +
&gt; +       /* 3. Wait IOATC flush to happen */
&gt; +       riscv_iommu_iofence_sync(ep-&gt;iommu);
&gt; +
&gt; +       /* 4. ATS invalidation */
&gt; +       riscv_iommu_cmd_ats_inval(&amp;cmd);
&gt; +       riscv_iommu_cmd_ats_set_dseg(&amp;cmd, ep-&gt;domid);
&gt; +       riscv_iommu_cmd_ats_set_rid(&amp;cmd, ep-&gt;devid);
&gt; +       riscv_iommu_cmd_ats_set_pid(&amp;cmd, pasid);
&gt; +       riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
&gt; +       riscv_iommu_post(ep-&gt;iommu, &amp;cmd);
&gt; +
&gt; +       /* 5. Wait DevATC flush to happen */
&gt; +       riscv_iommu_iofence_sync(ep-&gt;iommu);
&gt; +}
&gt; +
&gt;  static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt;                                           unsigned long *start, unsigned long *end,
&gt;                                           size_t *pgsize)
&gt;  {
&gt;         struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;         struct riscv_iommu_command cmd;
&gt; +       struct riscv_iommu_endpoint *endpoint;
&gt;         unsigned long iova;
&gt; +       unsigned long payload;
&gt;
&gt;         if (domain-&gt;mode == RISCV_IOMMU_DC_FSC_MODE_BARE)
&gt;                 return;
&gt; @@ -1065,6 +1616,12 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt;         /* Domain not attached to an IOMMU! */
&gt;         BUG_ON(!domain-&gt;iommu);
&gt;
&gt; +       if (start &amp;&amp; end) {
&gt; +               payload = riscv_iommu_ats_inval_payload(*start, *end, true);
&gt; +       } else {
&gt; +               payload = riscv_iommu_ats_inval_all_payload(true);
&gt; +       }
&gt; +
&gt;         riscv_iommu_cmd_inval_vma(&amp;cmd);
&gt;         riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
&gt;
&gt; @@ -1078,6 +1635,20 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt;                 riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt;         }
&gt;         riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt; +
&gt; +       /* ATS invalidation for every device and for every translation */
&gt; +       list_for_each_entry(endpoint, &amp;domain-&gt;endpoints, domain) {
&gt; +               if (!endpoint-&gt;pasid_enabled)
&gt; +                       continue;
&gt; +
&gt; +               riscv_iommu_cmd_ats_inval(&amp;cmd);
&gt; +               riscv_iommu_cmd_ats_set_dseg(&amp;cmd, endpoint-&gt;domid);
&gt; +               riscv_iommu_cmd_ats_set_rid(&amp;cmd, endpoint-&gt;devid);
&gt; +               riscv_iommu_cmd_ats_set_pid(&amp;cmd, domain-&gt;pasid);
&gt; +               riscv_iommu_cmd_ats_set_payload(&amp;cmd, payload);
&gt; +               riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +       }
&gt; +       riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt;  }
&gt;
&gt;  static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; @@ -1310,6 +1881,7 @@ static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned request
&gt;  static const struct iommu_domain_ops riscv_iommu_domain_ops = {
&gt;         .free = riscv_iommu_domain_free,
&gt;         .attach_dev = riscv_iommu_attach_dev,
&gt; +       .set_dev_pasid = riscv_iommu_set_dev_pasid,
&gt;         .map_pages = riscv_iommu_map_pages,
&gt;         .unmap_pages = riscv_iommu_unmap_pages,
&gt;         .iova_to_phys = riscv_iommu_iova_to_phys,
&gt; @@ -1326,9 +1898,13 @@ static const struct iommu_ops riscv_iommu_ops = {
&gt;         .probe_device = riscv_iommu_probe_device,
&gt;         .probe_finalize = riscv_iommu_probe_finalize,
&gt;         .release_device = riscv_iommu_release_device,
&gt; +       .remove_dev_pasid = riscv_iommu_remove_dev_pasid,
&gt;         .device_group = riscv_iommu_device_group,
&gt;         .get_resv_regions = riscv_iommu_get_resv_regions,
&gt;         .of_xlate = riscv_iommu_of_xlate,
&gt; +       .dev_enable_feat = riscv_iommu_dev_enable_feat,
&gt; +       .dev_disable_feat = riscv_iommu_dev_disable_feat,
&gt; +       .page_response = riscv_iommu_page_response,
&gt;         .default_domain_ops = &amp;riscv_iommu_domain_ops,
&gt;  };
&gt;
&gt; @@ -1340,6 +1916,7 @@ void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt;         riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt;         riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt;         riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt; +       iopf_queue_free(iommu-&gt;pq_work);
&gt;  }
&gt;
&gt;  int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; @@ -1362,6 +1939,12 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;         }
&gt;  #endif
&gt;
&gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_PD20)
&gt; +               iommu-&gt;iommu.max_pasids = 1u &lt;&lt; 20;
&gt; +       else if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_PD17)
&gt; +               iommu-&gt;iommu.max_pasids = 1u &lt;&lt; 17;
&gt; +       else if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_PD8)
&gt; +               iommu-&gt;iommu.max_pasids = 1u &lt;&lt; 8;
&gt;         /*
&gt;          * Assign queue lengths from module parameters if not already
&gt;          * set on the device tree.
&gt; @@ -1387,6 +1970,13 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;                 goto fail;
&gt;         if (!(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS))
&gt;                 goto no_ats;
&gt; +       /* PRI functionally depends on ATS’s capabilities. */
&gt; +       iommu-&gt;pq_work = iopf_queue_alloc(dev_name(dev));
&gt; +       if (!iommu-&gt;pq_work) {
&gt; +               dev_err(dev, "failed to allocate iopf queue\n");
&gt; +               ret = -ENOMEM;
&gt; +               goto fail;
&gt; +       }
&gt;
&gt;         ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_PAGE_REQUEST_QUEUE);
&gt;         if (ret)
&gt; @@ -1424,5 +2014,6 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;         riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt;         riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt;         riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt; +       iopf_queue_free(iommu-&gt;pq_work);
&gt;         return ret;
&gt;  }
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index fe32a4eff14e..83e8d00fd0f8 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -17,9 +17,11 @@
&gt;  #include &lt;linux/iova.h&gt;
&gt;  #include &lt;linux/io.h&gt;
&gt;  #include &lt;linux/idr.h&gt;
&gt; +#include &lt;linux/mmu_notifier.h&gt;
&gt;  #include &lt;linux/list.h&gt;
&gt;  #include &lt;linux/iommu.h&gt;
&gt;  #include &lt;linux/io-pgtable.h&gt;
&gt; +#include &lt;linux/mmu_notifier.h&gt;
</span>
You include the mmu_notifier.h twice in this header

<span class=q>&gt;
&gt;  #include "iommu-bits.h"
&gt;
&gt; @@ -76,6 +78,9 @@ struct riscv_iommu_device {
&gt;         unsigned ddt_mode;
&gt;         bool ddtp_in_iomem;
&gt;
&gt; +       /* I/O page fault queue */
&gt; +       struct iopf_queue *pq_work;
&gt; +
&gt;         /* hardware queues */
&gt;         struct riscv_iommu_queue cmdq;
&gt;         struct riscv_iommu_queue fltq;
&gt; @@ -91,11 +96,14 @@ struct riscv_iommu_domain {
&gt;         struct io_pgtable pgtbl;
&gt;
&gt;         struct list_head endpoints;
&gt; +       struct list_head notifiers;
&gt;         struct mutex lock;
&gt; +       struct mmu_notifier mn;
&gt;         struct riscv_iommu_device *iommu;
&gt;
&gt;         unsigned mode;          /* RIO_ATP_MODE_* enum */
&gt;         unsigned pscid;         /* RISC-V IOMMU PSCID */
&gt; +       ioasid_t pasid;         /* IOMMU_DOMAIN_SVA: Cached PASID */
&gt;
&gt;         pgd_t *pgd_root;        /* page table root pointer */
&gt;  };
&gt; @@ -107,10 +115,16 @@ struct riscv_iommu_endpoint {
&gt;         unsigned domid;                         /* PCI domain number, segment */
&gt;         struct rb_node node;                    /* device tracking node (lookup by devid) */
&gt;         struct riscv_iommu_dc *dc;              /* device context pointer */
&gt; +       struct riscv_iommu_pc *pc;              /* process context root, valid if pasid_enabled is true */
&gt;         struct riscv_iommu_device *iommu;       /* parent iommu device */
&gt;
&gt;         struct mutex lock;
&gt;         struct list_head domain;                /* endpoint attached managed domain */
&gt; +
&gt; +       /* end point info bits */
&gt; +       unsigned pasid_bits;
&gt; +       unsigned pasid_feat;
&gt; +       bool pasid_enabled;
&gt;  };
&gt;
&gt;  /* Helper functions and macros */
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#mdc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7 id=edc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0r1WDRc6fkgUkxJJnxKRuABvK6rdnLoZy7DngYVxV8gpA@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0r1WDRc6fkgUkxJJnxKRuABvK6rdnLoZy7DngYVxV8gpA@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0r1WDRc6fkgUkxJJnxKRuABvK6rdnLoZy7DngYVxV8gpA@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0r1WDRc6fkgUkxJJnxKRuABvK6rdnLoZy7DngYVxV8gpA@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0r1WDRc6fkgUkxJJnxKRuABvK6rdnLoZy7DngYVxV8gpA@mail.gmail.com/t/#u>nested</a>] <a href=#rdc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7>86+ messages in thread</a></pre><hr><pre><a href=#ee232eb871eb83c17c7ddecbc7cf02ed18dff1d71 id=me232eb871eb83c17c7ddecbc7cf02ed18dff1d71>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-29 12:58   ` <a href=#m47475dde350a53202c60665ebadd89162dc278d8>Zong Li</a>
<b>@ 2023-07-31  9:32     ` Nick Kossifidis</b>
  2023-07-31 13:15       ` <a href=#mea9e2032ef189efec9d6d487218475ae46f2902c>Zong Li</a>
  2023-08-02 20:50     ` <a href=#m407eda026cd986eb75d1fc2a13fa9e272c24019b>Tomasz Jeznach</a>
  <a href=#re232eb871eb83c17c7ddecbc7cf02ed18dff1d71>1 sibling, 1 reply; 86+ messages in thread</a>
From: Nick Kossifidis @ 2023-07-31  9:32 UTC (<a href=https://lore.kernel.org/lkml/3d4d9b22-8451-f4d5-bbd8-117988f3a545@ics.forth.gr/>permalink</a> / <a href=https://lore.kernel.org/lkml/3d4d9b22-8451-f4d5-bbd8-117988f3a545@ics.forth.gr/raw>raw</a>)
  To: Zong Li, Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230731093316">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, <a href="https://lore.kernel.org/linux-riscv/?t=20230731093316">linux-riscv</a>

On 7/29/23 15:58, Zong Li wrote:
<span class=q>&gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt;&gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt;&gt; +
&gt;&gt; +       /* For now we only support WSIs until we have AIA support */
&gt; 
&gt; I'm not completely understand AIA support here, because I saw the pci
&gt; case uses the MSI, and kernel seems to have the AIA implementation.
&gt; Could you please elaborate it?
&gt; 
</span>
When I wrote this we didn't have AIA in the kernel, and without IMSIC we 
can't have MSIs in the hart (we can still have MSIs in the PCIe controller).

<span class=q>&gt; 
&gt; Should we define the "interrupt-names" in dt-bindings?
&gt; 
</span>
Yes we should, along with queue lengths below.

<span class=q>&gt;&gt; +
&gt;&gt; +       /* Make sure fctl.WSI is set */
&gt;&gt; +       fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt;&gt; +       fctl |= RISCV_IOMMU_FCTL_WSI;
&gt;&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt;&gt; +
&gt;&gt; +       /* Parse Queue lengts */
&gt;&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt;&gt; +       if (!ret)
&gt;&gt; +               dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt;&gt; +
&gt;&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt;&gt; +       if (!ret)
&gt;&gt; +               dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt;&gt; +
&gt;&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt;&gt; +       if (!ret)
&gt;&gt; +               dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt;&gt; +
&gt;&gt;          dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt;&gt;
</span>
<a href=#me232eb871eb83c17c7ddecbc7cf02ed18dff1d71 id=ee232eb871eb83c17c7ddecbc7cf02ed18dff1d71>^</a> <a href=https://lore.kernel.org/lkml/3d4d9b22-8451-f4d5-bbd8-117988f3a545@ics.forth.gr/>permalink</a> <a href=https://lore.kernel.org/lkml/3d4d9b22-8451-f4d5-bbd8-117988f3a545@ics.forth.gr/raw>raw</a> <a href=https://lore.kernel.org/lkml/3d4d9b22-8451-f4d5-bbd8-117988f3a545@ics.forth.gr/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/3d4d9b22-8451-f4d5-bbd8-117988f3a545@ics.forth.gr/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/3d4d9b22-8451-f4d5-bbd8-117988f3a545@ics.forth.gr/t/#u>nested</a>] <a href=#re232eb871eb83c17c7ddecbc7cf02ed18dff1d71>86+ messages in thread</a></pre><hr><pre><a href=#eea9e2032ef189efec9d6d487218475ae46f2902c id=mea9e2032ef189efec9d6d487218475ae46f2902c>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-31  9:32     ` <a href=#me232eb871eb83c17c7ddecbc7cf02ed18dff1d71>Nick Kossifidis</a>
<b>@ 2023-07-31 13:15       ` Zong Li</b>
  2023-07-31 23:35         ` <a href=#m117ba0417f5cf6088454a6ff06bb517c3c128b86>Nick Kossifidis</a>
  <a href=#rea9e2032ef189efec9d6d487218475ae46f2902c>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-07-31 13:15 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0puxuHA2cEyb2+TobkoFTc=7MQqtv7DYbuZdvf0T8+iUQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0puxuHA2cEyb2+TobkoFTc=7MQqtv7DYbuZdvf0T8+iUQ@mail.gmail.com/raw">raw</a>)
  To: Nick Kossifidis
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230731131608">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, <a href="https://lore.kernel.org/linux-riscv/?t=20230731131608">linux-riscv</a>

On Mon, Jul 31, 2023 at 5:32 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
<span class=q>&gt;
&gt; On 7/29/23 15:58, Zong Li wrote:
&gt; &gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt;&gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; &gt;&gt; +
&gt; &gt;&gt; +       /* For now we only support WSIs until we have AIA support */
&gt; &gt;
&gt; &gt; I'm not completely understand AIA support here, because I saw the pci
&gt; &gt; case uses the MSI, and kernel seems to have the AIA implementation.
&gt; &gt; Could you please elaborate it?
&gt; &gt;
&gt;
&gt; When I wrote this we didn't have AIA in the kernel, and without IMSIC we
&gt; can't have MSIs in the hart (we can still have MSIs in the PCIe controller).
</span>
Thanks for your clarification, do we support the MSI in next version?

<span class=q>&gt;
&gt; &gt;
&gt; &gt; Should we define the "interrupt-names" in dt-bindings?
&gt; &gt;
&gt;
&gt; Yes we should, along with queue lengths below.
&gt;
&gt; &gt;&gt; +
&gt; &gt;&gt; +       /* Make sure fctl.WSI is set */
&gt; &gt;&gt; +       fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; &gt;&gt; +       fctl |= RISCV_IOMMU_FCTL_WSI;
&gt; &gt;&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; &gt;&gt; +
&gt; &gt;&gt; +       /* Parse Queue lengts */
&gt; &gt;&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt;&gt; +       if (!ret)
&gt; &gt;&gt; +               dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt;&gt; +
&gt; &gt;&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt;&gt; +       if (!ret)
&gt; &gt;&gt; +               dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt;&gt; +
&gt; &gt;&gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt;&gt; +       if (!ret)
&gt; &gt;&gt; +               dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt;&gt; +
&gt; &gt;&gt;          dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt;&gt;
</span>
<a href=#mea9e2032ef189efec9d6d487218475ae46f2902c id=eea9e2032ef189efec9d6d487218475ae46f2902c>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0puxuHA2cEyb2+TobkoFTc=7MQqtv7DYbuZdvf0T8+iUQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0puxuHA2cEyb2+TobkoFTc=7MQqtv7DYbuZdvf0T8+iUQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0puxuHA2cEyb2+TobkoFTc=7MQqtv7DYbuZdvf0T8+iUQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0puxuHA2cEyb2+TobkoFTc=7MQqtv7DYbuZdvf0T8+iUQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0puxuHA2cEyb2+TobkoFTc=7MQqtv7DYbuZdvf0T8+iUQ@mail.gmail.com/t/#u">nested</a>] <a href=#rea9e2032ef189efec9d6d487218475ae46f2902c>86+ messages in thread</a></pre><hr><pre><a href=#e117ba0417f5cf6088454a6ff06bb517c3c128b86 id=m117ba0417f5cf6088454a6ff06bb517c3c128b86>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-31 13:15       ` <a href=#mea9e2032ef189efec9d6d487218475ae46f2902c>Zong Li</a>
<b>@ 2023-07-31 23:35         ` Nick Kossifidis</b>
  2023-08-01  0:37           ` <a href=#m12841e87db77013d6e9d0c13504791fa53f52482>Zong Li</a>
  <a href=#r117ba0417f5cf6088454a6ff06bb517c3c128b86>0 siblings, 1 reply; 86+ messages in thread</a>
From: Nick Kossifidis @ 2023-07-31 23:35 UTC (<a href=https://lore.kernel.org/lkml/dc3974f0-500c-b7d3-c8ca-df069dbd02a8@ics.forth.gr/>permalink</a> / <a href=https://lore.kernel.org/lkml/dc3974f0-500c-b7d3-c8ca-df069dbd02a8@ics.forth.gr/raw>raw</a>)
  To: Zong Li
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230731233542">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, <a href="https://lore.kernel.org/linux-riscv/?t=20230731233542">linux-riscv</a>

On 7/31/23 16:15, Zong Li wrote:
<span class=q>&gt; On Mon, Jul 31, 2023 at 5:32 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt;&gt;
&gt;&gt; On 7/29/23 15:58, Zong Li wrote:
&gt;&gt;&gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt;&gt;&gt;&gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt;&gt;&gt;&gt; +
&gt;&gt;&gt;&gt; +       /* For now we only support WSIs until we have AIA support */
&gt;&gt;&gt;
&gt;&gt;&gt; I'm not completely understand AIA support here, because I saw the pci
&gt;&gt;&gt; case uses the MSI, and kernel seems to have the AIA implementation.
&gt;&gt;&gt; Could you please elaborate it?
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; When I wrote this we didn't have AIA in the kernel, and without IMSIC we
&gt;&gt; can't have MSIs in the hart (we can still have MSIs in the PCIe controller).
&gt; 
&gt; Thanks for your clarification, do we support the MSI in next version?
&gt; 
</span>
I don't think there is an IOMMU implementation out there (emulated or in 
hw) that can do MSIs and is not a pcie device (the QEMU implementation 
is a pcie device). If we have something to test this against, and we 
also have an IMSIC etc, we can work on that.

<a href=#m117ba0417f5cf6088454a6ff06bb517c3c128b86 id=e117ba0417f5cf6088454a6ff06bb517c3c128b86>^</a> <a href=https://lore.kernel.org/lkml/dc3974f0-500c-b7d3-c8ca-df069dbd02a8@ics.forth.gr/>permalink</a> <a href=https://lore.kernel.org/lkml/dc3974f0-500c-b7d3-c8ca-df069dbd02a8@ics.forth.gr/raw>raw</a> <a href=https://lore.kernel.org/lkml/dc3974f0-500c-b7d3-c8ca-df069dbd02a8@ics.forth.gr/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/dc3974f0-500c-b7d3-c8ca-df069dbd02a8@ics.forth.gr/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/dc3974f0-500c-b7d3-c8ca-df069dbd02a8@ics.forth.gr/t/#u>nested</a>] <a href=#r117ba0417f5cf6088454a6ff06bb517c3c128b86>86+ messages in thread</a></pre><hr><pre><a href=#e12841e87db77013d6e9d0c13504791fa53f52482 id=m12841e87db77013d6e9d0c13504791fa53f52482>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-31 23:35         ` <a href=#m117ba0417f5cf6088454a6ff06bb517c3c128b86>Nick Kossifidis</a>
<b>@ 2023-08-01  0:37           ` Zong Li</b>
  2023-08-02 20:28             ` <a href=#m4e963b463685688ec10151f89f3672b74268594b>Tomasz Jeznach</a>
  <a href=#r12841e87db77013d6e9d0c13504791fa53f52482>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-08-01  0:37 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0pz5U2i3V7P2qYnhZf5fpcNUrs4J24in2ffMncK7yx6pw@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0pz5U2i3V7P2qYnhZf5fpcNUrs4J24in2ffMncK7yx6pw@mail.gmail.com/raw>raw</a>)
  To: Nick Kossifidis
  Cc: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230801003812">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, <a href="https://lore.kernel.org/linux-riscv/?t=20230801003812">linux-riscv</a>

On Tue, Aug 1, 2023 at 7:35 AM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
<span class=q>&gt;
&gt; On 7/31/23 16:15, Zong Li wrote:
&gt; &gt; On Mon, Jul 31, 2023 at 5:32 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; On 7/29/23 15:58, Zong Li wrote:
&gt; &gt;&gt;&gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt;&gt;&gt;&gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; &gt;&gt;&gt;&gt; +
&gt; &gt;&gt;&gt;&gt; +       /* For now we only support WSIs until we have AIA support */
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; I'm not completely understand AIA support here, because I saw the pci
&gt; &gt;&gt;&gt; case uses the MSI, and kernel seems to have the AIA implementation.
&gt; &gt;&gt;&gt; Could you please elaborate it?
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; When I wrote this we didn't have AIA in the kernel, and without IMSIC we
&gt; &gt;&gt; can't have MSIs in the hart (we can still have MSIs in the PCIe controller).
&gt; &gt;
&gt; &gt; Thanks for your clarification, do we support the MSI in next version?
&gt; &gt;
&gt;
&gt; I don't think there is an IOMMU implementation out there (emulated or in
&gt; hw) that can do MSIs and is not a pcie device (the QEMU implementation
&gt; is a pcie device). If we have something to test this against, and we
&gt; also have an IMSIC etc, we can work on that.
</span>
I guess I can assist with that. We have an IOMMU hardware (non-pcie
device) that has already implemented the MSI functionality, and I have
conducted testing on it. Perhaps let me add the related implementation
here after this series is merged.

<a href=#m12841e87db77013d6e9d0c13504791fa53f52482 id=e12841e87db77013d6e9d0c13504791fa53f52482>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0pz5U2i3V7P2qYnhZf5fpcNUrs4J24in2ffMncK7yx6pw@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0pz5U2i3V7P2qYnhZf5fpcNUrs4J24in2ffMncK7yx6pw@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0pz5U2i3V7P2qYnhZf5fpcNUrs4J24in2ffMncK7yx6pw@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0pz5U2i3V7P2qYnhZf5fpcNUrs4J24in2ffMncK7yx6pw@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0pz5U2i3V7P2qYnhZf5fpcNUrs4J24in2ffMncK7yx6pw@mail.gmail.com/t/#u>nested</a>] <a href=#r12841e87db77013d6e9d0c13504791fa53f52482>86+ messages in thread</a></pre><hr><pre><a href=#e6bea4b3cd6bb3324224d86b9abb254943fb6124a id=m6bea4b3cd6bb3324224d86b9abb254943fb6124a>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-28  2:42   ` <a href=#m522f968d0909aad51fe7e480809ea548917990fa>Zong Li</a>
<b>@ 2023-08-02 20:15     ` Tomasz Jeznach</b>
  2023-08-02 20:25       ` <a href=#m64fbb77e574cead28d126c26f5193ed27f5df4af>Conor Dooley</a>
  2023-08-03  3:37       ` <a href=#m37555fe53501d9e3bd60231c586cec52ef1fe838>Zong Li</a>
  <a href=#r6bea4b3cd6bb3324224d86b9abb254943fb6124a>0 siblings, 2 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-08-02 20:15 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u5Sr0XigUbhna0E-Zk=U76CLZZ4LbM0u4ahPaN5+nOK6A@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u5Sr0XigUbhna0E-Zk=U76CLZZ4LbM0u4ahPaN5+nOK6A@mail.gmail.com/raw">raw</a>)
  To: Zong Li
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230802201538">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230802201538">linux-riscv</a>

On Thu, Jul 27, 2023 at 7:42 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
<span class=q>&gt;
&gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt;
&gt; &gt; +static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; &gt; +{
&gt; &gt; +       struct device *dev = &amp;pdev-&gt;dev;
&gt; &gt; +       struct riscv_iommu_device *iommu = NULL;
&gt; &gt; +       struct resource *res = NULL;
&gt; &gt; +       int ret = 0;
&gt; &gt; +
&gt; &gt; +       iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; &gt; +       if (!iommu)
&gt; &gt; +               return -ENOMEM;
&gt; &gt; +
&gt; &gt; +       iommu-&gt;dev = dev;
&gt; &gt; +       dev_set_drvdata(dev, iommu);
&gt; &gt; +
&gt; &gt; +       res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
&gt; &gt; +       if (!res) {
&gt; &gt; +               dev_err(dev, "could not find resource for register region\n");
&gt; &gt; +               return -EINVAL;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       iommu-&gt;reg = devm_platform_get_and_ioremap_resource(pdev, 0, &amp;res);
&gt; &gt; +       if (IS_ERR(iommu-&gt;reg)) {
&gt; &gt; +               ret = dev_err_probe(dev, PTR_ERR(iommu-&gt;reg),
&gt; &gt; +                                   "could not map register region\n");
&gt; &gt; +               goto fail;
&gt; &gt; +       };
&gt; &gt; +
&gt; &gt; +       iommu-&gt;reg_phys = res-&gt;start;
&gt; &gt; +
&gt; &gt; +       ret = -ENODEV;
&gt; &gt; +
&gt; &gt; +       /* Sanity check: Did we get the whole register space ? */
&gt; &gt; +       if ((res-&gt;end - res-&gt;start + 1) &lt; RISCV_IOMMU_REG_SIZE) {
&gt; &gt; +               dev_err(dev, "device region smaller than register file (0x%llx)\n",
&gt; &gt; +                       res-&gt;end - res-&gt;start);
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt;
&gt; Could we assume that DT should be responsible for specifying the right size?
&gt;
</span>
This only to validate DT provided info and driver expected register
file size. Expectation is that DT will provide right size.


<span class=q>&gt; &gt; +static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_domain *domain;
&gt; &gt; +
&gt; &gt; +       if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; &gt; +           type != IOMMU_DOMAIN_BLOCKED)
&gt; &gt; +               return NULL;
&gt; &gt; +
&gt; &gt; +       domain = kzalloc(sizeof(*domain), GFP_KERNEL);
&gt; &gt; +       if (!domain)
&gt; &gt; +               return NULL;
&gt; &gt; +
&gt; &gt; +       mutex_init(&amp;domain-&gt;lock);
&gt; &gt; +       INIT_LIST_HEAD(&amp;domain-&gt;endpoints);
&gt; &gt; +
&gt; &gt; +       domain-&gt;domain.ops = &amp;riscv_iommu_domain_ops;
&gt; &gt; +       domain-&gt;mode = RISCV_IOMMU_DC_FSC_MODE_BARE;
&gt; &gt; +       domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt; &gt; +                                       RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
&gt; &gt; +
&gt; &gt; +       printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; &gt; +
&gt;
&gt; Could it uses pr_xxx instead of printk?
&gt;
</span>
Absolutely, fixed here and elsewhere. Also, used dev_dbg wherever applicable.

<span class=q>&gt; &gt; +
&gt; &gt; +static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned requested_mode)
&gt; &gt; +{
&gt; &gt; +       struct device *dev = iommu-&gt;dev;
&gt; &gt; +       u64 ddtp = 0;
&gt; &gt; +       u64 ddtp_paddr = 0;
&gt; &gt; +       unsigned mode = requested_mode;
&gt; &gt; +       unsigned mode_readback = 0;
&gt; &gt; +
&gt; &gt; +       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; &gt; +       if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY)
&gt; &gt; +               return -EBUSY;
&gt; &gt; +
&gt; &gt; +       /* Disallow state transtion from xLVL to xLVL. */
&gt; &gt; +       switch (FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp)) {
&gt; &gt; +       case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; &gt; +       case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; &gt; +               break;
&gt; &gt; +       default:
&gt; &gt; +               if ((mode != RISCV_IOMMU_DDTP_MODE_BARE)
&gt; &gt; +                   &amp;&amp; (mode != RISCV_IOMMU_DDTP_MODE_OFF))
&gt; &gt; +                       return -EINVAL;
&gt; &gt; +               break;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; + retry:
&gt;
&gt; We need to consider the `iommu.passthrough` before we set up the mode
&gt; in switch case, something like
&gt;
</span>
This function is only to execute configuration and set device directory mode.
Handling global iommu.passthrough policy is implemented in
riscv_iommu_init() call (patch #7).

Best,
- Tomasz

<a href=#m6bea4b3cd6bb3324224d86b9abb254943fb6124a id=e6bea4b3cd6bb3324224d86b9abb254943fb6124a>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u5Sr0XigUbhna0E-Zk=U76CLZZ4LbM0u4ahPaN5+nOK6A@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u5Sr0XigUbhna0E-Zk=U76CLZZ4LbM0u4ahPaN5+nOK6A@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u5Sr0XigUbhna0E-Zk=U76CLZZ4LbM0u4ahPaN5+nOK6A@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u5Sr0XigUbhna0E-Zk=U76CLZZ4LbM0u4ahPaN5+nOK6A@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u5Sr0XigUbhna0E-Zk=U76CLZZ4LbM0u4ahPaN5+nOK6A@mail.gmail.com/t/#u">nested</a>] <a href=#r6bea4b3cd6bb3324224d86b9abb254943fb6124a>86+ messages in thread</a></pre><hr><pre><a href=#e64fbb77e574cead28d126c26f5193ed27f5df4af id=m64fbb77e574cead28d126c26f5193ed27f5df4af>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-08-02 20:15     ` <a href=#m6bea4b3cd6bb3324224d86b9abb254943fb6124a>Tomasz Jeznach</a>
<b>@ 2023-08-02 20:25       ` Conor Dooley</b>
  2023-08-03  3:37       ` <a href=#m37555fe53501d9e3bd60231c586cec52ef1fe838>Zong Li</a>
  <a href=#r64fbb77e574cead28d126c26f5193ed27f5df4af>1 sibling, 0 replies; 86+ messages in thread</a>
From: Conor Dooley @ 2023-08-02 20:25 UTC (<a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/>permalink</a> / <a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Zong Li, Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230802202546">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230802202546">linux-riscv</a>

<a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/1-a.txt>[-- Attachment #1: Type: text/plain, Size: 2079 bytes --]</a>

On Wed, Aug 02, 2023 at 01:15:22PM -0700, Tomasz Jeznach wrote:
<span class=q>&gt; On Thu, Jul 27, 2023 at 7:42 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; +static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct device *dev = &amp;pdev-&gt;dev;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu = NULL;
&gt; &gt; &gt; +       struct resource *res = NULL;
&gt; &gt; &gt; +       int ret = 0;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; &gt; &gt; +       if (!iommu)
&gt; &gt; &gt; +               return -ENOMEM;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;dev = dev;
&gt; &gt; &gt; +       dev_set_drvdata(dev, iommu);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
&gt; &gt; &gt; +       if (!res) {
&gt; &gt; &gt; +               dev_err(dev, "could not find resource for register region\n");
&gt; &gt; &gt; +               return -EINVAL;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;reg = devm_platform_get_and_ioremap_resource(pdev, 0, &amp;res);
&gt; &gt; &gt; +       if (IS_ERR(iommu-&gt;reg)) {
&gt; &gt; &gt; +               ret = dev_err_probe(dev, PTR_ERR(iommu-&gt;reg),
&gt; &gt; &gt; +                                   "could not map register region\n");
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       };
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;reg_phys = res-&gt;start;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       ret = -ENODEV;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Sanity check: Did we get the whole register space ? */
&gt; &gt; &gt; +       if ((res-&gt;end - res-&gt;start + 1) &lt; RISCV_IOMMU_REG_SIZE) {
&gt; &gt; &gt; +               dev_err(dev, "device region smaller than register file (0x%llx)\n",
&gt; &gt; &gt; +                       res-&gt;end - res-&gt;start);
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt;
&gt; &gt; Could we assume that DT should be responsible for specifying the right size?
&gt; &gt;
&gt; 
&gt; This only to validate DT provided info and driver expected register
&gt; file size. Expectation is that DT will provide right size.
</span>
FWIW this check seems needless to me, it's not the kernels job to
validate the devicetree.


<a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/2-signature.asc>[-- Attachment #2: signature.asc --]
[-- Type: application/pgp-signature, Size: 228 bytes --]</a>

<a href=#m64fbb77e574cead28d126c26f5193ed27f5df4af id=e64fbb77e574cead28d126c26f5193ed27f5df4af>^</a> <a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/>permalink</a> <a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/raw>raw</a> <a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/20230802-maimed-spotted-5fa1fe4be386@spud/t/#u>nested</a>] <a href=#r64fbb77e574cead28d126c26f5193ed27f5df4af>86+ messages in thread</a></pre><hr><pre><a href=#e4e963b463685688ec10151f89f3672b74268594b id=m4e963b463685688ec10151f89f3672b74268594b>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-08-01  0:37           ` <a href=#m12841e87db77013d6e9d0c13504791fa53f52482>Zong Li</a>
<b>@ 2023-08-02 20:28             ` Tomasz Jeznach</b>
  <a href=#r4e963b463685688ec10151f89f3672b74268594b>0 siblings, 0 replies; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-08-02 20:28 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u7BodgZO2R03e9gyMGCR+bU58aAq2-uKYUSF4F7=Xiifg@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u7BodgZO2R03e9gyMGCR+bU58aAq2-uKYUSF4F7=Xiifg@mail.gmail.com/raw">raw</a>)
  To: Zong Li
  Cc: Nick Kossifidis, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley, Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230802202907">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, <a href="https://lore.kernel.org/linux-riscv/?t=20230802202907">linux-riscv</a>

On Mon, Jul 31, 2023 at 5:38 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
<span class=q>&gt;
&gt; On Tue, Aug 1, 2023 at 7:35 AM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt; &gt;
&gt; &gt; On 7/31/23 16:15, Zong Li wrote:
&gt; &gt; &gt; On Mon, Jul 31, 2023 at 5:32 PM Nick Kossifidis &lt;mick@ics.forth.gr&gt; wrote:
&gt; &gt; &gt;&gt;
&gt; &gt; &gt;&gt; On 7/29/23 15:58, Zong Li wrote:
&gt; &gt; &gt;&gt;&gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt;&gt;&gt;&gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; &gt; &gt;&gt;&gt;&gt; +
&gt; &gt; &gt;&gt;&gt;&gt; +       /* For now we only support WSIs until we have AIA support */
&gt; &gt; &gt;&gt;&gt;
&gt; &gt; &gt;&gt;&gt; I'm not completely understand AIA support here, because I saw the pci
&gt; &gt; &gt;&gt;&gt; case uses the MSI, and kernel seems to have the AIA implementation.
&gt; &gt; &gt;&gt;&gt; Could you please elaborate it?
&gt; &gt; &gt;&gt;&gt;
&gt; &gt; &gt;&gt;
&gt; &gt; &gt;&gt; When I wrote this we didn't have AIA in the kernel, and without IMSIC we
&gt; &gt; &gt;&gt; can't have MSIs in the hart (we can still have MSIs in the PCIe controller).
&gt; &gt; &gt;
&gt; &gt; &gt; Thanks for your clarification, do we support the MSI in next version?
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; I don't think there is an IOMMU implementation out there (emulated or in
&gt; &gt; hw) that can do MSIs and is not a pcie device (the QEMU implementation
&gt; &gt; is a pcie device). If we have something to test this against, and we
&gt; &gt; also have an IMSIC etc, we can work on that.
&gt;
&gt; I guess I can assist with that. We have an IOMMU hardware (non-pcie
&gt; device) that has already implemented the MSI functionality, and I have
&gt; conducted testing on it. Perhaps let me add the related implementation
&gt; here after this series is merged.
</span>
Thanks, getting MSI support for non-PCIe IOMMU hardware would be great!

best,
- Tomasz

<a href=#m4e963b463685688ec10151f89f3672b74268594b id=e4e963b463685688ec10151f89f3672b74268594b>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u7BodgZO2R03e9gyMGCR+bU58aAq2-uKYUSF4F7=Xiifg@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u7BodgZO2R03e9gyMGCR+bU58aAq2-uKYUSF4F7=Xiifg@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u7BodgZO2R03e9gyMGCR+bU58aAq2-uKYUSF4F7=Xiifg@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u7BodgZO2R03e9gyMGCR+bU58aAq2-uKYUSF4F7=Xiifg@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u7BodgZO2R03e9gyMGCR+bU58aAq2-uKYUSF4F7=Xiifg@mail.gmail.com/t/#u">nested</a>] <a href=#r4e963b463685688ec10151f89f3672b74268594b>86+ messages in thread</a></pre><hr><pre><a href=#e407eda026cd986eb75d1fc2a13fa9e272c24019b id=m407eda026cd986eb75d1fc2a13fa9e272c24019b>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-29 12:58   ` <a href=#m47475dde350a53202c60665ebadd89162dc278d8>Zong Li</a>
  2023-07-31  9:32     ` <a href=#me232eb871eb83c17c7ddecbc7cf02ed18dff1d71>Nick Kossifidis</a>
<b>@ 2023-08-02 20:50     ` Tomasz Jeznach</b>
  2023-08-03  8:24       ` <a href=#m5d2c47156d2d94a03257441a04bb19a53bb29675>Zong Li</a>
  <a href=#r407eda026cd986eb75d1fc2a13fa9e272c24019b>1 sibling, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2023-08-02 20:50 UTC (<a href=https://lore.kernel.org/lkml/CAH2o1u5P-y8UF-nCXGPs8kiKk3Y1MY8XVdDCcjp+5+zdDqxZXQ@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CAH2o1u5P-y8UF-nCXGPs8kiKk3Y1MY8XVdDCcjp+5+zdDqxZXQ@mail.gmail.com/raw>raw</a>)
  To: Zong Li
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230802205103">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230802205103">linux-riscv</a>

On Sat, Jul 29, 2023 at 5:58 AM Zong Li &lt;zong.li@sifive.com&gt; wrote:
<span class=q>&gt;
&gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt;
&gt; &gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; &gt;
&gt; &gt; Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; &gt; Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; &gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; ---
&gt; &gt;  drivers/iommu/riscv/iommu-pci.c      |  72 ++++
&gt; &gt;  drivers/iommu/riscv/iommu-platform.c |  66 +++
&gt; &gt;  drivers/iommu/riscv/iommu.c          | 604 ++++++++++++++++++++++++++-
&gt; &gt;  drivers/iommu/riscv/iommu.h          |  28 ++
&gt; &gt;  4 files changed, 769 insertions(+), 1 deletion(-)
&gt; &gt;
&gt; &gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; &gt; index c91f963d7a29..9ea0647f7b92 100644
&gt; &gt; --- a/drivers/iommu/riscv/iommu-pci.c
&gt; &gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; &gt; @@ -34,6 +34,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt; &gt;  {
&gt; &gt;         struct device *dev = &amp;pdev-&gt;dev;
&gt; &gt;         struct riscv_iommu_device *iommu;
&gt; &gt; +       u64 icvec;
&gt; &gt;         int ret;
&gt; &gt;
&gt; &gt;         ret = pci_enable_device_mem(pdev);
&gt; &gt; @@ -67,14 +68,84 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt; &gt;         iommu-&gt;dev = dev;
&gt; &gt;         dev_set_drvdata(dev, iommu);
&gt; &gt;
&gt; &gt; +       /* Check device reported capabilities. */
&gt; &gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; &gt; +
&gt; &gt; +       /* The PCI driver only uses MSIs, make sure the IOMMU supports this */
&gt; &gt; +       switch (FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap)) {
&gt; &gt; +       case RISCV_IOMMU_CAP_IGS_MSI:
&gt; &gt; +       case RISCV_IOMMU_CAP_IGS_BOTH:
&gt; &gt; +               break;
&gt; &gt; +       default:
&gt; &gt; +               dev_err(dev, "unable to use message-signaled interrupts\n");
&gt; &gt; +               ret = -ENODEV;
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt;         dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
&gt; &gt;         pci_set_master(pdev);
&gt; &gt;
&gt; &gt; +       /* Allocate and assign IRQ vectors for the various events */
&gt; &gt; +       ret = pci_alloc_irq_vectors(pdev, 1, RISCV_IOMMU_INTR_COUNT, PCI_IRQ_MSIX);
&gt; &gt; +       if (ret &lt; 0) {
&gt; &gt; +               dev_err(dev, "unable to allocate irq vectors\n");
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       ret = -ENODEV;
&gt; &gt; +
&gt; &gt; +       iommu-&gt;irq_cmdq = msi_get_virq(dev, RISCV_IOMMU_INTR_CQ);
&gt; &gt; +       if (!iommu-&gt;irq_cmdq) {
&gt; &gt; +               dev_warn(dev, "no MSI vector %d for the command queue\n",
&gt; &gt; +                        RISCV_IOMMU_INTR_CQ);
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       iommu-&gt;irq_fltq = msi_get_virq(dev, RISCV_IOMMU_INTR_FQ);
&gt; &gt; +       if (!iommu-&gt;irq_fltq) {
&gt; &gt; +               dev_warn(dev, "no MSI vector %d for the fault/event queue\n",
&gt; &gt; +                        RISCV_IOMMU_INTR_FQ);
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; &gt; +               iommu-&gt;irq_pm = msi_get_virq(dev, RISCV_IOMMU_INTR_PM);
&gt; &gt; +               if (!iommu-&gt;irq_pm) {
&gt; &gt; +                       dev_warn(dev,
&gt; &gt; +                                "no MSI vector %d for performance monitoring\n",
&gt; &gt; +                                RISCV_IOMMU_INTR_PM);
&gt; &gt; +                       goto fail;
&gt; &gt; +               }
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; &gt; +               iommu-&gt;irq_priq = msi_get_virq(dev, RISCV_IOMMU_INTR_PQ);
&gt; &gt; +               if (!iommu-&gt;irq_priq) {
&gt; &gt; +                       dev_warn(dev,
&gt; &gt; +                                "no MSI vector %d for page-request queue\n",
&gt; &gt; +                                RISCV_IOMMU_INTR_PQ);
&gt; &gt; +                       goto fail;
&gt; &gt; +               }
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       /* Set simple 1:1 mapping for MSI vectors */
&gt; &gt; +       icvec = FIELD_PREP(RISCV_IOMMU_IVEC_CIV, RISCV_IOMMU_INTR_CQ) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_IVEC_FIV, RISCV_IOMMU_INTR_FQ);
&gt; &gt; +
&gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM)
&gt; &gt; +               icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PMIV, RISCV_IOMMU_INTR_PM);
&gt; &gt; +
&gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS)
&gt; &gt; +               icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PIV, RISCV_IOMMU_INTR_PQ);
&gt; &gt; +
&gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IVEC, icvec);
&gt; &gt; +
&gt; &gt;         ret = riscv_iommu_init(iommu);
&gt; &gt;         if (!ret)
&gt; &gt;                 return ret;
&gt; &gt;
&gt; &gt;   fail:
&gt; &gt; +       pci_free_irq_vectors(pdev);
&gt; &gt;         pci_clear_master(pdev);
&gt; &gt;         pci_release_regions(pdev);
&gt; &gt;         pci_disable_device(pdev);
&gt; &gt; @@ -85,6 +156,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt; &gt;  static void riscv_iommu_pci_remove(struct pci_dev *pdev)
&gt; &gt;  {
&gt; &gt;         riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; &gt; +       pci_free_irq_vectors(pdev);
&gt; &gt;         pci_clear_master(pdev);
&gt; &gt;         pci_release_regions(pdev);
&gt; &gt;         pci_disable_device(pdev);
&gt; &gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; &gt; index e4e8ca6711e7..35935d3c7ef4 100644
&gt; &gt; --- a/drivers/iommu/riscv/iommu-platform.c
&gt; &gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; &gt; @@ -20,6 +20,8 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; &gt;         struct device *dev = &amp;pdev-&gt;dev;
&gt; &gt;         struct riscv_iommu_device *iommu = NULL;
&gt; &gt;         struct resource *res = NULL;
&gt; &gt; +       u32 fctl = 0;
&gt; &gt; +       int irq = 0;
&gt; &gt;         int ret = 0;
&gt; &gt;
&gt; &gt;         iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; &gt; @@ -53,6 +55,70 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; &gt;                 goto fail;
&gt; &gt;         }
&gt; &gt;
&gt; &gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; &gt; +
&gt; &gt; +       /* For now we only support WSIs until we have AIA support */
&gt;
&gt; I'm not completely understand AIA support here, because I saw the pci
&gt; case uses the MSI, and kernel seems to have the AIA implementation.
&gt; Could you please elaborate it?
&gt;
&gt; &gt; +       ret = FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap);
&gt; &gt; +       if (ret == RISCV_IOMMU_CAP_IGS_MSI) {
&gt; &gt; +               dev_err(dev, "IOMMU only supports MSIs\n");
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       /* Parse IRQ assignment */
&gt; &gt; +       irq = platform_get_irq_byname_optional(pdev, "cmdq");
&gt; &gt; +       if (irq &gt; 0)
&gt; &gt; +               iommu-&gt;irq_cmdq = irq;
&gt; &gt; +       else {
&gt; &gt; +               dev_err(dev, "no IRQ provided for the command queue\n");
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       irq = platform_get_irq_byname_optional(pdev, "fltq");
&gt; &gt; +       if (irq &gt; 0)
&gt; &gt; +               iommu-&gt;irq_fltq = irq;
&gt; &gt; +       else {
&gt; &gt; +               dev_err(dev, "no IRQ provided for the fault/event queue\n");
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; &gt; +               irq = platform_get_irq_byname_optional(pdev, "pm");
&gt; &gt; +               if (irq &gt; 0)
&gt; &gt; +                       iommu-&gt;irq_pm = irq;
&gt; &gt; +               else {
&gt; &gt; +                       dev_err(dev, "no IRQ provided for performance monitoring\n");
&gt; &gt; +                       goto fail;
&gt; &gt; +               }
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; &gt; +               irq = platform_get_irq_byname_optional(pdev, "priq");
&gt; &gt; +               if (irq &gt; 0)
&gt; &gt; +                       iommu-&gt;irq_priq = irq;
&gt; &gt; +               else {
&gt; &gt; +                       dev_err(dev, "no IRQ provided for the page-request queue\n");
&gt; &gt; +                       goto fail;
&gt; &gt; +               }
&gt; &gt; +       }
&gt;
&gt; Should we define the "interrupt-names" in dt-bindings?
&gt;
</span>
Yes, this was brought up earlier wrt dt-bindings.

I'm considering removal of interrupt names from DT (and get-byname
option), as IOMMU hardware cause-to-vector remapping `icvec` should be
used to map interrupt source to actual interrupt vector. If possible
device driver should map cause to interrupt (based on number of
vectors available) or rely on ICVEC WARL properties to discover fixed
cause-to-vector mapping in the hardware.

Please let me know if this is reasonable change.

<span class=q>&gt; &gt; +
&gt; &gt; +       /* Make sure fctl.WSI is set */
&gt; &gt; +       fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; &gt; +       fctl |= RISCV_IOMMU_FCTL_WSI;
&gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; &gt; +
&gt; &gt; +       /* Parse Queue lengts */
&gt; &gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt; +       if (!ret)
&gt; &gt; +               dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt; +
&gt; &gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt; +       if (!ret)
&gt; &gt; +               dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt; +
&gt; &gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt; +       if (!ret)
&gt; &gt; +               dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt; +
&gt; &gt;         dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt;
&gt; &gt;         return riscv_iommu_init(iommu);
&gt; &gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; &gt; index 31dc3c458e13..5c4cf9875302 100644
&gt; &gt; --- a/drivers/iommu/riscv/iommu.c
&gt; &gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; &gt; @@ -45,6 +45,18 @@ static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt; &gt;  module_param(ddt_mode, int, 0644);
&gt; &gt;  MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt; &gt;
&gt; &gt; +static int cmdq_length = 1024;
&gt; &gt; +module_param(cmdq_length, int, 0644);
&gt; &gt; +MODULE_PARM_DESC(cmdq_length, "Command queue length.");
&gt; &gt; +
&gt; &gt; +static int fltq_length = 1024;
&gt; &gt; +module_param(fltq_length, int, 0644);
&gt; &gt; +MODULE_PARM_DESC(fltq_length, "Fault queue length.");
&gt; &gt; +
&gt; &gt; +static int priq_length = 1024;
&gt; &gt; +module_param(priq_length, int, 0644);
&gt; &gt; +MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
&gt; &gt; +
&gt; &gt;  /* IOMMU PSCID allocation namespace. */
&gt; &gt;  #define RISCV_IOMMU_MAX_PSCID  (1U &lt;&lt; 20)
&gt; &gt;  static DEFINE_IDA(riscv_iommu_pscids);
&gt; &gt; @@ -65,6 +77,497 @@ static DEFINE_IDA(riscv_iommu_pscids);
&gt; &gt;  static const struct iommu_domain_ops riscv_iommu_domain_ops;
&gt; &gt;  static const struct iommu_ops riscv_iommu_ops;
&gt; &gt;
&gt; &gt; +/*
&gt; &gt; + * Common queue management routines
&gt; &gt; + */
&gt; &gt; +
&gt; &gt; +/* Note: offsets are the same for all queues */
&gt; &gt; +#define Q_HEAD(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQH - RISCV_IOMMU_REG_CQB))
&gt; &gt; +#define Q_TAIL(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQT - RISCV_IOMMU_REG_CQB))
&gt; &gt; +
&gt; &gt; +static unsigned riscv_iommu_queue_consume(struct riscv_iommu_device *iommu,
&gt; &gt; +                                         struct riscv_iommu_queue *q, unsigned *ready)
&gt; &gt; +{
&gt; &gt; +       u32 tail = riscv_iommu_readl(iommu, Q_TAIL(q));
&gt; &gt; +       *ready = q-&gt;lui;
&gt; &gt; +
&gt; &gt; +       BUG_ON(q-&gt;cnt &lt;= tail);
&gt; &gt; +       if (q-&gt;lui &lt;= tail)
&gt; &gt; +               return tail - q-&gt;lui;
&gt; &gt; +       return q-&gt;cnt - q-&gt;lui;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static void riscv_iommu_queue_release(struct riscv_iommu_device *iommu,
&gt; &gt; +                                     struct riscv_iommu_queue *q, unsigned count)
&gt; &gt; +{
&gt; &gt; +       q-&gt;lui = (q-&gt;lui + count) &amp; (q-&gt;cnt - 1);
&gt; &gt; +       riscv_iommu_writel(iommu, Q_HEAD(q), q-&gt;lui);
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static u32 riscv_iommu_queue_ctrl(struct riscv_iommu_device *iommu,
&gt; &gt; +                                 struct riscv_iommu_queue *q, u32 val)
&gt; &gt; +{
&gt; &gt; +       cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
&gt; &gt; +
&gt; &gt; +       riscv_iommu_writel(iommu, q-&gt;qcr, val);
&gt; &gt; +       do {
&gt; &gt; +               val = riscv_iommu_readl(iommu, q-&gt;qcr);
&gt; &gt; +               if (!(val &amp; RISCV_IOMMU_QUEUE_BUSY))
&gt; &gt; +                       break;
&gt; &gt; +               cpu_relax();
&gt; &gt; +       } while (get_cycles() &lt; end_cycles);
&gt; &gt; +
&gt; &gt; +       return val;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static void riscv_iommu_queue_free(struct riscv_iommu_device *iommu,
&gt; &gt; +                                  struct riscv_iommu_queue *q)
&gt; &gt; +{
&gt; &gt; +       size_t size = q-&gt;len * q-&gt;cnt;
&gt; &gt; +
&gt; &gt; +       riscv_iommu_queue_ctrl(iommu, q, 0);
&gt; &gt; +
&gt; &gt; +       if (q-&gt;base) {
&gt; &gt; +               if (q-&gt;in_iomem)
&gt; &gt; +                       iounmap(q-&gt;base);
&gt; &gt; +               else
&gt; &gt; +                       dmam_free_coherent(iommu-&gt;dev, size, q-&gt;base, q-&gt;base_dma);
&gt; &gt; +       }
&gt; &gt; +       if (q-&gt;irq)
&gt; &gt; +               free_irq(q-&gt;irq, q);
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data);
&gt; &gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data);
&gt; &gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data);
&gt; &gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data);
&gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; &gt; +
&gt; &gt; +static int riscv_iommu_queue_init(struct riscv_iommu_device *iommu, int queue_id)
&gt; &gt; +{
&gt; &gt; +       struct device *dev = iommu-&gt;dev;
&gt; &gt; +       struct riscv_iommu_queue *q = NULL;
&gt; &gt; +       size_t queue_size = 0;
&gt; &gt; +       irq_handler_t irq_check;
&gt; &gt; +       irq_handler_t irq_process;
&gt; &gt; +       const char *name;
&gt; &gt; +       int count = 0;
&gt; &gt; +       int irq = 0;
&gt; &gt; +       unsigned order = 0;
&gt; &gt; +       u64 qbr_val = 0;
&gt; &gt; +       u64 qbr_readback = 0;
&gt; &gt; +       u64 qbr_paddr = 0;
&gt; &gt; +       int ret = 0;
&gt; &gt; +
&gt; &gt; +       switch (queue_id) {
&gt; &gt; +       case RISCV_IOMMU_COMMAND_QUEUE:
&gt; &gt; +               q = &amp;iommu-&gt;cmdq;
&gt; &gt; +               q-&gt;len = sizeof(struct riscv_iommu_command);
&gt; &gt; +               count = iommu-&gt;cmdq_len;
&gt; &gt; +               irq = iommu-&gt;irq_cmdq;
&gt; &gt; +               irq_check = riscv_iommu_cmdq_irq_check;
&gt; &gt; +               irq_process = riscv_iommu_cmdq_process;
&gt; &gt; +               q-&gt;qbr = RISCV_IOMMU_REG_CQB;
&gt; &gt; +               q-&gt;qcr = RISCV_IOMMU_REG_CQCSR;
&gt; &gt; +               name = "cmdq";
&gt; &gt; +               break;
&gt; &gt; +       case RISCV_IOMMU_FAULT_QUEUE:
&gt; &gt; +               q = &amp;iommu-&gt;fltq;
&gt; &gt; +               q-&gt;len = sizeof(struct riscv_iommu_fq_record);
&gt; &gt; +               count = iommu-&gt;fltq_len;
&gt; &gt; +               irq = iommu-&gt;irq_fltq;
&gt; &gt; +               irq_check = riscv_iommu_fltq_irq_check;
&gt; &gt; +               irq_process = riscv_iommu_fltq_process;
&gt; &gt; +               q-&gt;qbr = RISCV_IOMMU_REG_FQB;
&gt; &gt; +               q-&gt;qcr = RISCV_IOMMU_REG_FQCSR;
&gt; &gt; +               name = "fltq";
&gt; &gt; +               break;
&gt; &gt; +       case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; &gt; +               q = &amp;iommu-&gt;priq;
&gt; &gt; +               q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; &gt; +               count = iommu-&gt;priq_len;
&gt; &gt; +               irq = iommu-&gt;irq_priq;
&gt; &gt; +               irq_check = riscv_iommu_priq_irq_check;
&gt; &gt; +               irq_process = riscv_iommu_priq_process;
&gt; &gt; +               q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; &gt; +               q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; &gt; +               name = "priq";
&gt; &gt; +               break;
&gt; &gt; +       default:
&gt; &gt; +               dev_err(dev, "invalid queue interrupt index in queue_init!\n");
&gt; &gt; +               return -EINVAL;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       /* Polling not implemented */
&gt; &gt; +       if (!irq)
&gt; &gt; +               return -ENODEV;
&gt; &gt; +
&gt; &gt; +       /* Allocate queue in memory and set the base register */
&gt; &gt; +       order = ilog2(count);
&gt; &gt; +       do {
&gt; &gt; +               queue_size = q-&gt;len * (1ULL &lt;&lt; order);
&gt; &gt; +               q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
&gt; &gt; +               if (q-&gt;base || queue_size &lt; PAGE_SIZE)
&gt; &gt; +                       break;
&gt; &gt; +
&gt; &gt; +               order--;
&gt; &gt; +       } while (1);
&gt; &gt; +
&gt; &gt; +       if (!q-&gt;base) {
&gt; &gt; +               dev_err(dev, "failed to allocate %s queue (cnt: %u)\n", name, count);
&gt; &gt; +               return -ENOMEM;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; &gt; +
&gt; &gt; +       qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; &gt; +
&gt; &gt; +       riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; &gt; +
&gt; &gt; +       /*
&gt; &gt; +        * Queue base registers are WARL, so it's possible that whatever we wrote
&gt; &gt; +        * there was illegal/not supported by the hw in which case we need to make
&gt; &gt; +        * sure we set a supported PPN and/or queue size.
&gt; &gt; +        */
&gt; &gt; +       qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; &gt; +       if (qbr_readback == qbr_val)
&gt; &gt; +               goto irq;
&gt; &gt; +
&gt; &gt; +       dmam_free_coherent(dev, queue_size, q-&gt;base, q-&gt;base_dma);
&gt; &gt; +
&gt; &gt; +       /* Get supported queue size */
&gt; &gt; +       order = FIELD_GET(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, qbr_readback) + 1;
&gt; &gt; +       q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; &gt; +       queue_size = q-&gt;len * q-&gt;cnt;
&gt; &gt; +
&gt; &gt; +       /*
&gt; &gt; +        * In case we also failed to set PPN, it means the field is hardcoded and the
&gt; &gt; +        * queue resides in I/O memory instead, so get its physical address and
&gt; &gt; +        * ioremap it.
&gt; &gt; +        */
&gt; &gt; +       qbr_paddr = ppn_to_phys(qbr_readback);
&gt; &gt; +       if (qbr_paddr != q-&gt;base_dma) {
&gt; &gt; +               dev_info(dev,
&gt; &gt; +                        "hardcoded ppn in %s base register, using io memory for the queue\n",
&gt; &gt; +                        name);
&gt; &gt; +               dev_info(dev, "queue length for %s set to %i\n", name, q-&gt;cnt);
&gt; &gt; +               q-&gt;in_iomem = true;
&gt; &gt; +               q-&gt;base = ioremap(qbr_paddr, queue_size);
&gt; &gt; +               if (!q-&gt;base) {
&gt; &gt; +                       dev_err(dev, "failed to map %s queue (cnt: %u)\n", name, q-&gt;cnt);
&gt; &gt; +                       return -ENOMEM;
&gt; &gt; +               }
&gt; &gt; +               q-&gt;base_dma = qbr_paddr;
&gt; &gt; +       } else {
&gt; &gt; +               /*
&gt; &gt; +                * We only failed to set the queue size, re-try to allocate memory with
&gt; &gt; +                * the queue size supported by the hw.
&gt; &gt; +                */
&gt; &gt; +               dev_info(dev, "hardcoded queue size in %s base register\n", name);
&gt; &gt; +               dev_info(dev, "retrying with queue length: %i\n", q-&gt;cnt);
&gt; &gt; +               q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
&gt; &gt; +               if (!q-&gt;base) {
&gt; &gt; +                       dev_err(dev, "failed to allocate %s queue (cnt: %u)\n",
&gt; &gt; +                               name, q-&gt;cnt);
&gt; &gt; +                       return -ENOMEM;
&gt; &gt; +               }
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; &gt; +       riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; &gt; +
&gt; &gt; +       /* Final check to make sure hw accepted our write */
&gt; &gt; +       qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; &gt; +       if (qbr_readback != qbr_val) {
&gt; &gt; +               dev_err(dev, "failed to set base register for %s\n", name);
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; + irq:
&gt; &gt; +       if (request_threaded_irq(irq, irq_check, irq_process, IRQF_ONESHOT | IRQF_SHARED,
&gt; &gt; +                                dev_name(dev), q)) {
&gt; &gt; +               dev_err(dev, "fail to request irq %d for %s\n", irq, name);
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       q-&gt;irq = irq;
&gt; &gt; +
&gt; &gt; +       /* Note: All RIO_xQ_EN/IE fields are in the same offsets */
&gt; &gt; +       ret =
&gt; &gt; +           riscv_iommu_queue_ctrl(iommu, q,
&gt; &gt; +                                  RISCV_IOMMU_QUEUE_ENABLE |
&gt; &gt; +                                  RISCV_IOMMU_QUEUE_INTR_ENABLE);
&gt; &gt; +       if (ret &amp; RISCV_IOMMU_QUEUE_BUSY) {
&gt; &gt; +               dev_err(dev, "%s init timeout\n", name);
&gt; &gt; +               ret = -EBUSY;
&gt; &gt; +               goto fail;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       return 0;
&gt; &gt; +
&gt; &gt; + fail:
&gt; &gt; +       riscv_iommu_queue_free(iommu, q);
&gt; &gt; +       return 0;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/*
&gt; &gt; + * I/O MMU Command queue chapter 3.1
&gt; &gt; + */
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_inval_vma(struct riscv_iommu_command *cmd)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 =
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_OPCODE,
&gt; &gt; +                      RISCV_IOMMU_CMD_IOTINVAL_OPCODE) | FIELD_PREP(RISCV_IOMMU_CMD_FUNC,
&gt; &gt; +                                                                    RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA);
&gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; &gt; +                                                 u64 addr)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; &gt; +       cmd-&gt;dword1 = addr;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_inval_set_pscid(struct riscv_iommu_command *cmd,
&gt; &gt; +                                                  unsigned pscid)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_PSCID, pscid) |
&gt; &gt; +           RISCV_IOMMU_CMD_IOTINVAL_PSCV;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_inval_set_gscid(struct riscv_iommu_command *cmd,
&gt; &gt; +                                                  unsigned gscid)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_GSCID, gscid) |
&gt; &gt; +           RISCV_IOMMU_CMD_IOTINVAL_GV;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_iofence(struct riscv_iommu_command *cmd)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C);
&gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_iofence_set_av(struct riscv_iommu_command *cmd,
&gt; &gt; +                                                 u64 addr, u32 data)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_IOFENCE_DATA, data) | RISCV_IOMMU_CMD_IOFENCE_AV;
&gt; &gt; +       cmd-&gt;dword1 = (addr &gt;&gt; 2);
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_iodir_inval_ddt(struct riscv_iommu_command *cmd)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT);
&gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_iodir_inval_pdt(struct riscv_iommu_command *cmd)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT);
&gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static inline void riscv_iommu_cmd_iodir_set_did(struct riscv_iommu_command *cmd,
&gt; &gt; +                                                unsigned devid)
&gt; &gt; +{
&gt; &gt; +       cmd-&gt;dword0 |=
&gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_IODIR_DID, devid) | RISCV_IOMMU_CMD_IODIR_DV;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/* TODO: Convert into lock-less MPSC implementation. */
&gt; &gt; +static bool riscv_iommu_post_sync(struct riscv_iommu_device *iommu,
&gt; &gt; +                                 struct riscv_iommu_command *cmd, bool sync)
&gt; &gt; +{
&gt; &gt; +       u32 head, tail, next, last;
&gt; &gt; +       unsigned long flags;
&gt; &gt; +
&gt; &gt; +       spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; +       head = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; +       tail = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; +       last = iommu-&gt;cmdq.lui;
&gt; &gt; +       if (tail != last) {
&gt; &gt; +               spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; +               /*
&gt; &gt; +                * FIXME: This is a workaround for dropped MMIO writes/reads on QEMU platform.
&gt; &gt; +                *        While debugging of the problem is still ongoing, this provides
&gt; &gt; +                *        a simple impolementation of try-again policy.
&gt; &gt; +                *        Will be changed to lock-less algorithm in the feature.
&gt; &gt; +                */
&gt; &gt; +               dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (1st)\n", last, tail);
&gt; &gt; +               spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; +               tail =
&gt; &gt; +                   riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; +               last = iommu-&gt;cmdq.lui;
&gt; &gt; +               if (tail != last) {
&gt; &gt; +                       spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; +                       dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (2nd)\n", last, tail);
&gt; &gt; +                       spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; +               }
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       next = (last + 1) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; +       if (next != head) {
&gt; &gt; +               struct riscv_iommu_command *ptr = iommu-&gt;cmdq.base;
&gt; &gt; +               ptr[last] = *cmd;
&gt; &gt; +               wmb();
&gt; &gt; +               riscv_iommu_writel(iommu, RISCV_IOMMU_REG_CQT, next);
&gt; &gt; +               iommu-&gt;cmdq.lui = next;
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; +
&gt; &gt; +       if (sync &amp;&amp; head != next) {
&gt; &gt; +               cycles_t start_time = get_cycles();
&gt; &gt; +               while (1) {
&gt; &gt; +                       last = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp;
&gt; &gt; +                           (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; +                       if (head &lt; next &amp;&amp; last &gt;= next)
&gt; &gt; +                               break;
&gt; &gt; +                       if (head &gt; next &amp;&amp; last &lt; head &amp;&amp; last &gt;= next)
&gt; &gt; +                               break;
&gt; &gt; +                       if (RISCV_IOMMU_TIMEOUT &lt; (get_cycles() - start_time)) {
&gt;
&gt; This condition will be imprecise, because here is not in irq disabled
&gt; context, it will be scheduled out or preempted. When we come back
&gt; here, it might be over 1 second, but the IOFENCE is actually
&gt; completed.
&gt;
</span>
Good point. Thank.


<span class=q>&gt; &gt; +                               dev_err(iommu-&gt;dev, "IOFENCE TIMEOUT\n");
&gt; &gt; +                               return false;
&gt; &gt; +                       }
&gt; &gt; +                       cpu_relax();
&gt; &gt; +               }
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       return next != head;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static bool riscv_iommu_post(struct riscv_iommu_device *iommu,
&gt; &gt; +                            struct riscv_iommu_command *cmd)
&gt; &gt; +{
&gt; &gt; +       return riscv_iommu_post_sync(iommu, cmd, false);
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_command cmd;
&gt; &gt; +       riscv_iommu_cmd_iofence(&amp;cmd);
&gt; &gt; +       return riscv_iommu_post_sync(iommu, &amp;cmd, true);
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/* Command queue primary interrupt handler */
&gt; &gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; +       struct riscv_iommu_device *iommu =
&gt; &gt; +           container_of(q, struct riscv_iommu_device, cmdq);
&gt; &gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; &gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_CIP)
&gt; &gt; +               return IRQ_WAKE_THREAD;
&gt; &gt; +       return IRQ_NONE;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/* Command queue interrupt hanlder thread function */
&gt; &gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; +       struct riscv_iommu_device *iommu;
&gt; &gt; +       unsigned ctrl;
&gt; &gt; +
&gt; &gt; +       iommu = container_of(q, struct riscv_iommu_device, cmdq);
&gt; &gt; +
&gt; &gt; +       /* Error reporting, clear error reports if any. */
&gt; &gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQCSR);
&gt; &gt; +       if (ctrl &amp; (RISCV_IOMMU_CQCSR_CQMF |
&gt; &gt; +                   RISCV_IOMMU_CQCSR_CMD_TO | RISCV_IOMMU_CQCSR_CMD_ILL)) {
&gt; &gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;cmdq, ctrl);
&gt; &gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; +                                    "Command queue error: fault: %d tout: %d err: %d\n",
&gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CQMF),
&gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_TO),
&gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_ILL));
&gt;
&gt; We need to handle the error by either adjusting the tail to remove the
&gt; failed command or fixing the failed command itself. Otherwise, the
&gt; failed command will keep in the queue and IOMMU will try to execute
&gt; it. I guess the first option might be easier to implement.
&gt;
</span>
Correct. Thanks for pointing this out.
Error handling / recovery was not pushed in this series. There is
work-in-progress series to handle various types of failures, including
command processing errors, DDT misconfiguration, queue overflows,
device reported faults handling, etc.  I can bring some of the error
handling here, if needed. Otherwise I'd prefer to keep it as separate
series, sent out once this one is merged.

<span class=q>&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       /* Clear fault interrupt pending. */
&gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_CIP);
&gt; &gt; +
&gt; &gt; +       return IRQ_HANDLED;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/*
&gt; &gt; + * Fault/event queue, chapter 3.2
&gt; &gt; + */
&gt; &gt; +
&gt; &gt; +static void riscv_iommu_fault_report(struct riscv_iommu_device *iommu,
&gt; &gt; +                                    struct riscv_iommu_fq_record *event)
&gt; &gt; +{
&gt; &gt; +       unsigned err, devid;
&gt; &gt; +
&gt; &gt; +       err = FIELD_GET(RISCV_IOMMU_FQ_HDR_CAUSE, event-&gt;hdr);
&gt; &gt; +       devid = FIELD_GET(RISCV_IOMMU_FQ_HDR_DID, event-&gt;hdr);
&gt; &gt; +
&gt; &gt; +       dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; +                            "Fault %d devid: %d" " iotval: %llx iotval2: %llx\n", err,
&gt; &gt; +                            devid, event-&gt;iotval, event-&gt;iotval2);
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/* Fault/event queue primary interrupt handler */
&gt; &gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; +       struct riscv_iommu_device *iommu =
&gt; &gt; +           container_of(q, struct riscv_iommu_device, fltq);
&gt; &gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; &gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_FIP)
&gt; &gt; +               return IRQ_WAKE_THREAD;
&gt; &gt; +       return IRQ_NONE;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/* Fault queue interrupt hanlder thread function */
&gt; &gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; +       struct riscv_iommu_device *iommu;
&gt; &gt; +       struct riscv_iommu_fq_record *events;
&gt; &gt; +       unsigned cnt, len, idx, ctrl;
&gt; &gt; +
&gt; &gt; +       iommu = container_of(q, struct riscv_iommu_device, fltq);
&gt; &gt; +       events = (struct riscv_iommu_fq_record *)q-&gt;base;
&gt; &gt; +
&gt; &gt; +       /* Error reporting, clear error reports if any. */
&gt; &gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FQCSR);
&gt; &gt; +       if (ctrl &amp; (RISCV_IOMMU_FQCSR_FQMF | RISCV_IOMMU_FQCSR_FQOF)) {
&gt; &gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;fltq, ctrl);
&gt; &gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; +                                    "Fault queue error: fault: %d full: %d\n",
&gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQMF),
&gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQOF));
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       /* Clear fault interrupt pending. */
&gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_FIP);
&gt; &gt; +
&gt; &gt; +       /* Report fault events. */
&gt; &gt; +       do {
&gt; &gt; +               cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; &gt; +               if (!cnt)
&gt; &gt; +                       break;
&gt; &gt; +               for (len = 0; len &lt; cnt; idx++, len++)
&gt; &gt; +                       riscv_iommu_fault_report(iommu, &amp;events[idx]);
&gt; &gt; +               riscv_iommu_queue_release(iommu, q, cnt);
&gt; &gt; +       } while (1);
&gt; &gt; +
&gt; &gt; +       return IRQ_HANDLED;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/*
&gt; &gt; + * Page request queue, chapter 3.3
&gt; &gt; + */
&gt; &gt; +
&gt; &gt;  /*
&gt; &gt;   * Register device for IOMMU tracking.
&gt; &gt;   */
&gt; &gt; @@ -97,6 +600,54 @@ static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct devi
&gt; &gt;         mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; &gt;  }
&gt; &gt;
&gt; &gt; +/* Page request interface queue primary interrupt handler */
&gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; +       struct riscv_iommu_device *iommu =
&gt; &gt; +           container_of(q, struct riscv_iommu_device, priq);
&gt; &gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; &gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_PIP)
&gt; &gt; +               return IRQ_WAKE_THREAD;
&gt; &gt; +       return IRQ_NONE;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt; +/* Page request interface queue interrupt hanlder thread function */
&gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt; &gt; +{
&gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; +       struct riscv_iommu_device *iommu;
&gt; &gt; +       struct riscv_iommu_pq_record *requests;
&gt; &gt; +       unsigned cnt, idx, ctrl;
&gt; &gt; +
&gt; &gt; +       iommu = container_of(q, struct riscv_iommu_device, priq);
&gt; &gt; +       requests = (struct riscv_iommu_pq_record *)q-&gt;base;
&gt; &gt; +
&gt; &gt; +       /* Error reporting, clear error reports if any. */
&gt; &gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_PQCSR);
&gt; &gt; +       if (ctrl &amp; (RISCV_IOMMU_PQCSR_PQMF | RISCV_IOMMU_PQCSR_PQOF)) {
&gt; &gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;priq, ctrl);
&gt; &gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; +                                    "Page request queue error: fault: %d full: %d\n",
&gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQMF),
&gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQOF));
&gt; &gt; +       }
&gt; &gt; +
&gt; &gt; +       /* Clear page request interrupt pending. */
&gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_PIP);
&gt; &gt; +
&gt; &gt; +       /* Process page requests. */
&gt; &gt; +       do {
&gt; &gt; +               cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; &gt; +               if (!cnt)
&gt; &gt; +                       break;
&gt; &gt; +               dev_warn(iommu-&gt;dev, "unexpected %u page requests\n", cnt);
&gt; &gt; +               riscv_iommu_queue_release(iommu, q, cnt);
&gt; &gt; +       } while (1);
&gt; &gt; +
&gt; &gt; +       return IRQ_HANDLED;
&gt; &gt; +}
&gt; &gt; +
&gt; &gt;  /*
&gt; &gt;   * Endpoint management
&gt; &gt;   */
&gt; &gt; @@ -350,7 +901,29 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt; &gt;                                           unsigned long *start, unsigned long *end,
&gt; &gt;                                           size_t *pgsize)
&gt; &gt;  {
&gt; &gt; -       /* Command interface not implemented */
&gt; &gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; &gt; +       struct riscv_iommu_command cmd;
&gt; &gt; +       unsigned long iova;
&gt; &gt; +
&gt; &gt; +       if (domain-&gt;mode == RISCV_IOMMU_DC_FSC_MODE_BARE)
&gt; &gt; +               return;
&gt; &gt; +
&gt; &gt; +       /* Domain not attached to an IOMMU! */
&gt; &gt; +       BUG_ON(!domain-&gt;iommu);
&gt; &gt; +
&gt; &gt; +       riscv_iommu_cmd_inval_vma(&amp;cmd);
&gt; &gt; +       riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
&gt; &gt; +
&gt; &gt; +       if (start &amp;&amp; end &amp;&amp; pgsize) {
&gt; &gt; +               /* Cover only the range that is needed */
&gt; &gt; +               for (iova = *start; iova &lt;= *end; iova += *pgsize) {
&gt; &gt; +                       riscv_iommu_cmd_inval_set_addr(&amp;cmd, iova);
&gt; &gt; +                       riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; &gt; +               }
&gt; &gt; +       } else {
&gt; &gt; +               riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; &gt; +       }
&gt; &gt; +       riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt; &gt;  }
&gt; &gt;
&gt; &gt;  static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; &gt; @@ -610,6 +1183,9 @@ void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt; &gt;         iommu_device_unregister(&amp;iommu-&gt;iommu);
&gt; &gt;         iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
&gt; &gt;         riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt; &gt;  }
&gt; &gt;
&gt; &gt;  int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt; @@ -632,6 +1208,16 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt;         }
&gt; &gt;  #endif
&gt; &gt;
&gt; &gt; +       /*
&gt; &gt; +        * Assign queue lengths from module parameters if not already
&gt; &gt; +        * set on the device tree.
&gt; &gt; +        */
&gt; &gt; +       if (!iommu-&gt;cmdq_len)
&gt; &gt; +               iommu-&gt;cmdq_len = cmdq_length;
&gt; &gt; +       if (!iommu-&gt;fltq_len)
&gt; &gt; +               iommu-&gt;fltq_len = fltq_length;
&gt; &gt; +       if (!iommu-&gt;priq_len)
&gt; &gt; +               iommu-&gt;priq_len = priq_length;
&gt; &gt;         /* Clear any pending interrupt flag. */
&gt; &gt;         riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt; &gt;                            RISCV_IOMMU_IPSR_CIP |
&gt; &gt; @@ -639,7 +1225,20 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt;                            RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt; &gt;         spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt; &gt;         mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; &gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_COMMAND_QUEUE);
&gt; &gt; +       if (ret)
&gt; &gt; +               goto fail;
&gt; &gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_FAULT_QUEUE);
&gt; &gt; +       if (ret)
&gt; &gt; +               goto fail;
&gt; &gt; +       if (!(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS))
&gt; &gt; +               goto no_ats;
&gt; &gt; +
&gt; &gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_PAGE_REQUEST_QUEUE);
&gt; &gt; +       if (ret)
&gt; &gt; +               goto fail;
&gt; &gt;
&gt; &gt; + no_ats:
&gt; &gt;         ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt; &gt;
&gt; &gt;         if (ret) {
&gt; &gt; @@ -663,5 +1262,8 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt;         return 0;
&gt; &gt;   fail:
&gt; &gt;         riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt; &gt;         return ret;
&gt; &gt;  }
&gt; &gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; &gt; index 7dc9baa59a50..04148a2a8ffd 100644
&gt; &gt; --- a/drivers/iommu/riscv/iommu.h
&gt; &gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; &gt; @@ -28,6 +28,24 @@
&gt; &gt;  #define IOMMU_PAGE_SIZE_1G     BIT_ULL(30)
&gt; &gt;  #define IOMMU_PAGE_SIZE_512G   BIT_ULL(39)
&gt; &gt;
&gt; &gt; +struct riscv_iommu_queue {
&gt; &gt; +       dma_addr_t base_dma;    /* ring buffer bus address */
&gt; &gt; +       void *base;             /* ring buffer pointer */
&gt; &gt; +       size_t len;             /* single item length */
&gt; &gt; +       u32 cnt;                /* items count */
&gt; &gt; +       u32 lui;                /* last used index, consumer/producer share */
&gt; &gt; +       unsigned qbr;           /* queue base register offset */
&gt; &gt; +       unsigned qcr;           /* queue control and status register offset */
&gt; &gt; +       int irq;                /* registered interrupt number */
&gt; &gt; +       bool in_iomem;          /* indicates queue data are in I/O memory  */
&gt; &gt; +};
&gt; &gt; +
&gt; &gt; +enum riscv_queue_ids {
&gt; &gt; +       RISCV_IOMMU_COMMAND_QUEUE       = 0,
&gt; &gt; +       RISCV_IOMMU_FAULT_QUEUE         = 1,
&gt; &gt; +       RISCV_IOMMU_PAGE_REQUEST_QUEUE  = 2
&gt; &gt; +};
&gt; &gt; +
&gt; &gt;  struct riscv_iommu_device {
&gt; &gt;         struct iommu_device iommu;      /* iommu core interface */
&gt; &gt;         struct device *dev;             /* iommu hardware */
&gt; &gt; @@ -42,6 +60,11 @@ struct riscv_iommu_device {
&gt; &gt;         int irq_pm;
&gt; &gt;         int irq_priq;
&gt; &gt;
&gt; &gt; +       /* Queue lengths */
&gt; &gt; +       int cmdq_len;
&gt; &gt; +       int fltq_len;
&gt; &gt; +       int priq_len;
&gt; &gt; +
&gt; &gt;         /* supported and enabled hardware capabilities */
&gt; &gt;         u64 cap;
&gt; &gt;
&gt; &gt; @@ -53,6 +76,11 @@ struct riscv_iommu_device {
&gt; &gt;         unsigned ddt_mode;
&gt; &gt;         bool ddtp_in_iomem;
&gt; &gt;
&gt; &gt; +       /* hardware queues */
&gt; &gt; +       struct riscv_iommu_queue cmdq;
&gt; &gt; +       struct riscv_iommu_queue fltq;
&gt; &gt; +       struct riscv_iommu_queue priq;
&gt; &gt; +
&gt; &gt;         /* Connected end-points */
&gt; &gt;         struct rb_root eps;
&gt; &gt;         struct mutex eps_mutex;
&gt; &gt; --
&gt; &gt; 2.34.1
&gt; &gt;
&gt; &gt;
&gt; &gt; _______________________________________________
&gt; &gt; linux-riscv mailing list
&gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
best,
- Tomasz

<a href=#m407eda026cd986eb75d1fc2a13fa9e272c24019b id=e407eda026cd986eb75d1fc2a13fa9e272c24019b>^</a> <a href=https://lore.kernel.org/lkml/CAH2o1u5P-y8UF-nCXGPs8kiKk3Y1MY8XVdDCcjp+5+zdDqxZXQ@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CAH2o1u5P-y8UF-nCXGPs8kiKk3Y1MY8XVdDCcjp+5+zdDqxZXQ@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CAH2o1u5P-y8UF-nCXGPs8kiKk3Y1MY8XVdDCcjp+5+zdDqxZXQ@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CAH2o1u5P-y8UF-nCXGPs8kiKk3Y1MY8XVdDCcjp+5+zdDqxZXQ@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CAH2o1u5P-y8UF-nCXGPs8kiKk3Y1MY8XVdDCcjp+5+zdDqxZXQ@mail.gmail.com/t/#u>nested</a>] <a href=#r407eda026cd986eb75d1fc2a13fa9e272c24019b>86+ messages in thread</a></pre><hr><pre><a href=#e428d2ed3a8314242cc2c1bb7f013dd8b6093afb2 id=m428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
                     ` <a href=#r522f968d0909aad51fe7e480809ea548917990fa>(3 preceding siblings ...)</a>
  2023-07-28  2:42   ` <a href=#m522f968d0909aad51fe7e480809ea548917990fa>Zong Li</a>
<b>@ 2023-08-03  0:18   ` Jason Gunthorpe</b>
  2023-08-03  8:27   ` <a href=#mad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>Zong Li</a>
                     ` <a href=#rad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>(2 subsequent siblings)</a>
  <a href=#r428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>7 siblings, 0 replies; 86+ messages in thread</a>
From: Jason Gunthorpe @ 2023-08-03  0:18 UTC (<a href=https://lore.kernel.org/lkml/ZMryW%2FkrEWLEyaq+@nvidia.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/ZMryW%2FkrEWLEyaq+@nvidia.com/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230803001849">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230803001849">linux-kernel</a>, linux

On Wed, Jul 19, 2023 at 12:33:45PM -0700, Tomasz Jeznach wrote:

<span class=q>&gt; +static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt; +				       struct riscv_iommu_device *iommu)
&gt; +{
</span>
Do not introduce this finalize pattern into new drivers. We are trying
to get rid of it. I don't see anything here that suggest you need it.

Do all of this when you allocate the domain.

<span class=q>&gt; +	struct iommu_domain_geometry *geometry;
&gt; +
&gt; +	/* Domain assigned to another iommu */
&gt; +	if (domain-&gt;iommu &amp;&amp; domain-&gt;iommu != iommu)
&gt; +		return -EINVAL;
&gt; +	/* Domain already initialized */
&gt; +	else if (domain-&gt;iommu)
&gt; +		return 0;
</span>
These tests are not good, the domain should be able to be associated
with as many iommu instances as it likes.

<span class=q>&gt; +static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct device *dev)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +	int ret;
&gt; +
&gt; +	/* PSCID not valid */
&gt; +	if ((int)domain-&gt;pscid &lt; 0)
&gt; +		return -ENOMEM;
&gt; +
&gt; +	mutex_lock(&amp;domain-&gt;lock);
&gt; +	mutex_lock(&amp;ep-&gt;lock);
&gt; +
&gt; +	if (!list_empty(&amp;ep-&gt;domain)) {
&gt; +		dev_warn(dev, "endpoint already attached to a domain. dropping\n");
</span>
This is legitimate, it means the driver has to replace the domain, and
drivers have to implement this.

<span class=q>&gt; +/*
&gt; + * Common I/O MMU driver probe/teardown
&gt; + */
&gt; +
&gt; +static const struct iommu_domain_ops riscv_iommu_domain_ops = {
&gt; +	.free = riscv_iommu_domain_free,
&gt; +	.attach_dev = riscv_iommu_attach_dev,
&gt; +	.map_pages = riscv_iommu_map_pages,
&gt; +	.unmap_pages = riscv_iommu_unmap_pages,
&gt; +	.iova_to_phys = riscv_iommu_iova_to_phys,
&gt; +	.iotlb_sync = riscv_iommu_iotlb_sync,
&gt; +	.iotlb_sync_map = riscv_iommu_iotlb_sync_map,
&gt; +	.flush_iotlb_all = riscv_iommu_flush_iotlb_all,
&gt; +};
</span>
Please split the ops by domain type, eg identity, paging, sva, etc.

<span class=q>&gt; +int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +	struct device *dev = iommu-&gt;dev;
&gt; +	u32 fctl = 0;
&gt; +	int ret;
&gt; +
&gt; +	iommu-&gt;eps = RB_ROOT;
&gt; +
&gt; +	fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; +
&gt; +#ifdef CONFIG_CPU_BIG_ENDIAN
&gt; +	if (!(cap &amp; RISCV_IOMMU_CAP_END)) {
&gt; +		dev_err(dev, "IOMMU doesn't support Big Endian\n");
</span>
Why not?

<span class=q>&gt; +		return -EIO;
&gt; +	} else if (!(fctl &amp; RISCV_IOMMU_FCTL_BE)) {
&gt; +		fctl |= FIELD_PREP(RISCV_IOMMU_FCTL_BE, 1);
&gt; +		riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; +	}
&gt; +#endif
&gt; +
&gt; +	/* Clear any pending interrupt flag. */
&gt; +	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt; +			   RISCV_IOMMU_IPSR_CIP |
&gt; +			   RISCV_IOMMU_IPSR_FIP |
&gt; +			   RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt; +	spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt; +	mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +	ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt; +
&gt; +	if (ret) {
&gt; +		dev_err(dev, "cannot enable iommu device (%d)\n", ret);
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	ret = iommu_device_register(&amp;iommu-&gt;iommu, &amp;riscv_iommu_ops, dev);
&gt; +	if (ret) {
&gt; +		dev_err(dev, "cannot register iommu interface (%d)\n", ret);
&gt; +		iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
&gt; +		goto fail;
&gt; +	}
</span>
The calls to iommu_device_sysfs_add() are missing, this is mandatory..

Jason

<a href=#m428d2ed3a8314242cc2c1bb7f013dd8b6093afb2 id=e428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>^</a> <a href=https://lore.kernel.org/lkml/ZMryW%2FkrEWLEyaq+@nvidia.com/>permalink</a> <a href=https://lore.kernel.org/lkml/ZMryW%2FkrEWLEyaq+@nvidia.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/ZMryW%2FkrEWLEyaq+@nvidia.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/ZMryW%2FkrEWLEyaq+@nvidia.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/ZMryW%2FkrEWLEyaq+@nvidia.com/t/#u>nested</a>] <a href=#r428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>86+ messages in thread</a></pre><hr><pre><a href=#e37555fe53501d9e3bd60231c586cec52ef1fe838 id=m37555fe53501d9e3bd60231c586cec52ef1fe838>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-08-02 20:15     ` <a href=#m6bea4b3cd6bb3324224d86b9abb254943fb6124a>Tomasz Jeznach</a>
  2023-08-02 20:25       ` <a href=#m64fbb77e574cead28d126c26f5193ed27f5df4af>Conor Dooley</a>
<b>@ 2023-08-03  3:37       ` Zong Li</b>
  <a href=#r37555fe53501d9e3bd60231c586cec52ef1fe838>1 sibling, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-08-03  3:37 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0o5898J=U5XmKbmO4wLq5VkKHVaSwzzcixUqGkkFddhWw@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0o5898J=U5XmKbmO4wLq5VkKHVaSwzzcixUqGkkFddhWw@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230803033732">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230803033732">linux-riscv</a>

On Thu, Aug 3, 2023 at 4:15 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; On Thu, Jul 27, 2023 at 7:42 PM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; +static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct device *dev = &amp;pdev-&gt;dev;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu = NULL;
&gt; &gt; &gt; +       struct resource *res = NULL;
&gt; &gt; &gt; +       int ret = 0;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; &gt; &gt; +       if (!iommu)
&gt; &gt; &gt; +               return -ENOMEM;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;dev = dev;
&gt; &gt; &gt; +       dev_set_drvdata(dev, iommu);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
&gt; &gt; &gt; +       if (!res) {
&gt; &gt; &gt; +               dev_err(dev, "could not find resource for register region\n");
&gt; &gt; &gt; +               return -EINVAL;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;reg = devm_platform_get_and_ioremap_resource(pdev, 0, &amp;res);
&gt; &gt; &gt; +       if (IS_ERR(iommu-&gt;reg)) {
&gt; &gt; &gt; +               ret = dev_err_probe(dev, PTR_ERR(iommu-&gt;reg),
&gt; &gt; &gt; +                                   "could not map register region\n");
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       };
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;reg_phys = res-&gt;start;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       ret = -ENODEV;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Sanity check: Did we get the whole register space ? */
&gt; &gt; &gt; +       if ((res-&gt;end - res-&gt;start + 1) &lt; RISCV_IOMMU_REG_SIZE) {
&gt; &gt; &gt; +               dev_err(dev, "device region smaller than register file (0x%llx)\n",
&gt; &gt; &gt; +                       res-&gt;end - res-&gt;start);
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt;
&gt; &gt; Could we assume that DT should be responsible for specifying the right size?
&gt; &gt;
&gt;
&gt; This only to validate DT provided info and driver expected register
&gt; file size. Expectation is that DT will provide right size.
&gt;
&gt;
&gt; &gt; &gt; +static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_domain *domain;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; &gt; &gt; +           type != IOMMU_DOMAIN_BLOCKED)
&gt; &gt; &gt; +               return NULL;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       domain = kzalloc(sizeof(*domain), GFP_KERNEL);
&gt; &gt; &gt; +       if (!domain)
&gt; &gt; &gt; +               return NULL;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       mutex_init(&amp;domain-&gt;lock);
&gt; &gt; &gt; +       INIT_LIST_HEAD(&amp;domain-&gt;endpoints);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       domain-&gt;domain.ops = &amp;riscv_iommu_domain_ops;
&gt; &gt; &gt; +       domain-&gt;mode = RISCV_IOMMU_DC_FSC_MODE_BARE;
&gt; &gt; &gt; +       domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt; &gt; &gt; +                                       RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; &gt; &gt; +
&gt; &gt;
&gt; &gt; Could it uses pr_xxx instead of printk?
&gt; &gt;
&gt;
&gt; Absolutely, fixed here and elsewhere. Also, used dev_dbg wherever applicable.
&gt;
&gt; &gt; &gt; +
&gt; &gt; &gt; +static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned requested_mode)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct device *dev = iommu-&gt;dev;
&gt; &gt; &gt; +       u64 ddtp = 0;
&gt; &gt; &gt; +       u64 ddtp_paddr = 0;
&gt; &gt; &gt; +       unsigned mode = requested_mode;
&gt; &gt; &gt; +       unsigned mode_readback = 0;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; &gt; &gt; +       if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY)
&gt; &gt; &gt; +               return -EBUSY;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Disallow state transtion from xLVL to xLVL. */
&gt; &gt; &gt; +       switch (FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp)) {
&gt; &gt; &gt; +       case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; &gt; &gt; +       case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; &gt; &gt; +               break;
&gt; &gt; &gt; +       default:
&gt; &gt; &gt; +               if ((mode != RISCV_IOMMU_DDTP_MODE_BARE)
&gt; &gt; &gt; +                   &amp;&amp; (mode != RISCV_IOMMU_DDTP_MODE_OFF))
&gt; &gt; &gt; +                       return -EINVAL;
&gt; &gt; &gt; +               break;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; + retry:
&gt; &gt;
&gt; &gt; We need to consider the `iommu.passthrough` before we set up the mode
&gt; &gt; in switch case, something like
&gt; &gt;
&gt;
&gt; This function is only to execute configuration and set device directory mode.
&gt; Handling global iommu.passthrough policy is implemented in
&gt; riscv_iommu_init() call (patch #7).
</span>
Thanks. I saw that in patch #7.

<span class=q>&gt;
&gt; Best,
&gt; - Tomasz
</span>
<a href=#m37555fe53501d9e3bd60231c586cec52ef1fe838 id=e37555fe53501d9e3bd60231c586cec52ef1fe838>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0o5898J=U5XmKbmO4wLq5VkKHVaSwzzcixUqGkkFddhWw@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0o5898J=U5XmKbmO4wLq5VkKHVaSwzzcixUqGkkFddhWw@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0o5898J=U5XmKbmO4wLq5VkKHVaSwzzcixUqGkkFddhWw@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0o5898J=U5XmKbmO4wLq5VkKHVaSwzzcixUqGkkFddhWw@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0o5898J=U5XmKbmO4wLq5VkKHVaSwzzcixUqGkkFddhWw@mail.gmail.com/t/#u">nested</a>] <a href=#r37555fe53501d9e3bd60231c586cec52ef1fe838>86+ messages in thread</a></pre><hr><pre><a href=#e5d2c47156d2d94a03257441a04bb19a53bb29675 id=m5d2c47156d2d94a03257441a04bb19a53bb29675>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-08-02 20:50     ` <a href=#m407eda026cd986eb75d1fc2a13fa9e272c24019b>Tomasz Jeznach</a>
<b>@ 2023-08-03  8:24       ` Zong Li</b>
  <a href=#r5d2c47156d2d94a03257441a04bb19a53bb29675>0 siblings, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-08-03  8:24 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0qWQpnSmYp2rPYVYFCmFzdfxi7Lyo3nvVche6X9dCz89A@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0qWQpnSmYp2rPYVYFCmFzdfxi7Lyo3nvVche6X9dCz89A@mail.gmail.com/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230803082737">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230803082737">linux-riscv</a>

On Thu, Aug 3, 2023 at 4:50 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; On Sat, Jul 29, 2023 at 5:58 AM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; &gt; &gt;
&gt; &gt; &gt; Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; &gt; &gt; Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; &gt; &gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; &gt; &gt; ---
&gt; &gt; &gt;  drivers/iommu/riscv/iommu-pci.c      |  72 ++++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu-platform.c |  66 +++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu.c          | 604 ++++++++++++++++++++++++++-
&gt; &gt; &gt;  drivers/iommu/riscv/iommu.h          |  28 ++
&gt; &gt; &gt;  4 files changed, 769 insertions(+), 1 deletion(-)
&gt; &gt; &gt;
&gt; &gt; &gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; &gt; &gt; index c91f963d7a29..9ea0647f7b92 100644
&gt; &gt; &gt; --- a/drivers/iommu/riscv/iommu-pci.c
&gt; &gt; &gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; &gt; &gt; @@ -34,6 +34,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt; &gt; &gt;  {
&gt; &gt; &gt;         struct device *dev = &amp;pdev-&gt;dev;
&gt; &gt; &gt;         struct riscv_iommu_device *iommu;
&gt; &gt; &gt; +       u64 icvec;
&gt; &gt; &gt;         int ret;
&gt; &gt; &gt;
&gt; &gt; &gt;         ret = pci_enable_device_mem(pdev);
&gt; &gt; &gt; @@ -67,14 +68,84 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt; &gt; &gt;         iommu-&gt;dev = dev;
&gt; &gt; &gt;         dev_set_drvdata(dev, iommu);
&gt; &gt; &gt;
&gt; &gt; &gt; +       /* Check device reported capabilities. */
&gt; &gt; &gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* The PCI driver only uses MSIs, make sure the IOMMU supports this */
&gt; &gt; &gt; +       switch (FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap)) {
&gt; &gt; &gt; +       case RISCV_IOMMU_CAP_IGS_MSI:
&gt; &gt; &gt; +       case RISCV_IOMMU_CAP_IGS_BOTH:
&gt; &gt; &gt; +               break;
&gt; &gt; &gt; +       default:
&gt; &gt; &gt; +               dev_err(dev, "unable to use message-signaled interrupts\n");
&gt; &gt; &gt; +               ret = -ENODEV;
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt;         dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
&gt; &gt; &gt;         pci_set_master(pdev);
&gt; &gt; &gt;
&gt; &gt; &gt; +       /* Allocate and assign IRQ vectors for the various events */
&gt; &gt; &gt; +       ret = pci_alloc_irq_vectors(pdev, 1, RISCV_IOMMU_INTR_COUNT, PCI_IRQ_MSIX);
&gt; &gt; &gt; +       if (ret &lt; 0) {
&gt; &gt; &gt; +               dev_err(dev, "unable to allocate irq vectors\n");
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       ret = -ENODEV;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;irq_cmdq = msi_get_virq(dev, RISCV_IOMMU_INTR_CQ);
&gt; &gt; &gt; +       if (!iommu-&gt;irq_cmdq) {
&gt; &gt; &gt; +               dev_warn(dev, "no MSI vector %d for the command queue\n",
&gt; &gt; &gt; +                        RISCV_IOMMU_INTR_CQ);
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu-&gt;irq_fltq = msi_get_virq(dev, RISCV_IOMMU_INTR_FQ);
&gt; &gt; &gt; +       if (!iommu-&gt;irq_fltq) {
&gt; &gt; &gt; +               dev_warn(dev, "no MSI vector %d for the fault/event queue\n",
&gt; &gt; &gt; +                        RISCV_IOMMU_INTR_FQ);
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; &gt; &gt; +               iommu-&gt;irq_pm = msi_get_virq(dev, RISCV_IOMMU_INTR_PM);
&gt; &gt; &gt; +               if (!iommu-&gt;irq_pm) {
&gt; &gt; &gt; +                       dev_warn(dev,
&gt; &gt; &gt; +                                "no MSI vector %d for performance monitoring\n",
&gt; &gt; &gt; +                                RISCV_IOMMU_INTR_PM);
&gt; &gt; &gt; +                       goto fail;
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; &gt; &gt; +               iommu-&gt;irq_priq = msi_get_virq(dev, RISCV_IOMMU_INTR_PQ);
&gt; &gt; &gt; +               if (!iommu-&gt;irq_priq) {
&gt; &gt; &gt; +                       dev_warn(dev,
&gt; &gt; &gt; +                                "no MSI vector %d for page-request queue\n",
&gt; &gt; &gt; +                                RISCV_IOMMU_INTR_PQ);
&gt; &gt; &gt; +                       goto fail;
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Set simple 1:1 mapping for MSI vectors */
&gt; &gt; &gt; +       icvec = FIELD_PREP(RISCV_IOMMU_IVEC_CIV, RISCV_IOMMU_INTR_CQ) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_IVEC_FIV, RISCV_IOMMU_INTR_FQ);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM)
&gt; &gt; &gt; +               icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PMIV, RISCV_IOMMU_INTR_PM);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS)
&gt; &gt; &gt; +               icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PIV, RISCV_IOMMU_INTR_PQ);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IVEC, icvec);
&gt; &gt; &gt; +
&gt; &gt; &gt;         ret = riscv_iommu_init(iommu);
&gt; &gt; &gt;         if (!ret)
&gt; &gt; &gt;                 return ret;
&gt; &gt; &gt;
&gt; &gt; &gt;   fail:
&gt; &gt; &gt; +       pci_free_irq_vectors(pdev);
&gt; &gt; &gt;         pci_clear_master(pdev);
&gt; &gt; &gt;         pci_release_regions(pdev);
&gt; &gt; &gt;         pci_disable_device(pdev);
&gt; &gt; &gt; @@ -85,6 +156,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt; &gt; &gt;  static void riscv_iommu_pci_remove(struct pci_dev *pdev)
&gt; &gt; &gt;  {
&gt; &gt; &gt;         riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; &gt; &gt; +       pci_free_irq_vectors(pdev);
&gt; &gt; &gt;         pci_clear_master(pdev);
&gt; &gt; &gt;         pci_release_regions(pdev);
&gt; &gt; &gt;         pci_disable_device(pdev);
&gt; &gt; &gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; &gt; &gt; index e4e8ca6711e7..35935d3c7ef4 100644
&gt; &gt; &gt; --- a/drivers/iommu/riscv/iommu-platform.c
&gt; &gt; &gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; &gt; &gt; @@ -20,6 +20,8 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; &gt; &gt;         struct device *dev = &amp;pdev-&gt;dev;
&gt; &gt; &gt;         struct riscv_iommu_device *iommu = NULL;
&gt; &gt; &gt;         struct resource *res = NULL;
&gt; &gt; &gt; +       u32 fctl = 0;
&gt; &gt; &gt; +       int irq = 0;
&gt; &gt; &gt;         int ret = 0;
&gt; &gt; &gt;
&gt; &gt; &gt;         iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; &gt; &gt; @@ -53,6 +55,70 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; &gt; &gt;                 goto fail;
&gt; &gt; &gt;         }
&gt; &gt; &gt;
&gt; &gt; &gt; +       iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* For now we only support WSIs until we have AIA support */
&gt; &gt;
&gt; &gt; I'm not completely understand AIA support here, because I saw the pci
&gt; &gt; case uses the MSI, and kernel seems to have the AIA implementation.
&gt; &gt; Could you please elaborate it?
&gt; &gt;
&gt; &gt; &gt; +       ret = FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap);
&gt; &gt; &gt; +       if (ret == RISCV_IOMMU_CAP_IGS_MSI) {
&gt; &gt; &gt; +               dev_err(dev, "IOMMU only supports MSIs\n");
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Parse IRQ assignment */
&gt; &gt; &gt; +       irq = platform_get_irq_byname_optional(pdev, "cmdq");
&gt; &gt; &gt; +       if (irq &gt; 0)
&gt; &gt; &gt; +               iommu-&gt;irq_cmdq = irq;
&gt; &gt; &gt; +       else {
&gt; &gt; &gt; +               dev_err(dev, "no IRQ provided for the command queue\n");
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       irq = platform_get_irq_byname_optional(pdev, "fltq");
&gt; &gt; &gt; +       if (irq &gt; 0)
&gt; &gt; &gt; +               iommu-&gt;irq_fltq = irq;
&gt; &gt; &gt; +       else {
&gt; &gt; &gt; +               dev_err(dev, "no IRQ provided for the fault/event queue\n");
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; &gt; &gt; +               irq = platform_get_irq_byname_optional(pdev, "pm");
&gt; &gt; &gt; +               if (irq &gt; 0)
&gt; &gt; &gt; +                       iommu-&gt;irq_pm = irq;
&gt; &gt; &gt; +               else {
&gt; &gt; &gt; +                       dev_err(dev, "no IRQ provided for performance monitoring\n");
&gt; &gt; &gt; +                       goto fail;
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; &gt; &gt; +               irq = platform_get_irq_byname_optional(pdev, "priq");
&gt; &gt; &gt; +               if (irq &gt; 0)
&gt; &gt; &gt; +                       iommu-&gt;irq_priq = irq;
&gt; &gt; &gt; +               else {
&gt; &gt; &gt; +                       dev_err(dev, "no IRQ provided for the page-request queue\n");
&gt; &gt; &gt; +                       goto fail;
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       }
&gt; &gt;
&gt; &gt; Should we define the "interrupt-names" in dt-bindings?
&gt; &gt;
&gt;
&gt; Yes, this was brought up earlier wrt dt-bindings.
&gt;
&gt; I'm considering removal of interrupt names from DT (and get-byname
&gt; option), as IOMMU hardware cause-to-vector remapping `icvec` should be
&gt; used to map interrupt source to actual interrupt vector. If possible
&gt; device driver should map cause to interrupt (based on number of
&gt; vectors available) or rely on ICVEC WARL properties to discover fixed
&gt; cause-to-vector mapping in the hardware.
&gt;
</span>
I'm not sure if I understand correctly, but one thing we might need to
consider is when the vector numbers are less than interrupt sources,
for example, if IOMMU only supports single vector (i.e. supports a
single interrupt wire), the `request_threaded_irq` will request the
irq three times by using same irq number for command, fault and
page-request queues. It would cause a problem and fail to request an
IRQ for the other two queues. It seems that we still need to consider
this situation regardless of how we determine the IRQs for each
interrupt source.

<span class=q>&gt; Please let me know if this is reasonable change.
&gt;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Make sure fctl.WSI is set */
&gt; &gt; &gt; +       fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; &gt; &gt; +       fctl |= RISCV_IOMMU_FCTL_WSI;
&gt; &gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Parse Queue lengts */
&gt; &gt; &gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; &gt; &gt; +       if (!ret)
&gt; &gt; &gt; +               dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; &gt; &gt; +       if (!ret)
&gt; &gt; &gt; +               dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; &gt; &gt; +       if (!ret)
&gt; &gt; &gt; +               dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
&gt; &gt; &gt; +
&gt; &gt; &gt;         dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; &gt; &gt;
&gt; &gt; &gt;         return riscv_iommu_init(iommu);
&gt; &gt; &gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; &gt; &gt; index 31dc3c458e13..5c4cf9875302 100644
&gt; &gt; &gt; --- a/drivers/iommu/riscv/iommu.c
&gt; &gt; &gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; &gt; &gt; @@ -45,6 +45,18 @@ static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt; &gt; &gt;  module_param(ddt_mode, int, 0644);
&gt; &gt; &gt;  MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt; &gt; &gt;
&gt; &gt; &gt; +static int cmdq_length = 1024;
&gt; &gt; &gt; +module_param(cmdq_length, int, 0644);
&gt; &gt; &gt; +MODULE_PARM_DESC(cmdq_length, "Command queue length.");
&gt; &gt; &gt; +
&gt; &gt; &gt; +static int fltq_length = 1024;
&gt; &gt; &gt; +module_param(fltq_length, int, 0644);
&gt; &gt; &gt; +MODULE_PARM_DESC(fltq_length, "Fault queue length.");
&gt; &gt; &gt; +
&gt; &gt; &gt; +static int priq_length = 1024;
&gt; &gt; &gt; +module_param(priq_length, int, 0644);
&gt; &gt; &gt; +MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
&gt; &gt; &gt; +
&gt; &gt; &gt;  /* IOMMU PSCID allocation namespace. */
&gt; &gt; &gt;  #define RISCV_IOMMU_MAX_PSCID  (1U &lt;&lt; 20)
&gt; &gt; &gt;  static DEFINE_IDA(riscv_iommu_pscids);
&gt; &gt; &gt; @@ -65,6 +77,497 @@ static DEFINE_IDA(riscv_iommu_pscids);
&gt; &gt; &gt;  static const struct iommu_domain_ops riscv_iommu_domain_ops;
&gt; &gt; &gt;  static const struct iommu_ops riscv_iommu_ops;
&gt; &gt; &gt;
&gt; &gt; &gt; +/*
&gt; &gt; &gt; + * Common queue management routines
&gt; &gt; &gt; + */
&gt; &gt; &gt; +
&gt; &gt; &gt; +/* Note: offsets are the same for all queues */
&gt; &gt; &gt; +#define Q_HEAD(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQH - RISCV_IOMMU_REG_CQB))
&gt; &gt; &gt; +#define Q_TAIL(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQT - RISCV_IOMMU_REG_CQB))
&gt; &gt; &gt; +
&gt; &gt; &gt; +static unsigned riscv_iommu_queue_consume(struct riscv_iommu_device *iommu,
&gt; &gt; &gt; +                                         struct riscv_iommu_queue *q, unsigned *ready)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       u32 tail = riscv_iommu_readl(iommu, Q_TAIL(q));
&gt; &gt; &gt; +       *ready = q-&gt;lui;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       BUG_ON(q-&gt;cnt &lt;= tail);
&gt; &gt; &gt; +       if (q-&gt;lui &lt;= tail)
&gt; &gt; &gt; +               return tail - q-&gt;lui;
&gt; &gt; &gt; +       return q-&gt;cnt - q-&gt;lui;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static void riscv_iommu_queue_release(struct riscv_iommu_device *iommu,
&gt; &gt; &gt; +                                     struct riscv_iommu_queue *q, unsigned count)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       q-&gt;lui = (q-&gt;lui + count) &amp; (q-&gt;cnt - 1);
&gt; &gt; &gt; +       riscv_iommu_writel(iommu, Q_HEAD(q), q-&gt;lui);
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static u32 riscv_iommu_queue_ctrl(struct riscv_iommu_device *iommu,
&gt; &gt; &gt; +                                 struct riscv_iommu_queue *q, u32 val)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
&gt; &gt; &gt; +
&gt; &gt; &gt; +       riscv_iommu_writel(iommu, q-&gt;qcr, val);
&gt; &gt; &gt; +       do {
&gt; &gt; &gt; +               val = riscv_iommu_readl(iommu, q-&gt;qcr);
&gt; &gt; &gt; +               if (!(val &amp; RISCV_IOMMU_QUEUE_BUSY))
&gt; &gt; &gt; +                       break;
&gt; &gt; &gt; +               cpu_relax();
&gt; &gt; &gt; +       } while (get_cycles() &lt; end_cycles);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       return val;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static void riscv_iommu_queue_free(struct riscv_iommu_device *iommu,
&gt; &gt; &gt; +                                  struct riscv_iommu_queue *q)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       size_t size = q-&gt;len * q-&gt;cnt;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       riscv_iommu_queue_ctrl(iommu, q, 0);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (q-&gt;base) {
&gt; &gt; &gt; +               if (q-&gt;in_iomem)
&gt; &gt; &gt; +                       iounmap(q-&gt;base);
&gt; &gt; &gt; +               else
&gt; &gt; &gt; +                       dmam_free_coherent(iommu-&gt;dev, size, q-&gt;base, q-&gt;base_dma);
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +       if (q-&gt;irq)
&gt; &gt; &gt; +               free_irq(q-&gt;irq, q);
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data);
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data);
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data);
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data);
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; &gt; &gt; +
&gt; &gt; &gt; +static int riscv_iommu_queue_init(struct riscv_iommu_device *iommu, int queue_id)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct device *dev = iommu-&gt;dev;
&gt; &gt; &gt; +       struct riscv_iommu_queue *q = NULL;
&gt; &gt; &gt; +       size_t queue_size = 0;
&gt; &gt; &gt; +       irq_handler_t irq_check;
&gt; &gt; &gt; +       irq_handler_t irq_process;
&gt; &gt; &gt; +       const char *name;
&gt; &gt; &gt; +       int count = 0;
&gt; &gt; &gt; +       int irq = 0;
&gt; &gt; &gt; +       unsigned order = 0;
&gt; &gt; &gt; +       u64 qbr_val = 0;
&gt; &gt; &gt; +       u64 qbr_readback = 0;
&gt; &gt; &gt; +       u64 qbr_paddr = 0;
&gt; &gt; &gt; +       int ret = 0;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       switch (queue_id) {
&gt; &gt; &gt; +       case RISCV_IOMMU_COMMAND_QUEUE:
&gt; &gt; &gt; +               q = &amp;iommu-&gt;cmdq;
&gt; &gt; &gt; +               q-&gt;len = sizeof(struct riscv_iommu_command);
&gt; &gt; &gt; +               count = iommu-&gt;cmdq_len;
&gt; &gt; &gt; +               irq = iommu-&gt;irq_cmdq;
&gt; &gt; &gt; +               irq_check = riscv_iommu_cmdq_irq_check;
&gt; &gt; &gt; +               irq_process = riscv_iommu_cmdq_process;
&gt; &gt; &gt; +               q-&gt;qbr = RISCV_IOMMU_REG_CQB;
&gt; &gt; &gt; +               q-&gt;qcr = RISCV_IOMMU_REG_CQCSR;
&gt; &gt; &gt; +               name = "cmdq";
&gt; &gt; &gt; +               break;
&gt; &gt; &gt; +       case RISCV_IOMMU_FAULT_QUEUE:
&gt; &gt; &gt; +               q = &amp;iommu-&gt;fltq;
&gt; &gt; &gt; +               q-&gt;len = sizeof(struct riscv_iommu_fq_record);
&gt; &gt; &gt; +               count = iommu-&gt;fltq_len;
&gt; &gt; &gt; +               irq = iommu-&gt;irq_fltq;
&gt; &gt; &gt; +               irq_check = riscv_iommu_fltq_irq_check;
&gt; &gt; &gt; +               irq_process = riscv_iommu_fltq_process;
&gt; &gt; &gt; +               q-&gt;qbr = RISCV_IOMMU_REG_FQB;
&gt; &gt; &gt; +               q-&gt;qcr = RISCV_IOMMU_REG_FQCSR;
&gt; &gt; &gt; +               name = "fltq";
&gt; &gt; &gt; +               break;
&gt; &gt; &gt; +       case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; &gt; &gt; +               q = &amp;iommu-&gt;priq;
&gt; &gt; &gt; +               q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; &gt; &gt; +               count = iommu-&gt;priq_len;
&gt; &gt; &gt; +               irq = iommu-&gt;irq_priq;
&gt; &gt; &gt; +               irq_check = riscv_iommu_priq_irq_check;
&gt; &gt; &gt; +               irq_process = riscv_iommu_priq_process;
&gt; &gt; &gt; +               q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; &gt; &gt; +               q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; &gt; &gt; +               name = "priq";
&gt; &gt; &gt; +               break;
&gt; &gt; &gt; +       default:
&gt; &gt; &gt; +               dev_err(dev, "invalid queue interrupt index in queue_init!\n");
&gt; &gt; &gt; +               return -EINVAL;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Polling not implemented */
&gt; &gt; &gt; +       if (!irq)
&gt; &gt; &gt; +               return -ENODEV;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Allocate queue in memory and set the base register */
&gt; &gt; &gt; +       order = ilog2(count);
&gt; &gt; &gt; +       do {
&gt; &gt; &gt; +               queue_size = q-&gt;len * (1ULL &lt;&lt; order);
&gt; &gt; &gt; +               q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
&gt; &gt; &gt; +               if (q-&gt;base || queue_size &lt; PAGE_SIZE)
&gt; &gt; &gt; +                       break;
&gt; &gt; &gt; +
&gt; &gt; &gt; +               order--;
&gt; &gt; &gt; +       } while (1);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (!q-&gt;base) {
&gt; &gt; &gt; +               dev_err(dev, "failed to allocate %s queue (cnt: %u)\n", name, count);
&gt; &gt; &gt; +               return -ENOMEM;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /*
&gt; &gt; &gt; +        * Queue base registers are WARL, so it's possible that whatever we wrote
&gt; &gt; &gt; +        * there was illegal/not supported by the hw in which case we need to make
&gt; &gt; &gt; +        * sure we set a supported PPN and/or queue size.
&gt; &gt; &gt; +        */
&gt; &gt; &gt; +       qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; &gt; &gt; +       if (qbr_readback == qbr_val)
&gt; &gt; &gt; +               goto irq;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       dmam_free_coherent(dev, queue_size, q-&gt;base, q-&gt;base_dma);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Get supported queue size */
&gt; &gt; &gt; +       order = FIELD_GET(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, qbr_readback) + 1;
&gt; &gt; &gt; +       q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; &gt; &gt; +       queue_size = q-&gt;len * q-&gt;cnt;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /*
&gt; &gt; &gt; +        * In case we also failed to set PPN, it means the field is hardcoded and the
&gt; &gt; &gt; +        * queue resides in I/O memory instead, so get its physical address and
&gt; &gt; &gt; +        * ioremap it.
&gt; &gt; &gt; +        */
&gt; &gt; &gt; +       qbr_paddr = ppn_to_phys(qbr_readback);
&gt; &gt; &gt; +       if (qbr_paddr != q-&gt;base_dma) {
&gt; &gt; &gt; +               dev_info(dev,
&gt; &gt; &gt; +                        "hardcoded ppn in %s base register, using io memory for the queue\n",
&gt; &gt; &gt; +                        name);
&gt; &gt; &gt; +               dev_info(dev, "queue length for %s set to %i\n", name, q-&gt;cnt);
&gt; &gt; &gt; +               q-&gt;in_iomem = true;
&gt; &gt; &gt; +               q-&gt;base = ioremap(qbr_paddr, queue_size);
&gt; &gt; &gt; +               if (!q-&gt;base) {
&gt; &gt; &gt; +                       dev_err(dev, "failed to map %s queue (cnt: %u)\n", name, q-&gt;cnt);
&gt; &gt; &gt; +                       return -ENOMEM;
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +               q-&gt;base_dma = qbr_paddr;
&gt; &gt; &gt; +       } else {
&gt; &gt; &gt; +               /*
&gt; &gt; &gt; +                * We only failed to set the queue size, re-try to allocate memory with
&gt; &gt; &gt; +                * the queue size supported by the hw.
&gt; &gt; &gt; +                */
&gt; &gt; &gt; +               dev_info(dev, "hardcoded queue size in %s base register\n", name);
&gt; &gt; &gt; +               dev_info(dev, "retrying with queue length: %i\n", q-&gt;cnt);
&gt; &gt; &gt; +               q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
&gt; &gt; &gt; +               if (!q-&gt;base) {
&gt; &gt; &gt; +                       dev_err(dev, "failed to allocate %s queue (cnt: %u)\n",
&gt; &gt; &gt; +                               name, q-&gt;cnt);
&gt; &gt; &gt; +                       return -ENOMEM;
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; &gt; &gt; +       riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Final check to make sure hw accepted our write */
&gt; &gt; &gt; +       qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; &gt; &gt; +       if (qbr_readback != qbr_val) {
&gt; &gt; &gt; +               dev_err(dev, "failed to set base register for %s\n", name);
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; + irq:
&gt; &gt; &gt; +       if (request_threaded_irq(irq, irq_check, irq_process, IRQF_ONESHOT | IRQF_SHARED,
&gt; &gt; &gt; +                                dev_name(dev), q)) {
&gt; &gt; &gt; +               dev_err(dev, "fail to request irq %d for %s\n", irq, name);
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       q-&gt;irq = irq;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Note: All RIO_xQ_EN/IE fields are in the same offsets */
&gt; &gt; &gt; +       ret =
&gt; &gt; &gt; +           riscv_iommu_queue_ctrl(iommu, q,
&gt; &gt; &gt; +                                  RISCV_IOMMU_QUEUE_ENABLE |
&gt; &gt; &gt; +                                  RISCV_IOMMU_QUEUE_INTR_ENABLE);
&gt; &gt; &gt; +       if (ret &amp; RISCV_IOMMU_QUEUE_BUSY) {
&gt; &gt; &gt; +               dev_err(dev, "%s init timeout\n", name);
&gt; &gt; &gt; +               ret = -EBUSY;
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       return 0;
&gt; &gt; &gt; +
&gt; &gt; &gt; + fail:
&gt; &gt; &gt; +       riscv_iommu_queue_free(iommu, q);
&gt; &gt; &gt; +       return 0;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/*
&gt; &gt; &gt; + * I/O MMU Command queue chapter 3.1
&gt; &gt; &gt; + */
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_inval_vma(struct riscv_iommu_command *cmd)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 =
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_OPCODE,
&gt; &gt; &gt; +                      RISCV_IOMMU_CMD_IOTINVAL_OPCODE) | FIELD_PREP(RISCV_IOMMU_CMD_FUNC,
&gt; &gt; &gt; +                                                                    RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA);
&gt; &gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; +                                                 u64 addr)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; &gt; &gt; +       cmd-&gt;dword1 = addr;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_inval_set_pscid(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; +                                                  unsigned pscid)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_PSCID, pscid) |
&gt; &gt; &gt; +           RISCV_IOMMU_CMD_IOTINVAL_PSCV;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_inval_set_gscid(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; +                                                  unsigned gscid)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_GSCID, gscid) |
&gt; &gt; &gt; +           RISCV_IOMMU_CMD_IOTINVAL_GV;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_iofence(struct riscv_iommu_command *cmd)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C);
&gt; &gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_iofence_set_av(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; +                                                 u64 addr, u32 data)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_IOFENCE_DATA, data) | RISCV_IOMMU_CMD_IOFENCE_AV;
&gt; &gt; &gt; +       cmd-&gt;dword1 = (addr &gt;&gt; 2);
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_iodir_inval_ddt(struct riscv_iommu_command *cmd)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT);
&gt; &gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_iodir_inval_pdt(struct riscv_iommu_command *cmd)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT);
&gt; &gt; &gt; +       cmd-&gt;dword1 = 0;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static inline void riscv_iommu_cmd_iodir_set_did(struct riscv_iommu_command *cmd,
&gt; &gt; &gt; +                                                unsigned devid)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       cmd-&gt;dword0 |=
&gt; &gt; &gt; +           FIELD_PREP(RISCV_IOMMU_CMD_IODIR_DID, devid) | RISCV_IOMMU_CMD_IODIR_DV;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/* TODO: Convert into lock-less MPSC implementation. */
&gt; &gt; &gt; +static bool riscv_iommu_post_sync(struct riscv_iommu_device *iommu,
&gt; &gt; &gt; +                                 struct riscv_iommu_command *cmd, bool sync)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       u32 head, tail, next, last;
&gt; &gt; &gt; +       unsigned long flags;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; &gt; +       head = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; &gt; +       tail = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; &gt; +       last = iommu-&gt;cmdq.lui;
&gt; &gt; &gt; +       if (tail != last) {
&gt; &gt; &gt; +               spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; &gt; +               /*
&gt; &gt; &gt; +                * FIXME: This is a workaround for dropped MMIO writes/reads on QEMU platform.
&gt; &gt; &gt; +                *        While debugging of the problem is still ongoing, this provides
&gt; &gt; &gt; +                *        a simple impolementation of try-again policy.
&gt; &gt; &gt; +                *        Will be changed to lock-less algorithm in the feature.
&gt; &gt; &gt; +                */
&gt; &gt; &gt; +               dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (1st)\n", last, tail);
&gt; &gt; &gt; +               spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; &gt; +               tail =
&gt; &gt; &gt; +                   riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; &gt; +               last = iommu-&gt;cmdq.lui;
&gt; &gt; &gt; +               if (tail != last) {
&gt; &gt; &gt; +                       spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; &gt; +                       dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (2nd)\n", last, tail);
&gt; &gt; &gt; +                       spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       next = (last + 1) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; &gt; +       if (next != head) {
&gt; &gt; &gt; +               struct riscv_iommu_command *ptr = iommu-&gt;cmdq.base;
&gt; &gt; &gt; +               ptr[last] = *cmd;
&gt; &gt; &gt; +               wmb();
&gt; &gt; &gt; +               riscv_iommu_writel(iommu, RISCV_IOMMU_REG_CQT, next);
&gt; &gt; &gt; +               iommu-&gt;cmdq.lui = next;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (sync &amp;&amp; head != next) {
&gt; &gt; &gt; +               cycles_t start_time = get_cycles();
&gt; &gt; &gt; +               while (1) {
&gt; &gt; &gt; +                       last = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp;
&gt; &gt; &gt; +                           (iommu-&gt;cmdq.cnt - 1);
&gt; &gt; &gt; +                       if (head &lt; next &amp;&amp; last &gt;= next)
&gt; &gt; &gt; +                               break;
&gt; &gt; &gt; +                       if (head &gt; next &amp;&amp; last &lt; head &amp;&amp; last &gt;= next)
&gt; &gt; &gt; +                               break;
&gt; &gt; &gt; +                       if (RISCV_IOMMU_TIMEOUT &lt; (get_cycles() - start_time)) {
&gt; &gt;
&gt; &gt; This condition will be imprecise, because here is not in irq disabled
&gt; &gt; context, it will be scheduled out or preempted. When we come back
&gt; &gt; here, it might be over 1 second, but the IOFENCE is actually
&gt; &gt; completed.
&gt; &gt;
&gt;
&gt; Good point. Thank.
&gt;
&gt;
&gt; &gt; &gt; +                               dev_err(iommu-&gt;dev, "IOFENCE TIMEOUT\n");
&gt; &gt; &gt; +                               return false;
&gt; &gt; &gt; +                       }
&gt; &gt; &gt; +                       cpu_relax();
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       return next != head;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static bool riscv_iommu_post(struct riscv_iommu_device *iommu,
&gt; &gt; &gt; +                            struct riscv_iommu_command *cmd)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       return riscv_iommu_post_sync(iommu, cmd, false);
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_command cmd;
&gt; &gt; &gt; +       riscv_iommu_cmd_iofence(&amp;cmd);
&gt; &gt; &gt; +       return riscv_iommu_post_sync(iommu, &amp;cmd, true);
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/* Command queue primary interrupt handler */
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu =
&gt; &gt; &gt; +           container_of(q, struct riscv_iommu_device, cmdq);
&gt; &gt; &gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; &gt; &gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_CIP)
&gt; &gt; &gt; +               return IRQ_WAKE_THREAD;
&gt; &gt; &gt; +       return IRQ_NONE;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/* Command queue interrupt hanlder thread function */
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu;
&gt; &gt; &gt; +       unsigned ctrl;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu = container_of(q, struct riscv_iommu_device, cmdq);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Error reporting, clear error reports if any. */
&gt; &gt; &gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQCSR);
&gt; &gt; &gt; +       if (ctrl &amp; (RISCV_IOMMU_CQCSR_CQMF |
&gt; &gt; &gt; +                   RISCV_IOMMU_CQCSR_CMD_TO | RISCV_IOMMU_CQCSR_CMD_ILL)) {
&gt; &gt; &gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;cmdq, ctrl);
&gt; &gt; &gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; &gt; +                                    "Command queue error: fault: %d tout: %d err: %d\n",
&gt; &gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CQMF),
&gt; &gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_TO),
&gt; &gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_ILL));
&gt; &gt;
&gt; &gt; We need to handle the error by either adjusting the tail to remove the
&gt; &gt; failed command or fixing the failed command itself. Otherwise, the
&gt; &gt; failed command will keep in the queue and IOMMU will try to execute
&gt; &gt; it. I guess the first option might be easier to implement.
&gt; &gt;
&gt;
&gt; Correct. Thanks for pointing this out.
&gt; Error handling / recovery was not pushed in this series. There is
&gt; work-in-progress series to handle various types of failures, including
&gt; command processing errors, DDT misconfiguration, queue overflows,
&gt; device reported faults handling, etc.  I can bring some of the error
&gt; handling here, if needed. Otherwise I'd prefer to keep it as separate
&gt; series, sent out once this one is merged.
</span>
It sounds good to me, thanks.

<span class=q>&gt;
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Clear fault interrupt pending. */
&gt; &gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_CIP);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       return IRQ_HANDLED;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/*
&gt; &gt; &gt; + * Fault/event queue, chapter 3.2
&gt; &gt; &gt; + */
&gt; &gt; &gt; +
&gt; &gt; &gt; +static void riscv_iommu_fault_report(struct riscv_iommu_device *iommu,
&gt; &gt; &gt; +                                    struct riscv_iommu_fq_record *event)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       unsigned err, devid;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       err = FIELD_GET(RISCV_IOMMU_FQ_HDR_CAUSE, event-&gt;hdr);
&gt; &gt; &gt; +       devid = FIELD_GET(RISCV_IOMMU_FQ_HDR_DID, event-&gt;hdr);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; &gt; +                            "Fault %d devid: %d" " iotval: %llx iotval2: %llx\n", err,
&gt; &gt; &gt; +                            devid, event-&gt;iotval, event-&gt;iotval2);
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/* Fault/event queue primary interrupt handler */
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu =
&gt; &gt; &gt; +           container_of(q, struct riscv_iommu_device, fltq);
&gt; &gt; &gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; &gt; &gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_FIP)
&gt; &gt; &gt; +               return IRQ_WAKE_THREAD;
&gt; &gt; &gt; +       return IRQ_NONE;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/* Fault queue interrupt hanlder thread function */
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu;
&gt; &gt; &gt; +       struct riscv_iommu_fq_record *events;
&gt; &gt; &gt; +       unsigned cnt, len, idx, ctrl;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu = container_of(q, struct riscv_iommu_device, fltq);
&gt; &gt; &gt; +       events = (struct riscv_iommu_fq_record *)q-&gt;base;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Error reporting, clear error reports if any. */
&gt; &gt; &gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FQCSR);
&gt; &gt; &gt; +       if (ctrl &amp; (RISCV_IOMMU_FQCSR_FQMF | RISCV_IOMMU_FQCSR_FQOF)) {
&gt; &gt; &gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;fltq, ctrl);
&gt; &gt; &gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; &gt; +                                    "Fault queue error: fault: %d full: %d\n",
&gt; &gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQMF),
&gt; &gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQOF));
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Clear fault interrupt pending. */
&gt; &gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_FIP);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Report fault events. */
&gt; &gt; &gt; +       do {
&gt; &gt; &gt; +               cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; &gt; &gt; +               if (!cnt)
&gt; &gt; &gt; +                       break;
&gt; &gt; &gt; +               for (len = 0; len &lt; cnt; idx++, len++)
&gt; &gt; &gt; +                       riscv_iommu_fault_report(iommu, &amp;events[idx]);
&gt; &gt; &gt; +               riscv_iommu_queue_release(iommu, q, cnt);
&gt; &gt; &gt; +       } while (1);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       return IRQ_HANDLED;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/*
&gt; &gt; &gt; + * Page request queue, chapter 3.3
&gt; &gt; &gt; + */
&gt; &gt; &gt; +
&gt; &gt; &gt;  /*
&gt; &gt; &gt;   * Register device for IOMMU tracking.
&gt; &gt; &gt;   */
&gt; &gt; &gt; @@ -97,6 +600,54 @@ static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct devi
&gt; &gt; &gt;         mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; &gt; &gt;  }
&gt; &gt; &gt;
&gt; &gt; &gt; +/* Page request interface queue primary interrupt handler */
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu =
&gt; &gt; &gt; +           container_of(q, struct riscv_iommu_device, priq);
&gt; &gt; &gt; +       u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; &gt; &gt; +       if (ipsr &amp; RISCV_IOMMU_IPSR_PIP)
&gt; &gt; &gt; +               return IRQ_WAKE_THREAD;
&gt; &gt; &gt; +       return IRQ_NONE;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt; +/* Page request interface queue interrupt hanlder thread function */
&gt; &gt; &gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +       struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; &gt; &gt; +       struct riscv_iommu_device *iommu;
&gt; &gt; &gt; +       struct riscv_iommu_pq_record *requests;
&gt; &gt; &gt; +       unsigned cnt, idx, ctrl;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       iommu = container_of(q, struct riscv_iommu_device, priq);
&gt; &gt; &gt; +       requests = (struct riscv_iommu_pq_record *)q-&gt;base;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Error reporting, clear error reports if any. */
&gt; &gt; &gt; +       ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_PQCSR);
&gt; &gt; &gt; +       if (ctrl &amp; (RISCV_IOMMU_PQCSR_PQMF | RISCV_IOMMU_PQCSR_PQOF)) {
&gt; &gt; &gt; +               riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;priq, ctrl);
&gt; &gt; &gt; +               dev_warn_ratelimited(iommu-&gt;dev,
&gt; &gt; &gt; +                                    "Page request queue error: fault: %d full: %d\n",
&gt; &gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQMF),
&gt; &gt; &gt; +                                    !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQOF));
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Clear page request interrupt pending. */
&gt; &gt; &gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_PIP);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Process page requests. */
&gt; &gt; &gt; +       do {
&gt; &gt; &gt; +               cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; &gt; &gt; +               if (!cnt)
&gt; &gt; &gt; +                       break;
&gt; &gt; &gt; +               dev_warn(iommu-&gt;dev, "unexpected %u page requests\n", cnt);
&gt; &gt; &gt; +               riscv_iommu_queue_release(iommu, q, cnt);
&gt; &gt; &gt; +       } while (1);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       return IRQ_HANDLED;
&gt; &gt; &gt; +}
&gt; &gt; &gt; +
&gt; &gt; &gt;  /*
&gt; &gt; &gt;   * Endpoint management
&gt; &gt; &gt;   */
&gt; &gt; &gt; @@ -350,7 +901,29 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt; &gt; &gt;                                           unsigned long *start, unsigned long *end,
&gt; &gt; &gt;                                           size_t *pgsize)
&gt; &gt; &gt;  {
&gt; &gt; &gt; -       /* Command interface not implemented */
&gt; &gt; &gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; &gt; &gt; +       struct riscv_iommu_command cmd;
&gt; &gt; &gt; +       unsigned long iova;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (domain-&gt;mode == RISCV_IOMMU_DC_FSC_MODE_BARE)
&gt; &gt; &gt; +               return;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       /* Domain not attached to an IOMMU! */
&gt; &gt; &gt; +       BUG_ON(!domain-&gt;iommu);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       riscv_iommu_cmd_inval_vma(&amp;cmd);
&gt; &gt; &gt; +       riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
&gt; &gt; &gt; +
&gt; &gt; &gt; +       if (start &amp;&amp; end &amp;&amp; pgsize) {
&gt; &gt; &gt; +               /* Cover only the range that is needed */
&gt; &gt; &gt; +               for (iova = *start; iova &lt;= *end; iova += *pgsize) {
&gt; &gt; &gt; +                       riscv_iommu_cmd_inval_set_addr(&amp;cmd, iova);
&gt; &gt; &gt; +                       riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; &gt; &gt; +               }
&gt; &gt; &gt; +       } else {
&gt; &gt; &gt; +               riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; &gt; &gt; +       }
&gt; &gt; &gt; +       riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt; &gt; &gt;  }
&gt; &gt; &gt;
&gt; &gt; &gt;  static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; &gt; &gt; @@ -610,6 +1183,9 @@ void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt; &gt; &gt;         iommu_device_unregister(&amp;iommu-&gt;iommu);
&gt; &gt; &gt;         iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
&gt; &gt; &gt;         riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; &gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt; &gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; &gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt; &gt; &gt;  }
&gt; &gt; &gt;
&gt; &gt; &gt;  int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt; &gt; @@ -632,6 +1208,16 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt; &gt;         }
&gt; &gt; &gt;  #endif
&gt; &gt; &gt;
&gt; &gt; &gt; +       /*
&gt; &gt; &gt; +        * Assign queue lengths from module parameters if not already
&gt; &gt; &gt; +        * set on the device tree.
&gt; &gt; &gt; +        */
&gt; &gt; &gt; +       if (!iommu-&gt;cmdq_len)
&gt; &gt; &gt; +               iommu-&gt;cmdq_len = cmdq_length;
&gt; &gt; &gt; +       if (!iommu-&gt;fltq_len)
&gt; &gt; &gt; +               iommu-&gt;fltq_len = fltq_length;
&gt; &gt; &gt; +       if (!iommu-&gt;priq_len)
&gt; &gt; &gt; +               iommu-&gt;priq_len = priq_length;
&gt; &gt; &gt;         /* Clear any pending interrupt flag. */
&gt; &gt; &gt;         riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt; &gt; &gt;                            RISCV_IOMMU_IPSR_CIP |
&gt; &gt; &gt; @@ -639,7 +1225,20 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt; &gt;                            RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt; &gt; &gt;         spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt; &gt; &gt;         mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; &gt; &gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_COMMAND_QUEUE);
&gt; &gt; &gt; +       if (ret)
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_FAULT_QUEUE);
&gt; &gt; &gt; +       if (ret)
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt; +       if (!(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS))
&gt; &gt; &gt; +               goto no_ats;
&gt; &gt; &gt; +
&gt; &gt; &gt; +       ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_PAGE_REQUEST_QUEUE);
&gt; &gt; &gt; +       if (ret)
&gt; &gt; &gt; +               goto fail;
&gt; &gt; &gt;
&gt; &gt; &gt; + no_ats:
&gt; &gt; &gt;         ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt; &gt; &gt;
&gt; &gt; &gt;         if (ret) {
&gt; &gt; &gt; @@ -663,5 +1262,8 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; &gt; &gt;         return 0;
&gt; &gt; &gt;   fail:
&gt; &gt; &gt;         riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; &gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt; &gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; &gt; &gt; +       riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt; &gt; &gt;         return ret;
&gt; &gt; &gt;  }
&gt; &gt; &gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; &gt; &gt; index 7dc9baa59a50..04148a2a8ffd 100644
&gt; &gt; &gt; --- a/drivers/iommu/riscv/iommu.h
&gt; &gt; &gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; &gt; &gt; @@ -28,6 +28,24 @@
&gt; &gt; &gt;  #define IOMMU_PAGE_SIZE_1G     BIT_ULL(30)
&gt; &gt; &gt;  #define IOMMU_PAGE_SIZE_512G   BIT_ULL(39)
&gt; &gt; &gt;
&gt; &gt; &gt; +struct riscv_iommu_queue {
&gt; &gt; &gt; +       dma_addr_t base_dma;    /* ring buffer bus address */
&gt; &gt; &gt; +       void *base;             /* ring buffer pointer */
&gt; &gt; &gt; +       size_t len;             /* single item length */
&gt; &gt; &gt; +       u32 cnt;                /* items count */
&gt; &gt; &gt; +       u32 lui;                /* last used index, consumer/producer share */
&gt; &gt; &gt; +       unsigned qbr;           /* queue base register offset */
&gt; &gt; &gt; +       unsigned qcr;           /* queue control and status register offset */
&gt; &gt; &gt; +       int irq;                /* registered interrupt number */
&gt; &gt; &gt; +       bool in_iomem;          /* indicates queue data are in I/O memory  */
&gt; &gt; &gt; +};
&gt; &gt; &gt; +
&gt; &gt; &gt; +enum riscv_queue_ids {
&gt; &gt; &gt; +       RISCV_IOMMU_COMMAND_QUEUE       = 0,
&gt; &gt; &gt; +       RISCV_IOMMU_FAULT_QUEUE         = 1,
&gt; &gt; &gt; +       RISCV_IOMMU_PAGE_REQUEST_QUEUE  = 2
&gt; &gt; &gt; +};
&gt; &gt; &gt; +
&gt; &gt; &gt;  struct riscv_iommu_device {
&gt; &gt; &gt;         struct iommu_device iommu;      /* iommu core interface */
&gt; &gt; &gt;         struct device *dev;             /* iommu hardware */
&gt; &gt; &gt; @@ -42,6 +60,11 @@ struct riscv_iommu_device {
&gt; &gt; &gt;         int irq_pm;
&gt; &gt; &gt;         int irq_priq;
&gt; &gt; &gt;
&gt; &gt; &gt; +       /* Queue lengths */
&gt; &gt; &gt; +       int cmdq_len;
&gt; &gt; &gt; +       int fltq_len;
&gt; &gt; &gt; +       int priq_len;
&gt; &gt; &gt; +
&gt; &gt; &gt;         /* supported and enabled hardware capabilities */
&gt; &gt; &gt;         u64 cap;
&gt; &gt; &gt;
&gt; &gt; &gt; @@ -53,6 +76,11 @@ struct riscv_iommu_device {
&gt; &gt; &gt;         unsigned ddt_mode;
&gt; &gt; &gt;         bool ddtp_in_iomem;
&gt; &gt; &gt;
&gt; &gt; &gt; +       /* hardware queues */
&gt; &gt; &gt; +       struct riscv_iommu_queue cmdq;
&gt; &gt; &gt; +       struct riscv_iommu_queue fltq;
&gt; &gt; &gt; +       struct riscv_iommu_queue priq;
&gt; &gt; &gt; +
&gt; &gt; &gt;         /* Connected end-points */
&gt; &gt; &gt;         struct rb_root eps;
&gt; &gt; &gt;         struct mutex eps_mutex;
&gt; &gt; &gt; --
&gt; &gt; &gt; 2.34.1
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; _______________________________________________
&gt; &gt; &gt; linux-riscv mailing list
&gt; &gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
&gt;
&gt; best,
&gt; - Tomasz
</span>
<a href=#m5d2c47156d2d94a03257441a04bb19a53bb29675 id=e5d2c47156d2d94a03257441a04bb19a53bb29675>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0qWQpnSmYp2rPYVYFCmFzdfxi7Lyo3nvVche6X9dCz89A@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0qWQpnSmYp2rPYVYFCmFzdfxi7Lyo3nvVche6X9dCz89A@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0qWQpnSmYp2rPYVYFCmFzdfxi7Lyo3nvVche6X9dCz89A@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0qWQpnSmYp2rPYVYFCmFzdfxi7Lyo3nvVche6X9dCz89A@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0qWQpnSmYp2rPYVYFCmFzdfxi7Lyo3nvVche6X9dCz89A@mail.gmail.com/t/#u>nested</a>] <a href=#r5d2c47156d2d94a03257441a04bb19a53bb29675>86+ messages in thread</a></pre><hr><pre><a href=#ead9d1c189bf7f0a0a37fb9de00572b6d4aaea68e id=mad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
                     ` <a href=#r428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>(4 preceding siblings ...)</a>
  2023-08-03  0:18   ` <a href=#m428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>Jason Gunthorpe</a>
<b>@ 2023-08-03  8:27   ` Zong Li</b>
  2023-08-16 18:05   ` <a href=#me6007fa63b4fd2def06b60bba503fe5072f38376>Robin Murphy</a>
  2024-04-13 10:15   ` <a href=#m155b6f2fffe6b140c3bb8189cb19c02033deff9d>Xingyou Chen</a>
  <a href=#rad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>7 siblings, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2023-08-03  8:27 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0qhtPzm69TqfO6ELtGR=mbeP99JnmcUNaTA6m5xzRYP+A@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0qhtPzm69TqfO6ELtGR=mbeP99JnmcUNaTA6m5xzRYP+A@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Joerg Roedel, Will Deacon, Robin Murphy, Paul Walmsley,
	Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230803083128">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20230803083128">linux-riscv</a>

On Thu, Jul 20, 2023 at 3:34 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; The patch introduces skeleton IOMMU device driver implementation as defined
&gt; by RISC-V IOMMU Architecture Specification, Version 1.0 [1], with minimal support
&gt; for pass-through mapping, basic initialization and bindings for platform and PCIe
&gt; hardware implementations.
&gt;
&gt; Series of patches following specification evolution has been reorganized to provide
&gt; functional separation of implemented blocks, compliant with ratified specification.
&gt;
&gt; This and following patch series includes code contributed by: Nick Kossifidis
&gt; &lt;mick@ics.forth.gr&gt; (iommu-platform device, number of specification clarification
&gt; and bugfixes and readability improvements), Sebastien Boeuf &lt;seb@rivosinc.com&gt; (page
&gt; table creation, ATS/PGR flow).
&gt;
&gt; Complete history can be found at the maintainer's repository branch [2].
&gt;
&gt; Device driver enables RISC-V 32/64 support for memory translation for DMA capable
&gt; PCI and platform devices, multilevel device directory table, process directory,
&gt; shared virtual address support, wired and message signaled interrupt for translation
&gt; I/O fault, page request interface and command processing.
&gt;
&gt; Matching RISCV-V IOMMU device emulation implementation is available for QEMU project,
&gt; along with educational device extensions for PASID ATS/PRI support [3].
&gt;
&gt; References:
&gt;  - [1] <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
&gt;  - [2] <a href=https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu</a>
&gt;  - [3] <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu</a>
&gt;
&gt; Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;  drivers/iommu/Kconfig                |   1 +
&gt;  drivers/iommu/Makefile               |   2 +-
&gt;  drivers/iommu/riscv/Kconfig          |  22 +
&gt;  drivers/iommu/riscv/Makefile         |   1 +
&gt;  drivers/iommu/riscv/iommu-bits.h     | 704 +++++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu-pci.c      | 134 +++++
&gt;  drivers/iommu/riscv/iommu-platform.c |  94 ++++
&gt;  drivers/iommu/riscv/iommu.c          | 660 +++++++++++++++++++++++++
&gt;  drivers/iommu/riscv/iommu.h          | 115 +++++
&gt;  9 files changed, 1732 insertions(+), 1 deletion(-)
&gt;  create mode 100644 drivers/iommu/riscv/Kconfig
&gt;  create mode 100644 drivers/iommu/riscv/Makefile
&gt;  create mode 100644 drivers/iommu/riscv/iommu-bits.h
&gt;  create mode 100644 drivers/iommu/riscv/iommu-pci.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu-platform.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu.h
&gt;
&gt; diff --git a/drivers/iommu/Kconfig b/drivers/iommu/Kconfig
&gt; index 2b12b583ef4b..36fcc6fd5b4e 100644
&gt; --- a/drivers/iommu/Kconfig
&gt; +++ b/drivers/iommu/Kconfig
&gt; @@ -187,6 +187,7 @@ config MSM_IOMMU
&gt;  source "drivers/iommu/amd/Kconfig"
&gt;  source "drivers/iommu/intel/Kconfig"
&gt;  source "drivers/iommu/iommufd/Kconfig"
&gt; +source "drivers/iommu/riscv/Kconfig"
&gt;
&gt;  config IRQ_REMAP
&gt;         bool "Support for Interrupt Remapping"
&gt; diff --git a/drivers/iommu/Makefile b/drivers/iommu/Makefile
&gt; index 769e43d780ce..8f57110a9fb1 100644
&gt; --- a/drivers/iommu/Makefile
&gt; +++ b/drivers/iommu/Makefile
&gt; @@ -1,5 +1,5 @@
&gt;  # SPDX-License-Identifier: GPL-2.0
&gt; -obj-y += amd/ intel/ arm/ iommufd/
&gt; +obj-y += amd/ intel/ arm/ iommufd/ riscv/
&gt;  obj-$(CONFIG_IOMMU_API) += iommu.o
&gt;  obj-$(CONFIG_IOMMU_API) += iommu-traces.o
&gt;  obj-$(CONFIG_IOMMU_API) += iommu-sysfs.o
&gt; diff --git a/drivers/iommu/riscv/Kconfig b/drivers/iommu/riscv/Kconfig
&gt; new file mode 100644
&gt; index 000000000000..01d4043849d4
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/Kconfig
&gt; @@ -0,0 +1,22 @@
&gt; +# SPDX-License-Identifier: GPL-2.0-only
&gt; +# RISC-V IOMMU support
&gt; +
&gt; +config RISCV_IOMMU
&gt; +       bool "RISC-V IOMMU driver"
&gt; +       depends on RISCV
&gt; +       select IOMMU_API
&gt; +       select IOMMU_DMA
&gt; +       select IOMMU_SVA
&gt; +       select IOMMU_IOVA
&gt; +       select IOMMU_IO_PGTABLE
&gt; +       select IOASID
&gt; +       select PCI_MSI
&gt; +       select PCI_ATS
&gt; +       select PCI_PRI
&gt; +       select PCI_PASID
&gt; +       select MMU_NOTIFIER
&gt; +       help
&gt; +         Support for devices following RISC-V IOMMU specification.
&gt; +
&gt; +         If unsure, say N here.
&gt; +
&gt; diff --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
&gt; new file mode 100644
&gt; index 000000000000..38730c11e4a8
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/Makefile
&gt; @@ -0,0 +1 @@
&gt; +obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o
&gt; \ No newline at end of file
&gt; diff --git a/drivers/iommu/riscv/iommu-bits.h b/drivers/iommu/riscv/iommu-bits.h
&gt; new file mode 100644
&gt; index 000000000000..b2946793a73d
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-bits.h
&gt; @@ -0,0 +1,704 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + * Copyright © 2023 RISC-V IOMMU Task Group
&gt; + *
&gt; + * RISC-V Ziommu - Register Layout and Data Structures.
&gt; + *
&gt; + * Based on the 'RISC-V IOMMU Architecture Specification', Version 1.0
&gt; + * Published at  <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
&gt; + *
&gt; + */
&gt; +
&gt; +#ifndef _RISCV_IOMMU_BITS_H_
&gt; +#define _RISCV_IOMMU_BITS_H_
&gt; +
&gt; +#include &lt;linux/types.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +#include &lt;linux/bits.h&gt;
&gt; +
&gt; +/*
&gt; + * Chapter 5: Memory Mapped register interface
&gt; + */
&gt; +
&gt; +/* Common field positions */
&gt; +#define RISCV_IOMMU_PPN_FIELD          GENMASK_ULL(53, 10)
&gt; +#define RISCV_IOMMU_QUEUE_LOGSZ_FIELD  GENMASK_ULL(4, 0)
&gt; +#define RISCV_IOMMU_QUEUE_INDEX_FIELD  GENMASK_ULL(31, 0)
&gt; +#define RISCV_IOMMU_QUEUE_ENABLE       BIT(0)
&gt; +#define RISCV_IOMMU_QUEUE_INTR_ENABLE  BIT(1)
&gt; +#define RISCV_IOMMU_QUEUE_MEM_FAULT    BIT(8)
&gt; +#define RISCV_IOMMU_QUEUE_OVERFLOW     BIT(9)
&gt; +#define RISCV_IOMMU_QUEUE_ACTIVE       BIT(16)
&gt; +#define RISCV_IOMMU_QUEUE_BUSY         BIT(17)
&gt; +
&gt; +#define RISCV_IOMMU_ATP_PPN_FIELD      GENMASK_ULL(43, 0)
&gt; +#define RISCV_IOMMU_ATP_MODE_FIELD     GENMASK_ULL(63, 60)
&gt; +
&gt; +/* 5.3 IOMMU Capabilities (64bits) */
&gt; +#define RISCV_IOMMU_REG_CAP            0x0000
&gt; +#define RISCV_IOMMU_CAP_VERSION                GENMASK_ULL(7, 0)
&gt; +#define RISCV_IOMMU_CAP_S_SV32         BIT_ULL(8)
&gt; +#define RISCV_IOMMU_CAP_S_SV39         BIT_ULL(9)
&gt; +#define RISCV_IOMMU_CAP_S_SV48         BIT_ULL(10)
&gt; +#define RISCV_IOMMU_CAP_S_SV57         BIT_ULL(11)
&gt; +#define RISCV_IOMMU_CAP_SVPBMT         BIT_ULL(15)
&gt; +#define RISCV_IOMMU_CAP_G_SV32         BIT_ULL(16)
&gt; +#define RISCV_IOMMU_CAP_G_SV39         BIT_ULL(17)
&gt; +#define RISCV_IOMMU_CAP_G_SV48         BIT_ULL(18)
&gt; +#define RISCV_IOMMU_CAP_G_SV57         BIT_ULL(19)
&gt; +#define RISCV_IOMMU_CAP_MSI_FLAT       BIT_ULL(22)
&gt; +#define RISCV_IOMMU_CAP_MSI_MRIF       BIT_ULL(23)
&gt; +#define RISCV_IOMMU_CAP_AMO            BIT_ULL(24)
&gt; +#define RISCV_IOMMU_CAP_ATS            BIT_ULL(25)
&gt; +#define RISCV_IOMMU_CAP_T2GPA          BIT_ULL(26)
&gt; +#define RISCV_IOMMU_CAP_END            BIT_ULL(27)
&gt; +#define RISCV_IOMMU_CAP_IGS            GENMASK_ULL(29, 28)
&gt; +#define RISCV_IOMMU_CAP_HPM            BIT_ULL(30)
&gt; +#define RISCV_IOMMU_CAP_DBG            BIT_ULL(31)
&gt; +#define RISCV_IOMMU_CAP_PAS            GENMASK_ULL(37, 32)
&gt; +#define RISCV_IOMMU_CAP_PD8            BIT_ULL(38)
&gt; +#define RISCV_IOMMU_CAP_PD17           BIT_ULL(39)
&gt; +#define RISCV_IOMMU_CAP_PD20           BIT_ULL(40)
&gt; +
&gt; +#define RISCV_IOMMU_CAP_VERSION_VER_MASK       0xF0
&gt; +#define RISCV_IOMMU_CAP_VERSION_REV_MASK       0x0F
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_igs_settings - Interrupt Generation Support Settings
&gt; + * @RISCV_IOMMU_CAP_IGS_MSI: I/O MMU supports only MSI generation
&gt; + * @RISCV_IOMMU_CAP_IGS_WSI: I/O MMU supports only Wired-Signaled interrupt
&gt; + * @RISCV_IOMMU_CAP_IGS_BOTH: I/O MMU supports both MSI and WSI generation
&gt; + * @RISCV_IOMMU_CAP_IGS_RSRV: Reserved for standard use
&gt; + */
&gt; +enum riscv_iommu_igs_settings {
&gt; +       RISCV_IOMMU_CAP_IGS_MSI = 0,
&gt; +       RISCV_IOMMU_CAP_IGS_WSI = 1,
&gt; +       RISCV_IOMMU_CAP_IGS_BOTH = 2,
&gt; +       RISCV_IOMMU_CAP_IGS_RSRV = 3
&gt; +};
&gt; +
&gt; +/* 5.4 Features control register (32bits) */
&gt; +#define RISCV_IOMMU_REG_FCTL           0x0008
&gt; +#define RISCV_IOMMU_FCTL_BE            BIT(0)
&gt; +#define RISCV_IOMMU_FCTL_WSI           BIT(1)
&gt; +#define RISCV_IOMMU_FCTL_GXL           BIT(2)
&gt; +
&gt; +/* 5.5 Device-directory-table pointer (64bits) */
&gt; +#define RISCV_IOMMU_REG_DDTP           0x0010
&gt; +#define RISCV_IOMMU_DDTP_MODE          GENMASK_ULL(3, 0)
&gt; +#define RISCV_IOMMU_DDTP_BUSY          BIT_ULL(4)
&gt; +#define RISCV_IOMMU_DDTP_PPN           RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_ddtp_modes - I/O MMU translation modes
&gt; + * @RISCV_IOMMU_DDTP_MODE_OFF: No inbound transactions allowed
&gt; + * @RISCV_IOMMU_DDTP_MODE_BARE: Pass-through mode
&gt; + * @RISCV_IOMMU_DDTP_MODE_1LVL: One-level DDT
&gt; + * @RISCV_IOMMU_DDTP_MODE_2LVL: Two-level DDT
&gt; + * @RISCV_IOMMU_DDTP_MODE_3LVL: Three-level DDT
&gt; + */
&gt; +enum riscv_iommu_ddtp_modes {
&gt; +       RISCV_IOMMU_DDTP_MODE_OFF = 0,
&gt; +       RISCV_IOMMU_DDTP_MODE_BARE = 1,
&gt; +       RISCV_IOMMU_DDTP_MODE_1LVL = 2,
&gt; +       RISCV_IOMMU_DDTP_MODE_2LVL = 3,
&gt; +       RISCV_IOMMU_DDTP_MODE_3LVL = 4,
&gt; +       RISCV_IOMMU_DDTP_MODE_MAX = 4
&gt; +};
&gt; +
&gt; +/* 5.6 Command Queue Base (64bits) */
&gt; +#define RISCV_IOMMU_REG_CQB            0x0018
&gt; +#define RISCV_IOMMU_CQB_ENTRIES                RISCV_IOMMU_QUEUE_LOGSZ_FIELD
&gt; +#define RISCV_IOMMU_CQB_PPN            RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.7 Command Queue head (32bits) */
&gt; +#define RISCV_IOMMU_REG_CQH            0x0020
&gt; +#define RISCV_IOMMU_CQH_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.8 Command Queue tail (32bits) */
&gt; +#define RISCV_IOMMU_REG_CQT            0x0024
&gt; +#define RISCV_IOMMU_CQT_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.9 Fault Queue Base (64bits) */
&gt; +#define RISCV_IOMMU_REG_FQB            0x0028
&gt; +#define RISCV_IOMMU_FQB_ENTRIES                RISCV_IOMMU_QUEUE_LOGSZ_FIELD
&gt; +#define RISCV_IOMMU_FQB_PPN            RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.10 Fault Queue Head (32bits) */
&gt; +#define RISCV_IOMMU_REG_FQH            0x0030
&gt; +#define RISCV_IOMMU_FQH_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.11 Fault Queue tail (32bits) */
&gt; +#define RISCV_IOMMU_REG_FQT            0x0034
&gt; +#define RISCV_IOMMU_FQT_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.12 Page Request Queue base (64bits) */
&gt; +#define RISCV_IOMMU_REG_PQB            0x0038
&gt; +#define RISCV_IOMMU_PQB_ENTRIES                RISCV_IOMMU_QUEUE_LOGSZ_FIELD
&gt; +#define RISCV_IOMMU_PQB_PPN            RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.13 Page Request Queue head (32bits) */
&gt; +#define RISCV_IOMMU_REG_PQH            0x0040
&gt; +#define RISCV_IOMMU_PQH_INDEX          RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.14 Page Request Queue tail (32bits) */
&gt; +#define RISCV_IOMMU_REG_PQT            0x0044
&gt; +#define RISCV_IOMMU_PQT_INDEX_MASK     RISCV_IOMMU_QUEUE_INDEX_FIELD
&gt; +
&gt; +/* 5.15 Command Queue CSR (32bits) */
&gt; +#define RISCV_IOMMU_REG_CQCSR          0x0048
&gt; +#define RISCV_IOMMU_CQCSR_CQEN         RISCV_IOMMU_QUEUE_ENABLE
&gt; +#define RISCV_IOMMU_CQCSR_CIE          RISCV_IOMMU_QUEUE_INTR_ENABLE
&gt; +#define RISCV_IOMMU_CQCSR_CQMF         RISCV_IOMMU_QUEUE_MEM_FAULT
&gt; +#define RISCV_IOMMU_CQCSR_CMD_TO       BIT(9)
&gt; +#define RISCV_IOMMU_CQCSR_CMD_ILL      BIT(10)
&gt; +#define RISCV_IOMMU_CQCSR_FENCE_W_IP   BIT(11)
&gt; +#define RISCV_IOMMU_CQCSR_CQON         RISCV_IOMMU_QUEUE_ACTIVE
&gt; +#define RISCV_IOMMU_CQCSR_BUSY         RISCV_IOMMU_QUEUE_BUSY
&gt; +
&gt; +/* 5.16 Fault Queue CSR (32bits) */
&gt; +#define RISCV_IOMMU_REG_FQCSR          0x004C
&gt; +#define RISCV_IOMMU_FQCSR_FQEN         RISCV_IOMMU_QUEUE_ENABLE
&gt; +#define RISCV_IOMMU_FQCSR_FIE          RISCV_IOMMU_QUEUE_INTR_ENABLE
&gt; +#define RISCV_IOMMU_FQCSR_FQMF         RISCV_IOMMU_QUEUE_MEM_FAULT
&gt; +#define RISCV_IOMMU_FQCSR_FQOF         RISCV_IOMMU_QUEUE_OVERFLOW
&gt; +#define RISCV_IOMMU_FQCSR_FQON         RISCV_IOMMU_QUEUE_ACTIVE
&gt; +#define RISCV_IOMMU_FQCSR_BUSY         RISCV_IOMMU_QUEUE_BUSY
&gt; +
&gt; +/* 5.17 Page Request Queue CSR (32bits) */
&gt; +#define RISCV_IOMMU_REG_PQCSR          0x0050
&gt; +#define RISCV_IOMMU_PQCSR_PQEN         RISCV_IOMMU_QUEUE_ENABLE
&gt; +#define RISCV_IOMMU_PQCSR_PIE          RISCV_IOMMU_QUEUE_INTR_ENABLE
&gt; +#define RISCV_IOMMU_PQCSR_PQMF         RISCV_IOMMU_QUEUE_MEM_FAULT
&gt; +#define RISCV_IOMMU_PQCSR_PQOF         RISCV_IOMMU_QUEUE_OVERFLOW
&gt; +#define RISCV_IOMMU_PQCSR_PQON         RISCV_IOMMU_QUEUE_ACTIVE
&gt; +#define RISCV_IOMMU_PQCSR_BUSY         RISCV_IOMMU_QUEUE_BUSY
&gt; +
&gt; +/* 5.18 Interrupt Pending Status (32bits) */
&gt; +#define RISCV_IOMMU_REG_IPSR           0x0054
&gt; +
&gt; +#define RISCV_IOMMU_INTR_CQ            0
&gt; +#define RISCV_IOMMU_INTR_FQ            1
&gt; +#define RISCV_IOMMU_INTR_PM            2
&gt; +#define RISCV_IOMMU_INTR_PQ            3
&gt; +#define RISCV_IOMMU_INTR_COUNT         4
&gt; +
&gt; +#define RISCV_IOMMU_IPSR_CIP           BIT(RISCV_IOMMU_INTR_CQ)
&gt; +#define RISCV_IOMMU_IPSR_FIP           BIT(RISCV_IOMMU_INTR_FQ)
&gt; +#define RISCV_IOMMU_IPSR_PMIP          BIT(RISCV_IOMMU_INTR_PM)
&gt; +#define RISCV_IOMMU_IPSR_PIP           BIT(RISCV_IOMMU_INTR_PQ)
&gt; +
&gt; +/* 5.19 Performance monitoring counter overflow status (32bits) */
&gt; +#define RISCV_IOMMU_REG_IOCOUNTOVF     0x0058
&gt; +#define RISCV_IOMMU_IOCOUNTOVF_CY      BIT(0)
&gt; +#define RISCV_IOMMU_IOCOUNTOVF_HPM     GENMASK_ULL(31, 1)
&gt; +
&gt; +/* 5.20 Performance monitoring counter inhibits (32bits) */
&gt; +#define RISCV_IOMMU_REG_IOCOUNTINH     0x005C
&gt; +#define RISCV_IOMMU_IOCOUNTINH_CY      BIT(0)
&gt; +#define RISCV_IOMMU_IOCOUNTINH_HPM     GENMASK(31, 1)
&gt; +
&gt; +/* 5.21 Performance monitoring cycles counter (64bits) */
&gt; +#define RISCV_IOMMU_REG_IOHPMCYCLES     0x0060
&gt; +#define RISCV_IOMMU_IOHPMCYCLES_COUNTER        GENMASK_ULL(62, 0)
&gt; +#define RISCV_IOMMU_IOHPMCYCLES_OVF    BIT_ULL(63)
&gt; +
&gt; +/* 5.22 Performance monitoring event counters (31 * 64bits) */
&gt; +#define RISCV_IOMMU_REG_IOHPMCTR_BASE  0x0068
&gt; +#define RISCV_IOMMU_REG_IOHPMCTR(_n)   (RISCV_IOMMU_REG_IOHPMCTR_BASE + (_n * 0x8))
&gt; +
&gt; +/* 5.23 Performance monitoring event selectors (31 * 64bits) */
&gt; +#define RISCV_IOMMU_REG_IOHPMEVT_BASE  0x0160
&gt; +#define RISCV_IOMMU_REG_IOHPMEVT(_n)   (RISCV_IOMMU_REG_IOHPMEVT_BASE + (_n * 0x8))
&gt; +#define RISCV_IOMMU_IOHPMEVT_EVENT_ID  GENMASK_ULL(14, 0)
&gt; +#define RISCV_IOMMU_IOHPMEVT_DMASK     BIT_ULL(15)
&gt; +#define RISCV_IOMMU_IOHPMEVT_PID_PSCID GENMASK_ULL(35, 16)
&gt; +#define RISCV_IOMMU_IOHPMEVT_DID_GSCID GENMASK_ULL(59, 36)
&gt; +#define RISCV_IOMMU_IOHPMEVT_PV_PSCV   BIT_ULL(60)
&gt; +#define RISCV_IOMMU_IOHPMEVT_DV_GSCV   BIT_ULL(61)
&gt; +#define RISCV_IOMMU_IOHPMEVT_IDT       BIT_ULL(62)
&gt; +#define RISCV_IOMMU_IOHPMEVT_OF                BIT_ULL(63)
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_hpmevent_id - Performance-monitoring event identifier
&gt; + *
&gt; + * @RISCV_IOMMU_HPMEVENT_INVALID: Invalid event, do not count
&gt; + * @RISCV_IOMMU_HPMEVENT_URQ: Untranslated requests
&gt; + * @RISCV_IOMMU_HPMEVENT_TRQ: Translated requests
&gt; + * @RISCV_IOMMU_HPMEVENT_ATS_RQ: ATS translation requests
&gt; + * @RISCV_IOMMU_HPMEVENT_TLB_MISS: TLB misses
&gt; + * @RISCV_IOMMU_HPMEVENT_DD_WALK: Device directory walks
&gt; + * @RISCV_IOMMU_HPMEVENT_PD_WALK: Process directory walks
&gt; + * @RISCV_IOMMU_HPMEVENT_S_VS_WALKS: S/VS-Stage page table walks
&gt; + * @RISCV_IOMMU_HPMEVENT_G_WALKS: G-Stage page table walks
&gt; + * @RISCV_IOMMU_HPMEVENT_MAX: Value to denote maximum Event IDs
&gt; + */
&gt; +enum riscv_iommu_hpmevent_id {
&gt; +       RISCV_IOMMU_HPMEVENT_INVALID    = 0,
&gt; +       RISCV_IOMMU_HPMEVENT_URQ        = 1,
&gt; +       RISCV_IOMMU_HPMEVENT_TRQ        = 2,
&gt; +       RISCV_IOMMU_HPMEVENT_ATS_RQ     = 3,
&gt; +       RISCV_IOMMU_HPMEVENT_TLB_MISS   = 4,
&gt; +       RISCV_IOMMU_HPMEVENT_DD_WALK    = 5,
&gt; +       RISCV_IOMMU_HPMEVENT_PD_WALK    = 6,
&gt; +       RISCV_IOMMU_HPMEVENT_S_VS_WALKS = 7,
&gt; +       RISCV_IOMMU_HPMEVENT_G_WALKS    = 8,
&gt; +       RISCV_IOMMU_HPMEVENT_MAX        = 9
&gt; +};
&gt; +
&gt; +/* 5.24 Translation request IOVA (64bits) */
&gt; +#define RISCV_IOMMU_REG_TR_REQ_IOVA     0x0258
&gt; +#define RISCV_IOMMU_TR_REQ_IOVA_VPN    GENMASK_ULL(63, 12)
&gt; +
&gt; +/* 5.25 Translation request control (64bits) */
&gt; +#define RISCV_IOMMU_REG_TR_REQ_CTL     0x0260
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_GO_BUSY BIT_ULL(0)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_PRIV    BIT_ULL(1)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_EXE     BIT_ULL(2)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_NW      BIT_ULL(3)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_PID     GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_PV      BIT_ULL(32)
&gt; +#define RISCV_IOMMU_TR_REQ_CTL_DID     GENMASK_ULL(63, 40)
&gt; +
&gt; +/* 5.26 Translation request response (64bits) */
&gt; +#define RISCV_IOMMU_REG_TR_RESPONSE    0x0268
&gt; +#define RISCV_IOMMU_TR_RESPONSE_FAULT  BIT_ULL(0)
&gt; +#define RISCV_IOMMU_TR_RESPONSE_PBMT   GENMASK_ULL(8, 7)
&gt; +#define RISCV_IOMMU_TR_RESPONSE_SZ     BIT_ULL(9)
&gt; +#define RISCV_IOMMU_TR_RESPONSE_PPN    RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/* 5.27 Interrupt cause to vector (64bits) */
&gt; +#define RISCV_IOMMU_REG_IVEC           0x02F8
&gt; +#define RISCV_IOMMU_IVEC_CIV           GENMASK_ULL(3, 0)
&gt; +#define RISCV_IOMMU_IVEC_FIV           GENMASK_ULL(7, 4)
&gt; +#define RISCV_IOMMU_IVEC_PMIV          GENMASK_ULL(11, 8)
&gt; +#define RISCV_IOMMU_IVEC_PIV           GENMASK_ULL(15,12)
&gt; +
&gt; +/* 5.28 MSI Configuration table (32 * 64bits) */
&gt; +#define RISCV_IOMMU_REG_MSI_CONFIG     0x0300
&gt; +#define RISCV_IOMMU_REG_MSI_ADDR(_n)   (RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10))
&gt; +#define RISCV_IOMMU_MSI_ADDR           GENMASK_ULL(55, 2)
&gt; +#define RISCV_IOMMU_REG_MSI_DATA(_n)   (RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10) + 0x08)
&gt; +#define RISCV_IOMMU_MSI_DATA           GENMASK_ULL(31, 0)
&gt; +#define RISCV_IOMMU_REG_MSI_VEC_CTL(_n)        (RISCV_IOMMU_REG_MSI_CONFIG + (_n * 0x10) + 0x0C)
&gt; +#define RISCV_IOMMU_MSI_VEC_CTL_M      BIT_ULL(0)
&gt; +
&gt; +#define RISCV_IOMMU_REG_SIZE   0x1000
&gt; +
&gt; +/*
&gt; + * Chapter 2: Data structures
&gt; + */
&gt; +
&gt; +/*
&gt; + * Device Directory Table macros for non-leaf nodes
&gt; + */
&gt; +#define RISCV_IOMMU_DDTE_VALID BIT_ULL(0)
&gt; +#define RISCV_IOMMU_DDTE_PPN   RISCV_IOMMU_PPN_FIELD
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_dc - Device Context
&gt; + * @tc: Translation Control
&gt; + * @iohgatp: I/O Hypervisor guest address translation and protection
&gt; + *          (Second stage context)
&gt; + * @ta: Translation Attributes
&gt; + * @fsc: First stage context
&gt; + * @msiptpt: MSI page table pointer
&gt; + * @msi_addr_mask: MSI address mask
&gt; + * @msi_addr_pattern: MSI address pattern
&gt; + *
&gt; + * This structure is used for leaf nodes on the Device Directory Table,
&gt; + * in case RISCV_IOMMU_CAP_MSI_FLAT is not set, the bottom 4 fields are
&gt; + * not present and are skipped with pointer arithmetic to avoid
&gt; + * casting, check out riscv_iommu_get_dc().
&gt; + * See section 2.1 for more details
&gt; + */
&gt; +struct riscv_iommu_dc {
&gt; +       u64 tc;
&gt; +       u64 iohgatp;
&gt; +       u64 ta;
&gt; +       u64 fsc;
&gt; +       u64 msiptp;
&gt; +       u64 msi_addr_mask;
&gt; +       u64 msi_addr_pattern;
&gt; +       u64 _reserved;
&gt; +};
&gt; +
&gt; +/* Translation control fields */
&gt; +#define RISCV_IOMMU_DC_TC_V            BIT_ULL(0)
&gt; +#define RISCV_IOMMU_DC_TC_EN_ATS       BIT_ULL(1)
&gt; +#define RISCV_IOMMU_DC_TC_EN_PRI       BIT_ULL(2)
&gt; +#define RISCV_IOMMU_DC_TC_T2GPA                BIT_ULL(3)
&gt; +#define RISCV_IOMMU_DC_TC_DTF          BIT_ULL(4)
&gt; +#define RISCV_IOMMU_DC_TC_PDTV         BIT_ULL(5)
&gt; +#define RISCV_IOMMU_DC_TC_PRPR         BIT_ULL(6)
&gt; +#define RISCV_IOMMU_DC_TC_GADE         BIT_ULL(7)
&gt; +#define RISCV_IOMMU_DC_TC_SADE         BIT_ULL(8)
&gt; +#define RISCV_IOMMU_DC_TC_DPE          BIT_ULL(9)
&gt; +#define RISCV_IOMMU_DC_TC_SBE          BIT_ULL(10)
&gt; +#define RISCV_IOMMU_DC_TC_SXL          BIT_ULL(11)
&gt; +
&gt; +/* Second-stage (aka G-stage) context fields */
&gt; +#define RISCV_IOMMU_DC_IOHGATP_PPN     RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_DC_IOHGATP_GSCID   GENMASK_ULL(59, 44)
&gt; +#define RISCV_IOMMU_DC_IOHGATP_MODE    RISCV_IOMMU_ATP_MODE_FIELD
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_dc_iohgatp_modes - Guest address translation/protection modes
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_BARE: No translation/protection
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV32X4: Sv32x4 (2-bit extension of Sv32), when fctl.GXL == 1
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV39X4: Sv39x4 (2-bit extension of Sv39), when fctl.GXL == 0
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV48X4: Sv48x4 (2-bit extension of Sv48), when fctl.GXL == 0
&gt; + * @RISCV_IOMMU_DC_IOHGATP_MODE_SV57X4: Sv57x4 (2-bit extension of Sv57), when fctl.GXL == 0
&gt; + */
&gt; +enum riscv_iommu_dc_iohgatp_modes {
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_BARE = 0,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV32X4 = 8,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV39X4 = 8,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV48X4 = 9,
&gt; +       RISCV_IOMMU_DC_IOHGATP_MODE_SV57X4 = 10
&gt; +};
&gt; +
&gt; +/* Translation attributes fields */
&gt; +#define RISCV_IOMMU_DC_TA_PSCID                GENMASK_ULL(31,12)
&gt; +
&gt; +/* First-stage context fields */
&gt; +#define RISCV_IOMMU_DC_FSC_PPN         RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_DC_FSC_MODE                RISCV_IOMMU_ATP_MODE_FIELD
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_dc_fsc_atp_modes - First stage address translation/protection modes
&gt; + * @RISCV_IOMMU_DC_FSC_MODE_BARE: No translation/protection
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV32: Sv32, when dc.tc.SXL == 1
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV39: Sv39, when dc.tc.SXL == 0
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV48: Sv48, when dc.tc.SXL == 0
&gt; + * @RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV57: Sv57, when dc.tc.SXL == 0
&gt; + * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8: 1lvl PDT, 8bit process ids
&gt; + * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD17: 2lvl PDT, 17bit process ids
&gt; + * @RISCV_IOMMU_DC_FSC_PDTP_MODE_PD20: 3lvl PDT, 20bit process ids
&gt; + *
&gt; + * FSC holds IOSATP when RISCV_IOMMU_DC_TC_PDTV is 0 and PDTP otherwise.
&gt; + * IOSATP controls the first stage address translation (same as the satp register on
&gt; + * the RISC-V MMU), and PDTP holds the process directory table, used to select a
&gt; + * first stage page table based on a process id (for devices that support multiple
&gt; + * process ids).
&gt; + */
&gt; +enum riscv_iommu_dc_fsc_atp_modes {
&gt; +       RISCV_IOMMU_DC_FSC_MODE_BARE = 0,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV32 = 8,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV39 = 8,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV48 = 9,
&gt; +       RISCV_IOMMU_DC_FSC_IOSATP_MODE_SV57 = 10,
&gt; +       RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8 = 1,
&gt; +       RISCV_IOMMU_DC_FSC_PDTP_MODE_PD17 = 2,
&gt; +       RISCV_IOMMU_DC_FSC_PDTP_MODE_PD20 = 3
&gt; +};
&gt; +
&gt; +/* MSI page table pointer */
&gt; +#define RISCV_IOMMU_DC_MSIPTP_PPN      RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_DC_MSIPTP_MODE     RISCV_IOMMU_ATP_MODE_FIELD
&gt; +#define RISCV_IOMMU_DC_MSIPTP_MODE_OFF 0
&gt; +#define RISCV_IOMMU_DC_MSIPTP_MODE_FLAT        1
&gt; +
&gt; +/* MSI address mask */
&gt; +#define RISCV_IOMMU_DC_MSI_ADDR_MASK   GENMASK_ULL(51, 0)
&gt; +
&gt; +/* MSI address pattern */
&gt; +#define RISCV_IOMMU_DC_MSI_PATTERN     GENMASK_ULL(51, 0)
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_pc - Process Context
&gt; + * @ta: Translation Attributes
&gt; + * @fsc: First stage context
&gt; + *
&gt; + * This structure is used for leaf nodes on the Process Directory Table
&gt; + * See section 2.3 for more details
&gt; + */
&gt; +struct riscv_iommu_pc {
&gt; +       u64 ta;
&gt; +       u64 fsc;
&gt; +};
&gt; +
&gt; +/* Translation attributes fields */
&gt; +#define RISCV_IOMMU_PC_TA_V    BIT_ULL(0)
&gt; +#define RISCV_IOMMU_PC_TA_ENS  BIT_ULL(1)
&gt; +#define RISCV_IOMMU_PC_TA_SUM  BIT_ULL(2)
&gt; +#define RISCV_IOMMU_PC_TA_PSCID        GENMASK_ULL(31, 12)
&gt; +
&gt; +/* First stage context fields */
&gt; +#define RISCV_IOMMU_PC_FSC_PPN RISCV_IOMMU_ATP_PPN_FIELD
&gt; +#define RISCV_IOMMU_PC_FSC_MODE        RISCV_IOMMU_ATP_MODE_FIELD
&gt; +
&gt; +/*
&gt; + * Chapter 3: In-memory queue interface
&gt; + */
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_cmd - Generic I/O MMU command structure
&gt; + * @dword0: Includes the opcode and the function identifier
&gt; + * @dword1: Opcode specific data
&gt; + *
&gt; + * The commands are interpreted as two 64bit fields, where the first
&gt; + * 7bits of the first field are the opcode which also defines the
&gt; + * command's format, followed by a 3bit field that specifies the
&gt; + * function invoked by that command, and the rest is opcode-specific.
&gt; + * This is a generic struct which will be populated differently
&gt; + * according to each command. For more infos on the commands and
&gt; + * the command queue check section 3.1.
&gt; + */
&gt; +struct riscv_iommu_command {
&gt; +       u64 dword0;
&gt; +       u64 dword1;
&gt; +};
&gt; +
&gt; +/* Fields on dword0, common for all commands */
&gt; +#define RISCV_IOMMU_CMD_OPCODE GENMASK_ULL(6, 0)
&gt; +#define        RISCV_IOMMU_CMD_FUNC    GENMASK_ULL(9, 7)
&gt; +
&gt; +/* 3.1.1 I/O MMU Page-table cache invalidation */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_OPCODE                1
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA      0
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_FUNC_GVMA     1
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_AV            BIT_ULL(10)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_PSCID         GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_PSCV          BIT_ULL(32)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_GV            BIT_ULL(33)
&gt; +#define RISCV_IOMMU_CMD_IOTINVAL_GSCID         GENMASK_ULL(59, 44)
&gt; +/* dword1 is the address, 4K-alligned and shifted to the right by
&gt; + * two bits. */
&gt; +
&gt; +/* 3.1.2 I/O MMU Command Queue Fences */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_OPCODE         2
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_FUNC_C         0
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_AV             BIT_ULL(10)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_WSI            BIT_ULL(11)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_PR             BIT_ULL(12)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_PW             BIT_ULL(13)
&gt; +#define RISCV_IOMMU_CMD_IOFENCE_DATA           GENMASK_ULL(63, 32)
&gt; +/* dword1 is the address, word-size alligned and shifted to the
&gt; + * right by two bits. */
&gt; +
&gt; +/* 3.1.3 I/O MMU Directory cache invalidation */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_IODIR_OPCODE           3
&gt; +#define RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT   0
&gt; +#define RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT   1
&gt; +#define RISCV_IOMMU_CMD_IODIR_PID              GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_CMD_IODIR_DV               BIT_ULL(33)
&gt; +#define RISCV_IOMMU_CMD_IODIR_DID              GENMASK_ULL(63, 40)
&gt; +/* dword1 is reserved for standard use */
&gt; +
&gt; +/* 3.1.4 I/O MMU PCIe ATS */
&gt; +/* Fields on dword0 */
&gt; +#define RISCV_IOMMU_CMD_ATS_OPCODE             4
&gt; +#define RISCV_IOMMU_CMD_ATS_FUNC_INVAL         0
&gt; +#define RISCV_IOMMU_CMD_ATS_FUNC_PRGR          1
&gt; +#define RISCV_IOMMU_CMD_ATS_PID                        GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_CMD_ATS_PV                 BIT_ULL(32)
&gt; +#define RISCV_IOMMU_CMD_ATS_DSV                        BIT_ULL(33)
&gt; +#define RISCV_IOMMU_CMD_ATS_RID                        GENMASK_ULL(55, 40)
&gt; +#define RISCV_IOMMU_CMD_ATS_DSEG               GENMASK_ULL(63, 56)
&gt; +/* dword1 is the ATS payload, two different payload types for INVAL and PRGR */
&gt; +
&gt; +/* ATS.INVAL payload*/
&gt; +#define RISCV_IOMMU_CMD_ATS_INVAL_G            BIT_ULL(0)
&gt; +/* Bits 1 - 10 are zeroed */
&gt; +#define RISCV_IOMMU_CMD_ATS_INVAL_S            BIT_ULL(11)
&gt; +#define RISCV_IOMMU_CMD_ATS_INVAL_UADDR                GENMASK_ULL(63, 12)
&gt; +
&gt; +/* ATS.PRGR payload */
&gt; +/* Bits 0 - 31 are zeroed */
&gt; +#define RISCV_IOMMU_CMD_ATS_PRGR_PRG_INDEX     GENMASK_ULL(40, 32)
&gt; +/* Bits 41 - 43 are zeroed */
&gt; +#define RISCV_IOMMU_CMD_ATS_PRGR_RESP_CODE     GENMASK_ULL(47, 44)
&gt; +#define RISCV_IOMMU_CMD_ATS_PRGR_DST_ID                GENMASK_ULL(63, 48)
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_fq_record - Fault/Event Queue Record
&gt; + * @hdr: Header, includes fault/event cause, PID/DID, transaction type etc
&gt; + * @_reserved: Low 32bits for custom use, high 32bits for standard use
&gt; + * @iotval: Transaction-type/cause specific format
&gt; + * @iotval2: Cause specific format
&gt; + *
&gt; + * The fault/event queue reports events and failures raised when
&gt; + * processing transactions. Each record is a 32byte structure where
&gt; + * the first dword has a fixed format for providing generic infos
&gt; + * regarding the fault/event, and two more dwords are there for
&gt; + * fault/event-specific information. For more details see section
&gt; + * 3.2.
&gt; + */
&gt; +struct riscv_iommu_fq_record {
&gt; +       u64 hdr;
&gt; +       u64 _reserved;
&gt; +       u64 iotval;
&gt; +       u64 iotval2;
&gt; +};
&gt; +
&gt; +/* Fields on header */
&gt; +#define RISCV_IOMMU_FQ_HDR_CAUSE       GENMASK_ULL(11, 0)
&gt; +#define RISCV_IOMMU_FQ_HDR_PID         GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_FQ_HDR_PV          BIT_ULL(32)
&gt; +#define RISCV_IOMMU_FQ_HDR_PRIV                BIT_ULL(33)
&gt; +#define RISCV_IOMMU_FQ_HDR_TTYPE       GENMASK_ULL(39, 34)
&gt; +#define RISCV_IOMMU_FQ_HDR_DID         GENMASK_ULL(63, 40)
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_fq_causes - Fault/event cause values
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT: Instruction access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_ADDR_MISALIGNED: Read address misaligned
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT: Read load fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_ADDR_MISALIGNED: Write/AMO address misaligned
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT: Write/AMO access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT_S: Instruction page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT_S: Read page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT_S: Write/AMO page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INST_FAULT_VS: Instruction guest page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_RD_FAULT_VS: Read guest page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_WR_FAULT_VS: Write/AMO guest page fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DMA_DISABLED: All inbound transactions disallowed
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_LOAD_FAULT: DDT entry load access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_INVALID: DDT entry invalid
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_MISCONFIGURED: DDT entry misconfigured
&gt; + * @RISCV_IOMMU_FQ_CAUSE_TTYPE_BLOCKED: Transaction type disallowed
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_LOAD_FAULT: MSI PTE load access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_INVALID: MSI PTE invalid
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_MISCONFIGURED: MSI PTE misconfigured
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MRIF_FAULT: MRIF access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_LOAD_FAULT: PDT entry load access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_INVALID: PDT entry invalid
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_MISCONFIGURED: PDT entry misconfigured
&gt; + * @RISCV_IOMMU_FQ_CAUSE_DDT_CORRUPTED: DDT data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PDT_CORRUPTED: PDT data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_PT_CORRUPTED: MSI page table data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MRIF_CORRUIPTED: MRIF data corruption
&gt; + * @RISCV_IOMMU_FQ_CAUSE_INTERNAL_DP_ERROR: Internal data path error
&gt; + * @RISCV_IOMMU_FQ_CAUSE_MSI_WR_FAULT: IOMMU MSI write access fault
&gt; + * @RISCV_IOMMU_FQ_CAUSE_PT_CORRUPTED: First/second stage page table data corruption
&gt; + *
&gt; + * Values are on table 11 of the spec, encodings 275 - 2047 are reserved for standard
&gt; + * use, and 2048 - 4095 for custom use.
&gt; + */
&gt; +enum riscv_iommu_fq_causes {
&gt; +       RISCV_IOMMU_FQ_CAUSE_INST_FAULT = 1,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_ADDR_MISALIGNED = 4,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_FAULT = 5,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_ADDR_MISALIGNED = 6,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_FAULT = 7,
&gt; +       RISCV_IOMMU_FQ_CAUSE_INST_FAULT_S = 12,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_FAULT_S = 13,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_FAULT_S = 15,
&gt; +       RISCV_IOMMU_FQ_CAUSE_INST_FAULT_VS = 20,
&gt; +       RISCV_IOMMU_FQ_CAUSE_RD_FAULT_VS = 21,
&gt; +       RISCV_IOMMU_FQ_CAUSE_WR_FAULT_VS = 23,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DMA_DISABLED = 256,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_LOAD_FAULT = 257,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_INVALID = 258,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_MISCONFIGURED = 259,
&gt; +       RISCV_IOMMU_FQ_CAUSE_TTYPE_BLOCKED = 260,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_LOAD_FAULT = 261,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_INVALID = 262,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_MISCONFIGURED = 263,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MRIF_FAULT = 264,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_LOAD_FAULT = 265,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_INVALID = 266,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_MISCONFIGURED = 267,
&gt; +       RISCV_IOMMU_FQ_CAUSE_DDT_CORRUPTED = 268,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PDT_CORRUPTED = 269,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_PT_CORRUPTED = 270,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MRIF_CORRUIPTED = 271,
&gt; +       RISCV_IOMMU_FQ_CAUSE_INTERNAL_DP_ERROR = 272,
&gt; +       RISCV_IOMMU_FQ_CAUSE_MSI_WR_FAULT = 273,
&gt; +       RISCV_IOMMU_FQ_CAUSE_PT_CORRUPTED = 274
&gt; +};
&gt; +
&gt; +/**
&gt; + * enum riscv_iommu_fq_ttypes: Fault/event transaction types
&gt; + * @RISCV_IOMMU_FQ_TTYPE_NONE: None. Fault not caused by an inbound transaction.
&gt; + * @RISCV_IOMMU_FQ_TTYPE_UADDR_INST_FETCH: Instruction fetch from untranslated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_UADDR_RD: Read from untranslated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_UADDR_WR: Write/AMO to untranslated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_TADDR_INST_FETCH: Instruction fetch from translated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_TADDR_RD: Read from translated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_TADDR_WR: Write/AMO to translated address
&gt; + * @RISCV_IOMMU_FQ_TTYPE_PCIE_ATS_REQ: PCIe ATS translation request
&gt; + * @RISCV_IOMMU_FW_TTYPE_PCIE_MSG_REQ: PCIe message request
&gt; + *
&gt; + * Values are on table 12 of the spec, type 4 and 10 - 31 are reserved for standard use
&gt; + * and 31 - 63 for custom use.
&gt; + */
&gt; +enum riscv_iommu_fq_ttypes {
&gt; +       RISCV_IOMMU_FQ_TTYPE_NONE = 0,
&gt; +       RISCV_IOMMU_FQ_TTYPE_UADDR_INST_FETCH = 1,
&gt; +       RISCV_IOMMU_FQ_TTYPE_UADDR_RD = 2,
&gt; +       RISCV_IOMMU_FQ_TTYPE_UADDR_WR = 3,
&gt; +       RISCV_IOMMU_FQ_TTYPE_TADDR_INST_FETCH = 5,
&gt; +       RISCV_IOMMU_FQ_TTYPE_TADDR_RD = 6,
&gt; +       RISCV_IOMMU_FQ_TTYPE_TADDR_WR = 7,
&gt; +       RISCV_IOMMU_FQ_TTYPE_PCIE_ATS_REQ = 8,
&gt; +       RISCV_IOMMU_FW_TTYPE_PCIE_MSG_REQ = 9,
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_pq_record - PCIe Page Request record
&gt; + * @hdr: Header, includes PID, DID etc
&gt; + * @payload: Holds the page address, request group and permission bits
&gt; + *
&gt; + * For more infos on the PCIe Page Request queue see chapter 3.3.
&gt; + */
&gt; +struct riscv_iommu_pq_record {
&gt; +       u64 hdr;
&gt; +       u64 payload;
&gt; +};
&gt; +
&gt; +/* Header fields */
&gt; +#define RISCV_IOMMU_PREQ_HDR_PID       GENMASK_ULL(31, 12)
&gt; +#define RISCV_IOMMU_PREQ_HDR_PV                BIT_ULL(32)
&gt; +#define RISCV_IOMMU_PREQ_HDR_PRIV      BIT_ULL(33)
&gt; +#define RISCV_IOMMU_PREQ_HDR_EXEC      BIT_ULL(34)
&gt; +#define RISCV_IOMMU_PREQ_HDR_DID       GENMASK_ULL(63, 40)
&gt; +
&gt; +/* Payload fields */
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_R     BIT_ULL(0)
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_W     BIT_ULL(1)
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_L     BIT_ULL(2)
&gt; +#define RISCV_IOMMU_PREQ_PAYLOAD_M     GENMASK_ULL(2, 0)       /* Mask of RWL for convenience */
&gt; +#define RISCV_IOMMU_PREQ_PRG_INDEX     GENMASK_ULL(11, 3)
&gt; +#define RISCV_IOMMU_PREQ_UADDR         GENMASK_ULL(63, 12)
&gt; +
&gt; +/**
&gt; + * struct riscv_iommu_msi_pte - MSI Page Table Entry
&gt; + * @pte: MSI PTE
&gt; + * @mrif_info: Memory-resident interrupt file info
&gt; + *
&gt; + * The MSI Page Table is used for virtualizing MSIs, so that when
&gt; + * a device sends an MSI to a guest, the IOMMU can reroute it
&gt; + * by translating the MSI address, either to a guest interrupt file
&gt; + * or a memory resident interrupt file (MRIF). Note that this page table
&gt; + * is an array of MSI PTEs, not a multi-level pt, each entry
&gt; + * is a leaf entry. For more infos check out the the AIA spec, chapter 9.5.
&gt; + *
&gt; + * Also in basic mode the mrif_info field is ignored by the IOMMU and can
&gt; + * be used by software, any other reserved fields on pte must be zeroed-out
&gt; + * by software.
&gt; + */
&gt; +struct riscv_iommu_msi_pte {
&gt; +       u64 pte;
&gt; +       u64 mrif_info;
&gt; +};
&gt; +
&gt; +/* Fields on pte */
&gt; +#define RISCV_IOMMU_MSI_PTE_V          BIT_ULL(0)
&gt; +#define RISCV_IOMMU_MSI_PTE_M          GENMASK_ULL(2, 1)
&gt; +#define RISCV_IOMMU_MSI_PTE_MRIF_ADDR  GENMASK_ULL(53, 7)      /* When M == 1 (MRIF mode) */
&gt; +#define RISCV_IOMMU_MSI_PTE_PPN                RISCV_IOMMU_PPN_FIELD   /* When M == 3 (basic mode) */
&gt; +#define RISCV_IOMMU_MSI_PTE_C          BIT_ULL(63)
&gt; +
&gt; +/* Fields on mrif_info */
&gt; +#define RISCV_IOMMU_MSI_MRIF_NID       GENMASK_ULL(9, 0)
&gt; +#define RISCV_IOMMU_MSI_MRIF_NPPN      RISCV_IOMMU_PPN_FIELD
&gt; +#define RISCV_IOMMU_MSI_MRIF_NID_MSB   BIT_ULL(60)
&gt; +
&gt; +#endif /* _RISCV_IOMMU_BITS_H_ */
&gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; new file mode 100644
&gt; index 000000000000..c91f963d7a29
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; @@ -0,0 +1,134 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * RISCV IOMMU as a PCIe device
&gt; + *
&gt; + * Authors
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/compiler.h&gt;
&gt; +#include &lt;linux/pci.h&gt;
&gt; +#include &lt;linux/init.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +
&gt; +#include "iommu.h"
&gt; +
&gt; +/* Rivos Inc. assigned PCI Vendor and Device IDs */
&gt; +#ifndef PCI_VENDOR_ID_RIVOS
&gt; +#define PCI_VENDOR_ID_RIVOS             0x1efd
&gt; +#endif
&gt; +
&gt; +#ifndef PCI_DEVICE_ID_RIVOS_IOMMU
&gt; +#define PCI_DEVICE_ID_RIVOS_IOMMU       0xedf1
&gt; +#endif
&gt; +
&gt; +static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
&gt; +{
&gt; +       struct device *dev = &amp;pdev-&gt;dev;
&gt; +       struct riscv_iommu_device *iommu;
&gt; +       int ret;
&gt; +
&gt; +       ret = pci_enable_device_mem(pdev);
&gt; +       if (ret &lt; 0)
&gt; +               return ret;
&gt; +
&gt; +       ret = pci_request_mem_regions(pdev, KBUILD_MODNAME);
&gt; +       if (ret &lt; 0)
&gt; +               goto fail;
&gt; +
&gt; +       ret = -ENOMEM;
&gt; +
&gt; +       iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; +       if (!iommu)
&gt; +               goto fail;
&gt; +
&gt; +       if (!(pci_resource_flags(pdev, 0) &amp; IORESOURCE_MEM))
&gt; +               goto fail;
&gt; +
&gt; +       if (pci_resource_len(pdev, 0) &lt; RISCV_IOMMU_REG_SIZE)
&gt; +               goto fail;
&gt; +
&gt; +       iommu-&gt;reg_phys = pci_resource_start(pdev, 0);
&gt; +       if (!iommu-&gt;reg_phys)
&gt; +               goto fail;
&gt; +
&gt; +       iommu-&gt;reg = devm_ioremap(dev, iommu-&gt;reg_phys, RISCV_IOMMU_REG_SIZE);
&gt; +       if (!iommu-&gt;reg)
&gt; +               goto fail;
&gt; +
&gt; +       iommu-&gt;dev = dev;
&gt; +       dev_set_drvdata(dev, iommu);
&gt; +
&gt; +       dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
&gt; +       pci_set_master(pdev);
&gt; +
&gt; +       ret = riscv_iommu_init(iommu);
&gt; +       if (!ret)
&gt; +               return ret;
&gt; +
&gt; + fail:
&gt; +       pci_clear_master(pdev);
&gt; +       pci_release_regions(pdev);
&gt; +       pci_disable_device(pdev);
&gt; +       /* Note: devres_release_all() will release iommu and iommu-&gt;reg */
&gt; +       return ret;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_pci_remove(struct pci_dev *pdev)
&gt; +{
&gt; +       riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +       pci_clear_master(pdev);
&gt; +       pci_release_regions(pdev);
&gt; +       pci_disable_device(pdev);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_suspend(struct device *dev)
&gt; +{
&gt; +       dev_warn(dev, "RISC-V IOMMU PM not implemented");
&gt; +       return -ENODEV;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_resume(struct device *dev)
&gt; +{
&gt; +       dev_warn(dev, "RISC-V IOMMU PM not implemented");
&gt; +       return -ENODEV;
&gt; +}
&gt; +
&gt; +static DEFINE_SIMPLE_DEV_PM_OPS(riscv_iommu_pm_ops, riscv_iommu_suspend,
&gt; +                               riscv_iommu_resume);
&gt; +
&gt; +static const struct pci_device_id riscv_iommu_pci_tbl[] = {
&gt; +       {PCI_VENDOR_ID_RIVOS, PCI_DEVICE_ID_RIVOS_IOMMU,
&gt; +        PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0},
&gt; +       {0,}
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(pci, riscv_iommu_pci_tbl);
&gt; +
&gt; +static const struct of_device_id riscv_iommu_of_match[] = {
&gt; +       {.compatible = "riscv,pci-iommu",},
&gt; +       {},
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
&gt; +
&gt; +static struct pci_driver riscv_iommu_pci_driver = {
&gt; +       .name = KBUILD_MODNAME,
&gt; +       .id_table = riscv_iommu_pci_tbl,
&gt; +       .probe = riscv_iommu_pci_probe,
&gt; +       .remove = riscv_iommu_pci_remove,
&gt; +       .driver = {
&gt; +                  .pm = pm_sleep_ptr(&amp;riscv_iommu_pm_ops),
&gt; +                  .of_match_table = riscv_iommu_of_match,
&gt; +                  },
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_pci_driver, pci_register_driver, pci_unregister_driver);
&gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; new file mode 100644
&gt; index 000000000000..e4e8ca6711e7
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; @@ -0,0 +1,94 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * RISC-V IOMMU as a platform device
&gt; + *
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * Author: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/of_platform.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +
&gt; +#include "iommu-bits.h"
&gt; +#include "iommu.h"
&gt; +
&gt; +static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; +{
&gt; +       struct device *dev = &amp;pdev-&gt;dev;
&gt; +       struct riscv_iommu_device *iommu = NULL;
&gt; +       struct resource *res = NULL;
&gt; +       int ret = 0;
&gt; +
&gt; +       iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; +       if (!iommu)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       iommu-&gt;dev = dev;
&gt; +       dev_set_drvdata(dev, iommu);
&gt; +
&gt; +       res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
&gt; +       if (!res) {
&gt; +               dev_err(dev, "could not find resource for register region\n");
&gt; +               return -EINVAL;
&gt; +       }
&gt; +
&gt; +       iommu-&gt;reg = devm_platform_get_and_ioremap_resource(pdev, 0, &amp;res);
&gt; +       if (IS_ERR(iommu-&gt;reg)) {
&gt; +               ret = dev_err_probe(dev, PTR_ERR(iommu-&gt;reg),
&gt; +                                   "could not map register region\n");
&gt; +               goto fail;
&gt; +       };
&gt; +
&gt; +       iommu-&gt;reg_phys = res-&gt;start;
&gt; +
&gt; +       ret = -ENODEV;
&gt; +
&gt; +       /* Sanity check: Did we get the whole register space ? */
&gt; +       if ((res-&gt;end - res-&gt;start + 1) &lt; RISCV_IOMMU_REG_SIZE) {
&gt; +               dev_err(dev, "device region smaller than register file (0x%llx)\n",
&gt; +                       res-&gt;end - res-&gt;start);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; +
&gt; +       return riscv_iommu_init(iommu);
&gt; +
&gt; + fail:
&gt; +       /* Note: devres_release_all() will release iommu and iommu-&gt;reg */
&gt; +       return ret;
&gt; +};
&gt; +
&gt; +static void riscv_iommu_platform_remove(struct platform_device *pdev)
&gt; +{
&gt; +       riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +};
&gt; +
&gt; +static void riscv_iommu_platform_shutdown(struct platform_device *pdev)
&gt; +{
&gt; +       return;
&gt; +};
&gt; +
&gt; +static const struct of_device_id riscv_iommu_of_match[] = {
&gt; +       {.compatible = "riscv,iommu",},
&gt; +       {},
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
&gt; +
&gt; +static struct platform_driver riscv_iommu_platform_driver = {
&gt; +       .driver = {
&gt; +                  .name = "riscv,iommu",
&gt; +                  .of_match_table = riscv_iommu_of_match,
&gt; +                  .suppress_bind_attrs = true,
&gt; +                  },
&gt; +       .probe = riscv_iommu_platform_probe,
&gt; +       .remove_new = riscv_iommu_platform_remove,
&gt; +       .shutdown = riscv_iommu_platform_shutdown,
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_platform_driver, platform_driver_register,
&gt; +             platform_driver_unregister);
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; new file mode 100644
&gt; index 000000000000..8c236242e2cc
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -0,0 +1,660 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * IOMMU API for RISC-V architected Ziommu implementations.
&gt; + *
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * Authors
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
&gt; +
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/compiler.h&gt;
&gt; +#include &lt;linux/pci.h&gt;
&gt; +#include &lt;linux/pci-ats.h&gt;
&gt; +#include &lt;linux/init.h&gt;
&gt; +#include &lt;linux/completion.h&gt;
&gt; +#include &lt;linux/uaccess.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/irqdomain.h&gt;
&gt; +#include &lt;linux/platform_device.h&gt;
&gt; +#include &lt;linux/dma-map-ops.h&gt;
&gt; +#include &lt;asm/page.h&gt;
&gt; +
&gt; +#include "../dma-iommu.h"
&gt; +#include "../iommu-sva.h"
&gt; +#include "iommu.h"
&gt; +
&gt; +#include &lt;asm/csr.h&gt;
&gt; +#include &lt;asm/delay.h&gt;
&gt; +
&gt; +MODULE_DESCRIPTION("IOMMU driver for RISC-V architected Ziommu implementations");
&gt; +MODULE_AUTHOR("Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;");
&gt; +MODULE_AUTHOR("Nick Kossifidis &lt;mick@ics.forth.gr&gt;");
&gt; +MODULE_ALIAS("riscv-iommu");
&gt; +MODULE_LICENSE("GPL v2");
&gt; +
&gt; +/* Global IOMMU params. */
&gt; +static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt; +module_param(ddt_mode, int, 0644);
&gt; +MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt; +
&gt; +/* IOMMU PSCID allocation namespace. */
&gt; +#define RISCV_IOMMU_MAX_PSCID  (1U &lt;&lt; 20)
&gt; +static DEFINE_IDA(riscv_iommu_pscids);
&gt; +
&gt; +/* 1 second */
&gt; +#define RISCV_IOMMU_TIMEOUT    riscv_timebase
&gt; +
&gt; +/* RISC-V IOMMU PPN &lt;&gt; PHYS address conversions, PHYS &lt;=&gt; PPN[53:10] */
&gt; +#define phys_to_ppn(va)  (((va) &gt;&gt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 10))
&gt; +#define ppn_to_phys(pn)         (((pn) &lt;&lt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 12))
&gt; +
&gt; +#define iommu_domain_to_riscv(iommu_domain) \
&gt; +    container_of(iommu_domain, struct riscv_iommu_domain, domain)
&gt; +
&gt; +#define iommu_device_to_riscv(iommu_device) \
&gt; +    container_of(iommu_device, struct riscv_iommu, iommu)
&gt; +
&gt; +static const struct iommu_domain_ops riscv_iommu_domain_ops;
&gt; +static const struct iommu_ops riscv_iommu_ops;
&gt; +
&gt; +/*
&gt; + * Register device for IOMMU tracking.
&gt; + */
&gt; +static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_endpoint *ep, *rb_ep;
&gt; +       struct rb_node **new_node, *parent_node = NULL;
&gt; +
&gt; +       mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +       new_node = &amp;(iommu-&gt;eps.rb_node);
&gt; +       while (*new_node) {
&gt; +               rb_ep = rb_entry(*new_node, struct riscv_iommu_endpoint, node);
&gt; +               parent_node = *new_node;
&gt; +               if (rb_ep-&gt;devid &gt; ep-&gt;devid) {
&gt; +                       new_node = &amp;((*new_node)-&gt;rb_left);
&gt; +               } else if (rb_ep-&gt;devid &lt; ep-&gt;devid) {
&gt; +                       new_node = &amp;((*new_node)-&gt;rb_right);
&gt; +               } else {
&gt; +                       dev_warn(dev, "device %u already in the tree\n", ep-&gt;devid);
&gt; +                       break;
&gt; +               }
&gt; +       }
&gt; +
&gt; +       rb_link_node(&amp;ep-&gt;node, parent_node, new_node);
&gt; +       rb_insert_color(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; +
&gt; +       mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; +}
&gt; +
&gt; +/*
&gt; + * Endpoint management
&gt; + */
&gt; +
&gt; +static int riscv_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)
&gt; +{
&gt; +       return iommu_fwspec_add_ids(dev, args-&gt;args, 1);
&gt; +}
&gt; +
&gt; +static bool riscv_iommu_capable(struct device *dev, enum iommu_cap cap)
&gt; +{
&gt; +       switch (cap) {
&gt; +       case IOMMU_CAP_CACHE_COHERENCY:
&gt; +       case IOMMU_CAP_PRE_BOOT_PROTECTION:
&gt; +               return true;
&gt; +
&gt; +       default:
&gt; +               break;
&gt; +       }
&gt; +
&gt; +       return false;
&gt; +}
&gt; +
&gt; +static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_device *iommu;
&gt; +       struct riscv_iommu_endpoint *ep;
&gt; +       struct iommu_fwspec *fwspec;
&gt; +
&gt; +       fwspec = dev_iommu_fwspec_get(dev);
&gt; +       if (!fwspec || fwspec-&gt;ops != &amp;riscv_iommu_ops ||
&gt; +           !fwspec-&gt;iommu_fwnode || !fwspec-&gt;iommu_fwnode-&gt;dev)
&gt; +               return ERR_PTR(-ENODEV);
&gt; +
&gt; +       iommu = dev_get_drvdata(fwspec-&gt;iommu_fwnode-&gt;dev);
&gt; +       if (!iommu)
&gt; +               return ERR_PTR(-ENODEV);
&gt; +
&gt; +       if (dev_iommu_priv_get(dev))
&gt; +               return &amp;iommu-&gt;iommu;
&gt; +
&gt; +       ep = kzalloc(sizeof(*ep), GFP_KERNEL);
&gt; +       if (!ep)
&gt; +               return ERR_PTR(-ENOMEM);
&gt; +
&gt; +       mutex_init(&amp;ep-&gt;lock);
&gt; +       INIT_LIST_HEAD(&amp;ep-&gt;domain);
&gt; +
&gt; +       if (dev_is_pci(dev)) {
&gt; +               ep-&gt;devid = pci_dev_id(to_pci_dev(dev));
&gt; +               ep-&gt;domid = pci_domain_nr(to_pci_dev(dev)-&gt;bus);
&gt; +       } else {
&gt; +               /* TODO: Make this generic, for now hardcode domain id to 0 */
&gt; +               ep-&gt;devid = fwspec-&gt;ids[0];
&gt; +               ep-&gt;domid = 0;
&gt; +       }
&gt; +
&gt; +       ep-&gt;iommu = iommu;
&gt; +       ep-&gt;dev = dev;
&gt; +
&gt; +       dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt; +               ep-&gt;devid, ep-&gt;domid);
&gt; +
&gt; +       dev_iommu_priv_set(dev, ep);
&gt; +       riscv_iommu_add_device(iommu, dev);
&gt; +
&gt; +       return &amp;iommu-&gt;iommu;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_probe_finalize(struct device *dev)
&gt; +{
&gt; +       set_dma_ops(dev, NULL);
&gt; +       iommu_setup_dma_ops(dev, 0, U64_MAX);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_release_device(struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +       struct riscv_iommu_device *iommu = ep-&gt;iommu;
&gt; +
&gt; +       dev_info(dev, "device with devid %i released\n", ep-&gt;devid);
&gt; +
&gt; +       mutex_lock(&amp;ep-&gt;lock);
&gt; +       list_del(&amp;ep-&gt;domain);
&gt; +       mutex_unlock(&amp;ep-&gt;lock);
&gt; +
&gt; +       /* Remove endpoint from IOMMU tracking structures */
&gt; +       mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt; +       rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; +       mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       set_dma_ops(dev, NULL);
&gt; +       dev_iommu_priv_set(dev, NULL);
&gt; +
&gt; +       kfree(ep);
&gt; +}
&gt; +
&gt; +static struct iommu_group *riscv_iommu_device_group(struct device *dev)
&gt; +{
&gt; +       if (dev_is_pci(dev))
&gt; +               return pci_device_group(dev);
&gt; +       return generic_device_group(dev);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_get_resv_regions(struct device *dev, struct list_head *head)
&gt; +{
&gt; +       iommu_dma_get_resv_regions(dev, head);
&gt; +}
&gt; +
&gt; +/*
&gt; + * Domain management
&gt; + */
&gt; +
&gt; +static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain;
&gt; +
&gt; +       if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; +           type != IOMMU_DOMAIN_BLOCKED)
&gt; +               return NULL;
&gt; +
&gt; +       domain = kzalloc(sizeof(*domain), GFP_KERNEL);
&gt; +       if (!domain)
&gt; +               return NULL;
&gt; +
&gt; +       mutex_init(&amp;domain-&gt;lock);
&gt; +       INIT_LIST_HEAD(&amp;domain-&gt;endpoints);
&gt; +
&gt; +       domain-&gt;domain.ops = &amp;riscv_iommu_domain_ops;
&gt; +       domain-&gt;mode = RISCV_IOMMU_DC_FSC_MODE_BARE;
&gt; +       domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt; +                                       RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
&gt; +
&gt; +       printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; +
&gt; +       return &amp;domain-&gt;domain;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (!list_empty(&amp;domain-&gt;endpoints)) {
&gt; +               pr_warn("IOMMU domain is not empty!\n");
&gt; +       }
&gt; +
&gt; +       if (domain-&gt;pgd_root)
&gt; +               free_pages((unsigned long)domain-&gt;pgd_root, 0);
&gt; +
&gt; +       if ((int)domain-&gt;pscid &gt; 0)
&gt; +               ida_free(&amp;riscv_iommu_pscids, domain-&gt;pscid);
&gt; +
&gt; +       printk("domain free %u\n", domain-&gt;pscid);
&gt; +
&gt; +       kfree(domain);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt; +                                      struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       struct iommu_domain_geometry *geometry;
&gt; +
&gt; +       /* Domain assigned to another iommu */
&gt; +       if (domain-&gt;iommu &amp;&amp; domain-&gt;iommu != iommu)
&gt; +               return -EINVAL;
&gt; +       /* Domain already initialized */
&gt; +       else if (domain-&gt;iommu)
&gt; +               return 0;
&gt; +
&gt; +       /*
&gt; +        * TODO: Before using VA_BITS and satp_mode here, verify they
&gt; +        * are supported by the iommu, through the capabilities register.
&gt; +        */
&gt; +
&gt; +       geometry = &amp;domain-&gt;domain.geometry;
&gt; +
&gt; +       /*
&gt; +        * Note: RISC-V Privilege spec mandates that virtual addresses
&gt; +        * need to be sign-extended, so if (VA_BITS - 1) is set, all
&gt; +        * bits &gt;= VA_BITS need to also be set or else we'll get a
&gt; +        * page fault. However the code that creates the mappings
&gt; +        * above us (e.g. iommu_dma_alloc_iova()) won't do that for us
&gt; +        * for now, so we'll end up with invalid virtual addresses
&gt; +        * to map. As a workaround until we get this sorted out
&gt; +        * limit the available virtual addresses to VA_BITS - 1.
&gt; +        */
&gt; +       geometry-&gt;aperture_start = 0;
&gt; +       geometry-&gt;aperture_end = DMA_BIT_MASK(VA_BITS - 1);
&gt; +       geometry-&gt;force_aperture = true;
&gt; +
&gt; +       domain-&gt;iommu = iommu;
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return 0;
&gt; +
&gt; +       /* TODO: Fix this for RV32 */
&gt; +       domain-&gt;mode = satp_mode &gt;&gt; 60;
&gt; +       domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO, 0);
&gt; +
&gt; +       if (!domain-&gt;pgd_root)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct device *dev)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +       struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +       int ret;
&gt; +
&gt; +       /* PSCID not valid */
&gt; +       if ((int)domain-&gt;pscid &lt; 0)
&gt; +               return -ENOMEM;
&gt; +
&gt; +       mutex_lock(&amp;domain-&gt;lock);
&gt; +       mutex_lock(&amp;ep-&gt;lock);
&gt; +
&gt; +       if (!list_empty(&amp;ep-&gt;domain)) {
&gt; +               dev_warn(dev, "endpoint already attached to a domain. dropping\n");
&gt; +               list_del_init(&amp;ep-&gt;domain);
&gt; +       }
&gt; +
&gt; +       /* allocate root pages, initialize io-pgtable ops, etc. */
&gt; +       ret = riscv_iommu_domain_finalize(domain, ep-&gt;iommu);
&gt; +       if (ret &lt; 0) {
&gt; +               dev_err(dev, "can not finalize domain: %d\n", ret);
&gt; +               mutex_unlock(&amp;ep-&gt;lock);
&gt; +               mutex_unlock(&amp;domain-&gt;lock);
&gt; +               return ret;
&gt; +       }
&gt; +
&gt; +       if (ep-&gt;iommu-&gt;ddt_mode != RISCV_IOMMU_DDTP_MODE_BARE ||
&gt; +           domain-&gt;domain.type != IOMMU_DOMAIN_IDENTITY) {
&gt; +               dev_warn(dev, "domain type %d not supported\n",
&gt; +                   domain-&gt;domain.type);
&gt; +               return -ENODEV;
&gt; +       }
&gt; +
&gt; +       list_add_tail(&amp;ep-&gt;domain, &amp;domain-&gt;endpoints);
&gt; +       mutex_unlock(&amp;ep-&gt;lock);
&gt; +       mutex_unlock(&amp;domain-&gt;lock);
&gt; +
&gt; +       dev_info(dev, "domain type %d attached w/ PSCID %u\n",
&gt; +           domain-&gt;domain.type, domain-&gt;pscid);
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt; +                                         unsigned long *start, unsigned long *end,
&gt; +                                         size_t *pgsize)
&gt; +{
&gt; +       /* Command interface not implemented */
&gt; +}
&gt; +
&gt; +static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; +{
&gt; +       riscv_iommu_flush_iotlb_range(iommu_domain, NULL, NULL, NULL);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_iotlb_sync(struct iommu_domain *iommu_domain,
&gt; +                                  struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +       riscv_iommu_flush_iotlb_range(iommu_domain, &amp;gather-&gt;start, &amp;gather-&gt;end,
&gt; +                                     &amp;gather-&gt;pgsize);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_iotlb_sync_map(struct iommu_domain *iommu_domain,
&gt; +                                      unsigned long iova, size_t size)
&gt; +{
&gt; +       unsigned long end = iova + size - 1;
&gt; +       /*
&gt; +        * Given we don't know the page size used by this range, we assume the
&gt; +        * smallest page size to ensure all possible entries are flushed from
&gt; +        * the IOATC.
&gt; +        */
&gt; +       size_t pgsize = PAGE_SIZE;
&gt; +       riscv_iommu_flush_iotlb_range(iommu_domain, &amp;iova, &amp;end, &amp;pgsize);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
&gt; +                                unsigned long iova, phys_addr_t phys,
&gt; +                                size_t pgsize, size_t pgcount, int prot,
&gt; +                                gfp_t gfp, size_t *mapped)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; +               *mapped = pgsize * pgcount;
&gt; +               return 0;
&gt; +       }
&gt; +
&gt; +       return -ENODEV;
&gt; +}
&gt; +
&gt; +static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt; +                                     unsigned long iova, size_t pgsize,
&gt; +                                     size_t pgcount, struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return pgsize * pgcount;
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt; +                                           dma_addr_t iova)
&gt; +{
&gt; +       struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +       if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +               return (phys_addr_t) iova;
&gt; +
&gt; +       return 0;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Translation mode setup
&gt; + */
&gt; +
&gt; +static u64 riscv_iommu_get_ddtp(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       u64 ddtp;
&gt; +       cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
&gt; +
&gt; +       /* Wait for DDTP.BUSY to be cleared and return latest value */
&gt; +       do {
&gt; +               ddtp = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_DDTP);
&gt; +               if (!(ddtp &amp; RISCV_IOMMU_DDTP_BUSY))
&gt; +                       break;
&gt; +               cpu_relax();
&gt; +       } while (get_cycles() &lt; end_cycles);
&gt; +
&gt; +       return ddtp;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_ddt_cleanup(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       /* TODO: teardown whole device directory tree. */
&gt; +       if (iommu-&gt;ddtp) {
&gt; +               if (iommu-&gt;ddtp_in_iomem) {
&gt; +                       iounmap((void *)iommu-&gt;ddtp);
&gt; +               } else
&gt; +                       free_page(iommu-&gt;ddtp);
&gt; +               iommu-&gt;ddtp = 0;
&gt; +       }
&gt; +}
&gt; +
&gt; +static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned requested_mode)
&gt; +{
&gt; +       struct device *dev = iommu-&gt;dev;
&gt; +       u64 ddtp = 0;
&gt; +       u64 ddtp_paddr = 0;
&gt; +       unsigned mode = requested_mode;
&gt; +       unsigned mode_readback = 0;
&gt; +
&gt; +       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +       if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY)
&gt; +               return -EBUSY;
&gt; +
&gt; +       /* Disallow state transtion from xLVL to xLVL. */
&gt; +       switch (FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp)) {
&gt; +       case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; +       case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; +               break;
&gt; +       default:
&gt; +               if ((mode != RISCV_IOMMU_DDTP_MODE_BARE)
&gt; +                   &amp;&amp; (mode != RISCV_IOMMU_DDTP_MODE_OFF))
&gt; +                       return -EINVAL;
&gt; +               break;
&gt; +       }
&gt; +
&gt; + retry:
&gt; +       switch (mode) {
&gt; +       case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; +       case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; +               riscv_iommu_ddt_cleanup(iommu);
&gt; +               ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode);
&gt; +               break;
&gt; +       case RISCV_IOMMU_DDTP_MODE_1LVL:
&gt; +       case RISCV_IOMMU_DDTP_MODE_2LVL:
&gt; +       case RISCV_IOMMU_DDTP_MODE_3LVL:
&gt; +               if (!iommu-&gt;ddtp) {
&gt; +                       /*
&gt; +                        * We haven't initialized ddtp yet, since it's WARL make
&gt; +                        * sure that we don't have a hardwired PPN field there
&gt; +                        * that points to i/o memory instead.
&gt; +                        */
&gt; +                       riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, 0);
&gt; +                       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +                       ddtp_paddr = ppn_to_phys(ddtp);
&gt; +                       if (ddtp_paddr) {
&gt; +                               dev_warn(dev, "ddtp at 0x%llx\n", ddtp_paddr);
&gt; +                               iommu-&gt;ddtp =
&gt; +                                   (unsigned long)ioremap(ddtp_paddr, PAGE_SIZE);
&gt; +                               iommu-&gt;ddtp_in_iomem = true;
&gt; +                       } else {
&gt; +                               iommu-&gt;ddtp = get_zeroed_page(GFP_KERNEL);
&gt; +                       }
&gt; +               }
&gt; +               if (!iommu-&gt;ddtp)
&gt; +                       return -ENOMEM;
&gt; +
&gt; +               ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode) |
&gt; +                   phys_to_ppn(__pa(iommu-&gt;ddtp));
&gt; +
&gt; +               break;
&gt; +       default:
&gt; +               return -EINVAL;
&gt; +       }
&gt; +
&gt; +       riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, ddtp);
&gt; +       ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +       if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY) {
&gt; +               dev_warn(dev, "timeout when setting ddtp (ddt mode: %i)\n", mode);
&gt; +               return -EBUSY;
&gt; +       }
&gt; +
&gt; +       mode_readback = FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp);
&gt; +       dev_info(dev, "mode_readback: %i, mode: %i\n", mode_readback, mode);
&gt; +       if (mode_readback != mode) {
&gt; +               /*
&gt; +                * Mode field is WARL, an I/O MMU may support a subset of
&gt; +                * directory table levels in which case if we tried to set
&gt; +                * an unsupported number of levels we'll readback either
&gt; +                * a valid xLVL or off/bare. If we got off/bare, try again
&gt; +                * with a smaller xLVL.
&gt; +                */
&gt; +               if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
&gt; +                   mode &gt; RISCV_IOMMU_DDTP_MODE_1LVL) {
&gt; +                       mode--;
&gt; +                       goto retry;
&gt; +               }
&gt; +
&gt; +               /*
&gt; +                * We tried all supported xLVL modes and still got off/bare instead,
&gt; +                * an I/O MMU must support at least one supported xLVL mode so something
&gt; +                * went very wrong.
&gt; +                */
&gt; +               if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
&gt; +                   mode == RISCV_IOMMU_DDTP_MODE_1LVL)
&gt; +                       goto fail;
&gt; +
&gt; +               /*
&gt; +                * We tried setting off or bare and got something else back, something
&gt; +                * went very wrong since off/bare is always legal.
&gt; +                */
&gt; +               if (mode &lt; RISCV_IOMMU_DDTP_MODE_1LVL)
&gt; +                       goto fail;
&gt; +
&gt; +               /*
&gt; +                * We tried setting an xLVL mode but got another xLVL mode that
&gt; +                * we don't support (e.g. a custom one).
&gt; +                */
&gt; +               if (mode_readback &gt; RISCV_IOMMU_DDTP_MODE_MAX)
&gt; +                       goto fail;
&gt; +
&gt; +               /* We tried setting an xLVL mode but got another supported xLVL mode */
&gt; +               mode = mode_readback;
&gt; +       }
&gt; +
&gt; +       if (mode != requested_mode)
&gt; +               dev_warn(dev, "unsupported DDT mode requested (%i), using %i instead\n",
&gt; +                        requested_mode, mode);
&gt; +
&gt; +       iommu-&gt;ddt_mode = mode;
&gt; +       dev_info(dev, "ddt_mode: %i\n", iommu-&gt;ddt_mode);
&gt; +       return 0;
&gt; +
&gt; + fail:
&gt; +       dev_err(dev, "failed to set DDT mode, tried: %i and got %i\n", mode,
&gt; +               mode_readback);
&gt; +       riscv_iommu_ddt_cleanup(iommu);
&gt; +       return -EINVAL;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Common I/O MMU driver probe/teardown
&gt; + */
&gt; +
&gt; +static const struct iommu_domain_ops riscv_iommu_domain_ops = {
&gt; +       .free = riscv_iommu_domain_free,
&gt; +       .attach_dev = riscv_iommu_attach_dev,
</span>
Could I know why there is no implementation of '.detach_dev' ? It
seems that we need to clear something when device is detached, such as
device context.

<span class=q>&gt; +       .map_pages = riscv_iommu_map_pages,
&gt; +       .unmap_pages = riscv_iommu_unmap_pages,
&gt; +       .iova_to_phys = riscv_iommu_iova_to_phys,
&gt; +       .iotlb_sync = riscv_iommu_iotlb_sync,
&gt; +       .iotlb_sync_map = riscv_iommu_iotlb_sync_map,
&gt; +       .flush_iotlb_all = riscv_iommu_flush_iotlb_all,
&gt; +};
&gt; +
&gt; +static const struct iommu_ops riscv_iommu_ops = {
&gt; +       .owner = THIS_MODULE,
&gt; +       .pgsize_bitmap = SZ_4K | SZ_2M | SZ_512M,
&gt; +       .capable = riscv_iommu_capable,
&gt; +       .domain_alloc = riscv_iommu_domain_alloc,
&gt; +       .probe_device = riscv_iommu_probe_device,
&gt; +       .probe_finalize = riscv_iommu_probe_finalize,
&gt; +       .release_device = riscv_iommu_release_device,
&gt; +       .device_group = riscv_iommu_device_group,
&gt; +       .get_resv_regions = riscv_iommu_get_resv_regions,
&gt; +       .of_xlate = riscv_iommu_of_xlate,
&gt; +       .default_domain_ops = &amp;riscv_iommu_domain_ops,
&gt; +};
&gt; +
&gt; +void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       iommu_device_unregister(&amp;iommu-&gt;iommu);
&gt; +       riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +}
&gt; +
&gt; +int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +       struct device *dev = iommu-&gt;dev;
&gt; +       u32 fctl = 0;
&gt; +       int ret;
&gt; +
&gt; +       iommu-&gt;eps = RB_ROOT;
&gt; +
&gt; +       fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; +
&gt; +#ifdef CONFIG_CPU_BIG_ENDIAN
&gt; +       if (!(cap &amp; RISCV_IOMMU_CAP_END)) {
&gt; +               dev_err(dev, "IOMMU doesn't support Big Endian\n");
&gt; +               return -EIO;
&gt; +       } else if (!(fctl &amp; RISCV_IOMMU_FCTL_BE)) {
&gt; +               fctl |= FIELD_PREP(RISCV_IOMMU_FCTL_BE, 1);
&gt; +               riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; +       }
&gt; +#endif
&gt; +
&gt; +       /* Clear any pending interrupt flag. */
&gt; +       riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt; +                          RISCV_IOMMU_IPSR_CIP |
&gt; +                          RISCV_IOMMU_IPSR_FIP |
&gt; +                          RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt; +       spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt; +       mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +       ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt; +
&gt; +       if (ret) {
&gt; +               dev_err(dev, "cannot enable iommu device (%d)\n", ret);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       ret = iommu_device_register(&amp;iommu-&gt;iommu, &amp;riscv_iommu_ops, dev);
&gt; +       if (ret) {
&gt; +               dev_err(dev, "cannot register iommu interface (%d)\n", ret);
&gt; +               iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
&gt; +               goto fail;
&gt; +       }
&gt; +
&gt; +       return 0;
&gt; + fail:
&gt; +       riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +       return ret;
&gt; +}
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; new file mode 100644
&gt; index 000000000000..7baefd3630b3
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -0,0 +1,115 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * RISC-V Ziommu - IOMMU Interface Specification.
&gt; + *
&gt; + * Authors
&gt; + *     Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *     Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#ifndef _RISCV_IOMMU_H_
&gt; +#define _RISCV_IOMMU_H_
&gt; +
&gt; +#include &lt;linux/types.h&gt;
&gt; +#include &lt;linux/iova.h&gt;
&gt; +#include &lt;linux/io.h&gt;
&gt; +#include &lt;linux/idr.h&gt;
&gt; +#include &lt;linux/list.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/io-pgtable.h&gt;
&gt; +
&gt; +#include "iommu-bits.h"
&gt; +
&gt; +#define IOMMU_PAGE_SIZE_4K     BIT_ULL(12)
&gt; +#define IOMMU_PAGE_SIZE_2M     BIT_ULL(21)
&gt; +#define IOMMU_PAGE_SIZE_1G     BIT_ULL(30)
&gt; +#define IOMMU_PAGE_SIZE_512G   BIT_ULL(39)
&gt; +
&gt; +struct riscv_iommu_device {
&gt; +       struct iommu_device iommu;      /* iommu core interface */
&gt; +       struct device *dev;             /* iommu hardware */
&gt; +
&gt; +       /* hardware control register space */
&gt; +       void __iomem *reg;
&gt; +       resource_size_t reg_phys;
&gt; +
&gt; +       /* IRQs for the various queues */
&gt; +       int irq_cmdq;
&gt; +       int irq_fltq;
&gt; +       int irq_pm;
&gt; +       int irq_priq;
&gt; +
&gt; +       /* supported and enabled hardware capabilities */
&gt; +       u64 cap;
&gt; +
&gt; +       /* global lock, to be removed */
&gt; +       spinlock_t cq_lock;
&gt; +
&gt; +       /* device directory table root pointer and mode */
&gt; +       unsigned long ddtp;
&gt; +       unsigned ddt_mode;
&gt; +       bool ddtp_in_iomem;
&gt; +
&gt; +       /* Connected end-points */
&gt; +       struct rb_root eps;
&gt; +       struct mutex eps_mutex;
&gt; +};
&gt; +
&gt; +struct riscv_iommu_domain {
&gt; +       struct iommu_domain domain;
&gt; +
&gt; +       struct list_head endpoints;
&gt; +       struct mutex lock;
&gt; +       struct riscv_iommu_device *iommu;
&gt; +
&gt; +       unsigned mode;          /* RIO_ATP_MODE_* enum */
&gt; +       unsigned pscid;         /* RISC-V IOMMU PSCID */
&gt; +
&gt; +       pgd_t *pgd_root;        /* page table root pointer */
&gt; +};
&gt; +
&gt; +/* Private dev_iommu_priv object, device-domain relationship. */
&gt; +struct riscv_iommu_endpoint {
&gt; +       struct device *dev;                     /* platform or PCI endpoint device */
&gt; +       unsigned devid;                         /* PCI bus:device:function number */
&gt; +       unsigned domid;                         /* PCI domain number, segment */
&gt; +       struct rb_node node;                    /* device tracking node (lookup by devid) */
&gt; +       struct riscv_iommu_device *iommu;       /* parent iommu device */
&gt; +
&gt; +       struct mutex lock;
&gt; +       struct list_head domain;                /* endpoint attached managed domain */
&gt; +};
&gt; +
&gt; +/* Helper functions and macros */
&gt; +
&gt; +static inline u32 riscv_iommu_readl(struct riscv_iommu_device *iommu,
&gt; +                                   unsigned offset)
&gt; +{
&gt; +       return readl_relaxed(iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_writel(struct riscv_iommu_device *iommu,
&gt; +                                     unsigned offset, u32 val)
&gt; +{
&gt; +       writel_relaxed(val, iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +static inline u64 riscv_iommu_readq(struct riscv_iommu_device *iommu,
&gt; +                                   unsigned offset)
&gt; +{
&gt; +       return readq_relaxed(iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_writeq(struct riscv_iommu_device *iommu,
&gt; +                                     unsigned offset, u64 val)
&gt; +{
&gt; +       writeq_relaxed(val, iommu-&gt;reg + offset);
&gt; +}
&gt; +
&gt; +int riscv_iommu_init(struct riscv_iommu_device *iommu);
&gt; +void riscv_iommu_remove(struct riscv_iommu_device *iommu);
&gt; +
&gt; +#endif
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
<a href=#mad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e id=ead9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0qhtPzm69TqfO6ELtGR=mbeP99JnmcUNaTA6m5xzRYP+A@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0qhtPzm69TqfO6ELtGR=mbeP99JnmcUNaTA6m5xzRYP+A@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0qhtPzm69TqfO6ELtGR=mbeP99JnmcUNaTA6m5xzRYP+A@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0qhtPzm69TqfO6ELtGR=mbeP99JnmcUNaTA6m5xzRYP+A@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0qhtPzm69TqfO6ELtGR=mbeP99JnmcUNaTA6m5xzRYP+A@mail.gmail.com/t/#u">nested</a>] <a href=#rad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>86+ messages in thread</a></pre><hr><pre><a href=#e2f7577e9b5cd357284c03e252264f511c553b0d9 id=m2f7577e9b5cd357284c03e252264f511c553b0d9>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-07-27  2:42                   ` <a href=#mb9392a38decda68a70e4996544c2137d88821f96>Zong Li</a>
<b>@ 2023-08-09 14:57                     ` Jason Gunthorpe</b>
  2023-08-15  1:28                       ` <a href=#m295d1b8b9afeed47fa52bcba25fa9afe29729895>Zong Li</a>
  <a href=#r2f7577e9b5cd357284c03e252264f511c553b0d9>0 siblings, 1 reply; 86+ messages in thread</a>
From: Jason Gunthorpe @ 2023-08-09 14:57 UTC (<a href=https://lore.kernel.org/lkml/ZNOpbac4i5zfmHj4@ziepe.ca/>permalink</a> / <a href=https://lore.kernel.org/lkml/ZNOpbac4i5zfmHj4@ziepe.ca/raw>raw</a>)
  To: Zong Li
  Cc: Baolu Lu, Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230809145754">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230809145754">linux-riscv</a>

On Thu, Jul 27, 2023 at 10:42:47AM +0800, Zong Li wrote:

<span class=q>&gt; Perhaps this question could be related to the scenarios in which
&gt; devices wish to be in bypass mode when the IOMMU is in translation
&gt; mode, and why IOMMU defines/supports this case. Currently, I could
&gt; envision a scenario where a device is already connected to the IOMMU
&gt; in hardware, but it is not functioning correctly, or there are
&gt; performance impacts. If modifying the hardware is not feasible, a
&gt; default configuration that allows bypass mode could be provided as a
&gt; solution. There might be other scenarios that I might have overlooked.
&gt; It seems to me since IOMMU supports this configuration, it would be
&gt; advantageous to have an approach to achieve it, and DT might be a
&gt; flexible way.
</span>
So far we've taken the approach that broken hardware is quirked in the
kernel by matching OF compatible string pattners. This is HW that is
completely broken and the IOMMU doesn't work at all for it.

HW that is slow or whatever is not quirked and this is an admin policy
choice where the system should land on the security/performance
spectrum.

So I'm not sure adding DT makes sense here.

Jason

<a href=#m2f7577e9b5cd357284c03e252264f511c553b0d9 id=e2f7577e9b5cd357284c03e252264f511c553b0d9>^</a> <a href=https://lore.kernel.org/lkml/ZNOpbac4i5zfmHj4@ziepe.ca/>permalink</a> <a href=https://lore.kernel.org/lkml/ZNOpbac4i5zfmHj4@ziepe.ca/raw>raw</a> <a href=https://lore.kernel.org/lkml/ZNOpbac4i5zfmHj4@ziepe.ca/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/ZNOpbac4i5zfmHj4@ziepe.ca/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/ZNOpbac4i5zfmHj4@ziepe.ca/t/#u>nested</a>] <a href=#r2f7577e9b5cd357284c03e252264f511c553b0d9>86+ messages in thread</a></pre><hr><pre><a href=#e295d1b8b9afeed47fa52bcba25fa9afe29729895 id=m295d1b8b9afeed47fa52bcba25fa9afe29729895>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-08-09 14:57                     ` <a href=#m2f7577e9b5cd357284c03e252264f511c553b0d9>Jason Gunthorpe</a>
<b>@ 2023-08-15  1:28                       ` Zong Li</b>
  2023-08-15 18:38                         ` <a href=#m4d2a1326efac7177bddd033e12c8ef79baa87f35>Jason Gunthorpe</a>
  <a href=#r295d1b8b9afeed47fa52bcba25fa9afe29729895>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-08-15  1:28 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0rzz1Sn8dKvNt7acvKN_g5yXFN9u6XPiRHr9ay7q2VbzA@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0rzz1Sn8dKvNt7acvKN_g5yXFN9u6XPiRHr9ay7q2VbzA@mail.gmail.com/raw>raw</a>)
  To: Jason Gunthorpe
  Cc: Baolu Lu, Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230815013011">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230815013011">linux-riscv</a>

On Wed, Aug 9, 2023 at 10:57 PM Jason Gunthorpe &lt;jgg@ziepe.ca&gt; wrote:
<span class=q>&gt;
&gt; On Thu, Jul 27, 2023 at 10:42:47AM +0800, Zong Li wrote:
&gt;
&gt; &gt; Perhaps this question could be related to the scenarios in which
&gt; &gt; devices wish to be in bypass mode when the IOMMU is in translation
&gt; &gt; mode, and why IOMMU defines/supports this case. Currently, I could
&gt; &gt; envision a scenario where a device is already connected to the IOMMU
&gt; &gt; in hardware, but it is not functioning correctly, or there are
&gt; &gt; performance impacts. If modifying the hardware is not feasible, a
&gt; &gt; default configuration that allows bypass mode could be provided as a
&gt; &gt; solution. There might be other scenarios that I might have overlooked.
&gt; &gt; It seems to me since IOMMU supports this configuration, it would be
&gt; &gt; advantageous to have an approach to achieve it, and DT might be a
&gt; &gt; flexible way.
&gt;
&gt; So far we've taken the approach that broken hardware is quirked in the
&gt; kernel by matching OF compatible string pattners. This is HW that is
&gt; completely broken and the IOMMU doesn't work at all for it.
&gt;
&gt; HW that is slow or whatever is not quirked and this is an admin policy
&gt; choice where the system should land on the security/performance
&gt; spectrum.
&gt;
&gt; So I'm not sure adding DT makes sense here.
&gt;
</span>
Hi Jason,
Sorry for being late here, I hadn't noticed this reply earlier. The
approach seems to address the situation. Could you kindly provide
information about the location of the patches? I was wondering about
further details regarding this particular implementation. Thanks

<span class=q>&gt; Jason
</span>
<a href=#m295d1b8b9afeed47fa52bcba25fa9afe29729895 id=e295d1b8b9afeed47fa52bcba25fa9afe29729895>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0rzz1Sn8dKvNt7acvKN_g5yXFN9u6XPiRHr9ay7q2VbzA@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0rzz1Sn8dKvNt7acvKN_g5yXFN9u6XPiRHr9ay7q2VbzA@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0rzz1Sn8dKvNt7acvKN_g5yXFN9u6XPiRHr9ay7q2VbzA@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0rzz1Sn8dKvNt7acvKN_g5yXFN9u6XPiRHr9ay7q2VbzA@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0rzz1Sn8dKvNt7acvKN_g5yXFN9u6XPiRHr9ay7q2VbzA@mail.gmail.com/t/#u>nested</a>] <a href=#r295d1b8b9afeed47fa52bcba25fa9afe29729895>86+ messages in thread</a></pre><hr><pre><a href=#e4d2a1326efac7177bddd033e12c8ef79baa87f35 id=m4d2a1326efac7177bddd033e12c8ef79baa87f35>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-08-15  1:28                       ` <a href=#m295d1b8b9afeed47fa52bcba25fa9afe29729895>Zong Li</a>
<b>@ 2023-08-15 18:38                         ` Jason Gunthorpe</b>
  2023-08-16  2:16                           ` <a href=#m49e53774d0e1d74bf3fa4ce8b156ea9b675228fe>Zong Li</a>
  <a href=#r4d2a1326efac7177bddd033e12c8ef79baa87f35>0 siblings, 1 reply; 86+ messages in thread</a>
From: Jason Gunthorpe @ 2023-08-15 18:38 UTC (<a href=https://lore.kernel.org/lkml/ZNvGH91EmlOAaxBK@ziepe.ca/>permalink</a> / <a href=https://lore.kernel.org/lkml/ZNvGH91EmlOAaxBK@ziepe.ca/raw>raw</a>)
  To: Zong Li
  Cc: Baolu Lu, Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230815183940">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230815183940">linux-riscv</a>

On Tue, Aug 15, 2023 at 09:28:54AM +0800, Zong Li wrote:
<span class=q>&gt; On Wed, Aug 9, 2023 at 10:57 PM Jason Gunthorpe &lt;jgg@ziepe.ca&gt; wrote:
&gt; &gt;
&gt; &gt; On Thu, Jul 27, 2023 at 10:42:47AM +0800, Zong Li wrote:
&gt; &gt;
&gt; &gt; &gt; Perhaps this question could be related to the scenarios in which
&gt; &gt; &gt; devices wish to be in bypass mode when the IOMMU is in translation
&gt; &gt; &gt; mode, and why IOMMU defines/supports this case. Currently, I could
&gt; &gt; &gt; envision a scenario where a device is already connected to the IOMMU
&gt; &gt; &gt; in hardware, but it is not functioning correctly, or there are
&gt; &gt; &gt; performance impacts. If modifying the hardware is not feasible, a
&gt; &gt; &gt; default configuration that allows bypass mode could be provided as a
&gt; &gt; &gt; solution. There might be other scenarios that I might have overlooked.
&gt; &gt; &gt; It seems to me since IOMMU supports this configuration, it would be
&gt; &gt; &gt; advantageous to have an approach to achieve it, and DT might be a
&gt; &gt; &gt; flexible way.
&gt; &gt;
&gt; &gt; So far we've taken the approach that broken hardware is quirked in the
&gt; &gt; kernel by matching OF compatible string pattners. This is HW that is
&gt; &gt; completely broken and the IOMMU doesn't work at all for it.
&gt; &gt;
&gt; &gt; HW that is slow or whatever is not quirked and this is an admin policy
&gt; &gt; choice where the system should land on the security/performance
&gt; &gt; spectrum.
&gt; &gt;
&gt; &gt; So I'm not sure adding DT makes sense here.
&gt; &gt;
&gt; 
&gt; Hi Jason,
&gt; Sorry for being late here, I hadn't noticed this reply earlier. The
&gt; approach seems to address the situation. Could you kindly provide
&gt; information about the location of the patches? I was wondering about
&gt; further details regarding this particular implementation. Thanks
</span>
There are a couple versions, eg  
 arm_smmu_def_domain_type()
 qcom_smmu_def_domain_type()

Jason

<a href=#m4d2a1326efac7177bddd033e12c8ef79baa87f35 id=e4d2a1326efac7177bddd033e12c8ef79baa87f35>^</a> <a href=https://lore.kernel.org/lkml/ZNvGH91EmlOAaxBK@ziepe.ca/>permalink</a> <a href=https://lore.kernel.org/lkml/ZNvGH91EmlOAaxBK@ziepe.ca/raw>raw</a> <a href=https://lore.kernel.org/lkml/ZNvGH91EmlOAaxBK@ziepe.ca/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/ZNvGH91EmlOAaxBK@ziepe.ca/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/ZNvGH91EmlOAaxBK@ziepe.ca/t/#u>nested</a>] <a href=#r4d2a1326efac7177bddd033e12c8ef79baa87f35>86+ messages in thread</a></pre><hr><pre><a href=#e49e53774d0e1d74bf3fa4ce8b156ea9b675228fe id=m49e53774d0e1d74bf3fa4ce8b156ea9b675228fe>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-08-15 18:38                         ` <a href=#m4d2a1326efac7177bddd033e12c8ef79baa87f35>Jason Gunthorpe</a>
<b>@ 2023-08-16  2:16                           ` Zong Li</b>
  2023-08-16  4:10                             ` <a href=#mada297bdfcbd76ad0a00e6b14972be46cc18ce40>Baolu Lu</a>
  <a href=#r49e53774d0e1d74bf3fa4ce8b156ea9b675228fe>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2023-08-16  2:16 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0pQ5wisNtbVjm031btUiO=y_MmA9rfbWwnMFo_1y2d50w@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0pQ5wisNtbVjm031btUiO=y_MmA9rfbWwnMFo_1y2d50w@mail.gmail.com/raw">raw</a>)
  To: Jason Gunthorpe
  Cc: Baolu Lu, Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230816021751">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230816021751">linux-riscv</a>

On Wed, Aug 16, 2023 at 2:38 AM Jason Gunthorpe &lt;jgg@ziepe.ca&gt; wrote:
<span class=q>&gt;
&gt; On Tue, Aug 15, 2023 at 09:28:54AM +0800, Zong Li wrote:
&gt; &gt; On Wed, Aug 9, 2023 at 10:57 PM Jason Gunthorpe &lt;jgg@ziepe.ca&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; On Thu, Jul 27, 2023 at 10:42:47AM +0800, Zong Li wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; Perhaps this question could be related to the scenarios in which
&gt; &gt; &gt; &gt; devices wish to be in bypass mode when the IOMMU is in translation
&gt; &gt; &gt; &gt; mode, and why IOMMU defines/supports this case. Currently, I could
&gt; &gt; &gt; &gt; envision a scenario where a device is already connected to the IOMMU
&gt; &gt; &gt; &gt; in hardware, but it is not functioning correctly, or there are
&gt; &gt; &gt; &gt; performance impacts. If modifying the hardware is not feasible, a
&gt; &gt; &gt; &gt; default configuration that allows bypass mode could be provided as a
&gt; &gt; &gt; &gt; solution. There might be other scenarios that I might have overlooked.
&gt; &gt; &gt; &gt; It seems to me since IOMMU supports this configuration, it would be
&gt; &gt; &gt; &gt; advantageous to have an approach to achieve it, and DT might be a
&gt; &gt; &gt; &gt; flexible way.
&gt; &gt; &gt;
&gt; &gt; &gt; So far we've taken the approach that broken hardware is quirked in the
&gt; &gt; &gt; kernel by matching OF compatible string pattners. This is HW that is
&gt; &gt; &gt; completely broken and the IOMMU doesn't work at all for it.
&gt; &gt; &gt;
&gt; &gt; &gt; HW that is slow or whatever is not quirked and this is an admin policy
&gt; &gt; &gt; choice where the system should land on the security/performance
&gt; &gt; &gt; spectrum.
&gt; &gt; &gt;
&gt; &gt; &gt; So I'm not sure adding DT makes sense here.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; Hi Jason,
&gt; &gt; Sorry for being late here, I hadn't noticed this reply earlier. The
&gt; &gt; approach seems to address the situation. Could you kindly provide
&gt; &gt; information about the location of the patches? I was wondering about
&gt; &gt; further details regarding this particular implementation. Thanks
&gt;
&gt; There are a couple versions, eg
&gt;  arm_smmu_def_domain_type()
&gt;  qcom_smmu_def_domain_type()
&gt;
</span>
I thought what you mentioned earlier is that there is a new approach
being considered for this. I think what you point out is the same as
Anup mentioned. However, as I mentioned earlier, I am exploring a more
flexible approach to achieve this objective. This way, we can avoid
hard coding anything (i.e.list compatible string) in the driver or
requiring a kernel rebuild every time we need to change the mode for
specific devices. For example, the driver could parse the device node
to determine and record if a device will be set to bypass, and then
the .def_domain_type could be used to set to IOMMU_DOMAIN_IDENTITY by
the record. I'm not sure if it makes sense for everyone, it seems to
me that it would be great if there is a way to do this. :)

<span class=q>&gt; Jason
</span>
<a href=#m49e53774d0e1d74bf3fa4ce8b156ea9b675228fe id=e49e53774d0e1d74bf3fa4ce8b156ea9b675228fe>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0pQ5wisNtbVjm031btUiO=y_MmA9rfbWwnMFo_1y2d50w@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0pQ5wisNtbVjm031btUiO=y_MmA9rfbWwnMFo_1y2d50w@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0pQ5wisNtbVjm031btUiO=y_MmA9rfbWwnMFo_1y2d50w@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0pQ5wisNtbVjm031btUiO=y_MmA9rfbWwnMFo_1y2d50w@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0pQ5wisNtbVjm031btUiO=y_MmA9rfbWwnMFo_1y2d50w@mail.gmail.com/t/#u">nested</a>] <a href=#r49e53774d0e1d74bf3fa4ce8b156ea9b675228fe>86+ messages in thread</a></pre><hr><pre><a href=#eada297bdfcbd76ad0a00e6b14972be46cc18ce40 id=mada297bdfcbd76ad0a00e6b14972be46cc18ce40>*</a> <b>Re: [PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</b>
  2023-08-16  2:16                           ` <a href=#m49e53774d0e1d74bf3fa4ce8b156ea9b675228fe>Zong Li</a>
<b>@ 2023-08-16  4:10                             ` Baolu Lu</b>
  <a href=#rada297bdfcbd76ad0a00e6b14972be46cc18ce40>0 siblings, 0 replies; 86+ messages in thread</a>
From: Baolu Lu @ 2023-08-16  4:10 UTC (<a href=https://lore.kernel.org/lkml/e9d339f0-89c6-10b4-3171-9c5b1725b76c@linux.intel.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/e9d339f0-89c6-10b4-3171-9c5b1725b76c@linux.intel.com/raw>raw</a>)
  To: Zong Li, Jason Gunthorpe
  Cc: baolu.lu, Anup Patel, Tomasz Jeznach, Joerg Roedel, Will Deacon,
	Robin Murphy, Paul Walmsley, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20230816041225">linux-kernel</a>,
	Sebastien Boeuf, iommu, Palmer Dabbelt, Nick Kossifidis,
	<a href="https://lore.kernel.org/linux-riscv/?t=20230816041225">linux-riscv</a>

On 2023/8/16 10:16, Zong Li wrote:
<span class=q>&gt; On Wed, Aug 16, 2023 at 2:38 AM Jason Gunthorpe&lt;jgg@ziepe.ca&gt;  wrote:
&gt;&gt; On Tue, Aug 15, 2023 at 09:28:54AM +0800, Zong Li wrote:
&gt;&gt;&gt; On Wed, Aug 9, 2023 at 10:57 PM Jason Gunthorpe&lt;jgg@ziepe.ca&gt;  wrote:
&gt;&gt;&gt;&gt; On Thu, Jul 27, 2023 at 10:42:47AM +0800, Zong Li wrote:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Perhaps this question could be related to the scenarios in which
&gt;&gt;&gt;&gt;&gt; devices wish to be in bypass mode when the IOMMU is in translation
&gt;&gt;&gt;&gt;&gt; mode, and why IOMMU defines/supports this case. Currently, I could
&gt;&gt;&gt;&gt;&gt; envision a scenario where a device is already connected to the IOMMU
&gt;&gt;&gt;&gt;&gt; in hardware, but it is not functioning correctly, or there are
&gt;&gt;&gt;&gt;&gt; performance impacts. If modifying the hardware is not feasible, a
&gt;&gt;&gt;&gt;&gt; default configuration that allows bypass mode could be provided as a
&gt;&gt;&gt;&gt;&gt; solution. There might be other scenarios that I might have overlooked.
&gt;&gt;&gt;&gt;&gt; It seems to me since IOMMU supports this configuration, it would be
&gt;&gt;&gt;&gt;&gt; advantageous to have an approach to achieve it, and DT might be a
&gt;&gt;&gt;&gt;&gt; flexible way.
&gt;&gt;&gt;&gt; So far we've taken the approach that broken hardware is quirked in the
&gt;&gt;&gt;&gt; kernel by matching OF compatible string pattners. This is HW that is
&gt;&gt;&gt;&gt; completely broken and the IOMMU doesn't work at all for it.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; HW that is slow or whatever is not quirked and this is an admin policy
&gt;&gt;&gt;&gt; choice where the system should land on the security/performance
&gt;&gt;&gt;&gt; spectrum.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; So I'm not sure adding DT makes sense here.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt; Hi Jason,
&gt;&gt;&gt; Sorry for being late here, I hadn't noticed this reply earlier. The
&gt;&gt;&gt; approach seems to address the situation. Could you kindly provide
&gt;&gt;&gt; information about the location of the patches? I was wondering about
&gt;&gt;&gt; further details regarding this particular implementation. Thanks
&gt;&gt; There are a couple versions, eg
&gt;&gt;   arm_smmu_def_domain_type()
&gt;&gt;   qcom_smmu_def_domain_type()
&gt;&gt;
&gt; I thought what you mentioned earlier is that there is a new approach
&gt; being considered for this. I think what you point out is the same as
&gt; Anup mentioned. However, as I mentioned earlier, I am exploring a more
&gt; flexible approach to achieve this objective. This way, we can avoid
&gt; hard coding anything (i.e.list compatible string) in the driver or
&gt; requiring a kernel rebuild every time we need to change the mode for
&gt; specific devices. For example, the driver could parse the device node
&gt; to determine and record if a device will be set to bypass, and then
&gt; the .def_domain_type could be used to set to IOMMU_DOMAIN_IDENTITY by
&gt; the record. I'm not sure if it makes sense for everyone, it seems to
&gt; me that it would be great if there is a way to do this. 😄
</span>
What you described applies to the case where the device is *quirky*, it
"is not functioning correctly" when the IOMMU is configured in DMA
translation mode.

But it could not be used in another case, as described above, where
IOMMU translation has performance impacts on the device's DMA
efficiency. This is a kind of a user policy and should not be achieved
through the "DT/APCI + def_domain_type" mechanism.

The iommu subsystem has provided a sysfs interface that users can use to
change the domain type for devices. This means that users can change the
domain type at their wishes, without having to modify the kernel
configuration.

Best regards,
baolu


<a href=#mada297bdfcbd76ad0a00e6b14972be46cc18ce40 id=eada297bdfcbd76ad0a00e6b14972be46cc18ce40>^</a> <a href=https://lore.kernel.org/lkml/e9d339f0-89c6-10b4-3171-9c5b1725b76c@linux.intel.com/>permalink</a> <a href=https://lore.kernel.org/lkml/e9d339f0-89c6-10b4-3171-9c5b1725b76c@linux.intel.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/e9d339f0-89c6-10b4-3171-9c5b1725b76c@linux.intel.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/e9d339f0-89c6-10b4-3171-9c5b1725b76c@linux.intel.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/e9d339f0-89c6-10b4-3171-9c5b1725b76c@linux.intel.com/t/#u>nested</a>] <a href=#rada297bdfcbd76ad0a00e6b14972be46cc18ce40>86+ messages in thread</a></pre><hr><pre><a href=#ee6007fa63b4fd2def06b60bba503fe5072f38376 id=me6007fa63b4fd2def06b60bba503fe5072f38376>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
                     ` <a href=#rad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>(5 preceding siblings ...)</a>
  2023-08-03  8:27   ` <a href=#mad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>Zong Li</a>
<b>@ 2023-08-16 18:05   ` Robin Murphy</b>
  2024-04-13 10:15   ` <a href=#m155b6f2fffe6b140c3bb8189cb19c02033deff9d>Xingyou Chen</a>
  <a href=#re6007fa63b4fd2def06b60bba503fe5072f38376>7 siblings, 0 replies; 86+ messages in thread</a>
From: Robin Murphy @ 2023-08-16 18:05 UTC (<a href=https://lore.kernel.org/lkml/7e875daa-c2f3-7d03-d797-369762638897@arm.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/7e875daa-c2f3-7d03-d797-369762638897@arm.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230816180653">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230816180653">linux-kernel</a>, linux

On 2023-07-19 20:33, Tomasz Jeznach wrote:
<span class=q>&gt; The patch introduces skeleton IOMMU device driver implementation as defined
&gt; by RISC-V IOMMU Architecture Specification, Version 1.0 [1], with minimal support
&gt; for pass-through mapping, basic initialization and bindings for platform and PCIe
&gt; hardware implementations.
&gt; 
&gt; Series of patches following specification evolution has been reorganized to provide
&gt; functional separation of implemented blocks, compliant with ratified specification.
&gt; 
&gt; This and following patch series includes code contributed by: Nick Kossifidis
&gt; &lt;mick@ics.forth.gr&gt; (iommu-platform device, number of specification clarification
&gt; and bugfixes and readability improvements), Sebastien Boeuf &lt;seb@rivosinc.com&gt; (page
&gt; table creation, ATS/PGR flow).
&gt; 
&gt; Complete history can be found at the maintainer's repository branch [2].
&gt; 
&gt; Device driver enables RISC-V 32/64 support for memory translation for DMA capable
&gt; PCI and platform devices, multilevel device directory table, process directory,
&gt; shared virtual address support, wired and message signaled interrupt for translation
&gt; I/O fault, page request interface and command processing.
&gt; 
&gt; Matching RISCV-V IOMMU device emulation implementation is available for QEMU project,
&gt; along with educational device extensions for PASID ATS/PRI support [3].
&gt; 
&gt; References:
&gt;   - [1] <a href=https://github.com/riscv-non-isa/riscv-iommu>https://github.com/riscv-non-isa/riscv-iommu</a>
&gt;   - [2] <a href=https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/linux/tree/tjeznach/riscv-iommu</a>
&gt;   - [3] <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu</a>
&gt; 
&gt; Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;   drivers/iommu/Kconfig                |   1 +
&gt;   drivers/iommu/Makefile               |   2 +-
&gt;   drivers/iommu/riscv/Kconfig          |  22 +
&gt;   drivers/iommu/riscv/Makefile         |   1 +
&gt;   drivers/iommu/riscv/iommu-bits.h     | 704 +++++++++++++++++++++++++++
&gt;   drivers/iommu/riscv/iommu-pci.c      | 134 +++++
&gt;   drivers/iommu/riscv/iommu-platform.c |  94 ++++
&gt;   drivers/iommu/riscv/iommu.c          | 660 +++++++++++++++++++++++++
&gt;   drivers/iommu/riscv/iommu.h          | 115 +++++
&gt;   9 files changed, 1732 insertions(+), 1 deletion(-)
&gt;   create mode 100644 drivers/iommu/riscv/Kconfig
&gt;   create mode 100644 drivers/iommu/riscv/Makefile
&gt;   create mode 100644 drivers/iommu/riscv/iommu-bits.h
&gt;   create mode 100644 drivers/iommu/riscv/iommu-pci.c
&gt;   create mode 100644 drivers/iommu/riscv/iommu-platform.c
&gt;   create mode 100644 drivers/iommu/riscv/iommu.c
&gt;   create mode 100644 drivers/iommu/riscv/iommu.h
&gt; 
&gt; diff --git a/drivers/iommu/Kconfig b/drivers/iommu/Kconfig
&gt; index 2b12b583ef4b..36fcc6fd5b4e 100644
&gt; --- a/drivers/iommu/Kconfig
&gt; +++ b/drivers/iommu/Kconfig
&gt; @@ -187,6 +187,7 @@ config MSM_IOMMU
&gt;   source "drivers/iommu/amd/Kconfig"
&gt;   source "drivers/iommu/intel/Kconfig"
&gt;   source "drivers/iommu/iommufd/Kconfig"
&gt; +source "drivers/iommu/riscv/Kconfig"
&gt;   
&gt;   config IRQ_REMAP
&gt;   	bool "Support for Interrupt Remapping"
&gt; diff --git a/drivers/iommu/Makefile b/drivers/iommu/Makefile
&gt; index 769e43d780ce..8f57110a9fb1 100644
&gt; --- a/drivers/iommu/Makefile
&gt; +++ b/drivers/iommu/Makefile
&gt; @@ -1,5 +1,5 @@
&gt;   # SPDX-License-Identifier: GPL-2.0
&gt; -obj-y += amd/ intel/ arm/ iommufd/
&gt; +obj-y += amd/ intel/ arm/ iommufd/ riscv/
&gt;   obj-$(CONFIG_IOMMU_API) += iommu.o
&gt;   obj-$(CONFIG_IOMMU_API) += iommu-traces.o
&gt;   obj-$(CONFIG_IOMMU_API) += iommu-sysfs.o
&gt; diff --git a/drivers/iommu/riscv/Kconfig b/drivers/iommu/riscv/Kconfig
&gt; new file mode 100644
&gt; index 000000000000..01d4043849d4
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/Kconfig
&gt; @@ -0,0 +1,22 @@
&gt; +# SPDX-License-Identifier: GPL-2.0-only
&gt; +# RISC-V IOMMU support
&gt; +
&gt; +config RISCV_IOMMU
&gt; +	bool "RISC-V IOMMU driver"
&gt; +	depends on RISCV
&gt; +	select IOMMU_API
&gt; +	select IOMMU_DMA
</span>
No. See commit de9f8a91eb32.

<span class=q>&gt; +	select IOMMU_SVA
&gt; +	select IOMMU_IOVA
</span>
No.

<span class=q>&gt; +	select IOMMU_IO_PGTABLE
</span>
Do you anticipate needing to support multiple pagetable formats, or 
sharing this format with other drivers? If not, I'd usually suggest 
avoiding the overhead of io-pgtable.

<span class=q>&gt; +	select IOASID
</span>
Doesn't exist.

<span class=q>&gt; +	select PCI_MSI
</span>
Already selected at the arch level, does it really need reselecting here?

<span class=q>&gt; +	select PCI_ATS
&gt; +	select PCI_PRI
&gt; +	select PCI_PASID
&gt; +	select MMU_NOTIFIER
&gt; +	help
&gt; +	  Support for devices following RISC-V IOMMU specification.
&gt; +
&gt; +	  If unsure, say N here.
&gt; +
</span>[...]
<span class=q>&gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; new file mode 100644
&gt; index 000000000000..c91f963d7a29
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; @@ -0,0 +1,134 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * RISCV IOMMU as a PCIe device
&gt; + *
&gt; + * Authors
&gt; + *	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *	Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/compiler.h&gt;
&gt; +#include &lt;linux/pci.h&gt;
&gt; +#include &lt;linux/init.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +
&gt; +#include "iommu.h"
&gt; +
&gt; +/* Rivos Inc. assigned PCI Vendor and Device IDs */
&gt; +#ifndef PCI_VENDOR_ID_RIVOS
&gt; +#define PCI_VENDOR_ID_RIVOS             0x1efd
&gt; +#endif
&gt; +
&gt; +#ifndef PCI_DEVICE_ID_RIVOS_IOMMU
&gt; +#define PCI_DEVICE_ID_RIVOS_IOMMU       0xedf1
&gt; +#endif
&gt; +
&gt; +static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
&gt; +{
&gt; +	struct device *dev = &amp;pdev-&gt;dev;
&gt; +	struct riscv_iommu_device *iommu;
&gt; +	int ret;
&gt; +
&gt; +	ret = pci_enable_device_mem(pdev);
&gt; +	if (ret &lt; 0)
&gt; +		return ret;
&gt; +
&gt; +	ret = pci_request_mem_regions(pdev, KBUILD_MODNAME);
&gt; +	if (ret &lt; 0)
&gt; +		goto fail;
&gt; +
&gt; +	ret = -ENOMEM;
&gt; +
&gt; +	iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; +	if (!iommu)
&gt; +		goto fail;
&gt; +
&gt; +	if (!(pci_resource_flags(pdev, 0) &amp; IORESOURCE_MEM))
&gt; +		goto fail;
&gt; +
&gt; +	if (pci_resource_len(pdev, 0) &lt; RISCV_IOMMU_REG_SIZE)
&gt; +		goto fail;
&gt; +
&gt; +	iommu-&gt;reg_phys = pci_resource_start(pdev, 0);
&gt; +	if (!iommu-&gt;reg_phys)
&gt; +		goto fail;
&gt; +
&gt; +	iommu-&gt;reg = devm_ioremap(dev, iommu-&gt;reg_phys, RISCV_IOMMU_REG_SIZE);
&gt; +	if (!iommu-&gt;reg)
&gt; +		goto fail;
&gt; +
&gt; +	iommu-&gt;dev = dev;
&gt; +	dev_set_drvdata(dev, iommu);
&gt; +
&gt; +	dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
&gt; +	pci_set_master(pdev);
&gt; +
&gt; +	ret = riscv_iommu_init(iommu);
&gt; +	if (!ret)
&gt; +		return ret;
&gt; +
&gt; + fail:
&gt; +	pci_clear_master(pdev);
&gt; +	pci_release_regions(pdev);
&gt; +	pci_disable_device(pdev);
&gt; +	/* Note: devres_release_all() will release iommu and iommu-&gt;reg */
&gt; +	return ret;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_pci_remove(struct pci_dev *pdev)
&gt; +{
&gt; +	riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +	pci_clear_master(pdev);
&gt; +	pci_release_regions(pdev);
&gt; +	pci_disable_device(pdev);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_suspend(struct device *dev)
&gt; +{
&gt; +	dev_warn(dev, "RISC-V IOMMU PM not implemented");
&gt; +	return -ENODEV;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_resume(struct device *dev)
&gt; +{
&gt; +	dev_warn(dev, "RISC-V IOMMU PM not implemented");
&gt; +	return -ENODEV;
&gt; +}
&gt; +
&gt; +static DEFINE_SIMPLE_DEV_PM_OPS(riscv_iommu_pm_ops, riscv_iommu_suspend,
&gt; +				riscv_iommu_resume);
&gt; +
&gt; +static const struct pci_device_id riscv_iommu_pci_tbl[] = {
&gt; +	{PCI_VENDOR_ID_RIVOS, PCI_DEVICE_ID_RIVOS_IOMMU,
&gt; +	 PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0},
&gt; +	{0,}
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(pci, riscv_iommu_pci_tbl);
&gt; +
&gt; +static const struct of_device_id riscv_iommu_of_match[] = {
&gt; +	{.compatible = "riscv,pci-iommu",},
&gt; +	{},
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
&gt; +
&gt; +static struct pci_driver riscv_iommu_pci_driver = {
&gt; +	.name = KBUILD_MODNAME,
&gt; +	.id_table = riscv_iommu_pci_tbl,
&gt; +	.probe = riscv_iommu_pci_probe,
&gt; +	.remove = riscv_iommu_pci_remove,
&gt; +	.driver = {
&gt; +		   .pm = pm_sleep_ptr(&amp;riscv_iommu_pm_ops),
&gt; +		   .of_match_table = riscv_iommu_of_match,
</span>
Does that even do anything for a PCI driver?

Also you're missing suppress_bind_attrs here.

<span class=q>&gt; +		   },
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_pci_driver, pci_register_driver, pci_unregister_driver);
&gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; new file mode 100644
&gt; index 000000000000..e4e8ca6711e7
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; @@ -0,0 +1,94 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * RISC-V IOMMU as a platform device
&gt; + *
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * Author: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/of_platform.h&gt;
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +
&gt; +#include "iommu-bits.h"
&gt; +#include "iommu.h"
&gt; +
&gt; +static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt; +{
&gt; +	struct device *dev = &amp;pdev-&gt;dev;
&gt; +	struct riscv_iommu_device *iommu = NULL;
&gt; +	struct resource *res = NULL;
&gt; +	int ret = 0;
&gt; +
&gt; +	iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; +	if (!iommu)
&gt; +		return -ENOMEM;
&gt; +
&gt; +	iommu-&gt;dev = dev;
&gt; +	dev_set_drvdata(dev, iommu);
&gt; +
&gt; +	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
&gt; +	if (!res) {
&gt; +		dev_err(dev, "could not find resource for register region\n");
&gt; +		return -EINVAL;
&gt; +	}
&gt; +
&gt; +	iommu-&gt;reg = devm_platform_get_and_ioremap_resource(pdev, 0, &amp;res);
&gt; +	if (IS_ERR(iommu-&gt;reg)) {
&gt; +		ret = dev_err_probe(dev, PTR_ERR(iommu-&gt;reg),
&gt; +				    "could not map register region\n");
&gt; +		goto fail;
&gt; +	};
&gt; +
&gt; +	iommu-&gt;reg_phys = res-&gt;start;
&gt; +
&gt; +	ret = -ENODEV;
&gt; +
&gt; +	/* Sanity check: Did we get the whole register space ? */
&gt; +	if ((res-&gt;end - res-&gt;start + 1) &lt; RISCV_IOMMU_REG_SIZE) {
&gt; +		dev_err(dev, "device region smaller than register file (0x%llx)\n",
&gt; +			res-&gt;end - res-&gt;start);
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt; +
&gt; +	return riscv_iommu_init(iommu);
&gt; +
&gt; + fail:
&gt; +	/* Note: devres_release_all() will release iommu and iommu-&gt;reg */
&gt; +	return ret;
&gt; +};
&gt; +
&gt; +static void riscv_iommu_platform_remove(struct platform_device *pdev)
&gt; +{
&gt; +	riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +};
&gt; +
&gt; +static void riscv_iommu_platform_shutdown(struct platform_device *pdev)
&gt; +{
&gt; +	return;
</span>
Surely just don't implement it at all?

<span class=q>&gt; +};
&gt; +
&gt; +static const struct of_device_id riscv_iommu_of_match[] = {
&gt; +	{.compatible = "riscv,iommu",},
&gt; +	{},
&gt; +};
&gt; +
&gt; +MODULE_DEVICE_TABLE(of, riscv_iommu_of_match);
&gt; +
&gt; +static struct platform_driver riscv_iommu_platform_driver = {
&gt; +	.driver = {
&gt; +		   .name = "riscv,iommu",
&gt; +		   .of_match_table = riscv_iommu_of_match,
&gt; +		   .suppress_bind_attrs = true,
&gt; +		   },
&gt; +	.probe = riscv_iommu_platform_probe,
&gt; +	.remove_new = riscv_iommu_platform_remove,
&gt; +	.shutdown = riscv_iommu_platform_shutdown,
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_platform_driver, platform_driver_register,
&gt; +	      platform_driver_unregister);
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; new file mode 100644
&gt; index 000000000000..8c236242e2cc
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -0,0 +1,660 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * IOMMU API for RISC-V architected Ziommu implementations.
&gt; + *
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + * Copyright © 2023 FORTH-ICS/CARV
&gt; + *
&gt; + * Authors
&gt; + *	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *	Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; + */
&gt; +
&gt; +#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
&gt; +
&gt; +#include &lt;linux/bitfield.h&gt;
&gt; +#include &lt;linux/module.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/compiler.h&gt;
&gt; +#include &lt;linux/pci.h&gt;
&gt; +#include &lt;linux/pci-ats.h&gt;
&gt; +#include &lt;linux/init.h&gt;
&gt; +#include &lt;linux/completion.h&gt;
&gt; +#include &lt;linux/uaccess.h&gt;
&gt; +#include &lt;linux/iommu.h&gt;
&gt; +#include &lt;linux/irqdomain.h&gt;
&gt; +#include &lt;linux/platform_device.h&gt;
&gt; +#include &lt;linux/dma-map-ops.h&gt;
</span>
No. This is a device driver, not a DMA ops implemenmtation.

<span class=q>&gt; +#include &lt;asm/page.h&gt;
&gt; +
&gt; +#include "../dma-iommu.h"
&gt; +#include "../iommu-sva.h"
&gt; +#include "iommu.h"
&gt; +
&gt; +#include &lt;asm/csr.h&gt;
&gt; +#include &lt;asm/delay.h&gt;
&gt; +
&gt; +MODULE_DESCRIPTION("IOMMU driver for RISC-V architected Ziommu implementations");
&gt; +MODULE_AUTHOR("Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;");
&gt; +MODULE_AUTHOR("Nick Kossifidis &lt;mick@ics.forth.gr&gt;");
&gt; +MODULE_ALIAS("riscv-iommu");
&gt; +MODULE_LICENSE("GPL v2");
&gt; +
&gt; +/* Global IOMMU params. */
&gt; +static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt; +module_param(ddt_mode, int, 0644);
&gt; +MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt; +
&gt; +/* IOMMU PSCID allocation namespace. */
&gt; +#define RISCV_IOMMU_MAX_PSCID	(1U &lt;&lt; 20)
&gt; +static DEFINE_IDA(riscv_iommu_pscids);
&gt; +
&gt; +/* 1 second */
&gt; +#define RISCV_IOMMU_TIMEOUT	riscv_timebase
&gt; +
&gt; +/* RISC-V IOMMU PPN &lt;&gt; PHYS address conversions, PHYS &lt;=&gt; PPN[53:10] */
&gt; +#define phys_to_ppn(va)  (((va) &gt;&gt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 10))
&gt; +#define ppn_to_phys(pn)	 (((pn) &lt;&lt; 2) &amp; (((1ULL &lt;&lt; 44) - 1) &lt;&lt; 12))
&gt; +
&gt; +#define iommu_domain_to_riscv(iommu_domain) \
&gt; +    container_of(iommu_domain, struct riscv_iommu_domain, domain)
&gt; +
&gt; +#define iommu_device_to_riscv(iommu_device) \
&gt; +    container_of(iommu_device, struct riscv_iommu, iommu)
&gt; +
&gt; +static const struct iommu_domain_ops riscv_iommu_domain_ops;
&gt; +static const struct iommu_ops riscv_iommu_ops;
&gt; +
&gt; +/*
&gt; + * Register device for IOMMU tracking.
&gt; + */
&gt; +static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct device *dev)
&gt; +{
&gt; +	struct riscv_iommu_endpoint *ep, *rb_ep;
&gt; +	struct rb_node **new_node, *parent_node = NULL;
&gt; +
&gt; +	mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +	ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +	new_node = &amp;(iommu-&gt;eps.rb_node);
&gt; +	while (*new_node) {
&gt; +		rb_ep = rb_entry(*new_node, struct riscv_iommu_endpoint, node);
&gt; +		parent_node = *new_node;
&gt; +		if (rb_ep-&gt;devid &gt; ep-&gt;devid) {
&gt; +			new_node = &amp;((*new_node)-&gt;rb_left);
&gt; +		} else if (rb_ep-&gt;devid &lt; ep-&gt;devid) {
&gt; +			new_node = &amp;((*new_node)-&gt;rb_right);
&gt; +		} else {
&gt; +			dev_warn(dev, "device %u already in the tree\n", ep-&gt;devid);
&gt; +			break;
&gt; +		}
&gt; +	}
&gt; +
&gt; +	rb_link_node(&amp;ep-&gt;node, parent_node, new_node);
&gt; +	rb_insert_color(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; +
&gt; +	mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; +}
&gt; +
&gt; +/*
&gt; + * Endpoint management
&gt; + */
&gt; +
&gt; +static int riscv_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)
&gt; +{
&gt; +	return iommu_fwspec_add_ids(dev, args-&gt;args, 1);
&gt; +}
&gt; +
&gt; +static bool riscv_iommu_capable(struct device *dev, enum iommu_cap cap)
&gt; +{
&gt; +	switch (cap) {
&gt; +	case IOMMU_CAP_CACHE_COHERENCY:
&gt; +	case IOMMU_CAP_PRE_BOOT_PROTECTION:
</span>
I don't think you can ever unconditionally claim pre-boot protection. 
Even if an IOMMU implementation does come out of reset in "Off" state - 
which I see the spec only recommends, not requires - something that ran 
before Linux could have done something and left it in "Bare" state.

<span class=q>&gt; +		return true;
&gt; +
&gt; +	default:
&gt; +		break;
&gt; +	}
&gt; +
&gt; +	return false;
&gt; +}
&gt; +
&gt; +static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt; +{
&gt; +	struct riscv_iommu_device *iommu;
&gt; +	struct riscv_iommu_endpoint *ep;
&gt; +	struct iommu_fwspec *fwspec;
&gt; +
&gt; +	fwspec = dev_iommu_fwspec_get(dev);
&gt; +	if (!fwspec || fwspec-&gt;ops != &amp;riscv_iommu_ops ||
&gt; +	    !fwspec-&gt;iommu_fwnode || !fwspec-&gt;iommu_fwnode-&gt;dev)
</span>
I'm pretty sure it shouldn't be possible for a fwspec to have ops set 
without a valid fwnode, given that the fwnode is used to find the ops :/

<span class=q>&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	iommu = dev_get_drvdata(fwspec-&gt;iommu_fwnode-&gt;dev);
&gt; +	if (!iommu)
&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	if (dev_iommu_priv_get(dev))
</span>
That should never be true at this point.

<span class=q>&gt; +		return &amp;iommu-&gt;iommu;
&gt; +
&gt; +	ep = kzalloc(sizeof(*ep), GFP_KERNEL);
&gt; +	if (!ep)
&gt; +		return ERR_PTR(-ENOMEM);
&gt; +
&gt; +	mutex_init(&amp;ep-&gt;lock);
&gt; +	INIT_LIST_HEAD(&amp;ep-&gt;domain);
&gt; +
&gt; +	if (dev_is_pci(dev)) {
&gt; +		ep-&gt;devid = pci_dev_id(to_pci_dev(dev));
&gt; +		ep-&gt;domid = pci_domain_nr(to_pci_dev(dev)-&gt;bus);
&gt; +	} else {
&gt; +		/* TODO: Make this generic, for now hardcode domain id to 0 */
&gt; +		ep-&gt;devid = fwspec-&gt;ids[0];
&gt; +		ep-&gt;domid = 0;
&gt; +	}
&gt; +
&gt; +	ep-&gt;iommu = iommu;
&gt; +	ep-&gt;dev = dev;
&gt; +
&gt; +	dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt; +		ep-&gt;devid, ep-&gt;domid);
</span>
Please clean up all these debugging prints before submitting patches 
upstream. I do start to wonder how worthwhile it is to review code that 
doesn't even look finished...

<span class=q>&gt; +
&gt; +	dev_iommu_priv_set(dev, ep);
&gt; +	riscv_iommu_add_device(iommu, dev);
&gt; +
&gt; +	return &amp;iommu-&gt;iommu;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_probe_finalize(struct device *dev)
&gt; +{
&gt; +	set_dma_ops(dev, NULL);
&gt; +	iommu_setup_dma_ops(dev, 0, U64_MAX);
&gt; +}
</span>
riscv already implements arch_setup_dma_ops(), so please make use of 
that flow; this probe_finalize bodge is an x86 thing, mostly for legacy 
reasons.

<span class=q>&gt; +
&gt; +static void riscv_iommu_release_device(struct device *dev)
&gt; +{
&gt; +	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +	struct riscv_iommu_device *iommu = ep-&gt;iommu;
&gt; +
&gt; +	dev_info(dev, "device with devid %i released\n", ep-&gt;devid);
&gt; +
&gt; +	mutex_lock(&amp;ep-&gt;lock);
&gt; +	list_del(&amp;ep-&gt;domain);
&gt; +	mutex_unlock(&amp;ep-&gt;lock);
&gt; +
&gt; +	/* Remove endpoint from IOMMU tracking structures */
&gt; +	mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt; +	rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; +	mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +	set_dma_ops(dev, NULL);
&gt; +	dev_iommu_priv_set(dev, NULL);
&gt; +
&gt; +	kfree(ep);
&gt; +}
&gt; +
&gt; +static struct iommu_group *riscv_iommu_device_group(struct device *dev)
&gt; +{
&gt; +	if (dev_is_pci(dev))
&gt; +		return pci_device_group(dev);
&gt; +	return generic_device_group(dev);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_get_resv_regions(struct device *dev, struct list_head *head)
&gt; +{
&gt; +	iommu_dma_get_resv_regions(dev, head);
</span>
Just assign it as the callback directly - the wrapper function serves no 
purpose.

<span class=q>&gt; +}
&gt; +
&gt; +/*
&gt; + * Domain management
&gt; + */
&gt; +
&gt; +static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain;
&gt; +
&gt; +	if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; +	    type != IOMMU_DOMAIN_BLOCKED)
</span>
Whatever's going on here I don't think really fits the meaning of 
IOMMU_DOMAIN_BLOCKED.

<span class=q>&gt; +		return NULL;
&gt; +
&gt; +	domain = kzalloc(sizeof(*domain), GFP_KERNEL);
&gt; +	if (!domain)
&gt; +		return NULL;
&gt; +
&gt; +	mutex_init(&amp;domain-&gt;lock);
&gt; +	INIT_LIST_HEAD(&amp;domain-&gt;endpoints);
&gt; +
&gt; +	domain-&gt;domain.ops = &amp;riscv_iommu_domain_ops;
&gt; +	domain-&gt;mode = RISCV_IOMMU_DC_FSC_MODE_BARE;
&gt; +	domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt; +					RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
</span>
If this fails, it seems you "successfully" return a completely useless 
domain to which nothing can attach. Why not just fail the allocation 
right here?

<span class=q>&gt; +
&gt; +	printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; +
&gt; +	return &amp;domain-&gt;domain;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +	if (!list_empty(&amp;domain-&gt;endpoints)) {
&gt; +		pr_warn("IOMMU domain is not empty!\n");
&gt; +	}
&gt; +
&gt; +	if (domain-&gt;pgd_root)
&gt; +		free_pages((unsigned long)domain-&gt;pgd_root, 0);
&gt; +
&gt; +	if ((int)domain-&gt;pscid &gt; 0)
&gt; +		ida_free(&amp;riscv_iommu_pscids, domain-&gt;pscid);
&gt; +
&gt; +	printk("domain free %u\n", domain-&gt;pscid);
&gt; +
&gt; +	kfree(domain);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt; +				       struct riscv_iommu_device *iommu)
&gt; +{
&gt; +	struct iommu_domain_geometry *geometry;
&gt; +
&gt; +	/* Domain assigned to another iommu */
&gt; +	if (domain-&gt;iommu &amp;&amp; domain-&gt;iommu != iommu)
&gt; +		return -EINVAL;
&gt; +	/* Domain already initialized */
&gt; +	else if (domain-&gt;iommu)
&gt; +		return 0;
&gt; +
&gt; +	/*
&gt; +	 * TODO: Before using VA_BITS and satp_mode here, verify they
&gt; +	 * are supported by the iommu, through the capabilities register.
&gt; +	 */
</span>
Yes, doing that sounds like a very good idea.

<span class=q>&gt; +
&gt; +	geometry = &amp;domain-&gt;domain.geometry;
&gt; +
&gt; +	/*
&gt; +	 * Note: RISC-V Privilege spec mandates that virtual addresses
&gt; +	 * need to be sign-extended, so if (VA_BITS - 1) is set, all
&gt; +	 * bits &gt;= VA_BITS need to also be set or else we'll get a
&gt; +	 * page fault. However the code that creates the mappings
&gt; +	 * above us (e.g. iommu_dma_alloc_iova()) won't do that for us
&gt; +	 * for now, so we'll end up with invalid virtual addresses
&gt; +	 * to map. As a workaround until we get this sorted out
&gt; +	 * limit the available virtual addresses to VA_BITS - 1.
&gt; +	 */
</span>
Would you have a practical use for a single 64-bit VA space with a 
massive hole in the middle anyway?

<span class=q>&gt; +	geometry-&gt;aperture_start = 0;
&gt; +	geometry-&gt;aperture_end = DMA_BIT_MASK(VA_BITS - 1);
&gt; +	geometry-&gt;force_aperture = true;
&gt; +
&gt; +	domain-&gt;iommu = iommu;
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +		return 0;
&gt; +
&gt; +	/* TODO: Fix this for RV32 */
&gt; +	domain-&gt;mode = satp_mode &gt;&gt; 60;
&gt; +	domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO, 0);
&gt; +
&gt; +	if (!domain-&gt;pgd_root)
&gt; +		return -ENOMEM;
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct device *dev)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +	int ret;
&gt; +
&gt; +	/* PSCID not valid */
&gt; +	if ((int)domain-&gt;pscid &lt; 0)
&gt; +		return -ENOMEM;
&gt; +
&gt; +	mutex_lock(&amp;domain-&gt;lock);
&gt; +	mutex_lock(&amp;ep-&gt;lock);
&gt; +
&gt; +	if (!list_empty(&amp;ep-&gt;domain)) {
&gt; +		dev_warn(dev, "endpoint already attached to a domain. dropping\n");
</span>
This should not be a warning condition. Other than the very first attach 
at iommu_probe_device() time, .attach_dev will always be moving devices 
directly from one domain to another.

<span class=q>&gt; +		list_del_init(&amp;ep-&gt;domain);
&gt; +	}
&gt; +
&gt; +	/* allocate root pages, initialize io-pgtable ops, etc. */
&gt; +	ret = riscv_iommu_domain_finalize(domain, ep-&gt;iommu);
&gt; +	if (ret &lt; 0) {
&gt; +		dev_err(dev, "can not finalize domain: %d\n", ret);
&gt; +		mutex_unlock(&amp;ep-&gt;lock);
&gt; +		mutex_unlock(&amp;domain-&gt;lock);
&gt; +		return ret;
&gt; +	}
&gt; +
&gt; +	if (ep-&gt;iommu-&gt;ddt_mode != RISCV_IOMMU_DDTP_MODE_BARE ||
&gt; +	    domain-&gt;domain.type != IOMMU_DOMAIN_IDENTITY) {
&gt; +		dev_warn(dev, "domain type %d not supported\n",
&gt; +		    domain-&gt;domain.type);
&gt; +		return -ENODEV;
</span>
OK, so you don't actually support blocking domains anyway? In that case, 
don't accept the allocation request in the first place.

<span class=q>&gt; +	}
&gt; +
&gt; +	list_add_tail(&amp;ep-&gt;domain, &amp;domain-&gt;endpoints);
&gt; +	mutex_unlock(&amp;ep-&gt;lock);
&gt; +	mutex_unlock(&amp;domain-&gt;lock);
&gt; +
&gt; +	dev_info(dev, "domain type %d attached w/ PSCID %u\n",
&gt; +	    domain-&gt;domain.type, domain-&gt;pscid);
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt; +					  unsigned long *start, unsigned long *end,
&gt; +					  size_t *pgsize)
&gt; +{
&gt; +	/* Command interface not implemented */
&gt; +}
&gt; +
&gt; +static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; +{
&gt; +	riscv_iommu_flush_iotlb_range(iommu_domain, NULL, NULL, NULL);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_iotlb_sync(struct iommu_domain *iommu_domain,
&gt; +				   struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +	riscv_iommu_flush_iotlb_range(iommu_domain, &amp;gather-&gt;start, &amp;gather-&gt;end,
&gt; +				      &amp;gather-&gt;pgsize);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_iotlb_sync_map(struct iommu_domain *iommu_domain,
&gt; +				       unsigned long iova, size_t size)
&gt; +{
&gt; +	unsigned long end = iova + size - 1;
&gt; +	/*
&gt; +	 * Given we don't know the page size used by this range, we assume the
&gt; +	 * smallest page size to ensure all possible entries are flushed from
&gt; +	 * the IOATC.
&gt; +	 */
&gt; +	size_t pgsize = PAGE_SIZE;
&gt; +	riscv_iommu_flush_iotlb_range(iommu_domain, &amp;iova, &amp;end, &amp;pgsize);
</span>
The spec says the IOMMU is not permitted to cache invalid PTEs, so why 
have this? (I mean, it's clearly a completely useless no-op anyway, but 
hey...)

<span class=q>&gt; +}
&gt; +
&gt; +static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
&gt; +				 unsigned long iova, phys_addr_t phys,
&gt; +				 size_t pgsize, size_t pgcount, int prot,
&gt; +				 gfp_t gfp, size_t *mapped)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
</span>
That can't happen. Not to mention that pretending to successfully map 
any IOVA to any PA in an identity domain, which by definition doesn't do 
that, would be fundamentally nonsensical anyway.

<span class=q>&gt; +		*mapped = pgsize * pgcount;
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	return -ENODEV;
&gt; +}
&gt; +
&gt; +static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt; +				      unsigned long iova, size_t pgsize,
&gt; +				      size_t pgcount, struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
</span>
Ditto.

<span class=q>&gt; +		return pgsize * pgcount;
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt; +					    dma_addr_t iova)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
</span>
Ditto. Have you seen iommu_iova_to_phys()?

<span class=q>&gt; +		return (phys_addr_t) iova;
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Translation mode setup
&gt; + */
&gt; +
&gt; +static u64 riscv_iommu_get_ddtp(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +	u64 ddtp;
&gt; +	cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
&gt; +
&gt; +	/* Wait for DDTP.BUSY to be cleared and return latest value */
&gt; +	do {
&gt; +		ddtp = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_DDTP);
&gt; +		if (!(ddtp &amp; RISCV_IOMMU_DDTP_BUSY))
&gt; +			break;
&gt; +		cpu_relax();
&gt; +	} while (get_cycles() &lt; end_cycles);
</span>
Smells like readq_poll_timeout().

<span class=q>&gt; +
&gt; +	return ddtp;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_ddt_cleanup(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +	/* TODO: teardown whole device directory tree. */
&gt; +	if (iommu-&gt;ddtp) {
&gt; +		if (iommu-&gt;ddtp_in_iomem) {
&gt; +			iounmap((void *)iommu-&gt;ddtp);
&gt; +		} else
&gt; +			free_page(iommu-&gt;ddtp);
&gt; +		iommu-&gt;ddtp = 0;
&gt; +	}
&gt; +}
&gt; +
&gt; +static int riscv_iommu_enable(struct riscv_iommu_device *iommu, unsigned requested_mode)
&gt; +{
&gt; +	struct device *dev = iommu-&gt;dev;
&gt; +	u64 ddtp = 0;
&gt; +	u64 ddtp_paddr = 0;
&gt; +	unsigned mode = requested_mode;
&gt; +	unsigned mode_readback = 0;
&gt; +
&gt; +	ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +	if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY)
&gt; +		return -EBUSY;
&gt; +
&gt; +	/* Disallow state transtion from xLVL to xLVL. */
&gt; +	switch (FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp)) {
&gt; +	case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; +	case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; +		break;
&gt; +	default:
&gt; +		if ((mode != RISCV_IOMMU_DDTP_MODE_BARE)
&gt; +		    &amp;&amp; (mode != RISCV_IOMMU_DDTP_MODE_OFF))
&gt; +			return -EINVAL;
&gt; +		break;
&gt; +	}
&gt; +
&gt; + retry:
&gt; +	switch (mode) {
&gt; +	case RISCV_IOMMU_DDTP_MODE_BARE:
&gt; +	case RISCV_IOMMU_DDTP_MODE_OFF:
&gt; +		riscv_iommu_ddt_cleanup(iommu);
&gt; +		ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode);
&gt; +		break;
&gt; +	case RISCV_IOMMU_DDTP_MODE_1LVL:
&gt; +	case RISCV_IOMMU_DDTP_MODE_2LVL:
&gt; +	case RISCV_IOMMU_DDTP_MODE_3LVL:
&gt; +		if (!iommu-&gt;ddtp) {
&gt; +			/*
&gt; +			 * We haven't initialized ddtp yet, since it's WARL make
&gt; +			 * sure that we don't have a hardwired PPN field there
&gt; +			 * that points to i/o memory instead.
&gt; +			 */
&gt; +			riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, 0);
&gt; +			ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +			ddtp_paddr = ppn_to_phys(ddtp);
&gt; +			if (ddtp_paddr) {
&gt; +				dev_warn(dev, "ddtp at 0x%llx\n", ddtp_paddr);
&gt; +				iommu-&gt;ddtp =
&gt; +				    (unsigned long)ioremap(ddtp_paddr, PAGE_SIZE);
&gt; +				iommu-&gt;ddtp_in_iomem = true;
&gt; +			} else {
&gt; +				iommu-&gt;ddtp = get_zeroed_page(GFP_KERNEL);
&gt; +			}
&gt; +		}
&gt; +		if (!iommu-&gt;ddtp)
&gt; +			return -ENOMEM;
&gt; +
&gt; +		ddtp = FIELD_PREP(RISCV_IOMMU_DDTP_MODE, mode) |
&gt; +		    phys_to_ppn(__pa(iommu-&gt;ddtp));
&gt; +
&gt; +		break;
&gt; +	default:
&gt; +		return -EINVAL;
&gt; +	}
&gt; +
&gt; +	riscv_iommu_writeq(iommu, RISCV_IOMMU_REG_DDTP, ddtp);
&gt; +	ddtp = riscv_iommu_get_ddtp(iommu);
&gt; +	if (ddtp &amp; RISCV_IOMMU_DDTP_BUSY) {
&gt; +		dev_warn(dev, "timeout when setting ddtp (ddt mode: %i)\n", mode);
&gt; +		return -EBUSY;
&gt; +	}
&gt; +
&gt; +	mode_readback = FIELD_GET(RISCV_IOMMU_DDTP_MODE, ddtp);
&gt; +	dev_info(dev, "mode_readback: %i, mode: %i\n", mode_readback, mode);
&gt; +	if (mode_readback != mode) {
&gt; +		/*
&gt; +		 * Mode field is WARL, an I/O MMU may support a subset of
&gt; +		 * directory table levels in which case if we tried to set
&gt; +		 * an unsupported number of levels we'll readback either
&gt; +		 * a valid xLVL or off/bare. If we got off/bare, try again
&gt; +		 * with a smaller xLVL.
&gt; +		 */
&gt; +		if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
&gt; +		    mode &gt; RISCV_IOMMU_DDTP_MODE_1LVL) {
&gt; +			mode--;
&gt; +			goto retry;
&gt; +		}
&gt; +
&gt; +		/*
&gt; +		 * We tried all supported xLVL modes and still got off/bare instead,
&gt; +		 * an I/O MMU must support at least one supported xLVL mode so something
&gt; +		 * went very wrong.
&gt; +		 */
&gt; +		if (mode_readback &lt; RISCV_IOMMU_DDTP_MODE_1LVL &amp;&amp;
&gt; +		    mode == RISCV_IOMMU_DDTP_MODE_1LVL)
&gt; +			goto fail;
&gt; +
&gt; +		/*
&gt; +		 * We tried setting off or bare and got something else back, something
&gt; +		 * went very wrong since off/bare is always legal.
&gt; +		 */
&gt; +		if (mode &lt; RISCV_IOMMU_DDTP_MODE_1LVL)
&gt; +			goto fail;
&gt; +
&gt; +		/*
&gt; +		 * We tried setting an xLVL mode but got another xLVL mode that
&gt; +		 * we don't support (e.g. a custom one).
&gt; +		 */
&gt; +		if (mode_readback &gt; RISCV_IOMMU_DDTP_MODE_MAX)
&gt; +			goto fail;
&gt; +
&gt; +		/* We tried setting an xLVL mode but got another supported xLVL mode */
&gt; +		mode = mode_readback;
&gt; +	}
&gt; +
&gt; +	if (mode != requested_mode)
&gt; +		dev_warn(dev, "unsupported DDT mode requested (%i), using %i instead\n",
&gt; +			 requested_mode, mode);
&gt; +
&gt; +	iommu-&gt;ddt_mode = mode;
&gt; +	dev_info(dev, "ddt_mode: %i\n", iommu-&gt;ddt_mode);
&gt; +	return 0;
&gt; +
&gt; + fail:
&gt; +	dev_err(dev, "failed to set DDT mode, tried: %i and got %i\n", mode,
&gt; +		mode_readback);
&gt; +	riscv_iommu_ddt_cleanup(iommu);
&gt; +	return -EINVAL;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Common I/O MMU driver probe/teardown
&gt; + */
&gt; +
&gt; +static const struct iommu_domain_ops riscv_iommu_domain_ops = {
&gt; +	.free = riscv_iommu_domain_free,
&gt; +	.attach_dev = riscv_iommu_attach_dev,
&gt; +	.map_pages = riscv_iommu_map_pages,
&gt; +	.unmap_pages = riscv_iommu_unmap_pages,
&gt; +	.iova_to_phys = riscv_iommu_iova_to_phys,
&gt; +	.iotlb_sync = riscv_iommu_iotlb_sync,
&gt; +	.iotlb_sync_map = riscv_iommu_iotlb_sync_map,
&gt; +	.flush_iotlb_all = riscv_iommu_flush_iotlb_all,
&gt; +};
&gt; +
&gt; +static const struct iommu_ops riscv_iommu_ops = {
&gt; +	.owner = THIS_MODULE,
&gt; +	.pgsize_bitmap = SZ_4K | SZ_2M | SZ_512M,
&gt; +	.capable = riscv_iommu_capable,
&gt; +	.domain_alloc = riscv_iommu_domain_alloc,
&gt; +	.probe_device = riscv_iommu_probe_device,
&gt; +	.probe_finalize = riscv_iommu_probe_finalize,
&gt; +	.release_device = riscv_iommu_release_device,
&gt; +	.device_group = riscv_iommu_device_group,
&gt; +	.get_resv_regions = riscv_iommu_get_resv_regions,
&gt; +	.of_xlate = riscv_iommu_of_xlate,
&gt; +	.default_domain_ops = &amp;riscv_iommu_domain_ops,
&gt; +};
&gt; +
&gt; +void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +	iommu_device_unregister(&amp;iommu-&gt;iommu);
&gt; +	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +}
&gt; +
&gt; +int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +	struct device *dev = iommu-&gt;dev;
&gt; +	u32 fctl = 0;
&gt; +	int ret;
&gt; +
&gt; +	iommu-&gt;eps = RB_ROOT;
&gt; +
&gt; +	fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; +
&gt; +#ifdef CONFIG_CPU_BIG_ENDIAN
&gt; +	if (!(cap &amp; RISCV_IOMMU_CAP_END)) {
&gt; +		dev_err(dev, "IOMMU doesn't support Big Endian\n");
&gt; +		return -EIO;
&gt; +	} else if (!(fctl &amp; RISCV_IOMMU_FCTL_BE)) {
&gt; +		fctl |= FIELD_PREP(RISCV_IOMMU_FCTL_BE, 1);
&gt; +		riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; +	}
&gt; +#endif
&gt; +
&gt; +	/* Clear any pending interrupt flag. */
&gt; +	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt; +			   RISCV_IOMMU_IPSR_CIP |
&gt; +			   RISCV_IOMMU_IPSR_FIP |
&gt; +			   RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt; +	spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt; +	mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; +
&gt; +	ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
</span>
Um, yeah, you definitely don't support blocking domains if you just put 
the whole thing in bypass :/

<span class=q>&gt; +
&gt; +	if (ret) {
&gt; +		dev_err(dev, "cannot enable iommu device (%d)\n", ret);
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	ret = iommu_device_register(&amp;iommu-&gt;iommu, &amp;riscv_iommu_ops, dev);
&gt; +	if (ret) {
&gt; +		dev_err(dev, "cannot register iommu interface (%d)\n", ret);
&gt; +		iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
</span>
But it was never added?

<span class=q>&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	return 0;
&gt; + fail:
&gt; +	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +	return ret;
&gt; +}
</span>[...]
I appreciate the attempt to split the series up and not have one giant 
4000-line patch, but I have to say it's kind of hard to usefully review 
a patch like this where I'm struggling to tell the "real" code from the 
unfinished dead ends and plain nonsense. I'd suggest splitting it up 
slightly differently: strip out all the IOMMU API stuff here and just 
have this patch add the basic probing and hardware initialisation, then 
add the queues, device tables and pagetables, *then* wire it all up to 
the IOMMU API once it can be meaningfully functional. It ought to be 
possible to have each patch be purely additions of "final" code, no 
temporary placeholders and weird bodges just to let a bisection compile 
and/or pretend to work. Then "extra" features like SVA can be built on 
top as you have already. And of course we like the dt binding to be 
patch #1 :)

Thanks,
Robin.

<a href=#me6007fa63b4fd2def06b60bba503fe5072f38376 id=ee6007fa63b4fd2def06b60bba503fe5072f38376>^</a> <a href=https://lore.kernel.org/lkml/7e875daa-c2f3-7d03-d797-369762638897@arm.com/>permalink</a> <a href=https://lore.kernel.org/lkml/7e875daa-c2f3-7d03-d797-369762638897@arm.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/7e875daa-c2f3-7d03-d797-369762638897@arm.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/7e875daa-c2f3-7d03-d797-369762638897@arm.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/7e875daa-c2f3-7d03-d797-369762638897@arm.com/t/#u>nested</a>] <a href=#re6007fa63b4fd2def06b60bba503fe5072f38376>86+ messages in thread</a></pre><hr><pre><a href=#ef18bd90d921132d02c05d7d5894300a045bab960 id=mf18bd90d921132d02c05d7d5894300a045bab960>*</a> <b>Re: [PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</b>
  2023-07-19 19:33 ` <a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</a> Tomasz Jeznach
                     ` <a href=#r47475dde350a53202c60665ebadd89162dc278d8>(2 preceding siblings ...)</a>
  2023-07-29 12:58   ` <a href=#m47475dde350a53202c60665ebadd89162dc278d8>Zong Li</a>
<b>@ 2023-08-16 18:49   ` Robin Murphy</b>
  <a href=#rf18bd90d921132d02c05d7d5894300a045bab960>3 siblings, 0 replies; 86+ messages in thread</a>
From: Robin Murphy @ 2023-08-16 18:49 UTC (<a href=https://lore.kernel.org/lkml/e9f19296-80e3-f0be-f0e5-a751b481f7e1@arm.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/e9f19296-80e3-f0be-f0e5-a751b481f7e1@arm.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230816184950">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230816184950">linux-kernel</a>, linux

On 2023-07-19 20:33, Tomasz Jeznach wrote:
<span class=q>&gt; Enables message or wire signal interrupts for PCIe and platforms devices.
&gt; 
&gt; Co-developed-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Signed-off-by: Nick Kossifidis &lt;mick@ics.forth.gr&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;   drivers/iommu/riscv/iommu-pci.c      |  72 ++++
&gt;   drivers/iommu/riscv/iommu-platform.c |  66 +++
&gt;   drivers/iommu/riscv/iommu.c          | 604 ++++++++++++++++++++++++++-
&gt;   drivers/iommu/riscv/iommu.h          |  28 ++
&gt;   4 files changed, 769 insertions(+), 1 deletion(-)
&gt; 
&gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; index c91f963d7a29..9ea0647f7b92 100644
&gt; --- a/drivers/iommu/riscv/iommu-pci.c
&gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; @@ -34,6 +34,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt;   {
&gt;   	struct device *dev = &amp;pdev-&gt;dev;
&gt;   	struct riscv_iommu_device *iommu;
&gt; +	u64 icvec;
&gt;   	int ret;
&gt;   
&gt;   	ret = pci_enable_device_mem(pdev);
&gt; @@ -67,14 +68,84 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt;   	iommu-&gt;dev = dev;
&gt;   	dev_set_drvdata(dev, iommu);
&gt;   
&gt; +	/* Check device reported capabilities. */
&gt; +	iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; +
&gt; +	/* The PCI driver only uses MSIs, make sure the IOMMU supports this */
&gt; +	switch (FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap)) {
&gt; +	case RISCV_IOMMU_CAP_IGS_MSI:
&gt; +	case RISCV_IOMMU_CAP_IGS_BOTH:
&gt; +		break;
&gt; +	default:
&gt; +		dev_err(dev, "unable to use message-signaled interrupts\n");
&gt; +		ret = -ENODEV;
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt;   	dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));
&gt;   	pci_set_master(pdev);
&gt;   
&gt; +	/* Allocate and assign IRQ vectors for the various events */
&gt; +	ret = pci_alloc_irq_vectors(pdev, 1, RISCV_IOMMU_INTR_COUNT, PCI_IRQ_MSIX);
&gt; +	if (ret &lt; 0) {
&gt; +		dev_err(dev, "unable to allocate irq vectors\n");
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	ret = -ENODEV;
&gt; +
&gt; +	iommu-&gt;irq_cmdq = msi_get_virq(dev, RISCV_IOMMU_INTR_CQ);
&gt; +	if (!iommu-&gt;irq_cmdq) {
&gt; +		dev_warn(dev, "no MSI vector %d for the command queue\n",
&gt; +			 RISCV_IOMMU_INTR_CQ);
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	iommu-&gt;irq_fltq = msi_get_virq(dev, RISCV_IOMMU_INTR_FQ);
&gt; +	if (!iommu-&gt;irq_fltq) {
&gt; +		dev_warn(dev, "no MSI vector %d for the fault/event queue\n",
&gt; +			 RISCV_IOMMU_INTR_FQ);
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; +		iommu-&gt;irq_pm = msi_get_virq(dev, RISCV_IOMMU_INTR_PM);
&gt; +		if (!iommu-&gt;irq_pm) {
&gt; +			dev_warn(dev,
&gt; +				 "no MSI vector %d for performance monitoring\n",
&gt; +				 RISCV_IOMMU_INTR_PM);
&gt; +			goto fail;
&gt; +		}
&gt; +	}
&gt; +
&gt; +	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; +		iommu-&gt;irq_priq = msi_get_virq(dev, RISCV_IOMMU_INTR_PQ);
&gt; +		if (!iommu-&gt;irq_priq) {
&gt; +			dev_warn(dev,
&gt; +				 "no MSI vector %d for page-request queue\n",
&gt; +				 RISCV_IOMMU_INTR_PQ);
&gt; +			goto fail;
&gt; +		}
&gt; +	}
&gt; +
&gt; +	/* Set simple 1:1 mapping for MSI vectors */
&gt; +	icvec = FIELD_PREP(RISCV_IOMMU_IVEC_CIV, RISCV_IOMMU_INTR_CQ) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_IVEC_FIV, RISCV_IOMMU_INTR_FQ);
&gt; +
&gt; +	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM)
&gt; +		icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PMIV, RISCV_IOMMU_INTR_PM);
&gt; +
&gt; +	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS)
&gt; +		icvec |= FIELD_PREP(RISCV_IOMMU_IVEC_PIV, RISCV_IOMMU_INTR_PQ);
&gt; +
&gt; +	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IVEC, icvec);
&gt; +
&gt;   	ret = riscv_iommu_init(iommu);
&gt;   	if (!ret)
&gt;   		return ret;
&gt;   
&gt;    fail:
&gt; +	pci_free_irq_vectors(pdev);
&gt;   	pci_clear_master(pdev);
&gt;   	pci_release_regions(pdev);
&gt;   	pci_disable_device(pdev);
&gt; @@ -85,6 +156,7 @@ static int riscv_iommu_pci_probe(struct pci_dev *pdev, const struct pci_device_i
&gt;   static void riscv_iommu_pci_remove(struct pci_dev *pdev)
&gt;   {
&gt;   	riscv_iommu_remove(dev_get_drvdata(&amp;pdev-&gt;dev));
&gt; +	pci_free_irq_vectors(pdev);
&gt;   	pci_clear_master(pdev);
&gt;   	pci_release_regions(pdev);
&gt;   	pci_disable_device(pdev);
&gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; index e4e8ca6711e7..35935d3c7ef4 100644
&gt; --- a/drivers/iommu/riscv/iommu-platform.c
&gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; @@ -20,6 +20,8 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt;   	struct device *dev = &amp;pdev-&gt;dev;
&gt;   	struct riscv_iommu_device *iommu = NULL;
&gt;   	struct resource *res = NULL;
&gt; +	u32 fctl = 0;
&gt; +	int irq = 0;
&gt;   	int ret = 0;
&gt;   
&gt;   	iommu = devm_kzalloc(dev, sizeof(*iommu), GFP_KERNEL);
&gt; @@ -53,6 +55,70 @@ static int riscv_iommu_platform_probe(struct platform_device *pdev)
&gt;   		goto fail;
&gt;   	}
&gt;   
&gt; +	iommu-&gt;cap = riscv_iommu_readq(iommu, RISCV_IOMMU_REG_CAP);
&gt; +
&gt; +	/* For now we only support WSIs until we have AIA support */
&gt; +	ret = FIELD_GET(RISCV_IOMMU_CAP_IGS, iommu-&gt;cap);
&gt; +	if (ret == RISCV_IOMMU_CAP_IGS_MSI) {
&gt; +		dev_err(dev, "IOMMU only supports MSIs\n");
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	/* Parse IRQ assignment */
&gt; +	irq = platform_get_irq_byname_optional(pdev, "cmdq");
&gt; +	if (irq &gt; 0)
&gt; +		iommu-&gt;irq_cmdq = irq;
&gt; +	else {
&gt; +		dev_err(dev, "no IRQ provided for the command queue\n");
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	irq = platform_get_irq_byname_optional(pdev, "fltq");
&gt; +	if (irq &gt; 0)
&gt; +		iommu-&gt;irq_fltq = irq;
&gt; +	else {
&gt; +		dev_err(dev, "no IRQ provided for the fault/event queue\n");
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_HPM) {
&gt; +		irq = platform_get_irq_byname_optional(pdev, "pm");
&gt; +		if (irq &gt; 0)
&gt; +			iommu-&gt;irq_pm = irq;
&gt; +		else {
&gt; +			dev_err(dev, "no IRQ provided for performance monitoring\n");
&gt; +			goto fail;
&gt; +		}
&gt; +	}
&gt; +
&gt; +	if (iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS) {
&gt; +		irq = platform_get_irq_byname_optional(pdev, "priq");
&gt; +		if (irq &gt; 0)
&gt; +			iommu-&gt;irq_priq = irq;
&gt; +		else {
&gt; +			dev_err(dev, "no IRQ provided for the page-request queue\n");
&gt; +			goto fail;
&gt; +		}
&gt; +	}
&gt; +
&gt; +	/* Make sure fctl.WSI is set */
&gt; +	fctl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FCTL);
&gt; +	fctl |= RISCV_IOMMU_FCTL_WSI;
&gt; +	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_FCTL, fctl);
&gt; +
&gt; +	/* Parse Queue lengts */
&gt; +	ret = of_property_read_u32(pdev-&gt;dev.of_node, "cmdq_len", &amp;iommu-&gt;cmdq_len);
&gt; +	if (!ret)
&gt; +		dev_info(dev, "command queue length set to %i\n", iommu-&gt;cmdq_len);
&gt; +
&gt; +	ret = of_property_read_u32(pdev-&gt;dev.of_node, "fltq_len", &amp;iommu-&gt;fltq_len);
&gt; +	if (!ret)
&gt; +		dev_info(dev, "fault/event queue length set to %i\n", iommu-&gt;fltq_len);
&gt; +
&gt; +	ret = of_property_read_u32(pdev-&gt;dev.of_node, "priq_len", &amp;iommu-&gt;priq_len);
&gt; +	if (!ret)
&gt; +		dev_info(dev, "page request queue length set to %i\n", iommu-&gt;priq_len);
</span>
These properties are not documented in the binding, but are clearly 
Linux-specific driver policy which does not belong in DT anyway.

<span class=q>&gt; +
&gt;   	dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(64));
&gt;   
&gt;   	return riscv_iommu_init(iommu);
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 31dc3c458e13..5c4cf9875302 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -45,6 +45,18 @@ static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt;   module_param(ddt_mode, int, 0644);
&gt;   MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt;   
&gt; +static int cmdq_length = 1024;
&gt; +module_param(cmdq_length, int, 0644);
&gt; +MODULE_PARM_DESC(cmdq_length, "Command queue length.");
&gt; +
&gt; +static int fltq_length = 1024;
&gt; +module_param(fltq_length, int, 0644);
&gt; +MODULE_PARM_DESC(fltq_length, "Fault queue length.");
&gt; +
&gt; +static int priq_length = 1024;
&gt; +module_param(priq_length, int, 0644);
&gt; +MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
&gt; +
&gt;   /* IOMMU PSCID allocation namespace. */
&gt;   #define RISCV_IOMMU_MAX_PSCID	(1U &lt;&lt; 20)
&gt;   static DEFINE_IDA(riscv_iommu_pscids);
&gt; @@ -65,6 +77,497 @@ static DEFINE_IDA(riscv_iommu_pscids);
&gt;   static const struct iommu_domain_ops riscv_iommu_domain_ops;
&gt;   static const struct iommu_ops riscv_iommu_ops;
&gt;   
&gt; +/*
&gt; + * Common queue management routines
&gt; + */
&gt; +
&gt; +/* Note: offsets are the same for all queues */
&gt; +#define Q_HEAD(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQH - RISCV_IOMMU_REG_CQB))
&gt; +#define Q_TAIL(q) ((q)-&gt;qbr + (RISCV_IOMMU_REG_CQT - RISCV_IOMMU_REG_CQB))
&gt; +
&gt; +static unsigned riscv_iommu_queue_consume(struct riscv_iommu_device *iommu,
&gt; +					  struct riscv_iommu_queue *q, unsigned *ready)
&gt; +{
&gt; +	u32 tail = riscv_iommu_readl(iommu, Q_TAIL(q));
&gt; +	*ready = q-&gt;lui;
&gt; +
&gt; +	BUG_ON(q-&gt;cnt &lt;= tail);
&gt; +	if (q-&gt;lui &lt;= tail)
&gt; +		return tail - q-&gt;lui;
&gt; +	return q-&gt;cnt - q-&gt;lui;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_queue_release(struct riscv_iommu_device *iommu,
&gt; +				      struct riscv_iommu_queue *q, unsigned count)
&gt; +{
&gt; +	q-&gt;lui = (q-&gt;lui + count) &amp; (q-&gt;cnt - 1);
&gt; +	riscv_iommu_writel(iommu, Q_HEAD(q), q-&gt;lui);
&gt; +}
&gt; +
&gt; +static u32 riscv_iommu_queue_ctrl(struct riscv_iommu_device *iommu,
&gt; +				  struct riscv_iommu_queue *q, u32 val)
&gt; +{
&gt; +	cycles_t end_cycles = RISCV_IOMMU_TIMEOUT + get_cycles();
&gt; +
&gt; +	riscv_iommu_writel(iommu, q-&gt;qcr, val);
&gt; +	do {
&gt; +		val = riscv_iommu_readl(iommu, q-&gt;qcr);
&gt; +		if (!(val &amp; RISCV_IOMMU_QUEUE_BUSY))
&gt; +			break;
&gt; +		cpu_relax();
&gt; +	} while (get_cycles() &lt; end_cycles);
&gt; +
&gt; +	return val;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_queue_free(struct riscv_iommu_device *iommu,
&gt; +				   struct riscv_iommu_queue *q)
&gt; +{
&gt; +	size_t size = q-&gt;len * q-&gt;cnt;
&gt; +
&gt; +	riscv_iommu_queue_ctrl(iommu, q, 0);
&gt; +
&gt; +	if (q-&gt;base) {
&gt; +		if (q-&gt;in_iomem)
&gt; +			iounmap(q-&gt;base);
&gt; +		else
&gt; +			dmam_free_coherent(iommu-&gt;dev, size, q-&gt;base, q-&gt;base_dma);
&gt; +	}
&gt; +	if (q-&gt;irq)
&gt; +		free_irq(q-&gt;irq, q);
&gt; +}
&gt; +
&gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data);
&gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data);
&gt; +
&gt; +static int riscv_iommu_queue_init(struct riscv_iommu_device *iommu, int queue_id)
&gt; +{
&gt; +	struct device *dev = iommu-&gt;dev;
&gt; +	struct riscv_iommu_queue *q = NULL;
&gt; +	size_t queue_size = 0;
&gt; +	irq_handler_t irq_check;
&gt; +	irq_handler_t irq_process;
&gt; +	const char *name;
&gt; +	int count = 0;
&gt; +	int irq = 0;
&gt; +	unsigned order = 0;
&gt; +	u64 qbr_val = 0;
&gt; +	u64 qbr_readback = 0;
&gt; +	u64 qbr_paddr = 0;
&gt; +	int ret = 0;
&gt; +
&gt; +	switch (queue_id) {
&gt; +	case RISCV_IOMMU_COMMAND_QUEUE:
&gt; +		q = &amp;iommu-&gt;cmdq;
&gt; +		q-&gt;len = sizeof(struct riscv_iommu_command);
&gt; +		count = iommu-&gt;cmdq_len;
&gt; +		irq = iommu-&gt;irq_cmdq;
&gt; +		irq_check = riscv_iommu_cmdq_irq_check;
&gt; +		irq_process = riscv_iommu_cmdq_process;
&gt; +		q-&gt;qbr = RISCV_IOMMU_REG_CQB;
&gt; +		q-&gt;qcr = RISCV_IOMMU_REG_CQCSR;
&gt; +		name = "cmdq";
&gt; +		break;
&gt; +	case RISCV_IOMMU_FAULT_QUEUE:
&gt; +		q = &amp;iommu-&gt;fltq;
&gt; +		q-&gt;len = sizeof(struct riscv_iommu_fq_record);
&gt; +		count = iommu-&gt;fltq_len;
&gt; +		irq = iommu-&gt;irq_fltq;
&gt; +		irq_check = riscv_iommu_fltq_irq_check;
&gt; +		irq_process = riscv_iommu_fltq_process;
&gt; +		q-&gt;qbr = RISCV_IOMMU_REG_FQB;
&gt; +		q-&gt;qcr = RISCV_IOMMU_REG_FQCSR;
&gt; +		name = "fltq";
&gt; +		break;
&gt; +	case RISCV_IOMMU_PAGE_REQUEST_QUEUE:
&gt; +		q = &amp;iommu-&gt;priq;
&gt; +		q-&gt;len = sizeof(struct riscv_iommu_pq_record);
&gt; +		count = iommu-&gt;priq_len;
&gt; +		irq = iommu-&gt;irq_priq;
&gt; +		irq_check = riscv_iommu_priq_irq_check;
&gt; +		irq_process = riscv_iommu_priq_process;
&gt; +		q-&gt;qbr = RISCV_IOMMU_REG_PQB;
&gt; +		q-&gt;qcr = RISCV_IOMMU_REG_PQCSR;
&gt; +		name = "priq";
&gt; +		break;
&gt; +	default:
&gt; +		dev_err(dev, "invalid queue interrupt index in queue_init!\n");
&gt; +		return -EINVAL;
&gt; +	}
&gt; +
&gt; +	/* Polling not implemented */
&gt; +	if (!irq)
&gt; +		return -ENODEV;
&gt; +
&gt; +	/* Allocate queue in memory and set the base register */
&gt; +	order = ilog2(count);
&gt; +	do {
&gt; +		queue_size = q-&gt;len * (1ULL &lt;&lt; order);
&gt; +		q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
&gt; +		if (q-&gt;base || queue_size &lt; PAGE_SIZE)
&gt; +			break;
&gt; +
&gt; +		order--;
&gt; +	} while (1);
&gt; +
&gt; +	if (!q-&gt;base) {
&gt; +		dev_err(dev, "failed to allocate %s queue (cnt: %u)\n", name, count);
&gt; +		return -ENOMEM;
&gt; +	}
&gt; +
&gt; +	q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; +
&gt; +	qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; +
&gt; +	riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; +
&gt; +	/*
&gt; +	 * Queue base registers are WARL, so it's possible that whatever we wrote
&gt; +	 * there was illegal/not supported by the hw in which case we need to make
&gt; +	 * sure we set a supported PPN and/or queue size.
&gt; +	 */
&gt; +	qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; +	if (qbr_readback == qbr_val)
&gt; +		goto irq;
&gt; +
&gt; +	dmam_free_coherent(dev, queue_size, q-&gt;base, q-&gt;base_dma);
&gt; +
&gt; +	/* Get supported queue size */
&gt; +	order = FIELD_GET(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, qbr_readback) + 1;
&gt; +	q-&gt;cnt = 1ULL &lt;&lt; order;
&gt; +	queue_size = q-&gt;len * q-&gt;cnt;
</span>
Um... What? We allocate an arbitrarily-sized queue, free it again, 
*then* check what the hardware actually supports, and maybe allocate 
another queue? I can't help thinking there's a much better way...

<span class=q>&gt; +
&gt; +	/*
&gt; +	 * In case we also failed to set PPN, it means the field is hardcoded and the
&gt; +	 * queue resides in I/O memory instead, so get its physical address and
&gt; +	 * ioremap it.
&gt; +	 */
&gt; +	qbr_paddr = ppn_to_phys(qbr_readback);
&gt; +	if (qbr_paddr != q-&gt;base_dma) {
&gt; +		dev_info(dev,
&gt; +			 "hardcoded ppn in %s base register, using io memory for the queue\n",
&gt; +			 name);
&gt; +		dev_info(dev, "queue length for %s set to %i\n", name, q-&gt;cnt);
&gt; +		q-&gt;in_iomem = true;
&gt; +		q-&gt;base = ioremap(qbr_paddr, queue_size);
&gt; +		if (!q-&gt;base) {
&gt; +			dev_err(dev, "failed to map %s queue (cnt: %u)\n", name, q-&gt;cnt);
&gt; +			return -ENOMEM;
&gt; +		}
&gt; +		q-&gt;base_dma = qbr_paddr;
&gt; +	} else {
&gt; +		/*
&gt; +		 * We only failed to set the queue size, re-try to allocate memory with
&gt; +		 * the queue size supported by the hw.
&gt; +		 */
&gt; +		dev_info(dev, "hardcoded queue size in %s base register\n", name);
&gt; +		dev_info(dev, "retrying with queue length: %i\n", q-&gt;cnt);
&gt; +		q-&gt;base = dmam_alloc_coherent(dev, queue_size, &amp;q-&gt;base_dma, GFP_KERNEL);
</span>
Note that dma_alloc_coherent only guarantees natural alignment here, so 
if you need a minimum alignment of 4KB as the spec claims you should 
really make clamp your minimum allocation size to that.

<span class=q>&gt; +		if (!q-&gt;base) {
&gt; +			dev_err(dev, "failed to allocate %s queue (cnt: %u)\n",
&gt; +				name, q-&gt;cnt);
&gt; +			return -ENOMEM;
&gt; +		}
&gt; +	}
&gt; +
&gt; +	qbr_val = phys_to_ppn(q-&gt;base_dma) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_QUEUE_LOGSZ_FIELD, order - 1);
&gt; +	riscv_iommu_writeq(iommu, q-&gt;qbr, qbr_val);
&gt; +
&gt; +	/* Final check to make sure hw accepted our write */
&gt; +	qbr_readback = riscv_iommu_readq(iommu, q-&gt;qbr);
&gt; +	if (qbr_readback != qbr_val) {
&gt; +		dev_err(dev, "failed to set base register for %s\n", name);
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; + irq:
&gt; +	if (request_threaded_irq(irq, irq_check, irq_process, IRQF_ONESHOT | IRQF_SHARED,
&gt; +				 dev_name(dev), q)) {
&gt; +		dev_err(dev, "fail to request irq %d for %s\n", irq, name);
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	q-&gt;irq = irq;
&gt; +
&gt; +	/* Note: All RIO_xQ_EN/IE fields are in the same offsets */
&gt; +	ret =
&gt; +	    riscv_iommu_queue_ctrl(iommu, q,
&gt; +				   RISCV_IOMMU_QUEUE_ENABLE |
&gt; +				   RISCV_IOMMU_QUEUE_INTR_ENABLE);
&gt; +	if (ret &amp; RISCV_IOMMU_QUEUE_BUSY) {
&gt; +		dev_err(dev, "%s init timeout\n", name);
&gt; +		ret = -EBUSY;
&gt; +		goto fail;
&gt; +	}
&gt; +
&gt; +	return 0;
&gt; +
&gt; + fail:
&gt; +	riscv_iommu_queue_free(iommu, q);
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +/*
&gt; + * I/O MMU Command queue chapter 3.1
&gt; + */
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_vma(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +	cmd-&gt;dword0 =
&gt; +	    FIELD_PREP(RISCV_IOMMU_CMD_OPCODE,
&gt; +		       RISCV_IOMMU_CMD_IOTINVAL_OPCODE) | FIELD_PREP(RISCV_IOMMU_CMD_FUNC,
&gt; +								     RISCV_IOMMU_CMD_IOTINVAL_FUNC_VMA);
</span>
Interesting indentation... :/

<span class=q>&gt; +	cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_set_addr(struct riscv_iommu_command *cmd,
&gt; +						  u64 addr)
&gt; +{
&gt; +	cmd-&gt;dword0 |= RISCV_IOMMU_CMD_IOTINVAL_AV;
&gt; +	cmd-&gt;dword1 = addr;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_set_pscid(struct riscv_iommu_command *cmd,
&gt; +						   unsigned pscid)
&gt; +{
&gt; +	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_PSCID, pscid) |
&gt; +	    RISCV_IOMMU_CMD_IOTINVAL_PSCV;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_inval_set_gscid(struct riscv_iommu_command *cmd,
&gt; +						   unsigned gscid)
&gt; +{
&gt; +	cmd-&gt;dword0 |= FIELD_PREP(RISCV_IOMMU_CMD_IOTINVAL_GSCID, gscid) |
&gt; +	    RISCV_IOMMU_CMD_IOTINVAL_GV;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iofence(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C);
&gt; +	cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iofence_set_av(struct riscv_iommu_command *cmd,
&gt; +						  u64 addr, u32 data)
&gt; +{
&gt; +	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IOFENCE_OPCODE) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IOFENCE_FUNC_C) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_CMD_IOFENCE_DATA, data) | RISCV_IOMMU_CMD_IOFENCE_AV;
&gt; +	cmd-&gt;dword1 = (addr &gt;&gt; 2);
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iodir_inval_ddt(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_DDT);
&gt; +	cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iodir_inval_pdt(struct riscv_iommu_command *cmd)
&gt; +{
&gt; +	cmd-&gt;dword0 = FIELD_PREP(RISCV_IOMMU_CMD_OPCODE, RISCV_IOMMU_CMD_IODIR_OPCODE) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_CMD_FUNC, RISCV_IOMMU_CMD_IODIR_FUNC_INVAL_PDT);
&gt; +	cmd-&gt;dword1 = 0;
&gt; +}
&gt; +
&gt; +static inline void riscv_iommu_cmd_iodir_set_did(struct riscv_iommu_command *cmd,
&gt; +						 unsigned devid)
&gt; +{
&gt; +	cmd-&gt;dword0 |=
&gt; +	    FIELD_PREP(RISCV_IOMMU_CMD_IODIR_DID, devid) | RISCV_IOMMU_CMD_IODIR_DV;
&gt; +}
&gt; +
&gt; +/* TODO: Convert into lock-less MPSC implementation. */
&gt; +static bool riscv_iommu_post_sync(struct riscv_iommu_device *iommu,
&gt; +				  struct riscv_iommu_command *cmd, bool sync)
&gt; +{
&gt; +	u32 head, tail, next, last;
&gt; +	unsigned long flags;
&gt; +
&gt; +	spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; +	head = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +	tail = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +	last = iommu-&gt;cmdq.lui;
&gt; +	if (tail != last) {
&gt; +		spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; +		/*
&gt; +		 * FIXME: This is a workaround for dropped MMIO writes/reads on QEMU platform.
&gt; +		 *        While debugging of the problem is still ongoing, this provides
&gt; +		 *        a simple impolementation of try-again policy.
&gt; +		 *        Will be changed to lock-less algorithm in the feature.
&gt; +		 */
&gt; +		dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (1st)\n", last, tail);
&gt; +		spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; +		tail =
&gt; +		    riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQT) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +		last = iommu-&gt;cmdq.lui;
&gt; +		if (tail != last) {
&gt; +			spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; +			dev_dbg(iommu-&gt;dev, "IOMMU CQT: %x != %x (2nd)\n", last, tail);
&gt; +			spin_lock_irqsave(&amp;iommu-&gt;cq_lock, flags);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	next = (last + 1) &amp; (iommu-&gt;cmdq.cnt - 1);
&gt; +	if (next != head) {
&gt; +		struct riscv_iommu_command *ptr = iommu-&gt;cmdq.base;
&gt; +		ptr[last] = *cmd;
&gt; +		wmb();
&gt; +		riscv_iommu_writel(iommu, RISCV_IOMMU_REG_CQT, next);
&gt; +		iommu-&gt;cmdq.lui = next;
&gt; +	}
&gt; +
&gt; +	spin_unlock_irqrestore(&amp;iommu-&gt;cq_lock, flags);
&gt; +
&gt; +	if (sync &amp;&amp; head != next) {
&gt; +		cycles_t start_time = get_cycles();
&gt; +		while (1) {
&gt; +			last = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQH) &amp;
&gt; +			    (iommu-&gt;cmdq.cnt - 1);
&gt; +			if (head &lt; next &amp;&amp; last &gt;= next)
&gt; +				break;
&gt; +			if (head &gt; next &amp;&amp; last &lt; head &amp;&amp; last &gt;= next)
&gt; +				break;
&gt; +			if (RISCV_IOMMU_TIMEOUT &lt; (get_cycles() - start_time)) {
&gt; +				dev_err(iommu-&gt;dev, "IOFENCE TIMEOUT\n");
&gt; +				return false;
&gt; +			}
&gt; +			cpu_relax();
&gt; +		}
&gt; +	}
&gt; +
&gt; +	return next != head;
&gt; +}
&gt; +
&gt; +static bool riscv_iommu_post(struct riscv_iommu_device *iommu,
&gt; +			     struct riscv_iommu_command *cmd)
&gt; +{
&gt; +	return riscv_iommu_post_sync(iommu, cmd, false);
&gt; +}
&gt; +
&gt; +static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
&gt; +{
&gt; +	struct riscv_iommu_command cmd;
&gt; +	riscv_iommu_cmd_iofence(&amp;cmd);
&gt; +	return riscv_iommu_post_sync(iommu, &amp;cmd, true);
&gt; +}
&gt; +
&gt; +/* Command queue primary interrupt handler */
&gt; +static irqreturn_t riscv_iommu_cmdq_irq_check(int irq, void *data)
&gt; +{
&gt; +	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +	struct riscv_iommu_device *iommu =
&gt; +	    container_of(q, struct riscv_iommu_device, cmdq);
&gt; +	u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; +	if (ipsr &amp; RISCV_IOMMU_IPSR_CIP)
&gt; +		return IRQ_WAKE_THREAD;
&gt; +	return IRQ_NONE;
&gt; +}
&gt; +
&gt; +/* Command queue interrupt hanlder thread function */
&gt; +static irqreturn_t riscv_iommu_cmdq_process(int irq, void *data)
&gt; +{
&gt; +	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +	struct riscv_iommu_device *iommu;
&gt; +	unsigned ctrl;
&gt; +
&gt; +	iommu = container_of(q, struct riscv_iommu_device, cmdq);
&gt; +
&gt; +	/* Error reporting, clear error reports if any. */
&gt; +	ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_CQCSR);
&gt; +	if (ctrl &amp; (RISCV_IOMMU_CQCSR_CQMF |
&gt; +		    RISCV_IOMMU_CQCSR_CMD_TO | RISCV_IOMMU_CQCSR_CMD_ILL)) {
&gt; +		riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;cmdq, ctrl);
&gt; +		dev_warn_ratelimited(iommu-&gt;dev,
&gt; +				     "Command queue error: fault: %d tout: %d err: %d\n",
&gt; +				     !!(ctrl &amp; RISCV_IOMMU_CQCSR_CQMF),
&gt; +				     !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_TO),
&gt; +				     !!(ctrl &amp; RISCV_IOMMU_CQCSR_CMD_ILL));
&gt; +	}
&gt; +
&gt; +	/* Clear fault interrupt pending. */
&gt; +	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_CIP);
&gt; +
&gt; +	return IRQ_HANDLED;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Fault/event queue, chapter 3.2
&gt; + */
&gt; +
&gt; +static void riscv_iommu_fault_report(struct riscv_iommu_device *iommu,
&gt; +				     struct riscv_iommu_fq_record *event)
&gt; +{
&gt; +	unsigned err, devid;
&gt; +
&gt; +	err = FIELD_GET(RISCV_IOMMU_FQ_HDR_CAUSE, event-&gt;hdr);
&gt; +	devid = FIELD_GET(RISCV_IOMMU_FQ_HDR_DID, event-&gt;hdr);
&gt; +
&gt; +	dev_warn_ratelimited(iommu-&gt;dev,
&gt; +			     "Fault %d devid: %d" " iotval: %llx iotval2: %llx\n", err,
&gt; +			     devid, event-&gt;iotval, event-&gt;iotval2);
&gt; +}
&gt; +
&gt; +/* Fault/event queue primary interrupt handler */
&gt; +static irqreturn_t riscv_iommu_fltq_irq_check(int irq, void *data)
&gt; +{
&gt; +	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +	struct riscv_iommu_device *iommu =
&gt; +	    container_of(q, struct riscv_iommu_device, fltq);
&gt; +	u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; +	if (ipsr &amp; RISCV_IOMMU_IPSR_FIP)
&gt; +		return IRQ_WAKE_THREAD;
&gt; +	return IRQ_NONE;
&gt; +}
&gt; +
&gt; +/* Fault queue interrupt hanlder thread function */
&gt; +static irqreturn_t riscv_iommu_fltq_process(int irq, void *data)
&gt; +{
&gt; +	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +	struct riscv_iommu_device *iommu;
&gt; +	struct riscv_iommu_fq_record *events;
&gt; +	unsigned cnt, len, idx, ctrl;
&gt; +
&gt; +	iommu = container_of(q, struct riscv_iommu_device, fltq);
&gt; +	events = (struct riscv_iommu_fq_record *)q-&gt;base;
&gt; +
&gt; +	/* Error reporting, clear error reports if any. */
&gt; +	ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_FQCSR);
&gt; +	if (ctrl &amp; (RISCV_IOMMU_FQCSR_FQMF | RISCV_IOMMU_FQCSR_FQOF)) {
&gt; +		riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;fltq, ctrl);
&gt; +		dev_warn_ratelimited(iommu-&gt;dev,
&gt; +				     "Fault queue error: fault: %d full: %d\n",
&gt; +				     !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQMF),
&gt; +				     !!(ctrl &amp; RISCV_IOMMU_FQCSR_FQOF));
&gt; +	}
&gt; +
&gt; +	/* Clear fault interrupt pending. */
&gt; +	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_FIP);
&gt; +
&gt; +	/* Report fault events. */
&gt; +	do {
&gt; +		cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; +		if (!cnt)
&gt; +			break;
&gt; +		for (len = 0; len &lt; cnt; idx++, len++)
&gt; +			riscv_iommu_fault_report(iommu, &amp;events[idx]);
&gt; +		riscv_iommu_queue_release(iommu, q, cnt);
&gt; +	} while (1);
&gt; +
&gt; +	return IRQ_HANDLED;
&gt; +}
&gt; +
&gt; +/*
&gt; + * Page request queue, chapter 3.3
&gt; + */
&gt; +
&gt;   /*
&gt;    * Register device for IOMMU tracking.
&gt;    */
&gt; @@ -97,6 +600,54 @@ static void riscv_iommu_add_device(struct riscv_iommu_device *iommu, struct devi
&gt;   	mutex_unlock(&amp;iommu-&gt;eps_mutex);
&gt;   }
&gt;   
&gt; +/* Page request interface queue primary interrupt handler */
&gt; +static irqreturn_t riscv_iommu_priq_irq_check(int irq, void *data)
&gt; +{
&gt; +	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +	struct riscv_iommu_device *iommu =
&gt; +	    container_of(q, struct riscv_iommu_device, priq);
&gt; +	u32 ipsr = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_IPSR);
&gt; +	if (ipsr &amp; RISCV_IOMMU_IPSR_PIP)
&gt; +		return IRQ_WAKE_THREAD;
&gt; +	return IRQ_NONE;
&gt; +}
&gt; +
&gt; +/* Page request interface queue interrupt hanlder thread function */
&gt; +static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt; +{
&gt; +	struct riscv_iommu_queue *q = (struct riscv_iommu_queue *)data;
&gt; +	struct riscv_iommu_device *iommu;
&gt; +	struct riscv_iommu_pq_record *requests;
&gt; +	unsigned cnt, idx, ctrl;
&gt; +
&gt; +	iommu = container_of(q, struct riscv_iommu_device, priq);
&gt; +	requests = (struct riscv_iommu_pq_record *)q-&gt;base;
&gt; +
&gt; +	/* Error reporting, clear error reports if any. */
&gt; +	ctrl = riscv_iommu_readl(iommu, RISCV_IOMMU_REG_PQCSR);
&gt; +	if (ctrl &amp; (RISCV_IOMMU_PQCSR_PQMF | RISCV_IOMMU_PQCSR_PQOF)) {
&gt; +		riscv_iommu_queue_ctrl(iommu, &amp;iommu-&gt;priq, ctrl);
&gt; +		dev_warn_ratelimited(iommu-&gt;dev,
&gt; +				     "Page request queue error: fault: %d full: %d\n",
&gt; +				     !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQMF),
&gt; +				     !!(ctrl &amp; RISCV_IOMMU_PQCSR_PQOF));
&gt; +	}
&gt; +
&gt; +	/* Clear page request interrupt pending. */
&gt; +	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR, RISCV_IOMMU_IPSR_PIP);
&gt; +
&gt; +	/* Process page requests. */
&gt; +	do {
&gt; +		cnt = riscv_iommu_queue_consume(iommu, q, &amp;idx);
&gt; +		if (!cnt)
&gt; +			break;
&gt; +		dev_warn(iommu-&gt;dev, "unexpected %u page requests\n", cnt);
&gt; +		riscv_iommu_queue_release(iommu, q, cnt);
&gt; +	} while (1);
&gt; +
&gt; +	return IRQ_HANDLED;
&gt; +}
&gt; +
&gt;   /*
&gt;    * Endpoint management
&gt;    */
&gt; @@ -350,7 +901,29 @@ static void riscv_iommu_flush_iotlb_range(struct iommu_domain *iommu_domain,
&gt;   					  unsigned long *start, unsigned long *end,
&gt;   					  size_t *pgsize)
&gt;   {
&gt; -	/* Command interface not implemented */
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +	struct riscv_iommu_command cmd;
&gt; +	unsigned long iova;
&gt; +
&gt; +	if (domain-&gt;mode == RISCV_IOMMU_DC_FSC_MODE_BARE)
</span>
That should probably not happen - things shouldn't be calling TLB ops on 
identity domains (and ideally your identity domains wouldn't even *have* 
iotlb callbacks...)

<span class=q>&gt; +		return;
&gt; +
&gt; +	/* Domain not attached to an IOMMU! */
&gt; +	BUG_ON(!domain-&gt;iommu);
</span>
However I'm not sure how iommu_create_device_direct_mappings() isn't 
hitting that?

Thanks,
Robin.

<span class=q>&gt; +
&gt; +	riscv_iommu_cmd_inval_vma(&amp;cmd);
&gt; +	riscv_iommu_cmd_inval_set_pscid(&amp;cmd, domain-&gt;pscid);
&gt; +
&gt; +	if (start &amp;&amp; end &amp;&amp; pgsize) {
&gt; +		/* Cover only the range that is needed */
&gt; +		for (iova = *start; iova &lt;= *end; iova += *pgsize) {
&gt; +			riscv_iommu_cmd_inval_set_addr(&amp;cmd, iova);
&gt; +			riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +		}
&gt; +	} else {
&gt; +		riscv_iommu_post(domain-&gt;iommu, &amp;cmd);
&gt; +	}
&gt; +	riscv_iommu_iofence_sync(domain-&gt;iommu);
&gt;   }
&gt;   
&gt;   static void riscv_iommu_flush_iotlb_all(struct iommu_domain *iommu_domain)
&gt; @@ -610,6 +1183,9 @@ void riscv_iommu_remove(struct riscv_iommu_device *iommu)
&gt;   	iommu_device_unregister(&amp;iommu-&gt;iommu);
&gt;   	iommu_device_sysfs_remove(&amp;iommu-&gt;iommu);
&gt;   	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt; +	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; +	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt;   }
&gt;   
&gt;   int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt; @@ -632,6 +1208,16 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;   	}
&gt;   #endif
&gt;   
&gt; +	/*
&gt; +	 * Assign queue lengths from module parameters if not already
&gt; +	 * set on the device tree.
&gt; +	 */
&gt; +	if (!iommu-&gt;cmdq_len)
&gt; +		iommu-&gt;cmdq_len = cmdq_length;
&gt; +	if (!iommu-&gt;fltq_len)
&gt; +		iommu-&gt;fltq_len = fltq_length;
&gt; +	if (!iommu-&gt;priq_len)
&gt; +		iommu-&gt;priq_len = priq_length;
&gt;   	/* Clear any pending interrupt flag. */
&gt;   	riscv_iommu_writel(iommu, RISCV_IOMMU_REG_IPSR,
&gt;   			   RISCV_IOMMU_IPSR_CIP |
&gt; @@ -639,7 +1225,20 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;   			   RISCV_IOMMU_IPSR_PMIP | RISCV_IOMMU_IPSR_PIP);
&gt;   	spin_lock_init(&amp;iommu-&gt;cq_lock);
&gt;   	mutex_init(&amp;iommu-&gt;eps_mutex);
&gt; +	ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_COMMAND_QUEUE);
&gt; +	if (ret)
&gt; +		goto fail;
&gt; +	ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_FAULT_QUEUE);
&gt; +	if (ret)
&gt; +		goto fail;
&gt; +	if (!(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_ATS))
&gt; +		goto no_ats;
&gt; +
&gt; +	ret = riscv_iommu_queue_init(iommu, RISCV_IOMMU_PAGE_REQUEST_QUEUE);
&gt; +	if (ret)
&gt; +		goto fail;
&gt;   
&gt; + no_ats:
&gt;   	ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt;   
&gt;   	if (ret) {
&gt; @@ -663,5 +1262,8 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;   	return 0;
&gt;    fail:
&gt;   	riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_OFF);
&gt; +	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;priq);
&gt; +	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;fltq);
&gt; +	riscv_iommu_queue_free(iommu, &amp;iommu-&gt;cmdq);
&gt;   	return ret;
&gt;   }
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 7dc9baa59a50..04148a2a8ffd 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -28,6 +28,24 @@
&gt;   #define IOMMU_PAGE_SIZE_1G	BIT_ULL(30)
&gt;   #define IOMMU_PAGE_SIZE_512G	BIT_ULL(39)
&gt;   
&gt; +struct riscv_iommu_queue {
&gt; +	dma_addr_t base_dma;	/* ring buffer bus address */
&gt; +	void *base;		/* ring buffer pointer */
&gt; +	size_t len;		/* single item length */
&gt; +	u32 cnt;		/* items count */
&gt; +	u32 lui;		/* last used index, consumer/producer share */
&gt; +	unsigned qbr;		/* queue base register offset */
&gt; +	unsigned qcr;		/* queue control and status register offset */
&gt; +	int irq;		/* registered interrupt number */
&gt; +	bool in_iomem;		/* indicates queue data are in I/O memory  */
&gt; +};
&gt; +
&gt; +enum riscv_queue_ids {
&gt; +	RISCV_IOMMU_COMMAND_QUEUE	= 0,
&gt; +	RISCV_IOMMU_FAULT_QUEUE		= 1,
&gt; +	RISCV_IOMMU_PAGE_REQUEST_QUEUE	= 2
&gt; +};
&gt; +
&gt;   struct riscv_iommu_device {
&gt;   	struct iommu_device iommu;	/* iommu core interface */
&gt;   	struct device *dev;		/* iommu hardware */
&gt; @@ -42,6 +60,11 @@ struct riscv_iommu_device {
&gt;   	int irq_pm;
&gt;   	int irq_priq;
&gt;   
&gt; +	/* Queue lengths */
&gt; +	int cmdq_len;
&gt; +	int fltq_len;
&gt; +	int priq_len;
&gt; +
&gt;   	/* supported and enabled hardware capabilities */
&gt;   	u64 cap;
&gt;   
&gt; @@ -53,6 +76,11 @@ struct riscv_iommu_device {
&gt;   	unsigned ddt_mode;
&gt;   	bool ddtp_in_iomem;
&gt;   
&gt; +	/* hardware queues */
&gt; +	struct riscv_iommu_queue cmdq;
&gt; +	struct riscv_iommu_queue fltq;
&gt; +	struct riscv_iommu_queue priq;
&gt; +
&gt;   	/* Connected end-points */
&gt;   	struct rb_root eps;
&gt;   	struct mutex eps_mutex;
</span>
<a href=#mf18bd90d921132d02c05d7d5894300a045bab960 id=ef18bd90d921132d02c05d7d5894300a045bab960>^</a> <a href=https://lore.kernel.org/lkml/e9f19296-80e3-f0be-f0e5-a751b481f7e1@arm.com/>permalink</a> <a href=https://lore.kernel.org/lkml/e9f19296-80e3-f0be-f0e5-a751b481f7e1@arm.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/e9f19296-80e3-f0be-f0e5-a751b481f7e1@arm.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/e9f19296-80e3-f0be-f0e5-a751b481f7e1@arm.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/e9f19296-80e3-f0be-f0e5-a751b481f7e1@arm.com/t/#u>nested</a>] <a href=#rf18bd90d921132d02c05d7d5894300a045bab960>86+ messages in thread</a></pre><hr><pre><a href=#e794b93ecd24e4c126303d54185259a3506944063 id=m794b93ecd24e4c126303d54185259a3506944063>*</a> <b>Re: [PATCH 07/11] RISC-V: drivers/iommu/riscv: Add device context support</b>
  2023-07-19 19:33 ` <a href=#m02ea782700dca52c10fb471a2331de501bffb1a7>[PATCH 07/11] RISC-V: drivers/iommu/riscv: Add device context support</a> Tomasz Jeznach
<b>@ 2023-08-16 19:08   ` Robin Murphy</b>
  <a href=#r794b93ecd24e4c126303d54185259a3506944063>0 siblings, 0 replies; 86+ messages in thread</a>
From: Robin Murphy @ 2023-08-16 19:08 UTC (<a href=https://lore.kernel.org/lkml/9510695e-407c-53b6-2e91-cd8209d86c84@arm.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/9510695e-407c-53b6-2e91-cd8209d86c84@arm.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230816190914">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230816190914">linux-kernel</a>, linux

On 2023-07-19 20:33, Tomasz Jeznach wrote:
<span class=q>&gt; Introduces per device translation context, with 1,2 or 3 tree level
&gt; device tree structures.
&gt; 
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;   drivers/iommu/riscv/iommu.c | 163 ++++++++++++++++++++++++++++++++++--
&gt;   drivers/iommu/riscv/iommu.h |   1 +
&gt;   2 files changed, 158 insertions(+), 6 deletions(-)
&gt; 
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 5c4cf9875302..9ee7d2b222b5 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -41,7 +41,7 @@ MODULE_ALIAS("riscv-iommu");
&gt;   MODULE_LICENSE("GPL v2");
&gt;   
&gt;   /* Global IOMMU params. */
&gt; -static int ddt_mode = RISCV_IOMMU_DDTP_MODE_BARE;
&gt; +static int ddt_mode = RISCV_IOMMU_DDTP_MODE_3LVL;
&gt;   module_param(ddt_mode, int, 0644);
&gt;   MODULE_PARM_DESC(ddt_mode, "Device Directory Table mode.");
&gt;   
&gt; @@ -452,6 +452,14 @@ static bool riscv_iommu_post(struct riscv_iommu_device *iommu,
&gt;   	return riscv_iommu_post_sync(iommu, cmd, false);
&gt;   }
&gt;   
&gt; +static bool riscv_iommu_iodir_inv_devid(struct riscv_iommu_device *iommu, unsigned devid)
&gt; +{
&gt; +	struct riscv_iommu_command cmd;
&gt; +	riscv_iommu_cmd_iodir_inval_ddt(&amp;cmd);
&gt; +	riscv_iommu_cmd_iodir_set_did(&amp;cmd, devid);
&gt; +	return riscv_iommu_post(iommu, &amp;cmd);
&gt; +}
&gt; +
&gt;   static bool riscv_iommu_iofence_sync(struct riscv_iommu_device *iommu)
&gt;   {
&gt;   	struct riscv_iommu_command cmd;
&gt; @@ -671,6 +679,94 @@ static bool riscv_iommu_capable(struct device *dev, enum iommu_cap cap)
&gt;   	return false;
&gt;   }
&gt;   
&gt; +/* TODO: implement proper device context management, e.g. teardown flow */
&gt; +
&gt; +/* Lookup or initialize device directory info structure. */
&gt; +static struct riscv_iommu_dc *riscv_iommu_get_dc(struct riscv_iommu_device *iommu,
&gt; +						 unsigned devid)
&gt; +{
&gt; +	const bool base_format = !(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_MSI_FLAT);
&gt; +	unsigned depth = iommu-&gt;ddt_mode - RISCV_IOMMU_DDTP_MODE_1LVL;
&gt; +	u8 ddi_bits[3] = { 0 };
&gt; +	u64 *ddtp = NULL, ddt;
&gt; +
&gt; +	if (iommu-&gt;ddt_mode == RISCV_IOMMU_DDTP_MODE_OFF ||
&gt; +	    iommu-&gt;ddt_mode == RISCV_IOMMU_DDTP_MODE_BARE)
&gt; +		return NULL;
</span>
I don't see how the driver can ever be useful without a DDT - I'd have 
thought that you only ever want to use one of those modes on probe 
failure or remove.

<span class=q>&gt; +
&gt; +	/* Make sure the mode is valid */
&gt; +	if (iommu-&gt;ddt_mode &gt; RISCV_IOMMU_DDTP_MODE_MAX)
&gt; +		return NULL;
&gt; +
&gt; +	/*
&gt; +	 * Device id partitioning for base format:
&gt; +	 * DDI[0]: bits 0 - 6   (1st level) (7 bits)
&gt; +	 * DDI[1]: bits 7 - 15  (2nd level) (9 bits)
&gt; +	 * DDI[2]: bits 16 - 23 (3rd level) (8 bits)
&gt; +	 *
&gt; +	 * For extended format:
&gt; +	 * DDI[0]: bits 0 - 5   (1st level) (6 bits)
&gt; +	 * DDI[1]: bits 6 - 14  (2nd level) (9 bits)
&gt; +	 * DDI[2]: bits 15 - 23 (3rd level) (9 bits)
&gt; +	 */
&gt; +	if (base_format) {
&gt; +		ddi_bits[0] = 7;
&gt; +		ddi_bits[1] = 7 + 9;
&gt; +		ddi_bits[2] = 7 + 9 + 8;
&gt; +	} else {
&gt; +		ddi_bits[0] = 6;
&gt; +		ddi_bits[1] = 6 + 9;
&gt; +		ddi_bits[2] = 6 + 9 + 9;
&gt; +	}
&gt; +
&gt; +	/* Make sure device id is within range */
&gt; +	if (devid &gt;= (1 &lt;&lt; ddi_bits[depth]))
&gt; +		return NULL;
&gt; +
&gt; +	/* Get to the level of the non-leaf node that holds the device context */
&gt; +	for (ddtp = (u64 *) iommu-&gt;ddtp; depth-- &gt; 0;) {
&gt; +		const int split = ddi_bits[depth];
&gt; +		/*
&gt; +		 * Each non-leaf node is 64bits wide and on each level
&gt; +		 * nodes are indexed by DDI[depth].
&gt; +		 */
&gt; +		ddtp += (devid &gt;&gt; split) &amp; 0x1FF;
&gt; +
&gt; + retry:
&gt; +		/*
&gt; +		 * Check if this node has been populated and if not
&gt; +		 * allocate a new level and populate it.
&gt; +		 */
&gt; +		ddt = READ_ONCE(*ddtp);
&gt; +		if (ddt &amp; RISCV_IOMMU_DDTE_VALID) {
&gt; +			ddtp = __va(ppn_to_phys(ddt));
&gt; +		} else {
&gt; +			u64 old, new = get_zeroed_page(GFP_KERNEL);
&gt; +			if (!new)
&gt; +				return NULL;
&gt; +
&gt; +			old = cmpxchg64_relaxed(ddtp, ddt,
&gt; +						phys_to_ppn(__pa(new)) |
&gt; +						RISCV_IOMMU_DDTE_VALID);
&gt; +
&gt; +			if (old != ddt) {
&gt; +				free_page(new);
&gt; +				goto retry;
&gt; +			}
&gt; +
&gt; +			ddtp = (u64 *) new;
&gt; +		}
&gt; +	}
&gt; +
&gt; +	/*
&gt; +	 * Grab the node that matches DDI[depth], note that when using base
&gt; +	 * format the device context is 4 * 64bits, and the extended format
&gt; +	 * is 8 * 64bits, hence the (3 - base_format) below.
&gt; +	 */
&gt; +	ddtp += (devid &amp; ((64 &lt;&lt; base_format) - 1)) &lt;&lt; (3 - base_format);
&gt; +	return (struct riscv_iommu_dc *)ddtp;
&gt; +}
&gt; +
&gt;   static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;   {
&gt;   	struct riscv_iommu_device *iommu;
&gt; @@ -708,6 +804,9 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;   	ep-&gt;iommu = iommu;
&gt;   	ep-&gt;dev = dev;
&gt;   
&gt; +	/* Initial DC pointer can be NULL if IOMMU is configured in OFF or BARE mode */
&gt; +	ep-&gt;dc = riscv_iommu_get_dc(iommu, ep-&gt;devid);
&gt; +
&gt;   	dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt;   		ep-&gt;devid, ep-&gt;domid);
&gt;   
&gt; @@ -734,6 +833,16 @@ static void riscv_iommu_release_device(struct device *dev)
&gt;   	list_del(&amp;ep-&gt;domain);
&gt;   	mutex_unlock(&amp;ep-&gt;lock);
&gt;   
&gt; +	if (ep-&gt;dc) {
&gt; +		// this should be already done by domain detach.
</span>
What's domain detach? ;)

<span class=q>&gt; +		ep-&gt;dc-&gt;tc = 0ULL;
&gt; +		wmb();
&gt; +		ep-&gt;dc-&gt;fsc = 0ULL;
&gt; +		ep-&gt;dc-&gt;iohgatp = 0ULL;
&gt; +		wmb();
&gt; +		riscv_iommu_iodir_inv_devid(iommu, ep-&gt;devid);
&gt; +	}
&gt; +
&gt;   	/* Remove endpoint from IOMMU tracking structures */
&gt;   	mutex_lock(&amp;iommu-&gt;eps_mutex);
&gt;   	rb_erase(&amp;ep-&gt;node, &amp;iommu-&gt;eps);
&gt; @@ -853,11 +962,21 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt;   	return 0;
&gt;   }
&gt;   
&gt; +static u64 riscv_iommu_domain_atp(struct riscv_iommu_domain *domain)
&gt; +{
&gt; +	u64 atp = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, domain-&gt;mode);
&gt; +	if (domain-&gt;mode != RISCV_IOMMU_DC_FSC_MODE_BARE)
&gt; +		atp |= FIELD_PREP(RISCV_IOMMU_DC_FSC_PPN, virt_to_pfn(domain-&gt;pgd_root));
&gt; +	return atp;
&gt; +}
&gt; +
&gt;   static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct device *dev)
&gt;   {
&gt;   	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;   	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +	struct riscv_iommu_dc *dc = ep-&gt;dc;
&gt;   	int ret;
&gt; +	u64 val;
&gt;   
&gt;   	/* PSCID not valid */
&gt;   	if ((int)domain-&gt;pscid &lt; 0)
&gt; @@ -880,17 +999,44 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;   		return ret;
&gt;   	}
&gt;   
&gt; -	if (ep-&gt;iommu-&gt;ddt_mode != RISCV_IOMMU_DDTP_MODE_BARE ||
&gt; -	    domain-&gt;domain.type != IOMMU_DOMAIN_IDENTITY) {
&gt; -		dev_warn(dev, "domain type %d not supported\n",
&gt; -		    domain-&gt;domain.type);
&gt; +	if (ep-&gt;iommu-&gt;ddt_mode == RISCV_IOMMU_DDTP_MODE_BARE &amp;&amp;
&gt; +	    domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; +		dev_info(dev, "domain type %d attached w/ PSCID %u\n",
&gt; +		    domain-&gt;domain.type, domain-&gt;pscid);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	if (!dc) {
&gt;   		return -ENODEV;
&gt;   	}
&gt;   
&gt; +	/*
&gt; +	 * S-Stage translation table. G-Stage remains unmodified (BARE).
&gt; +	 */
&gt; +	val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt; +
&gt; +	dc-&gt;ta = cpu_to_le64(val);
&gt; +	dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +
&gt; +	wmb();
&gt; +
&gt; +	/* Mark device context as valid, synchronise device context cache. */
&gt; +	val = RISCV_IOMMU_DC_TC_V;
&gt; +
&gt; +	if (ep-&gt;iommu-&gt;cap &amp; RISCV_IOMMU_CAP_AMO) {
&gt; +		val |= RISCV_IOMMU_DC_TC_GADE |
&gt; +		       RISCV_IOMMU_DC_TC_SADE;
&gt; +	}
&gt; +
&gt; +	dc-&gt;tc = cpu_to_le64(val);
&gt; +	wmb();
&gt; +
&gt;   	list_add_tail(&amp;ep-&gt;domain, &amp;domain-&gt;endpoints);
&gt;   	mutex_unlock(&amp;ep-&gt;lock);
&gt;   	mutex_unlock(&amp;domain-&gt;lock);
&gt;   
&gt; +	riscv_iommu_iodir_inv_devid(ep-&gt;iommu, ep-&gt;devid);
&gt; +
&gt;   	dev_info(dev, "domain type %d attached w/ PSCID %u\n",
&gt;   	    domain-&gt;domain.type, domain-&gt;pscid);
&gt;   
&gt; @@ -1239,7 +1385,12 @@ int riscv_iommu_init(struct riscv_iommu_device *iommu)
&gt;   		goto fail;
&gt;   
&gt;    no_ats:
&gt; -	ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
&gt; +	if (iommu_default_passthrough()) {
&gt; +		dev_info(dev, "iommu set to passthrough mode\n");
&gt; +		ret = riscv_iommu_enable(iommu, RISCV_IOMMU_DDTP_MODE_BARE);
</span>
Yeah, disabling the whole IOMMU is not what default passthrough means... 
drivers should not care about that at all, it only affects the core 
code's choice of default domain type. Even if that is identity, 
translation absolutely still needs to be available on a per-device 
basis, for unmanaged domains or default domain changes via sysfs.

Thanks,
Robin.

<span class=q>&gt; +	} else {
&gt; +		ret = riscv_iommu_enable(iommu, ddt_mode);
&gt; +	}
&gt;   
&gt;   	if (ret) {
&gt;   		dev_err(dev, "cannot enable iommu device (%d)\n", ret);
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 04148a2a8ffd..9140df71e17b 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -105,6 +105,7 @@ struct riscv_iommu_endpoint {
&gt;   	unsigned devid;      			/* PCI bus:device:function number */
&gt;   	unsigned domid;    			/* PCI domain number, segment */
&gt;   	struct rb_node node;    		/* device tracking node (lookup by devid) */
&gt; +	struct riscv_iommu_dc *dc;		/* device context pointer */
&gt;   	struct riscv_iommu_device *iommu;	/* parent iommu device */
&gt;   
&gt;   	struct mutex lock;
</span>
<a href=#m794b93ecd24e4c126303d54185259a3506944063 id=e794b93ecd24e4c126303d54185259a3506944063>^</a> <a href=https://lore.kernel.org/lkml/9510695e-407c-53b6-2e91-cd8209d86c84@arm.com/>permalink</a> <a href=https://lore.kernel.org/lkml/9510695e-407c-53b6-2e91-cd8209d86c84@arm.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/9510695e-407c-53b6-2e91-cd8209d86c84@arm.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/9510695e-407c-53b6-2e91-cd8209d86c84@arm.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/9510695e-407c-53b6-2e91-cd8209d86c84@arm.com/t/#u>nested</a>] <a href=#r794b93ecd24e4c126303d54185259a3506944063>86+ messages in thread</a></pre><hr><pre><a href=#e4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259 id=m4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259>*</a> <b>Re: [PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</b>
  2023-07-19 19:33 ` <a href=#m50b13653960cd6e88a7efb588257ac568bffb87b>[PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</a> Tomasz Jeznach
  2023-07-25 13:13   ` <a href=#m35e1f370635d089a8dde16e4c70b533d4b503ee0>Zong Li</a>
  2023-07-31  7:19   ` <a href=#m525805e3cb4b98064a03306b5a208399736c02b0>Zong Li</a>
<b>@ 2023-08-16 21:04   ` Robin Murphy</b>
  <a href=#r4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259>2 siblings, 0 replies; 86+ messages in thread</a>
From: Robin Murphy @ 2023-08-16 21:04 UTC (<a href=https://lore.kernel.org/lkml/4c1bd243-6a94-08b4-6790-bb9e6ac6b0af@arm.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/4c1bd243-6a94-08b4-6790-bb9e6ac6b0af@arm.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230816210546">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230816210546">linux-kernel</a>, linux

On 2023-07-19 20:33, Tomasz Jeznach wrote:
<span class=q>&gt; Introduces I/O page level translation services, with 4K, 2M, 1G page
&gt; size support and enables page level iommu_map/unmap domain interfaces.
&gt; 
&gt; Co-developed-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;   drivers/iommu/io-pgtable.c       |   3 +
&gt;   drivers/iommu/riscv/Makefile     |   2 +-
&gt;   drivers/iommu/riscv/io_pgtable.c | 266 +++++++++++++++++++++++++++++++
&gt;   drivers/iommu/riscv/iommu.c      |  40 +++--
&gt;   drivers/iommu/riscv/iommu.h      |   1 +
&gt;   include/linux/io-pgtable.h       |   2 +
&gt;   6 files changed, 297 insertions(+), 17 deletions(-)
&gt;   create mode 100644 drivers/iommu/riscv/io_pgtable.c
&gt; 
&gt; diff --git a/drivers/iommu/io-pgtable.c b/drivers/iommu/io-pgtable.c
&gt; index b843fcd365d2..c4807175934f 100644
&gt; --- a/drivers/iommu/io-pgtable.c
&gt; +++ b/drivers/iommu/io-pgtable.c
&gt; @@ -32,6 +32,9 @@ io_pgtable_init_table[IO_PGTABLE_NUM_FMTS] = {
&gt;   	[AMD_IOMMU_V1] = &amp;io_pgtable_amd_iommu_v1_init_fns,
&gt;   	[AMD_IOMMU_V2] = &amp;io_pgtable_amd_iommu_v2_init_fns,
&gt;   #endif
&gt; +#ifdef CONFIG_RISCV_IOMMU
&gt; +	[RISCV_IOMMU] = &amp;io_pgtable_riscv_init_fns,
&gt; +#endif
&gt;   };
&gt;   
&gt;   struct io_pgtable_ops *alloc_io_pgtable_ops(enum io_pgtable_fmt fmt,
&gt; diff --git a/drivers/iommu/riscv/Makefile b/drivers/iommu/riscv/Makefile
&gt; index 9523eb053cfc..13af452c3052 100644
&gt; --- a/drivers/iommu/riscv/Makefile
&gt; +++ b/drivers/iommu/riscv/Makefile
&gt; @@ -1 +1 @@
&gt; -obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o
&gt; \ No newline at end of file
&gt; +obj-$(CONFIG_RISCV_IOMMU) += iommu.o iommu-pci.o iommu-platform.o iommu-sysfs.o io_pgtable.o
&gt; diff --git a/drivers/iommu/riscv/io_pgtable.c b/drivers/iommu/riscv/io_pgtable.c
&gt; new file mode 100644
&gt; index 000000000000..b6e603e6726e
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/io_pgtable.c
&gt; @@ -0,0 +1,266 @@
&gt; +// SPDX-License-Identifier: GPL-2.0-only
&gt; +/*
&gt; + * Copyright © 2022-2023 Rivos Inc.
&gt; + *
&gt; + * RISC-V IOMMU page table allocator.
&gt; + *
&gt; + * Authors:
&gt; + *	Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; + *	Sebastien Boeuf &lt;seb@rivosinc.com&gt;
&gt; + */
&gt; +
&gt; +#include &lt;linux/atomic.h&gt;
&gt; +#include &lt;linux/bitops.h&gt;
&gt; +#include &lt;linux/io-pgtable.h&gt;
&gt; +#include &lt;linux/kernel.h&gt;
&gt; +#include &lt;linux/sizes.h&gt;
&gt; +#include &lt;linux/slab.h&gt;
&gt; +#include &lt;linux/types.h&gt;
&gt; +#include &lt;linux/dma-mapping.h&gt;
</span>
There's no DMA API usage here. Should there be?

<span class=q>&gt; +
&gt; +#include "iommu.h"
&gt; +
&gt; +#define io_pgtable_to_domain(x) \
&gt; +	container_of((x), struct riscv_iommu_domain, pgtbl)
&gt; +
&gt; +#define io_pgtable_ops_to_domain(x) \
&gt; +	io_pgtable_to_domain(container_of((x), struct io_pgtable, ops))
&gt; +
&gt; +static inline size_t get_page_size(size_t size)
&gt; +{
&gt; +	if (size &gt;= IOMMU_PAGE_SIZE_512G)
&gt; +		return IOMMU_PAGE_SIZE_512G;
&gt; +
&gt; +	if (size &gt;= IOMMU_PAGE_SIZE_1G)
&gt; +		return IOMMU_PAGE_SIZE_1G;
&gt; +
&gt; +	if (size &gt;= IOMMU_PAGE_SIZE_2M)
&gt; +		return IOMMU_PAGE_SIZE_2M;
&gt; +
&gt; +	return IOMMU_PAGE_SIZE_4K;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_pt_walk_free(pmd_t * ptp, unsigned shift, bool root)
&gt; +{
&gt; +	pmd_t *pte, *pt_base;
&gt; +	int i;
&gt; +
&gt; +	if (shift == PAGE_SHIFT)
&gt; +		return;
&gt; +
&gt; +	if (root)
&gt; +		pt_base = ptp;
&gt; +	else
&gt; +		pt_base =
&gt; +		    (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp)));
&gt; +
&gt; +	/* Recursively free all sub page table pages */
&gt; +	for (i = 0; i &lt; PTRS_PER_PMD; i++) {
&gt; +		pte = pt_base + i;
&gt; +		if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
&gt; +			riscv_iommu_pt_walk_free(pte, shift - 9, false);
&gt; +	}
&gt; +
&gt; +	/* Now free the current page table page */
</span>
Without any TLB maintenance, even if it was live? Maybe walk caches and 
speculative prefetching are a long way from anyone's mind if this is 
still only running under Qemu, but it still makes me unconfortable to 
see a complete lack of appropriate looking maintenance in the places I 
would usually expect to. Especially if there's the prospect of the IOMMU 
doing hardware pagetable updates itself (which I see is a thing, even if 
it's not enabled here yet).

<span class=q>&gt; +	if (!root &amp;&amp; pmd_present(*pt_base))
&gt; +		free_page((unsigned long)pt_base);
&gt; +}
&gt; +
&gt; +static void riscv_iommu_free_pgtable(struct io_pgtable *iop)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = io_pgtable_to_domain(iop);
&gt; +	riscv_iommu_pt_walk_free((pmd_t *) domain-&gt;pgd_root, PGDIR_SHIFT, true);
&gt; +}
&gt; +
&gt; +static pte_t *riscv_iommu_pt_walk_alloc(pmd_t * ptp, unsigned long iova,
&gt; +					unsigned shift, bool root,
&gt; +					size_t pgsize,
&gt; +					unsigned long (*pd_alloc)(gfp_t),
&gt; +					gfp_t gfp)
&gt; +{
&gt; +	pmd_t *pte;
&gt; +	unsigned long pfn;
&gt; +
&gt; +	if (root)
&gt; +		pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +	else
&gt; +		pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
&gt; +		    ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +
&gt; +	if ((1ULL &lt;&lt; shift) &lt;= pgsize) {
&gt; +		if (pmd_present(*pte) &amp;&amp; !pmd_leaf(*pte))
&gt; +			riscv_iommu_pt_walk_free(pte, shift - 9, false);
&gt; +		return (pte_t *) pte;
&gt; +	}
&gt; +
&gt; +	if (pmd_none(*pte)) {
&gt; +		pfn = pd_alloc ? virt_to_pfn(pd_alloc(gfp)) : 0;
&gt; +		if (!pfn)
&gt; +			return NULL;
&gt; +		set_pmd(pte, __pmd((pfn &lt;&lt; _PAGE_PFN_SHIFT) | _PAGE_TABLE));
&gt; +	}
&gt; +
&gt; +	return riscv_iommu_pt_walk_alloc(pte, iova, shift - 9, false,
&gt; +					 pgsize, pd_alloc, gfp);
&gt; +}
&gt; +
&gt; +static pte_t *riscv_iommu_pt_walk_fetch(pmd_t * ptp,
&gt; +					unsigned long iova, unsigned shift,
&gt; +					bool root)
&gt; +{
&gt; +	pmd_t *pte;
&gt; +
&gt; +	if (root)
&gt; +		pte = ptp + ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +	else
&gt; +		pte = (pmd_t *) pfn_to_virt(__page_val_to_pfn(pmd_val(*ptp))) +
&gt; +		    ((iova &gt;&gt; shift) &amp; (PTRS_PER_PMD - 1));
&gt; +
&gt; +	if (pmd_leaf(*pte))
&gt; +		return (pte_t *) pte;
&gt; +	else if (pmd_none(*pte))
&gt; +		return NULL;
&gt; +	else if (shift == PAGE_SHIFT)
&gt; +		return NULL;
&gt; +
&gt; +	return riscv_iommu_pt_walk_fetch(pte, iova, shift - 9, false);
&gt; +}
&gt; +
&gt; +static int riscv_iommu_map_pages(struct io_pgtable_ops *ops,
&gt; +				 unsigned long iova, phys_addr_t phys,
&gt; +				 size_t pgsize, size_t pgcount, int prot,
&gt; +				 gfp_t gfp, size_t *mapped)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +	size_t size = 0;
&gt; +	size_t page_size = get_page_size(pgsize);
&gt; +	pte_t *pte;
&gt; +	pte_t pte_val;
&gt; +	pgprot_t pte_prot;
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_BLOCKED)
&gt; +		return -ENODEV;
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; +		*mapped = pgsize * pgcount;
&gt; +		return 0;
&gt; +	}
</span>
As before, these are utter nonsense, but cannot happen anyway.

<span class=q>&gt; +
&gt; +	pte_prot = (prot &amp; IOMMU_WRITE) ?
&gt; +	    __pgprot(_PAGE_BASE | _PAGE_READ | _PAGE_WRITE | _PAGE_DIRTY) :
&gt; +	    __pgprot(_PAGE_BASE | _PAGE_READ);
&gt; +
&gt; +	while (pgcount--) {
&gt; +		pte =
&gt; +		    riscv_iommu_pt_walk_alloc((pmd_t *) domain-&gt;pgd_root, iova,
&gt; +					      PGDIR_SHIFT, true, page_size,
&gt; +					      get_zeroed_page, gfp);
&gt; +		if (!pte) {
&gt; +			*mapped = size;
&gt; +			return -ENOMEM;
&gt; +		}
&gt; +
&gt; +		pte_val = pfn_pte(phys_to_pfn(phys), pte_prot);
&gt; +
&gt; +		set_pte(pte, pte_val);
&gt; +
&gt; +		size += page_size;
&gt; +		iova += page_size;
&gt; +		phys += page_size;
&gt; +	}
&gt; +
&gt; +	*mapped = size;
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static size_t riscv_iommu_unmap_pages(struct io_pgtable_ops *ops,
&gt; +				      unsigned long iova, size_t pgsize,
&gt; +				      size_t pgcount,
&gt; +				      struct iommu_iotlb_gather *gather)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +	size_t size = 0;
&gt; +	size_t page_size = get_page_size(pgsize);
&gt; +	pte_t *pte;
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +		return pgsize * pgcount;
</span>
"Yes, non-existent caller, those pages are definitely unmapped and 
inaccessible now. Totally secure. Device couldn't possibly touch them if 
it tried. Would I lie to you?"

<span class=q>&gt; +
&gt; +	while (pgcount--) {
&gt; +		pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
&gt; +						iova, PGDIR_SHIFT, true);
&gt; +		if (!pte)
&gt; +			return size;
&gt; +
&gt; +		set_pte(pte, __pte(0));
&gt; +
&gt; +		iommu_iotlb_gather_add_page(&amp;domain-&gt;domain, gather, iova,
&gt; +					    pgsize);
&gt; +
&gt; +		size += page_size;
&gt; +		iova += page_size;
&gt; +	}
&gt; +
&gt; +	return size;
&gt; +}
&gt; +
&gt; +static phys_addr_t riscv_iommu_iova_to_phys(struct io_pgtable_ops *ops,
&gt; +					    unsigned long iova)
&gt; +{
&gt; +	struct riscv_iommu_domain *domain = io_pgtable_ops_to_domain(ops);
&gt; +	pte_t *pte;
&gt; +
&gt; +	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; +		return (phys_addr_t) iova;
</span>
I mean, even if it was still 2 years ago before the core code handled 
this anyway (and it's only for a couple of broken network drivers doing 
dumb things they shouldn't), why would a sane IOMMU driver even bother 
going to the lengths of allocating io-pgtable ops for an identity domain 
that by definition doesn't use a pagetable!?

<span class=q>&gt; +
&gt; +	pte = riscv_iommu_pt_walk_fetch((pmd_t *) domain-&gt;pgd_root,
&gt; +					iova, PGDIR_SHIFT, true);
&gt; +	if (!pte || !pte_present(*pte))
&gt; +		return 0;
&gt; +
&gt; +	return (pfn_to_phys(pte_pfn(*pte)) | (iova &amp; PAGE_MASK));
&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_inv_all(void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_inv_walk(unsigned long iova, size_t size,
&gt; +				     size_t granule, void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static void riscv_iommu_tlb_add_page(struct iommu_iotlb_gather *gather,
&gt; +				     unsigned long iova, size_t granule,
&gt; +				     void *cookie)
&gt; +{
&gt; +}
&gt; +
&gt; +static const struct iommu_flush_ops riscv_iommu_flush_ops = {
&gt; +	.tlb_flush_all = riscv_iommu_tlb_inv_all,
&gt; +	.tlb_flush_walk = riscv_iommu_tlb_inv_walk,
&gt; +	.tlb_add_page = riscv_iommu_tlb_add_page,
&gt; +};
</span>
...Why? Either implement them properly, or don't implement them at all. 
And if they are implemented it needs to be by the driver, so either way 
they shouldn't be *here*.

<span class=q>&gt; +
&gt; +/* NOTE: cfg should point to riscv_iommu_domain structure member pgtbl.cfg */
&gt; +static struct io_pgtable *riscv_iommu_alloc_pgtable(struct io_pgtable_cfg *cfg,
&gt; +						    void *cookie)
&gt; +{
&gt; +	struct io_pgtable *iop = container_of(cfg, struct io_pgtable, cfg);
&gt; +
&gt; +	cfg-&gt;pgsize_bitmap = SZ_4K | SZ_2M | SZ_1G;
&gt; +	cfg-&gt;ias = 57;		// va mode, SvXX -&gt; ias
&gt; +	cfg-&gt;oas = 57;		// pa mode, or SvXX+4 -&gt; oas
</span>
At least IAS should be passed by the driver based on what the IOMMU 
actually supports (and isn't OAS 56?)

<span class=q>&gt; +	cfg-&gt;tlb = &amp;riscv_iommu_flush_ops;
&gt; +
&gt; +	iop-&gt;ops.map_pages = riscv_iommu_map_pages;
&gt; +	iop-&gt;ops.unmap_pages = riscv_iommu_unmap_pages;
&gt; +	iop-&gt;ops.iova_to_phys = riscv_iommu_iova_to_phys;
&gt; +
&gt; +	return iop;
&gt; +}
&gt; +
&gt; +struct io_pgtable_init_fns io_pgtable_riscv_init_fns = {
&gt; +	.alloc = riscv_iommu_alloc_pgtable,
&gt; +	.free = riscv_iommu_free_pgtable,
&gt; +};
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 9ee7d2b222b5..2ef6952a2109 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -807,7 +807,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;   	/* Initial DC pointer can be NULL if IOMMU is configured in OFF or BARE mode */
&gt;   	ep-&gt;dc = riscv_iommu_get_dc(iommu, ep-&gt;devid);
&gt;   
&gt; -	dev_info(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt; +	dev_dbg(iommu-&gt;dev, "adding device to iommu with devid %i in domain %i\n",
&gt;   		ep-&gt;devid, ep-&gt;domid);
&gt;   
&gt;   	dev_iommu_priv_set(dev, ep);
&gt; @@ -874,7 +874,10 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;   {
&gt;   	struct riscv_iommu_domain *domain;
&gt;   
&gt; -	if (type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt; +	if (type != IOMMU_DOMAIN_DMA &amp;&amp;
&gt; +	    type != IOMMU_DOMAIN_DMA_FQ &amp;&amp;
</span>
IOMMU_DOMAIN_DMA_FQ isn't exposed to drivers any more.

<span class=q>&gt; +	    type != IOMMU_DOMAIN_UNMANAGED &amp;&amp;
&gt; +	    type != IOMMU_DOMAIN_IDENTITY &amp;&amp;
&gt;   	    type != IOMMU_DOMAIN_BLOCKED)
</span>
I might start believing you could support blocking domains if I saw some 
kind of handling of them since patch #7, but no, still nothing.

AFAICS from the spec there's no super-convenient way if you did want to 
do it, since you apparently can't suppress the faults from simply making 
the DC invalid. I guess it might be a case of keeping a special 
always-empty context so you can point any device's FSC at that while 
setting DTF. But it's hardly critical, so for now I'd just remove the 
broken non-support and leave the idea as something to revisit later.

<span class=q>&gt;   		return NULL;
&gt;   
&gt; @@ -890,7 +893,7 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;   	domain-&gt;pscid = ida_alloc_range(&amp;riscv_iommu_pscids, 1,
&gt;   					RISCV_IOMMU_MAX_PSCID, GFP_KERNEL);
&gt;   
&gt; -	printk("domain type %x alloc %u\n", type, domain-&gt;pscid);
&gt; +	printk("domain alloc %u\n", domain-&gt;pscid);
&gt;   
&gt;   	return &amp;domain-&gt;domain;
&gt;   }
&gt; @@ -903,6 +906,9 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;   		pr_warn("IOMMU domain is not empty!\n");
&gt;   	}
&gt;   
&gt; +	if (domain-&gt;pgtbl.cookie)
&gt; +		free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
&gt; +
&gt;   	if (domain-&gt;pgd_root)
&gt;   		free_pages((unsigned long)domain-&gt;pgd_root, 0);
</span>
Is there a reason for this weird pgd_root setup where the io-pgtable 
implementation doesn't simply allocate and own the full pagetable itself?

<span class=q>&gt;   
&gt; @@ -959,6 +965,9 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt;   	if (!domain-&gt;pgd_root)
&gt;   		return -ENOMEM;
&gt;   
&gt; +	if (!alloc_io_pgtable_ops(RISCV_IOMMU, &amp;domain-&gt;pgtbl.cfg, domain))
&gt; +		return -ENOMEM;
&gt; +
&gt;   	return 0;
&gt;   }
&gt;   
&gt; @@ -1006,9 +1015,8 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;   		return 0;
&gt;   	}
&gt;   
&gt; -	if (!dc) {
&gt; +	if (!dc)
&gt;   		return -ENODEV;
&gt; -	}
</span>
This is a great example of more of the kind of stuff I was getting at on 
patch #1 - obviously unnecessary churn *within* a series is the ideal 
way to overload and annoy reviewers... and then I look at the rest of my 
screen below and see loads of code from an earlier patch being deleted 
already, so apparently it was a waste of time reviewing it at all :(

Thanks,
Robin.

<span class=q>&gt;   	/*
&gt;   	 * S-Stage translation table. G-Stage remains unmodified (BARE).
&gt; @@ -1104,12 +1112,11 @@ static int riscv_iommu_map_pages(struct iommu_domain *iommu_domain,
&gt;   {
&gt;   	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;   
&gt; -	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY) {
&gt; -		*mapped = pgsize * pgcount;
&gt; -		return 0;
&gt; -	}
&gt; +	if (!domain-&gt;pgtbl.ops.map_pages)
&gt; +		return -ENODEV;
&gt;   
&gt; -	return -ENODEV;
&gt; +	return domain-&gt;pgtbl.ops.map_pages(&amp;domain-&gt;pgtbl.ops, iova, phys,
&gt; +					   pgsize, pgcount, prot, gfp, mapped);
&gt;   }
&gt;   
&gt;   static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt; @@ -1118,10 +1125,11 @@ static size_t riscv_iommu_unmap_pages(struct iommu_domain *iommu_domain,
&gt;   {
&gt;   	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;   
&gt; -	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; -		return pgsize * pgcount;
&gt; +	if (!domain-&gt;pgtbl.ops.unmap_pages)
&gt; +		return 0;
&gt;   
&gt; -	return 0;
&gt; +	return domain-&gt;pgtbl.ops.unmap_pages(&amp;domain-&gt;pgtbl.ops, iova, pgsize,
&gt; +					     pgcount, gather);
&gt;   }
&gt;   
&gt;   static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt; @@ -1129,10 +1137,10 @@ static phys_addr_t riscv_iommu_iova_to_phys(struct iommu_domain *iommu_domain,
&gt;   {
&gt;   	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt;   
&gt; -	if (domain-&gt;domain.type == IOMMU_DOMAIN_IDENTITY)
&gt; -		return (phys_addr_t) iova;
&gt; +	if (!domain-&gt;pgtbl.ops.iova_to_phys)
&gt; +		return 0;
&gt;   
&gt; -	return 0;
&gt; +	return domain-&gt;pgtbl.ops.iova_to_phys(&amp;domain-&gt;pgtbl.ops, iova);
&gt;   }
&gt;   
&gt;   /*
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 9140df71e17b..fe32a4eff14e 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -88,6 +88,7 @@ struct riscv_iommu_device {
&gt;   
&gt;   struct riscv_iommu_domain {
&gt;   	struct iommu_domain domain;
&gt; +	struct io_pgtable pgtbl;
&gt;   
&gt;   	struct list_head endpoints;
&gt;   	struct mutex lock;
&gt; diff --git a/include/linux/io-pgtable.h b/include/linux/io-pgtable.h
&gt; index 1b7a44b35616..8dd9d3a28e3a 100644
&gt; --- a/include/linux/io-pgtable.h
&gt; +++ b/include/linux/io-pgtable.h
&gt; @@ -19,6 +19,7 @@ enum io_pgtable_fmt {
&gt;   	AMD_IOMMU_V2,
&gt;   	APPLE_DART,
&gt;   	APPLE_DART2,
&gt; +	RISCV_IOMMU,
&gt;   	IO_PGTABLE_NUM_FMTS,
&gt;   };
&gt;   
&gt; @@ -258,5 +259,6 @@ extern struct io_pgtable_init_fns io_pgtable_arm_mali_lpae_init_fns;
&gt;   extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v1_init_fns;
&gt;   extern struct io_pgtable_init_fns io_pgtable_amd_iommu_v2_init_fns;
&gt;   extern struct io_pgtable_init_fns io_pgtable_apple_dart_init_fns;
&gt; +extern struct io_pgtable_init_fns io_pgtable_riscv_init_fns;
&gt;   
&gt;   #endif /* __IO_PGTABLE_H */
</span>
<a href=#m4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259 id=e4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259>^</a> <a href=https://lore.kernel.org/lkml/4c1bd243-6a94-08b4-6790-bb9e6ac6b0af@arm.com/>permalink</a> <a href=https://lore.kernel.org/lkml/4c1bd243-6a94-08b4-6790-bb9e6ac6b0af@arm.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/4c1bd243-6a94-08b4-6790-bb9e6ac6b0af@arm.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/4c1bd243-6a94-08b4-6790-bb9e6ac6b0af@arm.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/4c1bd243-6a94-08b4-6790-bb9e6ac6b0af@arm.com/t/#u>nested</a>] <a href=#r4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259>86+ messages in thread</a></pre><hr><pre><a href=#e0c898cce80d8dc67ea1c5e12243227adb68db208 id=m0c898cce80d8dc67ea1c5e12243227adb68db208>*</a> <b>Re: [PATCH 11/11] RISC-V: drivers/iommu/riscv: Add G-Stage translation support</b>
  2023-07-19 19:33 ` <a href=#m6edef0662c8a8cd238cf3fa0929af7d0305c10f5>[PATCH 11/11] RISC-V: drivers/iommu/riscv: Add G-Stage translation support</a> Tomasz Jeznach
  2023-07-31  8:12   ` <a href=#m1a63028351b0e86a470c474db2d582acd5369901>Zong Li</a>
<b>@ 2023-08-16 21:13   ` Robin Murphy</b>
  <a href=#r0c898cce80d8dc67ea1c5e12243227adb68db208>1 sibling, 0 replies; 86+ messages in thread</a>
From: Robin Murphy @ 2023-08-16 21:13 UTC (<a href=https://lore.kernel.org/lkml/a0061d0c-2a74-9f32-e6ab-d3d9d06d9fd4@arm.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/a0061d0c-2a74-9f32-e6ab-d3d9d06d9fd4@arm.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230816211426">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230816211426">linux-kernel</a>, linux

On 2023-07-19 20:33, Tomasz Jeznach wrote:
<span class=q>&gt; This change introduces 2nd stage translation configuration
&gt; support, enabling nested translation for IOMMU hardware.
&gt; Pending integration with VMM IOMMUFD interfaces to manage
&gt; 1st stage translation and IOMMU virtialization interfaces.
&gt; 
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;   drivers/iommu/riscv/iommu.c | 58 ++++++++++++++++++++++++++++---------
&gt;   drivers/iommu/riscv/iommu.h |  3 +-
&gt;   2 files changed, 46 insertions(+), 15 deletions(-)
&gt; 
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 7b3e3e135cf6..3ca2f0194d3c 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -1418,6 +1418,19 @@ static struct iommu_domain *riscv_iommu_domain_alloc(unsigned type)
&gt;   	return &amp;domain-&gt;domain;
&gt;   }
&gt;   
&gt; +/* mark domain as second-stage translation */
&gt; +static int riscv_iommu_enable_nesting(struct iommu_domain *iommu_domain)
</span>
Please don't add more instances of enable_nesting. It's a dead end that 
has never actually been used and should be removed fairly soon. The new 
nesting infrastructure is all still in flight, but the current patchsets 
should give a good idea of what you'd want to work towards:

<a href=https://lore.kernel.org/linux-iommu/20230724110406.107212-1-yi.l.liu@intel.com/>https://lore.kernel.org/linux-iommu/20230724110406.107212-1-yi.l.liu@intel.com/</a>
<a href=https://lore.kernel.org/linux-iommu/20230724111335.107427-1-yi.l.liu@intel.com/>https://lore.kernel.org/linux-iommu/20230724111335.107427-1-yi.l.liu@intel.com/</a>
<a href=https://lore.kernel.org/linux-iommu/cover.1683688960.git.nicolinc@nvidia.com/>https://lore.kernel.org/linux-iommu/cover.1683688960.git.nicolinc@nvidia.com/</a>

Thanks,
Robin.

<span class=q>&gt; +{
&gt; +	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; +
&gt; +	mutex_lock(&amp;domain-&gt;lock);
&gt; +	if (list_empty(&amp;domain-&gt;endpoints))
&gt; +		domain-&gt;g_stage = true;
&gt; +	mutex_unlock(&amp;domain-&gt;lock);
&gt; +
&gt; +	return domain-&gt;g_stage ? 0 : -EBUSY;
&gt; +}
&gt; +
&gt;   static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;   {
&gt;   	struct riscv_iommu_domain *domain = iommu_domain_to_riscv(iommu_domain);
&gt; @@ -1433,7 +1446,7 @@ static void riscv_iommu_domain_free(struct iommu_domain *iommu_domain)
&gt;   		free_io_pgtable_ops(&amp;domain-&gt;pgtbl.ops);
&gt;   
&gt;   	if (domain-&gt;pgd_root)
&gt; -		free_pages((unsigned long)domain-&gt;pgd_root, 0);
&gt; +		free_pages((unsigned long)domain-&gt;pgd_root, domain-&gt;g_stage ? 2 : 0);
&gt;   
&gt;   	if ((int)domain-&gt;pscid &gt; 0)
&gt;   		ida_free(&amp;riscv_iommu_pscids, domain-&gt;pscid);
&gt; @@ -1483,7 +1496,8 @@ static int riscv_iommu_domain_finalize(struct riscv_iommu_domain *domain,
&gt;   
&gt;   	/* TODO: Fix this for RV32 */
&gt;   	domain-&gt;mode = satp_mode &gt;&gt; 60;
&gt; -	domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO, 0);
&gt; +	domain-&gt;pgd_root = (pgd_t *) __get_free_pages(GFP_KERNEL | __GFP_ZERO,
&gt; +						      domain-&gt;g_stage ? 2 : 0);
&gt;   
&gt;   	if (!domain-&gt;pgd_root)
&gt;   		return -ENOMEM;
&gt; @@ -1499,6 +1513,8 @@ static u64 riscv_iommu_domain_atp(struct riscv_iommu_domain *domain)
&gt;   	u64 atp = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, domain-&gt;mode);
&gt;   	if (domain-&gt;mode != RISCV_IOMMU_DC_FSC_MODE_BARE)
&gt;   		atp |= FIELD_PREP(RISCV_IOMMU_DC_FSC_PPN, virt_to_pfn(domain-&gt;pgd_root));
&gt; +	if (domain-&gt;g_stage)
&gt; +		atp |= FIELD_PREP(RISCV_IOMMU_DC_IOHGATP_GSCID, domain-&gt;pscid);
&gt;   	return atp;
&gt;   }
&gt;   
&gt; @@ -1541,20 +1557,30 @@ static int riscv_iommu_attach_dev(struct iommu_domain *iommu_domain, struct devi
&gt;   	if (!dc)
&gt;   		return -ENODEV;
&gt;   
&gt; -	/*
&gt; -	 * S-Stage translation table. G-Stage remains unmodified (BARE).
&gt; -	 */
&gt; -	val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt; -
&gt; -	if (ep-&gt;pasid_enabled) {
&gt; -		ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
&gt; -		ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +	if (domain-&gt;g_stage) {
&gt; +		/*
&gt; +		 * Enable G-Stage translation with initial pass-through mode
&gt; +		 * for S-Stage. VMM is responsible for more restrictive
&gt; +		 * guest VA translation scheme configuration.
&gt; +		 */
&gt;   		dc-&gt;ta = 0;
&gt; -		dc-&gt;fsc = cpu_to_le64(virt_to_pfn(ep-&gt;pc) |
&gt; -		    FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE, RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8));
&gt; +		dc-&gt;fsc = 0ULL; /* RISCV_IOMMU_DC_FSC_MODE_BARE */ ;
&gt; +		dc-&gt;iohgatp = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt;   	} else {
&gt; -		dc-&gt;ta = cpu_to_le64(val);
&gt; -		dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +		/* S-Stage translation table. G-Stage remains unmodified. */
&gt; +		if (ep-&gt;pasid_enabled) {
&gt; +			val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt; +			ep-&gt;pc[0].ta = cpu_to_le64(val | RISCV_IOMMU_PC_TA_V);
&gt; +			ep-&gt;pc[0].fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +			dc-&gt;ta = 0;
&gt; +			val = FIELD_PREP(RISCV_IOMMU_DC_FSC_MODE,
&gt; +					  RISCV_IOMMU_DC_FSC_PDTP_MODE_PD8);
&gt; +			dc-&gt;fsc = cpu_to_le64(val | virt_to_pfn(ep-&gt;pc));
&gt; +		} else {
&gt; +			val = FIELD_PREP(RISCV_IOMMU_DC_TA_PSCID, domain-&gt;pscid);
&gt; +			dc-&gt;ta = cpu_to_le64(val);
&gt; +			dc-&gt;fsc = cpu_to_le64(riscv_iommu_domain_atp(domain));
&gt; +		}
&gt;   	}
&gt;   
&gt;   	wmb();
&gt; @@ -1599,6 +1625,9 @@ static int riscv_iommu_set_dev_pasid(struct iommu_domain *iommu_domain,
&gt;   	if (!iommu_domain || !iommu_domain-&gt;mm)
&gt;   		return -EINVAL;
&gt;   
&gt; +	if (domain-&gt;g_stage)
&gt; +		return -EINVAL;
&gt; +
&gt;   	/* Driver uses TC.DPE mode, PASID #0 is incorrect. */
&gt;   	if (pasid == 0)
&gt;   		return -EINVAL;
&gt; @@ -1969,6 +1998,7 @@ static const struct iommu_domain_ops riscv_iommu_domain_ops = {
&gt;   	.iotlb_sync = riscv_iommu_iotlb_sync,
&gt;   	.iotlb_sync_map = riscv_iommu_iotlb_sync_map,
&gt;   	.flush_iotlb_all = riscv_iommu_flush_iotlb_all,
&gt; +	.enable_nesting = riscv_iommu_enable_nesting,
&gt;   };
&gt;   
&gt;   static const struct iommu_ops riscv_iommu_ops = {
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 55418a1144fb..55e5aafea5bc 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -102,8 +102,9 @@ struct riscv_iommu_domain {
&gt;   	struct riscv_iommu_device *iommu;
&gt;   
&gt;   	unsigned mode;		/* RIO_ATP_MODE_* enum */
&gt; -	unsigned pscid;		/* RISC-V IOMMU PSCID */
&gt; +	unsigned pscid;		/* RISC-V IOMMU PSCID / GSCID */
&gt;   	ioasid_t pasid;		/* IOMMU_DOMAIN_SVA: Cached PASID */
&gt; +	bool g_stage;		/* 2nd stage translation domain */
&gt;   
&gt;   	pgd_t *pgd_root;	/* page table root pointer */
&gt;   };
</span>
<a href=#m0c898cce80d8dc67ea1c5e12243227adb68db208 id=e0c898cce80d8dc67ea1c5e12243227adb68db208>^</a> <a href=https://lore.kernel.org/lkml/a0061d0c-2a74-9f32-e6ab-d3d9d06d9fd4@arm.com/>permalink</a> <a href=https://lore.kernel.org/lkml/a0061d0c-2a74-9f32-e6ab-d3d9d06d9fd4@arm.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/a0061d0c-2a74-9f32-e6ab-d3d9d06d9fd4@arm.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/a0061d0c-2a74-9f32-e6ab-d3d9d06d9fd4@arm.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/a0061d0c-2a74-9f32-e6ab-d3d9d06d9fd4@arm.com/t/#u>nested</a>] <a href=#r0c898cce80d8dc67ea1c5e12243227adb68db208>86+ messages in thread</a></pre><hr><pre><a href=#ef231abf8c9cfd6ea2015f815834751c8c88eb136 id=mf231abf8c9cfd6ea2015f815834751c8c88eb136>*</a> <b>Re: [PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</b>
  2023-07-19 19:33 ` <a href=#m2774c76ea4a5513d985e6c918e66c1e3730ad342>[PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</a> Tomasz Jeznach
  2023-07-31  8:02   ` <a href=#m50f9bd691aa7ab3a5a8b02029fa5678c52ad628d>Zong Li</a>
<b>@ 2023-08-16 21:43   ` Robin Murphy</b>
  <a href=#rf231abf8c9cfd6ea2015f815834751c8c88eb136>1 sibling, 0 replies; 86+ messages in thread</a>
From: Robin Murphy @ 2023-08-16 21:43 UTC (<a href=https://lore.kernel.org/lkml/0b2b9365-5e8c-35a0-38ac-ffcbdfdb9886@arm.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/0b2b9365-5e8c-35a0-38ac-ffcbdfdb9886@arm.com/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Paul Walmsley
  Cc: Palmer Dabbelt, Albert Ou, Anup Patel, Sunil V L, Nick Kossifidis,
	Sebastien Boeuf, iommu, <a href="https://lore.kernel.org/linux-riscv/?t=20230816214419">linux-riscv</a>, <a href="https://lore.kernel.org/lkml/?t=20230816214419">linux-kernel</a>, linux

On 2023-07-19 20:33, Tomasz Jeznach wrote:
<span class=q>&gt; This change provides basic identity mapping support to
&gt; excercise MSI_FLAT hardware capability.
&gt; 
&gt; Signed-off-by: Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt;
&gt; ---
&gt;   drivers/iommu/riscv/iommu.c | 81 +++++++++++++++++++++++++++++++++++++
&gt;   drivers/iommu/riscv/iommu.h |  3 ++
&gt;   2 files changed, 84 insertions(+)
&gt; 
&gt; diff --git a/drivers/iommu/riscv/iommu.c b/drivers/iommu/riscv/iommu.c
&gt; index 6042c35be3ca..7b3e3e135cf6 100644
&gt; --- a/drivers/iommu/riscv/iommu.c
&gt; +++ b/drivers/iommu/riscv/iommu.c
&gt; @@ -61,6 +61,9 @@ MODULE_PARM_DESC(priq_length, "Page request interface queue length.");
&gt;   #define RISCV_IOMMU_MAX_PSCID	(1U &lt;&lt; 20)
&gt;   static DEFINE_IDA(riscv_iommu_pscids);
&gt;   
&gt; +/* TODO: Enable MSI remapping */
&gt; +#define RISCV_IMSIC_BASE	0x28000000
&gt; +
&gt;   /* 1 second */
&gt;   #define RISCV_IOMMU_TIMEOUT	riscv_timebase
&gt;   
&gt; @@ -932,6 +935,72 @@ static irqreturn_t riscv_iommu_priq_process(int irq, void *data)
&gt;    * Endpoint management
&gt;    */
&gt;   
&gt; +static int riscv_iommu_enable_ir(struct riscv_iommu_endpoint *ep)
&gt; +{
&gt; +	struct riscv_iommu_device *iommu = ep-&gt;iommu;
&gt; +	struct iommu_resv_region *entry;
&gt; +	struct irq_domain *msi_domain;
&gt; +	u64 val;
&gt; +	int i;
&gt; +
&gt; +	/* Initialize MSI remapping */
&gt; +	if (!ep-&gt;dc || !(iommu-&gt;cap &amp; RISCV_IOMMU_CAP_MSI_FLAT))
&gt; +		return 0;
&gt; +
&gt; +	ep-&gt;msi_root = (struct riscv_iommu_msi_pte *)get_zeroed_page(GFP_KERNEL);
&gt; +	if (!ep-&gt;msi_root)
&gt; +		return -ENOMEM;
&gt; +
&gt; +	for (i = 0; i &lt; 256; i++) {
&gt; +		ep-&gt;msi_root[i].pte = RISCV_IOMMU_MSI_PTE_V |
&gt; +		    FIELD_PREP(RISCV_IOMMU_MSI_PTE_M, 3) |
&gt; +		    phys_to_ppn(RISCV_IMSIC_BASE + i * PAGE_SIZE);
&gt; +	}
&gt; +
&gt; +	entry = iommu_alloc_resv_region(RISCV_IMSIC_BASE, PAGE_SIZE * 256, 0,
&gt; +					IOMMU_RESV_SW_MSI, GFP_KERNEL);
&gt; +	if (entry)
&gt; +		list_add_tail(&amp;entry-&gt;list, &amp;ep-&gt;regions);
&gt; +
&gt; +	val = virt_to_pfn(ep-&gt;msi_root) |
&gt; +	    FIELD_PREP(RISCV_IOMMU_DC_MSIPTP_MODE, RISCV_IOMMU_DC_MSIPTP_MODE_FLAT);
&gt; +	ep-&gt;dc-&gt;msiptp = cpu_to_le64(val);
&gt; +
&gt; +	/* Single page of MSIPTP, 256 IMSIC files */
&gt; +	ep-&gt;dc-&gt;msi_addr_mask = cpu_to_le64(255);
&gt; +	ep-&gt;dc-&gt;msi_addr_pattern = cpu_to_le64(RISCV_IMSIC_BASE &gt;&gt; 12);
&gt; +	wmb();
&gt; +
&gt; +	/* set msi domain for the device as isolated. hack. */
</span>
Hack because this should be implemented as a proper hierarchical MSI 
domain, or hack because it doesn't actually represent isolation? Nothing 
really jumps out at me from the IOMMU and IMSIC specs, so I'm leaning 
towards the hunch that there's no real isolation, it's more just 
implicit in the assumption that each distinct VM/process with devices 
assigned should get its own interrupt file. I can't easily see how that 
would be achieved for things like VFIO :/

Thanks,
Robin.

<span class=q>&gt; +	msi_domain = dev_get_msi_domain(ep-&gt;dev);
&gt; +	if (msi_domain) {
&gt; +		msi_domain-&gt;flags |= IRQ_DOMAIN_FLAG_ISOLATED_MSI;
&gt; +	}
&gt; +
&gt; +	dev_dbg(ep-&gt;dev, "RV-IR enabled\n");
&gt; +
&gt; +	ep-&gt;ir_enabled = true;
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static void riscv_iommu_disable_ir(struct riscv_iommu_endpoint *ep)
&gt; +{
&gt; +	if (!ep-&gt;ir_enabled)
&gt; +		return;
&gt; +
&gt; +	ep-&gt;dc-&gt;msi_addr_pattern = 0ULL;
&gt; +	ep-&gt;dc-&gt;msi_addr_mask = 0ULL;
&gt; +	ep-&gt;dc-&gt;msiptp = 0ULL;
&gt; +	wmb();
&gt; +
&gt; +	dev_dbg(ep-&gt;dev, "RV-IR disabled\n");
&gt; +
&gt; +	free_pages((unsigned long)ep-&gt;msi_root, 0);
&gt; +	ep-&gt;msi_root = NULL;
&gt; +	ep-&gt;ir_enabled = false;
&gt; +}
&gt; +
&gt;   /* Endpoint features/capabilities */
&gt;   static void riscv_iommu_disable_ep(struct riscv_iommu_endpoint *ep)
&gt;   {
&gt; @@ -1226,6 +1295,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;   
&gt;   	mutex_init(&amp;ep-&gt;lock);
&gt;   	INIT_LIST_HEAD(&amp;ep-&gt;domain);
&gt; +	INIT_LIST_HEAD(&amp;ep-&gt;regions);
&gt;   
&gt;   	if (dev_is_pci(dev)) {
&gt;   		ep-&gt;devid = pci_dev_id(to_pci_dev(dev));
&gt; @@ -1248,6 +1318,7 @@ static struct iommu_device *riscv_iommu_probe_device(struct device *dev)
&gt;   	dev_iommu_priv_set(dev, ep);
&gt;   	riscv_iommu_add_device(iommu, dev);
&gt;   	riscv_iommu_enable_ep(ep);
&gt; +	riscv_iommu_enable_ir(ep);
&gt;   
&gt;   	return &amp;iommu-&gt;iommu;
&gt;   }
&gt; @@ -1279,6 +1350,7 @@ static void riscv_iommu_release_device(struct device *dev)
&gt;   		riscv_iommu_iodir_inv_devid(iommu, ep-&gt;devid);
&gt;   	}
&gt;   
&gt; +	riscv_iommu_disable_ir(ep);
&gt;   	riscv_iommu_disable_ep(ep);
&gt;   
&gt;   	/* Remove endpoint from IOMMU tracking structures */
&gt; @@ -1301,6 +1373,15 @@ static struct iommu_group *riscv_iommu_device_group(struct device *dev)
&gt;   
&gt;   static void riscv_iommu_get_resv_regions(struct device *dev, struct list_head *head)
&gt;   {
&gt; +	struct iommu_resv_region *entry, *new_entry;
&gt; +	struct riscv_iommu_endpoint *ep = dev_iommu_priv_get(dev);
&gt; +
&gt; +	list_for_each_entry(entry, &amp;ep-&gt;regions, list) {
&gt; +		new_entry = kmemdup(entry, sizeof(*entry), GFP_KERNEL);
&gt; +		if (new_entry)
&gt; +			list_add_tail(&amp;new_entry-&gt;list, head);
&gt; +	}
&gt; +
&gt;   	iommu_dma_get_resv_regions(dev, head);
&gt;   }
&gt;   
&gt; diff --git a/drivers/iommu/riscv/iommu.h b/drivers/iommu/riscv/iommu.h
&gt; index 83e8d00fd0f8..55418a1144fb 100644
&gt; --- a/drivers/iommu/riscv/iommu.h
&gt; +++ b/drivers/iommu/riscv/iommu.h
&gt; @@ -117,14 +117,17 @@ struct riscv_iommu_endpoint {
&gt;   	struct riscv_iommu_dc *dc;		/* device context pointer */
&gt;   	struct riscv_iommu_pc *pc;		/* process context root, valid if pasid_enabled is true */
&gt;   	struct riscv_iommu_device *iommu;	/* parent iommu device */
&gt; +	struct riscv_iommu_msi_pte *msi_root;	/* interrupt re-mapping */
&gt;   
&gt;   	struct mutex lock;
&gt;   	struct list_head domain;		/* endpoint attached managed domain */
&gt; +	struct list_head regions;		/* reserved regions, interrupt remapping window */
&gt;   
&gt;   	/* end point info bits */
&gt;   	unsigned pasid_bits;
&gt;   	unsigned pasid_feat;
&gt;   	bool pasid_enabled;
&gt; +	bool ir_enabled;
&gt;   };
&gt;   
&gt;   /* Helper functions and macros */
</span>
<a href=#mf231abf8c9cfd6ea2015f815834751c8c88eb136 id=ef231abf8c9cfd6ea2015f815834751c8c88eb136>^</a> <a href=https://lore.kernel.org/lkml/0b2b9365-5e8c-35a0-38ac-ffcbdfdb9886@arm.com/>permalink</a> <a href=https://lore.kernel.org/lkml/0b2b9365-5e8c-35a0-38ac-ffcbdfdb9886@arm.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/0b2b9365-5e8c-35a0-38ac-ffcbdfdb9886@arm.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/0b2b9365-5e8c-35a0-38ac-ffcbdfdb9886@arm.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/0b2b9365-5e8c-35a0-38ac-ffcbdfdb9886@arm.com/t/#u>nested</a>] <a href=#rf231abf8c9cfd6ea2015f815834751c8c88eb136>86+ messages in thread</a></pre><hr><pre><a href=#ee3f7b4a95b62a7f2374b64d11a97ef6c85c440e2 id=me3f7b4a95b62a7f2374b64d11a97ef6c85c440e2>*</a> <b>Re: [PATCH 00/13] Linux RISC-V IOMMU Support</b>
       [not found] ` &lt;<a href=#rfb5bfe039af10b3f60b7ff1b25962fb6b95beec7>CAHCEehJKYu3-GSX2L6L4_VVvYt1MagRgPJvYTbqekrjPw3ZSkA@mail.gmail.com</a>&gt;
<b>@ 2024-02-23 14:04   ` Zong Li</b>
  2024-04-04 17:37     ` <a href=#m2b6c38274c3bdc56a37ffb82f14d3be2e57796b1>Tomasz Jeznach</a>
  <a href=#re3f7b4a95b62a7f2374b64d11a97ef6c85c440e2>0 siblings, 1 reply; 86+ messages in thread</a>
From: Zong Li @ 2024-02-23 14:04 UTC (<a href=https://lore.kernel.org/lkml/CANXhq0qsZS7sB-npPKdnFaWi2+yUc_dROCsVXZDHo07-a34wcw@mail.gmail.com/>permalink</a> / <a href=https://lore.kernel.org/lkml/CANXhq0qsZS7sB-npPKdnFaWi2+yUc_dROCsVXZDHo07-a34wcw@mail.gmail.com/raw>raw</a>)
  To: Tomasz Jeznach
  Cc: Paul Walmsley, Palmer Dabbelt, Robin Murphy, Will Deacon,
	Joerg Roedel, Anup Patel, Albert Ou, Greentime Hu, linux,
	<a href="https://lore.kernel.org/lkml/?t=20240223140425">linux-kernel@vger.kernel.org List</a>, Sebastien Boeuf, iommu,
	Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20240223140425">linux-riscv</a>

<span class=q>&gt;
&gt; The RISC-V IOMMU specification is now ratified as-per the RISC-V international
&gt; process [1]. The latest frozen specifcation can be found at:
&gt; <a href=https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf>https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf</a>
&gt;
&gt; At a high-level, the RISC-V IOMMU specification defines:
&gt; 1) Memory-mapped programming interface
&gt;    - Mandatory and optional registers layout and description.
&gt;    - Software guidelines for device initialization and capabilities discovery.
&gt; 2) In-memory queue interface
&gt;    - A command-queue used by software to queue commands to the IOMMU.
&gt;    - A fault/event queue used to bring faults and events to software’s attention.
&gt;    - A page-request queue used to report “Page Request” messages received from
&gt;      PCIe devices.
&gt;    - Message-signalled and wire-signaled interrupt mechanism.
&gt; 3) In-memory data structures
&gt;    - Device-context: used to associate a device with an address space and to hold
&gt;      other per-device parameters used by the IOMMU to perform address translations.
&gt;    - Process-contexts: used to associate a different virtual address space based on
&gt;      device provided process identification number.
&gt;    - MSI page table configuration used to direct an MSI to a guest interrupt file
&gt;      in an IMSIC. The MSI page table formats are defined by the Advanced Interrupt
&gt;      Architecture specification [2].
&gt;
&gt; This series introduces complete single-level translation support, including shared
&gt; virtual address (SVA), ATS/PRI interfaces in the kernel driver. Patches adding MSI
&gt; identity remapping and G-Stage translation (GPA to SPA) are added only to excercise
&gt; hardware interfaces, to be complemented with AIA/KVM bindings in follow-up series.
&gt;
&gt; This series is a logical regrouping of series of incremental patches based on
&gt; RISC-V International IOMMU Task Group discussions and specification development
&gt; process. Original series can be found at the maintainer's repository branch [3].
&gt;
&gt; These patches can also be found in the riscv_iommu_v1 branch at:
&gt; <a href=https://github.com/tjeznach/linux/tree/riscv_iommu_v1>https://github.com/tjeznach/linux/tree/riscv_iommu_v1</a>
&gt;
&gt; To test this series, use QEMU/OpenSBI with RISC-V IOMMU implementation available in
&gt; the riscv_iommu_v1 branch at:
&gt; <a href=https://github.com/tjeznach/qemu/tree/riscv_iommu_v1>https://github.com/tjeznach/qemu/tree/riscv_iommu_v1</a>
&gt;
&gt; References:
&gt; [1] - <a href=https://wiki.riscv.org/display/HOME/Specification+Status>https://wiki.riscv.org/display/HOME/Specification+Status</a>
&gt; [2] - <a href=https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf>https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf</a>
&gt; [3] - <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719</a>
&gt;
&gt;
&gt; Anup Patel (1):
&gt;   dt-bindings: Add RISC-V IOMMU bindings
&gt;
&gt; Tomasz Jeznach (10):
&gt;   RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.
&gt;   RISC-V: arch/riscv/config: enable RISC-V IOMMU support
&gt;   MAINTAINERS: Add myself for RISC-V IOMMU driver
&gt;   RISC-V: drivers/iommu/riscv: Add sysfs interface
&gt;   RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues
&gt;   RISC-V: drivers/iommu/riscv: Add device context support
&gt;   RISC-V: drivers/iommu/riscv: Add page table support
&gt;   RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support.
&gt;   RISC-V: drivers/iommu/riscv: Add MSI identity remapping
&gt;   RISC-V: drivers/iommu/riscv: Add G-Stage translation support
&gt;
&gt;  .../bindings/iommu/riscv,iommu.yaml           |  146 ++
&gt;  MAINTAINERS                                   |    7 +
&gt;  arch/riscv/configs/defconfig                  |    1 +
&gt;  drivers/iommu/Kconfig                         |    1 +
&gt;  drivers/iommu/Makefile                        |    2 +-
&gt;  drivers/iommu/io-pgtable.c                    |    3 +
&gt;  drivers/iommu/riscv/Kconfig                   |   22 +
&gt;  drivers/iommu/riscv/Makefile                  |    1 +
&gt;  drivers/iommu/riscv/io_pgtable.c              |  266 ++
&gt;  drivers/iommu/riscv/iommu-bits.h              |  704 ++++++
&gt;  drivers/iommu/riscv/iommu-pci.c               |  206 ++
&gt;  drivers/iommu/riscv/iommu-platform.c          |  160 ++
&gt;  drivers/iommu/riscv/iommu-sysfs.c             |  183 ++
&gt;  drivers/iommu/riscv/iommu.c                   | 2130 +++++++++++++++++
&gt;  drivers/iommu/riscv/iommu.h                   |  165 ++
&gt;  include/linux/io-pgtable.h                    |    2 +
&gt;  16 files changed, 3998 insertions(+), 1 deletion(-)
&gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt;  create mode 100644 drivers/iommu/riscv/Kconfig
&gt;  create mode 100644 drivers/iommu/riscv/Makefile
&gt;  create mode 100644 drivers/iommu/riscv/io_pgtable.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu-bits.h
&gt;  create mode 100644 drivers/iommu/riscv/iommu-pci.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu-platform.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu-sysfs.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu.c
&gt;  create mode 100644 drivers/iommu/riscv/iommu.h
&gt;
&gt; --
&gt; 2.34.1
&gt;
&gt;
&gt; _______________________________________________
&gt; linux-riscv mailing list
&gt; linux-riscv@lists.infradead.org
&gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
</span>
Hi Tomasz,
Could I know if you have a plan for the next version and if you have
any estimates for when the v2 patch will be ready? We have some
patches based on top of your old implementation, and it would be great
if we can rebase them onto your next version. Thanks.

<a href=#me3f7b4a95b62a7f2374b64d11a97ef6c85c440e2 id=ee3f7b4a95b62a7f2374b64d11a97ef6c85c440e2>^</a> <a href=https://lore.kernel.org/lkml/CANXhq0qsZS7sB-npPKdnFaWi2+yUc_dROCsVXZDHo07-a34wcw@mail.gmail.com/>permalink</a> <a href=https://lore.kernel.org/lkml/CANXhq0qsZS7sB-npPKdnFaWi2+yUc_dROCsVXZDHo07-a34wcw@mail.gmail.com/raw>raw</a> <a href=https://lore.kernel.org/lkml/CANXhq0qsZS7sB-npPKdnFaWi2+yUc_dROCsVXZDHo07-a34wcw@mail.gmail.com/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/CANXhq0qsZS7sB-npPKdnFaWi2+yUc_dROCsVXZDHo07-a34wcw@mail.gmail.com/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/CANXhq0qsZS7sB-npPKdnFaWi2+yUc_dROCsVXZDHo07-a34wcw@mail.gmail.com/t/#u>nested</a>] <a href=#re3f7b4a95b62a7f2374b64d11a97ef6c85c440e2>86+ messages in thread</a></pre><hr><pre><a href=#e2b6c38274c3bdc56a37ffb82f14d3be2e57796b1 id=m2b6c38274c3bdc56a37ffb82f14d3be2e57796b1>*</a> <b>Re: [PATCH 00/13] Linux RISC-V IOMMU Support</b>
  2024-02-23 14:04   ` <a href=#me3f7b4a95b62a7f2374b64d11a97ef6c85c440e2>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Zong Li
<b>@ 2024-04-04 17:37     ` Tomasz Jeznach</b>
  2024-04-10  5:38       ` <a href=#mee8a4c5ea050653c3313a4fb05abcd396b1071ce>Zong Li</a>
  <a href=#r2b6c38274c3bdc56a37ffb82f14d3be2e57796b1>0 siblings, 1 reply; 86+ messages in thread</a>
From: Tomasz Jeznach @ 2024-04-04 17:37 UTC (<a href="https://lore.kernel.org/lkml/CAH2o1u6seMkt5stxkpr4JCdmU3ZXDid5gDL7+9abNg=zPqdFdQ@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CAH2o1u6seMkt5stxkpr4JCdmU3ZXDid5gDL7+9abNg=zPqdFdQ@mail.gmail.com/raw">raw</a>)
  To: Zong Li
  Cc: Paul Walmsley, Palmer Dabbelt, Robin Murphy, Will Deacon,
	Joerg Roedel, Anup Patel, Albert Ou, Greentime Hu, linux,
	<a href="https://lore.kernel.org/lkml/?t=20240404173716">linux-kernel@vger.kernel.org List</a>, Sebastien Boeuf, iommu,
	Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20240404173716">linux-riscv</a>

On Fri, Feb 23, 2024 at 6:04 AM Zong Li &lt;zong.li@sifive.com&gt; wrote:
<span class=q>&gt;
&gt; &gt;
&gt; &gt; The RISC-V IOMMU specification is now ratified as-per the RISC-V international
&gt; &gt; process [1]. The latest frozen specifcation can be found at:
&gt; &gt; <a href=https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf>https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf</a>
&gt; &gt;
&gt; &gt; At a high-level, the RISC-V IOMMU specification defines:
&gt; &gt; 1) Memory-mapped programming interface
&gt; &gt;    - Mandatory and optional registers layout and description.
&gt; &gt;    - Software guidelines for device initialization and capabilities discovery.
&gt; &gt; 2) In-memory queue interface
&gt; &gt;    - A command-queue used by software to queue commands to the IOMMU.
&gt; &gt;    - A fault/event queue used to bring faults and events to software’s attention.
&gt; &gt;    - A page-request queue used to report “Page Request” messages received from
&gt; &gt;      PCIe devices.
&gt; &gt;    - Message-signalled and wire-signaled interrupt mechanism.
&gt; &gt; 3) In-memory data structures
&gt; &gt;    - Device-context: used to associate a device with an address space and to hold
&gt; &gt;      other per-device parameters used by the IOMMU to perform address translations.
&gt; &gt;    - Process-contexts: used to associate a different virtual address space based on
&gt; &gt;      device provided process identification number.
&gt; &gt;    - MSI page table configuration used to direct an MSI to a guest interrupt file
&gt; &gt;      in an IMSIC. The MSI page table formats are defined by the Advanced Interrupt
&gt; &gt;      Architecture specification [2].
&gt; &gt;
&gt; &gt; This series introduces complete single-level translation support, including shared
&gt; &gt; virtual address (SVA), ATS/PRI interfaces in the kernel driver. Patches adding MSI
&gt; &gt; identity remapping and G-Stage translation (GPA to SPA) are added only to excercise
&gt; &gt; hardware interfaces, to be complemented with AIA/KVM bindings in follow-up series.
&gt; &gt;
&gt; &gt; This series is a logical regrouping of series of incremental patches based on
&gt; &gt; RISC-V International IOMMU Task Group discussions and specification development
&gt; &gt; process. Original series can be found at the maintainer's repository branch [3].
&gt; &gt;
&gt; &gt; These patches can also be found in the riscv_iommu_v1 branch at:
&gt; &gt; <a href=https://github.com/tjeznach/linux/tree/riscv_iommu_v1>https://github.com/tjeznach/linux/tree/riscv_iommu_v1</a>
&gt; &gt;
&gt; &gt; To test this series, use QEMU/OpenSBI with RISC-V IOMMU implementation available in
&gt; &gt; the riscv_iommu_v1 branch at:
&gt; &gt; <a href=https://github.com/tjeznach/qemu/tree/riscv_iommu_v1>https://github.com/tjeznach/qemu/tree/riscv_iommu_v1</a>
&gt; &gt;
&gt; &gt; References:
&gt; &gt; [1] - <a href=https://wiki.riscv.org/display/HOME/Specification+Status>https://wiki.riscv.org/display/HOME/Specification+Status</a>
&gt; &gt; [2] - <a href=https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf>https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf</a>
&gt; &gt; [3] - <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719</a>
&gt; &gt;
&gt; &gt;
&gt; &gt; Anup Patel (1):
&gt; &gt;   dt-bindings: Add RISC-V IOMMU bindings
&gt; &gt;
&gt; &gt; Tomasz Jeznach (10):
&gt; &gt;   RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.
&gt; &gt;   RISC-V: arch/riscv/config: enable RISC-V IOMMU support
&gt; &gt;   MAINTAINERS: Add myself for RISC-V IOMMU driver
&gt; &gt;   RISC-V: drivers/iommu/riscv: Add sysfs interface
&gt; &gt;   RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues
&gt; &gt;   RISC-V: drivers/iommu/riscv: Add device context support
&gt; &gt;   RISC-V: drivers/iommu/riscv: Add page table support
&gt; &gt;   RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support.
&gt; &gt;   RISC-V: drivers/iommu/riscv: Add MSI identity remapping
&gt; &gt;   RISC-V: drivers/iommu/riscv: Add G-Stage translation support
&gt; &gt;
&gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           |  146 ++
&gt; &gt;  MAINTAINERS                                   |    7 +
&gt; &gt;  arch/riscv/configs/defconfig                  |    1 +
&gt; &gt;  drivers/iommu/Kconfig                         |    1 +
&gt; &gt;  drivers/iommu/Makefile                        |    2 +-
&gt; &gt;  drivers/iommu/io-pgtable.c                    |    3 +
&gt; &gt;  drivers/iommu/riscv/Kconfig                   |   22 +
&gt; &gt;  drivers/iommu/riscv/Makefile                  |    1 +
&gt; &gt;  drivers/iommu/riscv/io_pgtable.c              |  266 ++
&gt; &gt;  drivers/iommu/riscv/iommu-bits.h              |  704 ++++++
&gt; &gt;  drivers/iommu/riscv/iommu-pci.c               |  206 ++
&gt; &gt;  drivers/iommu/riscv/iommu-platform.c          |  160 ++
&gt; &gt;  drivers/iommu/riscv/iommu-sysfs.c             |  183 ++
&gt; &gt;  drivers/iommu/riscv/iommu.c                   | 2130 +++++++++++++++++
&gt; &gt;  drivers/iommu/riscv/iommu.h                   |  165 ++
&gt; &gt;  include/linux/io-pgtable.h                    |    2 +
&gt; &gt;  16 files changed, 3998 insertions(+), 1 deletion(-)
&gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt;  create mode 100644 drivers/iommu/riscv/Kconfig
&gt; &gt;  create mode 100644 drivers/iommu/riscv/Makefile
&gt; &gt;  create mode 100644 drivers/iommu/riscv/io_pgtable.c
&gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-bits.h
&gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-pci.c
&gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-platform.c
&gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-sysfs.c
&gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu.c
&gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu.h
&gt; &gt;
&gt; &gt; --
&gt; &gt; 2.34.1
&gt; &gt;
&gt; &gt;
&gt; &gt; _______________________________________________
&gt; &gt; linux-riscv mailing list
&gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
&gt;
&gt; Hi Tomasz,
&gt; Could I know if you have a plan for the next version and if you have
&gt; any estimates for when the v2 patch will be ready? We have some
&gt; patches based on top of your old implementation, and it would be great
&gt; if we can rebase them onto your next version. Thanks.
</span>
Hi Zong,

Thank you for your interest. Next version of the iommu/riscv is almost ready to
be sent in next few days.
There is a number of bug fixes and design changes based on the testing and
great feedback after v1 was published.
Upcoming patch set will be smaller, with core functionality only, hopefully to
make the review easier. Functionality related to the MSI remapping, shared
virtual addressing, nested translations will be moved to separate patch sets.

Complete, up to date revision is always available at
<a href=https://github.com/tjeznach/linux/>https://github.com/tjeznach/linux/</a>

regards,
- Tomasz

<a href=#m2b6c38274c3bdc56a37ffb82f14d3be2e57796b1 id=e2b6c38274c3bdc56a37ffb82f14d3be2e57796b1>^</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6seMkt5stxkpr4JCdmU3ZXDid5gDL7+9abNg=zPqdFdQ@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6seMkt5stxkpr4JCdmU3ZXDid5gDL7+9abNg=zPqdFdQ@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CAH2o1u6seMkt5stxkpr4JCdmU3ZXDid5gDL7+9abNg=zPqdFdQ@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CAH2o1u6seMkt5stxkpr4JCdmU3ZXDid5gDL7+9abNg=zPqdFdQ@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CAH2o1u6seMkt5stxkpr4JCdmU3ZXDid5gDL7+9abNg=zPqdFdQ@mail.gmail.com/t/#u">nested</a>] <a href=#r2b6c38274c3bdc56a37ffb82f14d3be2e57796b1>86+ messages in thread</a></pre><hr><pre><a href=#eee8a4c5ea050653c3313a4fb05abcd396b1071ce id=mee8a4c5ea050653c3313a4fb05abcd396b1071ce>*</a> <b>Re: [PATCH 00/13] Linux RISC-V IOMMU Support</b>
  2024-04-04 17:37     ` <a href=#m2b6c38274c3bdc56a37ffb82f14d3be2e57796b1>Tomasz Jeznach</a>
<b>@ 2024-04-10  5:38       ` Zong Li</b>
  <a href=#ree8a4c5ea050653c3313a4fb05abcd396b1071ce>0 siblings, 0 replies; 86+ messages in thread</a>
From: Zong Li @ 2024-04-10  5:38 UTC (<a href="https://lore.kernel.org/lkml/CANXhq0q0UakMSBQ=j0K21TpC-Hq8eX4BrFQ0K6XzQ=h1Pr_buA@mail.gmail.com/">permalink</a> / <a href="https://lore.kernel.org/lkml/CANXhq0q0UakMSBQ=j0K21TpC-Hq8eX4BrFQ0K6XzQ=h1Pr_buA@mail.gmail.com/raw">raw</a>)
  To: Tomasz Jeznach
  Cc: Paul Walmsley, Palmer Dabbelt, Robin Murphy, Will Deacon,
	Joerg Roedel, Anup Patel, Albert Ou, Greentime Hu, linux,
	<a href="https://lore.kernel.org/lkml/?t=20240410053829">linux-kernel@vger.kernel.org List</a>, Sebastien Boeuf, iommu,
	Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20240410053829">linux-riscv</a>

On Fri, Apr 5, 2024 at 1:37 AM Tomasz Jeznach &lt;tjeznach@rivosinc.com&gt; wrote:
<span class=q>&gt;
&gt; On Fri, Feb 23, 2024 at 6:04 AM Zong Li &lt;zong.li@sifive.com&gt; wrote:
&gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; The RISC-V IOMMU specification is now ratified as-per the RISC-V international
&gt; &gt; &gt; process [1]. The latest frozen specifcation can be found at:
&gt; &gt; &gt; <a href=https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf>https://github.com/riscv-non-isa/riscv-iommu/releases/download/v1.0/riscv-iommu.pdf</a>
&gt; &gt; &gt;
&gt; &gt; &gt; At a high-level, the RISC-V IOMMU specification defines:
&gt; &gt; &gt; 1) Memory-mapped programming interface
&gt; &gt; &gt;    - Mandatory and optional registers layout and description.
&gt; &gt; &gt;    - Software guidelines for device initialization and capabilities discovery.
&gt; &gt; &gt; 2) In-memory queue interface
&gt; &gt; &gt;    - A command-queue used by software to queue commands to the IOMMU.
&gt; &gt; &gt;    - A fault/event queue used to bring faults and events to software’s attention.
&gt; &gt; &gt;    - A page-request queue used to report “Page Request” messages received from
&gt; &gt; &gt;      PCIe devices.
&gt; &gt; &gt;    - Message-signalled and wire-signaled interrupt mechanism.
&gt; &gt; &gt; 3) In-memory data structures
&gt; &gt; &gt;    - Device-context: used to associate a device with an address space and to hold
&gt; &gt; &gt;      other per-device parameters used by the IOMMU to perform address translations.
&gt; &gt; &gt;    - Process-contexts: used to associate a different virtual address space based on
&gt; &gt; &gt;      device provided process identification number.
&gt; &gt; &gt;    - MSI page table configuration used to direct an MSI to a guest interrupt file
&gt; &gt; &gt;      in an IMSIC. The MSI page table formats are defined by the Advanced Interrupt
&gt; &gt; &gt;      Architecture specification [2].
&gt; &gt; &gt;
&gt; &gt; &gt; This series introduces complete single-level translation support, including shared
&gt; &gt; &gt; virtual address (SVA), ATS/PRI interfaces in the kernel driver. Patches adding MSI
&gt; &gt; &gt; identity remapping and G-Stage translation (GPA to SPA) are added only to excercise
&gt; &gt; &gt; hardware interfaces, to be complemented with AIA/KVM bindings in follow-up series.
&gt; &gt; &gt;
&gt; &gt; &gt; This series is a logical regrouping of series of incremental patches based on
&gt; &gt; &gt; RISC-V International IOMMU Task Group discussions and specification development
&gt; &gt; &gt; process. Original series can be found at the maintainer's repository branch [3].
&gt; &gt; &gt;
&gt; &gt; &gt; These patches can also be found in the riscv_iommu_v1 branch at:
&gt; &gt; &gt; <a href=https://github.com/tjeznach/linux/tree/riscv_iommu_v1>https://github.com/tjeznach/linux/tree/riscv_iommu_v1</a>
&gt; &gt; &gt;
&gt; &gt; &gt; To test this series, use QEMU/OpenSBI with RISC-V IOMMU implementation available in
&gt; &gt; &gt; the riscv_iommu_v1 branch at:
&gt; &gt; &gt; <a href=https://github.com/tjeznach/qemu/tree/riscv_iommu_v1>https://github.com/tjeznach/qemu/tree/riscv_iommu_v1</a>
&gt; &gt; &gt;
&gt; &gt; &gt; References:
&gt; &gt; &gt; [1] - <a href=https://wiki.riscv.org/display/HOME/Specification+Status>https://wiki.riscv.org/display/HOME/Specification+Status</a>
&gt; &gt; &gt; [2] - <a href=https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf>https://github.com/riscv/riscv-aia/releases/download/1.0/riscv-interrupts-1.0.pdf</a>
&gt; &gt; &gt; [3] - <a href=https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719>https://github.com/tjeznach/qemu/tree/tjeznach/riscv-iommu-20230719</a>
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; Anup Patel (1):
&gt; &gt; &gt;   dt-bindings: Add RISC-V IOMMU bindings
&gt; &gt; &gt;
&gt; &gt; &gt; Tomasz Jeznach (10):
&gt; &gt; &gt;   RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.
&gt; &gt; &gt;   RISC-V: arch/riscv/config: enable RISC-V IOMMU support
&gt; &gt; &gt;   MAINTAINERS: Add myself for RISC-V IOMMU driver
&gt; &gt; &gt;   RISC-V: drivers/iommu/riscv: Add sysfs interface
&gt; &gt; &gt;   RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues
&gt; &gt; &gt;   RISC-V: drivers/iommu/riscv: Add device context support
&gt; &gt; &gt;   RISC-V: drivers/iommu/riscv: Add page table support
&gt; &gt; &gt;   RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support.
&gt; &gt; &gt;   RISC-V: drivers/iommu/riscv: Add MSI identity remapping
&gt; &gt; &gt;   RISC-V: drivers/iommu/riscv: Add G-Stage translation support
&gt; &gt; &gt;
&gt; &gt; &gt;  .../bindings/iommu/riscv,iommu.yaml           |  146 ++
&gt; &gt; &gt;  MAINTAINERS                                   |    7 +
&gt; &gt; &gt;  arch/riscv/configs/defconfig                  |    1 +
&gt; &gt; &gt;  drivers/iommu/Kconfig                         |    1 +
&gt; &gt; &gt;  drivers/iommu/Makefile                        |    2 +-
&gt; &gt; &gt;  drivers/iommu/io-pgtable.c                    |    3 +
&gt; &gt; &gt;  drivers/iommu/riscv/Kconfig                   |   22 +
&gt; &gt; &gt;  drivers/iommu/riscv/Makefile                  |    1 +
&gt; &gt; &gt;  drivers/iommu/riscv/io_pgtable.c              |  266 ++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu-bits.h              |  704 ++++++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu-pci.c               |  206 ++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu-platform.c          |  160 ++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu-sysfs.c             |  183 ++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu.c                   | 2130 +++++++++++++++++
&gt; &gt; &gt;  drivers/iommu/riscv/iommu.h                   |  165 ++
&gt; &gt; &gt;  include/linux/io-pgtable.h                    |    2 +
&gt; &gt; &gt;  16 files changed, 3998 insertions(+), 1 deletion(-)
&gt; &gt; &gt;  create mode 100644 Documentation/devicetree/bindings/iommu/riscv,iommu.yaml
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/Kconfig
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/Makefile
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/io_pgtable.c
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-bits.h
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-pci.c
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-platform.c
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu-sysfs.c
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu.c
&gt; &gt; &gt;  create mode 100644 drivers/iommu/riscv/iommu.h
&gt; &gt; &gt;
&gt; &gt; &gt; --
&gt; &gt; &gt; 2.34.1
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; _______________________________________________
&gt; &gt; &gt; linux-riscv mailing list
&gt; &gt; &gt; linux-riscv@lists.infradead.org
&gt; &gt; &gt; <a href=http://lists.infradead.org/mailman/listinfo/linux-riscv>http://lists.infradead.org/mailman/listinfo/linux-riscv</a>
&gt; &gt;
&gt; &gt; Hi Tomasz,
&gt; &gt; Could I know if you have a plan for the next version and if you have
&gt; &gt; any estimates for when the v2 patch will be ready? We have some
&gt; &gt; patches based on top of your old implementation, and it would be great
&gt; &gt; if we can rebase them onto your next version. Thanks.
&gt;
&gt; Hi Zong,
&gt;
&gt; Thank you for your interest. Next version of the iommu/riscv is almost ready to
&gt; be sent in next few days.
</span>
Hi Tomasz,
Thanks you for the update, I would help to review the v2 series as well.

<span class=q>&gt; There is a number of bug fixes and design changes based on the testing and
&gt; great feedback after v1 was published.
&gt; Upcoming patch set will be smaller, with core functionality only, hopefully to
&gt; make the review easier. Functionality related to the MSI remapping, shared
&gt; virtual addressing, nested translations will be moved to separate patch sets.
&gt;
&gt; Complete, up to date revision is always available at
&gt; <a href=https://github.com/tjeznach/linux/>https://github.com/tjeznach/linux/</a>
&gt;
&gt; regards,
&gt; - Tomasz
</span>
<a href=#mee8a4c5ea050653c3313a4fb05abcd396b1071ce id=eee8a4c5ea050653c3313a4fb05abcd396b1071ce>^</a> <a href="https://lore.kernel.org/lkml/CANXhq0q0UakMSBQ=j0K21TpC-Hq8eX4BrFQ0K6XzQ=h1Pr_buA@mail.gmail.com/">permalink</a> <a href="https://lore.kernel.org/lkml/CANXhq0q0UakMSBQ=j0K21TpC-Hq8eX4BrFQ0K6XzQ=h1Pr_buA@mail.gmail.com/raw">raw</a> <a href="https://lore.kernel.org/lkml/CANXhq0q0UakMSBQ=j0K21TpC-Hq8eX4BrFQ0K6XzQ=h1Pr_buA@mail.gmail.com/#R">reply</a>	[<a href="https://lore.kernel.org/lkml/CANXhq0q0UakMSBQ=j0K21TpC-Hq8eX4BrFQ0K6XzQ=h1Pr_buA@mail.gmail.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/lkml/CANXhq0q0UakMSBQ=j0K21TpC-Hq8eX4BrFQ0K6XzQ=h1Pr_buA@mail.gmail.com/t/#u">nested</a>] <a href=#ree8a4c5ea050653c3313a4fb05abcd396b1071ce>86+ messages in thread</a></pre><hr><pre><a href=#e155b6f2fffe6b140c3bb8189cb19c02033deff9d id=m155b6f2fffe6b140c3bb8189cb19c02033deff9d>*</a> <b>Re: [PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support.</b>
  2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
                     ` <a href=#re6007fa63b4fd2def06b60bba503fe5072f38376>(6 preceding siblings ...)</a>
  2023-08-16 18:05   ` <a href=#me6007fa63b4fd2def06b60bba503fe5072f38376>Robin Murphy</a>
<b>@ 2024-04-13 10:15   ` Xingyou Chen</b>
  <a href=#r155b6f2fffe6b140c3bb8189cb19c02033deff9d>7 siblings, 0 replies; 86+ messages in thread</a>
From: Xingyou Chen @ 2024-04-13 10:15 UTC (<a href=https://lore.kernel.org/lkml/2688421d-37c2-4038-8d03-24ae175f137e@rockwork.org/>permalink</a> / <a href=https://lore.kernel.org/lkml/2688421d-37c2-4038-8d03-24ae175f137e@rockwork.org/raw>raw</a>)
  To: Tomasz Jeznach, Joerg Roedel, Will Deacon, Robin Murphy,
	Paul Walmsley
  Cc: Anup Patel, Albert Ou, linux, <a href="https://lore.kernel.org/lkml/?t=20240413102211">linux-kernel</a>, Sebastien Boeuf,
	iommu, Palmer Dabbelt, Nick Kossifidis, <a href="https://lore.kernel.org/linux-riscv/?t=20240413102211">linux-riscv</a>


On 7/20/23 03:33, Tomasz Jeznach wrote:
<span class=q>&gt; ... &gt; +#endif /* _RISCV_IOMMU_BITS_H_ */
&gt; diff --git a/drivers/iommu/riscv/iommu-pci.c b/drivers/iommu/riscv/iommu-pci.c
&gt; new file mode 100644
&gt; index 000000000000..c91f963d7a29
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-pci.c
&gt; @@ -0,0 +1,134 @@
&gt; ...
&gt; +
&gt; +static struct pci_driver riscv_iommu_pci_driver = {
&gt; +	.name = KBUILD_MODNAME,
&gt; +	.id_table = riscv_iommu_pci_tbl,
&gt; +	.probe = riscv_iommu_pci_probe,
&gt; +	.remove = riscv_iommu_pci_remove,
&gt; +	.driver = {
&gt; +		   .pm = pm_sleep_ptr(&amp;riscv_iommu_pm_ops),
&gt; +		   .of_match_table = riscv_iommu_of_match,
&gt; +		   },
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_pci_driver, pci_register_driver, pci_unregister_driver);
</span>
There's helper macro to be considered, and not forced to:
   module_pci_driver(riscv_iommu_pci_driver);

<span class=q>&gt; diff --git a/drivers/iommu/riscv/iommu-platform.c b/drivers/iommu/riscv/iommu-platform.c
&gt; new file mode 100644
&gt; index 000000000000..e4e8ca6711e7
&gt; --- /dev/null
&gt; +++ b/drivers/iommu/riscv/iommu-platform.c
&gt; @@ -0,0 +1,94 @@
&gt; ...
&gt; +
&gt; +static struct platform_driver riscv_iommu_platform_driver = {
&gt; +	.driver = {
&gt; +		   .name = "riscv,iommu",
&gt; +		   .of_match_table = riscv_iommu_of_match,
&gt; +		   .suppress_bind_attrs = true,
&gt; +		   },
&gt; +	.probe = riscv_iommu_platform_probe,
&gt; +	.remove_new = riscv_iommu_platform_remove,
&gt; +	.shutdown = riscv_iommu_platform_shutdown,
&gt; +};
&gt; +
&gt; +module_driver(riscv_iommu_platform_driver, platform_driver_register,
&gt; +	      platform_driver_unregister);
</span>
And also:
   module_platform_driver(riscv_iommu_platform_driver);

<a href=#m155b6f2fffe6b140c3bb8189cb19c02033deff9d id=e155b6f2fffe6b140c3bb8189cb19c02033deff9d>^</a> <a href=https://lore.kernel.org/lkml/2688421d-37c2-4038-8d03-24ae175f137e@rockwork.org/>permalink</a> <a href=https://lore.kernel.org/lkml/2688421d-37c2-4038-8d03-24ae175f137e@rockwork.org/raw>raw</a> <a href=https://lore.kernel.org/lkml/2688421d-37c2-4038-8d03-24ae175f137e@rockwork.org/#R>reply</a>	[<a href=https://lore.kernel.org/lkml/2688421d-37c2-4038-8d03-24ae175f137e@rockwork.org/T/#u><b>flat</b></a>|<a href=https://lore.kernel.org/lkml/2688421d-37c2-4038-8d03-24ae175f137e@rockwork.org/t/#u>nested</a>] <a href=#r155b6f2fffe6b140c3bb8189cb19c02033deff9d>86+ messages in thread</a></pre><hr><pre>end of thread, other threads:[<a href="https://lore.kernel.org/lkml/?t=20240413102211">~2024-04-13 10:22 UTC</a> | <a href=https://lore.kernel.org/lkml/>newest</a>]

<b id=t>Thread overview:</b> 86+ messages (download: <a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/t.mbox.gz>mbox.gz</a> follow: <a href=https://lore.kernel.org/lkml/cover.1689792825.git.tjeznach@rivosinc.com/t.atom>Atom feed</a>
-- links below jump to the message on this page --
2023-07-19 19:33 <a href=#me750bc2afd9a61b23a45ff7a3a05bb653a4e13ed id=re750bc2afd9a61b23a45ff7a3a05bb653a4e13ed>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Tomasz Jeznach
2023-07-19 19:33 ` <a href=#mcbff9602b4590805d9db0bce8ed33655b290f552 id=rcbff9602b4590805d9db0bce8ed33655b290f552>[PATCH 01/11] RISC-V: drivers/iommu: Add RISC-V IOMMU - Ziommu support</a> Tomasz Jeznach
2023-07-19 20:49   ` <a href=#m475b3879d13e54e5f54247069b241516ceaf814e id=r475b3879d13e54e5f54247069b241516ceaf814e>Conor Dooley</a>
2023-07-19 21:43     ` <a href=#m7a575a3d69ac16e6fcb589d3f5517a473ee1e27d id=r7a575a3d69ac16e6fcb589d3f5517a473ee1e27d>Tomasz Jeznach</a>
2023-07-20 19:27       ` <a href=#m7c76b2906bb58a75b5a08e305e41c946fb24f5af id=r7c76b2906bb58a75b5a08e305e41c946fb24f5af>Conor Dooley</a>
2023-07-21  9:44       ` <a href=#m395bb5e2fc32d6655db1f3d57b32806919889e01 id=r395bb5e2fc32d6655db1f3d57b32806919889e01>Conor Dooley</a>
2023-07-20 10:38   ` <a href=#mce7ec12a032abfaca43b25278ff9762eb0fc2b37 id=rce7ec12a032abfaca43b25278ff9762eb0fc2b37>Baolu Lu</a>
2023-07-20 12:31   ` <a href=#m5c32a5e8f769114a8ba7611812fa02c944920207 id=r5c32a5e8f769114a8ba7611812fa02c944920207>Baolu Lu</a>
2023-07-20 17:30     ` <a href=#m22bfe5a5766790fcc48e9b406ffb296ff8be6413 id=r22bfe5a5766790fcc48e9b406ffb296ff8be6413>Tomasz Jeznach</a>
2023-07-28  2:42   ` <a href=#m522f968d0909aad51fe7e480809ea548917990fa id=r522f968d0909aad51fe7e480809ea548917990fa>Zong Li</a>
2023-08-02 20:15     ` <a href=#m6bea4b3cd6bb3324224d86b9abb254943fb6124a id=r6bea4b3cd6bb3324224d86b9abb254943fb6124a>Tomasz Jeznach</a>
2023-08-02 20:25       ` <a href=#m64fbb77e574cead28d126c26f5193ed27f5df4af id=r64fbb77e574cead28d126c26f5193ed27f5df4af>Conor Dooley</a>
2023-08-03  3:37       ` <a href=#m37555fe53501d9e3bd60231c586cec52ef1fe838 id=r37555fe53501d9e3bd60231c586cec52ef1fe838>Zong Li</a>
2023-08-03  0:18   ` <a href=#m428d2ed3a8314242cc2c1bb7f013dd8b6093afb2 id=r428d2ed3a8314242cc2c1bb7f013dd8b6093afb2>Jason Gunthorpe</a>
2023-08-03  8:27   ` <a href=#mad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e id=rad9d1c189bf7f0a0a37fb9de00572b6d4aaea68e>Zong Li</a>
2023-08-16 18:05   ` <a href=#me6007fa63b4fd2def06b60bba503fe5072f38376 id=re6007fa63b4fd2def06b60bba503fe5072f38376>Robin Murphy</a>
2024-04-13 10:15   ` <a href=#m155b6f2fffe6b140c3bb8189cb19c02033deff9d id=r155b6f2fffe6b140c3bb8189cb19c02033deff9d>Xingyou Chen</a>
2023-07-19 19:33 ` <a href=#m20d2511b6c12906189c92aa1f0e9ce0c668c5a83 id=r20d2511b6c12906189c92aa1f0e9ce0c668c5a83>[PATCH 02/11] RISC-V: arch/riscv/config: enable RISC-V IOMMU support</a> Tomasz Jeznach
2023-07-19 20:22   ` <a href=#m07e17b6f91977601733160534a5f82428a4a05be id=r07e17b6f91977601733160534a5f82428a4a05be>Conor Dooley</a>
2023-07-19 21:07     ` <a href=#me9f86974c28c0ca73e4be20e889e9ce55242ed8a id=re9f86974c28c0ca73e4be20e889e9ce55242ed8a>Tomasz Jeznach</a>
2023-07-20  6:37       ` <a href=#mca75c01519c7dca768f770f0a0b7b6bb9c709a39 id=rca75c01519c7dca768f770f0a0b7b6bb9c709a39>Krzysztof Kozlowski</a>
2023-07-19 19:33 ` <a href=#mbf8dc4098fb09b87b2618c5c545ae882f11b114b id=rbf8dc4098fb09b87b2618c5c545ae882f11b114b>[PATCH 03/11] dt-bindings: Add RISC-V IOMMU bindings</a> Tomasz Jeznach
2023-07-19 20:19   ` <a href=#m88a4003327a711a111ee2c4d48bf98696a66bc8b id=r88a4003327a711a111ee2c4d48bf98696a66bc8b>Conor Dooley</a>
     [not found]     ` &lt;<a href=https://lore.kernel.org/lkml/CAH2o1u6CZSb7pXcaXmh7dJQmNZYh3uORk4x7vJPrb+uCwFdU5g@mail.gmail.com/ id=red9fb23cde273365376c37e6496225c853d2784d>CAH2o1u6CZSb7pXcaXmh7dJQmNZYh3uORk4x7vJPrb+uCwFdU5g@mail.gmail.com</a>&gt;
2023-07-19 20:57       ` <a href=#mbba42ec3ff996c3818591fc58cabe98ad69cb42a id=rbba42ec3ff996c3818591fc58cabe98ad69cb42a>Conor Dooley</a>
2023-07-19 21:37     ` <a href=#md805d888f455929658b15f37f3dec4e04cbef73e id=rd805d888f455929658b15f37f3dec4e04cbef73e>Rob Herring</a>
2023-07-19 23:04       ` <a href=#md853fd009dec300692af2fb72bf786e9682c55c5 id=rd853fd009dec300692af2fb72bf786e9682c55c5>Tomasz Jeznach</a>
2023-07-24  8:03   ` <a href=#mefb742c2ddae58fd3cf54da7451501e4bd3a30a7 id=refb742c2ddae58fd3cf54da7451501e4bd3a30a7>Zong Li</a>
2023-07-24 10:02     ` <a href=#m570ddc11336ccb2371984a53d8c2206a4b125953 id=r570ddc11336ccb2371984a53d8c2206a4b125953>Anup Patel</a>
2023-07-24 11:31       ` <a href=#m2d7203bf37bc25c9576411b6e1fc88441dab6256 id=r2d7203bf37bc25c9576411b6e1fc88441dab6256>Zong Li</a>
2023-07-24 12:10         ` <a href=#m843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8 id=r843622a1f3d5c248d95ec0de9c9c5fbe1cbdebf8>Anup Patel</a>
2023-07-24 13:23           ` <a href=#m2f68d3d87e65ff461879a6fa2ab08e51464f5507 id=r2f68d3d87e65ff461879a6fa2ab08e51464f5507>Zong Li</a>
2023-07-26  3:21             ` <a href=#mc929b28389818fb366cddb7da7fa1c8aefd86240 id=rc929b28389818fb366cddb7da7fa1c8aefd86240>Baolu Lu</a>
2023-07-26  4:26               ` <a href=#m5eb9ba5978916aa33090c12ea6b51d8c00bd37a5 id=r5eb9ba5978916aa33090c12ea6b51d8c00bd37a5>Zong Li</a>
2023-07-26 12:17                 ` <a href=#ma6af771a2d7ce03a40ca3f822dc991cbf00147d3 id=ra6af771a2d7ce03a40ca3f822dc991cbf00147d3>Jason Gunthorpe</a>
2023-07-27  2:42                   ` <a href=#mb9392a38decda68a70e4996544c2137d88821f96 id=rb9392a38decda68a70e4996544c2137d88821f96>Zong Li</a>
2023-08-09 14:57                     ` <a href=#m2f7577e9b5cd357284c03e252264f511c553b0d9 id=r2f7577e9b5cd357284c03e252264f511c553b0d9>Jason Gunthorpe</a>
2023-08-15  1:28                       ` <a href=#m295d1b8b9afeed47fa52bcba25fa9afe29729895 id=r295d1b8b9afeed47fa52bcba25fa9afe29729895>Zong Li</a>
2023-08-15 18:38                         ` <a href=#m4d2a1326efac7177bddd033e12c8ef79baa87f35 id=r4d2a1326efac7177bddd033e12c8ef79baa87f35>Jason Gunthorpe</a>
2023-08-16  2:16                           ` <a href=#m49e53774d0e1d74bf3fa4ce8b156ea9b675228fe id=r49e53774d0e1d74bf3fa4ce8b156ea9b675228fe>Zong Li</a>
2023-08-16  4:10                             ` <a href=#mada297bdfcbd76ad0a00e6b14972be46cc18ce40 id=rada297bdfcbd76ad0a00e6b14972be46cc18ce40>Baolu Lu</a>
2023-07-19 19:33 ` <a href=#mc8ea74f153739ba422b2d84e3077559061512b9f id=rc8ea74f153739ba422b2d84e3077559061512b9f>[PATCH 04/11] MAINTAINERS: Add myself for RISC-V IOMMU driver</a> Tomasz Jeznach
2023-07-20 12:42   ` <a href=#mbad58991effdd4419c250623cc3d7d3d3edc6000 id=rbad58991effdd4419c250623cc3d7d3d3edc6000>Baolu Lu</a>
2023-07-20 17:32     ` <a href=#m592c653ab4affb67beeea816ec6af8c525df604f id=r592c653ab4affb67beeea816ec6af8c525df604f>Tomasz Jeznach</a>
2023-07-19 19:33 ` <a href=#m64db79f82cb551d51fc635ba160962c425c8cbb2 id=r64db79f82cb551d51fc635ba160962c425c8cbb2>[PATCH 05/11] RISC-V: drivers/iommu/riscv: Add sysfs interface</a> Tomasz Jeznach
2023-07-20  6:38   ` <a href=#m4531233107436be4728ad7c9e39b93b11e8c7e48 id=r4531233107436be4728ad7c9e39b93b11e8c7e48>Krzysztof Kozlowski</a>
2023-07-20 18:30     ` <a href=#m10ac8115fa338f5759d5ebc64181be18eecea21c id=r10ac8115fa338f5759d5ebc64181be18eecea21c>Tomasz Jeznach</a>
2023-07-20 21:37       ` <a href=#m553a62188f2eeca66633e2f6351bc323ed35dd3f id=r553a62188f2eeca66633e2f6351bc323ed35dd3f>Krzysztof Kozlowski</a>
2023-07-20 22:08         ` <a href=#m6000bce5c9a4c95efc9f2efc56d8acb45105082b id=r6000bce5c9a4c95efc9f2efc56d8acb45105082b>Conor Dooley</a>
2023-07-21  3:49           ` <a href=#m4f06e2bc03df48f15ed4a8577c6e825304ac91f1 id=r4f06e2bc03df48f15ed4a8577c6e825304ac91f1>Tomasz Jeznach</a>
2023-07-20 12:50   ` <a href=#m5f68224a21ecbc3e04df1c010fdc4945c78bf2fe id=r5f68224a21ecbc3e04df1c010fdc4945c78bf2fe>Baolu Lu</a>
2023-07-20 17:47     ` <a href=#m8378ca0f43c5f33e4a911ef72b4b758bca264722 id=r8378ca0f43c5f33e4a911ef72b4b758bca264722>Tomasz Jeznach</a>
2023-07-19 19:33 ` <a href=#mf2090d8e2af99230540f3b1dd5c9495dcc6523b1 id=rf2090d8e2af99230540f3b1dd5c9495dcc6523b1>[PATCH 06/11] RISC-V: drivers/iommu/riscv: Add command, fault, page-req queues</a> Tomasz Jeznach
2023-07-20  3:11   ` <a href=#me036e876659d5bad1074323224ed7dc70b2e49db id=re036e876659d5bad1074323224ed7dc70b2e49db>Nick Kossifidis</a>
2023-07-20 18:00     ` <a href=#m505d10dd50c508c0a38b520f5cd63968f20076a8 id=r505d10dd50c508c0a38b520f5cd63968f20076a8>Tomasz Jeznach</a>
2023-07-20 18:43       ` <a href=#m132855bc1023899551b404f99620d13a649274e8 id=r132855bc1023899551b404f99620d13a649274e8>Conor Dooley</a>
2023-07-24  9:47       ` <a href=#ma907ef87338b36d71e27c34ee0ef394c7f908811 id=ra907ef87338b36d71e27c34ee0ef394c7f908811>Zong Li</a>
2023-07-28  5:18         ` <a href=#m2c22e456fe699f9bda99e7579498d35ce7c66c0b id=r2c22e456fe699f9bda99e7579498d35ce7c66c0b>Tomasz Jeznach</a>
2023-07-28  8:48           ` <a href=#m61bdf97d5005e12a7fb847e1df93032acf19cd36 id=r61bdf97d5005e12a7fb847e1df93032acf19cd36>Zong Li</a>
2023-07-20 13:08   ` <a href=#m1715001bd807613c4ae6715e3679cf47b74e2a60 id=r1715001bd807613c4ae6715e3679cf47b74e2a60>Baolu Lu</a>
2023-07-20 17:49     ` <a href=#m58e762ce3954cfadac358e8316dbdbc9a05cf2d0 id=r58e762ce3954cfadac358e8316dbdbc9a05cf2d0>Tomasz Jeznach</a>
2023-07-29 12:58   ` <a href=#m47475dde350a53202c60665ebadd89162dc278d8 id=r47475dde350a53202c60665ebadd89162dc278d8>Zong Li</a>
2023-07-31  9:32     ` <a href=#me232eb871eb83c17c7ddecbc7cf02ed18dff1d71 id=re232eb871eb83c17c7ddecbc7cf02ed18dff1d71>Nick Kossifidis</a>
2023-07-31 13:15       ` <a href=#mea9e2032ef189efec9d6d487218475ae46f2902c id=rea9e2032ef189efec9d6d487218475ae46f2902c>Zong Li</a>
2023-07-31 23:35         ` <a href=#m117ba0417f5cf6088454a6ff06bb517c3c128b86 id=r117ba0417f5cf6088454a6ff06bb517c3c128b86>Nick Kossifidis</a>
2023-08-01  0:37           ` <a href=#m12841e87db77013d6e9d0c13504791fa53f52482 id=r12841e87db77013d6e9d0c13504791fa53f52482>Zong Li</a>
2023-08-02 20:28             ` <a href=#m4e963b463685688ec10151f89f3672b74268594b id=r4e963b463685688ec10151f89f3672b74268594b>Tomasz Jeznach</a>
2023-08-02 20:50     ` <a href=#m407eda026cd986eb75d1fc2a13fa9e272c24019b id=r407eda026cd986eb75d1fc2a13fa9e272c24019b>Tomasz Jeznach</a>
2023-08-03  8:24       ` <a href=#m5d2c47156d2d94a03257441a04bb19a53bb29675 id=r5d2c47156d2d94a03257441a04bb19a53bb29675>Zong Li</a>
2023-08-16 18:49   ` <a href=#mf18bd90d921132d02c05d7d5894300a045bab960 id=rf18bd90d921132d02c05d7d5894300a045bab960>Robin Murphy</a>
2023-07-19 19:33 ` <a href=#m02ea782700dca52c10fb471a2331de501bffb1a7 id=r02ea782700dca52c10fb471a2331de501bffb1a7>[PATCH 07/11] RISC-V: drivers/iommu/riscv: Add device context support</a> Tomasz Jeznach
2023-08-16 19:08   ` <a href=#m794b93ecd24e4c126303d54185259a3506944063 id=r794b93ecd24e4c126303d54185259a3506944063>Robin Murphy</a>
2023-07-19 19:33 ` <a href=#m50b13653960cd6e88a7efb588257ac568bffb87b id=r50b13653960cd6e88a7efb588257ac568bffb87b>[PATCH 08/11] RISC-V: drivers/iommu/riscv: Add page table support</a> Tomasz Jeznach
2023-07-25 13:13   ` <a href=#m35e1f370635d089a8dde16e4c70b533d4b503ee0 id=r35e1f370635d089a8dde16e4c70b533d4b503ee0>Zong Li</a>
2023-07-31  7:19   ` <a href=#m525805e3cb4b98064a03306b5a208399736c02b0 id=r525805e3cb4b98064a03306b5a208399736c02b0>Zong Li</a>
2023-08-16 21:04   ` <a href=#m4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259 id=r4d4aefd6db48cd05b7f7a5a17a42f95b2fbf3259>Robin Murphy</a>
2023-07-19 19:33 ` <a href=#mdc9e0e502299442d2ebce9ef9d4f317c16f89a05 id=rdc9e0e502299442d2ebce9ef9d4f317c16f89a05>[PATCH 09/11] RISC-V: drivers/iommu/riscv: Add SVA with PASID/ATS/PRI support</a> Tomasz Jeznach
2023-07-31  9:04   ` <a href=#mdc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7 id=rdc8525dc35842e8e68705aaf5afaf8f0b7cb9ec7>Zong Li</a>
2023-07-19 19:33 ` <a href=#m2774c76ea4a5513d985e6c918e66c1e3730ad342 id=r2774c76ea4a5513d985e6c918e66c1e3730ad342>[PATCH 10/11] RISC-V: drivers/iommu/riscv: Add MSI identity remapping</a> Tomasz Jeznach
2023-07-31  8:02   ` <a href=#m50f9bd691aa7ab3a5a8b02029fa5678c52ad628d id=r50f9bd691aa7ab3a5a8b02029fa5678c52ad628d>Zong Li</a>
2023-08-16 21:43   ` <a href=#mf231abf8c9cfd6ea2015f815834751c8c88eb136 id=rf231abf8c9cfd6ea2015f815834751c8c88eb136>Robin Murphy</a>
2023-07-19 19:33 ` <a href=#m6edef0662c8a8cd238cf3fa0929af7d0305c10f5 id=r6edef0662c8a8cd238cf3fa0929af7d0305c10f5>[PATCH 11/11] RISC-V: drivers/iommu/riscv: Add G-Stage translation support</a> Tomasz Jeznach
2023-07-31  8:12   ` <a href=#m1a63028351b0e86a470c474db2d582acd5369901 id=r1a63028351b0e86a470c474db2d582acd5369901>Zong Li</a>
2023-08-16 21:13   ` <a href=#m0c898cce80d8dc67ea1c5e12243227adb68db208 id=r0c898cce80d8dc67ea1c5e12243227adb68db208>Robin Murphy</a>
     [not found] ` &lt;<a href=https://lore.kernel.org/lkml/CAHCEehJKYu3-GSX2L6L4_VVvYt1MagRgPJvYTbqekrjPw3ZSkA@mail.gmail.com/ id=rfb5bfe039af10b3f60b7ff1b25962fb6b95beec7>CAHCEehJKYu3-GSX2L6L4_VVvYt1MagRgPJvYTbqekrjPw3ZSkA@mail.gmail.com</a>&gt;
2024-02-23 14:04   ` <a href=#me3f7b4a95b62a7f2374b64d11a97ef6c85c440e2 id=re3f7b4a95b62a7f2374b64d11a97ef6c85c440e2>[PATCH 00/13] Linux RISC-V IOMMU Support</a> Zong Li
2024-04-04 17:37     ` <a href=#m2b6c38274c3bdc56a37ffb82f14d3be2e57796b1 id=r2b6c38274c3bdc56a37ffb82f14d3be2e57796b1>Tomasz Jeznach</a>
2024-04-10  5:38       ` <a href=#mee8a4c5ea050653c3313a4fb05abcd396b1071ce id=ree8a4c5ea050653c3313a4fb05abcd396b1071ce>Zong Li</a>
</pre><hr><pre>This is a public inbox, see <a href=https://lore.kernel.org/lkml/_/text/mirror/>mirroring instructions</a>
for how to clone and mirror all data and code used for this inbox;
as well as URLs for NNTP newsgroup(s).</pre><div style=all:initial><div style=all:initial id=__hcfy__><template shadowrootmode=open><style class=sf-hidden>#root{-webkit-text-size-adjust:100%;box-sizing:border-box;font-size:14px;font-weight:400;letter-spacing:0;line-height:1.28581;text-transform:none;color:#182026;font-family:-apple-system,"BlinkMacSystemFont","Segoe UI","Roboto","Oxygen","Ubuntu","Cantarell","Open Sans","Helvetica Neue","Icons16",sans-serif;touch-action:manipulation}#root>.bp5-portal{z-index:9999999999}</style><style class=sf-hidden>#translate-panel{background-color:#f6f7f9;display:flex;flex-direction:column;padding-bottom:8px}.bp5-dark #translate-panel{background-color:#252a31}#translate-panel .fixed{flex-shrink:0;margin-bottom:10px}#translate-panel .body{flex-grow:1;overflow:auto;overscroll-behavior:contain}#translate-panel .body::-webkit-scrollbar{width:8px;background-color:rgba(0,0,0,0);-webkit-border-radius:100px}#translate-panel .body::-webkit-scrollbar:hover{background-color:rgba(0,0,0,.09)}#translate-panel .body::-webkit-scrollbar-thumb:vertical{background:rgba(0,0,0,.5);-webkit-border-radius:100px}#translate-panel .body::-webkit-scrollbar-thumb:vertical:active{background:rgba(0,0,0,.61);-webkit-border-radius:100px}#translate-panel.size-small,#translate-panel.size-small h6.bp5-heading,#translate-panel.size-small .bp5-control.bp5-large,#translate-panel.size-small textarea.bp5-input.bp5-small{font-size:14px}#translate-panel.size-small .phonetic-item,#translate-panel.size-small .quick-settings a{font-size:12px}#translate-panel.size-middle,#translate-panel.size-middle h6.bp5-heading,#translate-panel.size-middle .bp5-control.bp5-large,#translate-panel.size-middle textarea.bp5-input{font-size:18px}#translate-panel.size-middle .phonetic-item,#translate-panel.size-middle .quick-settings a{font-size:14px}#translate-panel.size-large,#translate-panel.size-large h6.bp5-heading,#translate-panel.size-large .bp5-control.bp5-large,#translate-panel.size-large textarea.bp5-input.bp5-large{font-size:22px}#translate-panel.size-large .source,#translate-panel.size-large .phonetic-item,#translate-panel.size-large .quick-settings a{font-size:18px}#translate-panel .bp5-button.bp5-small,#translate-panel .bp5-small .bp5-button{min-height:20px;min-width:20px}#translate-panel .header{display:flex;align-items:center;padding:4px 6px 4px 10px;border-bottom:1px solid #d1d1d1}.bp5-dark #translate-panel .header{border-bottom-color:rgba(17,20,24,.4)}#translate-panel .header .drag-block{min-width:5px;flex-shrink:0;flex-grow:1;align-self:stretch}#translate-panel .header .left{flex-shrink:0;display:flex}#translate-panel .header .right{flex-shrink:0;display:flex;align-items:center}#translate-panel .header .right .bp5-icon-arrow-right{flex-shrink:0;margin:0 5px}#translate-panel .header .right>.bp5-button{flex-shrink:0;margin:0 1px}#translate-panel .header .right>.bp5-button:last-child{margin-right:0}#translate-panel .quick-settings{padding:4px 9px;margin:0 1px}#translate-panel .quick-settings>div{margin-bottom:5px}#translate-panel .quick-settings .bp5-control{margin-bottom:0}#translate-panel .query-text{position:relative;padding:10px 10px 2px 10px}#translate-panel .query-text textarea.bp5-input{min-height:44px;font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";overscroll-behavior:contain}#translate-panel .query-text .translate-btn{position:absolute;opacity:.6}#translate-panel .query-text .translate-btn:hover{opacity:1}#translate-panel .body{padding:0 10px}#translate-panel .body .bp5-card:first-child{margin-top:1px}#translate-panel .body .bp5-card:last-child{margin-bottom:1px}#translate-panel .body .no-api{margin:20px 0}.result-block{margin:8px 0;padding:2px 5px}.result-block .bp5-button{visibility:hidden}.result-block .error .bp5-button,.result-block:hover .bp5-button{visibility:visible}.result-block .legend{display:flex;align-items:center;justify-content:space-between}.result-block .legend .legend-left{display:flex;align-items:center}.result-block .legend .api-ico,.result-block .legend .bp5-heading{flex-shrink:0;white-space:nowrap}.result-block .legend .api-ico{display:inline-block;width:14px;height:14px;background-size:contain;margin-right:3px}.result-block .legend .bp5-heading{margin-bottom:0;margin-right:10px}.result-block .legend .source{cursor:pointer;font-size:12px;display:inline-flex;align-items:center}.result-block .legend .source .source-text{overflow:hidden}.result-block .legend .source .bp5-icon{position:relative;top:-1px;margin-left:1px}.result-block .phonetic{display:flex;flex-wrap:wrap}.result-block .phonetic .phonetic-item{display:flex;align-items:center;font-size:12px}.result-block .phonetic .phonetic-item:not(:last-child){margin-right:12px}.result-block .common-result p{line-height:1.3;margin:2px 0;overflow-wrap:break-word}.result-block .common-result .dict a{text-decoration:underline}.result-block .error{font-size:12px;padding:5px 10px}.result-block .dict-pos{margin-right:5px}.external-translators{margin-bottom:3px;padding:0;display:flex;flex-wrap:wrap}.external-translators>div{margin:0 5px 5px 0}.quick-links a{margin:0 5px 5px 0}#popper-container{width:250px;max-width:100%;position:absolute;left:0;top:0;z-index:9999999998;touch-action:none;transition:opacity .2s;background-color:#f6f7f9}.bp5-dark #popper-container{background-color:#252a31}#popper-container.show{opacity:1;pointer-events:auto;-moz-user-select:auto;user-select:auto}#popper-container,#popper-container[data-popper-reference-hidden=true]{opacity:0;pointer-events:none;-moz-user-select:none;user-select:none}#popper-container .drag-block{cursor:-webkit-grab;cursor:grab}#popper-container.pin{position:fixed}#popper-container.pin .arrow{display:none}#popper-container .arrow,#popper-container .arrow::before{position:absolute;width:8px;height:8px;z-index:-1}#popper-container .arrow::before{content:"";transform:rotate(45deg);background:#f6f7f9}.bp5-dark #popper-container .arrow::before{background-color:#252a31}#popper-container .arrow{display:none}#popper-container.show[data-popper-placement]:not([data-popper-reference-hidden=true]) .arrow{display:block}#popper-container[data-popper-placement^=top] .arrow{bottom:-5px}#popper-container[data-popper-placement^=top] .arrow::before{border-right:1px solid #d1d1d1;border-bottom:1px solid #d1d1d1}#popper-container[data-popper-placement^=bottom] .arrow{top:-5px}#popper-container[data-popper-placement^=bottom] .arrow::before{border-left:1px solid #d1d1d1;border-top:1px solid #d1d1d1}#popper-container[data-popper-placement^=left] .arrow{right:-5px}#popper-container[data-popper-placement^=left] .arrow::before{border-right:1px solid #d1d1d1;border-top:1px solid #d1d1d1}#popper-container[data-popper-placement^=right] .arrow{left:-5px}#popper-container[data-popper-placement^=right] .arrow::before{border-left:1px solid #d1d1d1;border-bottom:1px solid #d1d1d1}#translate-btn{display:none;position:absolute;z-index:9999999999;left:0;top:0}#translate-btn .bp5-button{padding:2px;min-width:0;min-height:0}#translate-btn .btn-icon{width:18px;height:18px;background-image:url(moz-extension://19651fe5-a2eb-4315-b2c9-0ae3c022c917/logo.png);background-size:contain}.bp5-dark #translate-btn .btn-icon{background-image:url(moz-extension://19651fe5-a2eb-4315-b2c9-0ae3c022c917/logowhite36.png)}#translate-btn.show{display:block}.translate-type-selector .bp5-label{display:inline}.translate-type-selector .bp5-radio{margin-bottom:0}#ocr-container{position:fixed;z-index:99999999999999;left:0;top:0;right:0;bottom:0}#ocr-container .toolbar{display:none;position:absolute;z-index:1}#ocr-container img{max-width:100%}#app{cursor:default}.switch-pin{flex-shrink:0;cursor:pointer}.switch-pin .bp5-icon-pin{transition:transform .2s,color .2s;transform:rotate(-45deg)}.pin .switch-pin .bp5-icon-pin{transform:rotate(-70deg)}.cut-btn{margin-left:2px}.app-toaster-container{position:fixed!important;z-index:9999999999!important}.app-toaster-container .bp5-toast{min-width:auto}#web-trs-panel .app-toaster-container{padding-right:0;padding-left:0}#web-trs-panel .page-trs-form-group{margin:0 0 0 0;align-items:center}#web-trs-panel .page-trs-form-group>label{width:70px}</style><div id=root dir=ltr><div id=app><div id=translate-btn class=sf-hidden></div><div id=popper-container style=width:290px;transform:translate(0px) class=bp5-elevation-4><div id=translate-panel class=size-small><div class=fixed><div class=header><div class=left><div class=switch-pin><button type=button class="bp5-button bp5-minimal bp5-small"><span aria-hidden=true class="bp5-icon bp5-icon-pin"><svg data-icon=pin height=14 role=img viewBox="0 0 16 16" width=14><path d="M9.41.92c-.51.51-.41 1.5.15 2.56L4.34 7.54C2.8 6.48 1.45 6.05.92 6.58l3.54 3.54-3.54 4.95 4.95-3.54 3.54 3.54c.53-.53.1-1.88-.96-3.42l4.06-5.22c1.06.56 2.04.66 2.55.15L9.41.92z" fill-rule=evenodd></path></svg></span></button></div><button type=button title=图片翻译 class="bp5-button bp5-minimal bp5-small"><span aria-hidden=true class="bp5-icon bp5-icon-media"><svg data-icon=media height=14 role=img viewBox="0 0 16 16" width=14><path d="M11.99 6.99c.55 0 1-.45 1-1s-.45-1-1-1-1 .45-1 1 .45 1 1 1zm3-5h-14c-.55 0-1 .45-1 1v10c0 .55.45 1 1 1h14c.55 0 1-.45 1-1v-10c0-.55-.45-1-1-1zm-1 9l-5-3-1 2-3-4-3 5v-7h12v7z" fill-rule=evenodd></path></svg></span></button><button type=button title=语音翻译 class="bp5-button bp5-minimal bp5-small"><span class=bp5-icon><svg version=1.1 id=Capa_1 width=14 height=14 xmlns=http://www.w3.org/2000/svg xmlns:xlink=http://www.w3.org/1999/xlink x=0px y=0px viewBox="0 0 490.9 490.9" xml:space=preserve><g><g><path d="M245.5,322.9c53,0,96.2-43.2,96.2-96.2V96.2c0-53-43.2-96.2-96.2-96.2s-96.2,43.2-96.2,96.2v130.5 C149.3,279.8,192.5,322.9,245.5,322.9z M173.8,96.2c0-39.5,32.2-71.7,71.7-71.7s71.7,32.2,71.7,71.7v130.5 c0,39.5-32.2,71.7-71.7,71.7s-71.7-32.2-71.7-71.7V96.2z"></path><path d="M94.4,214.5c-6.8,0-12.3,5.5-12.3,12.3c0,85.9,66.7,156.6,151.1,162.8v76.7h-63.9c-6.8,0-12.3,5.5-12.3,12.3 s5.5,12.3,12.3,12.3h152.3c6.8,0,12.3-5.5,12.3-12.3s-5.5-12.3-12.3-12.3h-63.9v-76.7c84.4-6.3,151.1-76.9,151.1-162.8 c0-6.8-5.5-12.3-12.3-12.3s-12.3,5.5-12.3,12.3c0,76.6-62.3,138.9-138.9,138.9s-138.9-62.3-138.9-138.9 C106.6,220,101.2,214.5,94.4,214.5z"></path></g></g></svg></span></button></div><div class=drag-block title=按住不放可以拖动></div><div class=right><button type=button disabled title=添加到收藏夹 class="bp5-button bp5-disabled bp5-minimal bp5-small" tabindex=-1><span aria-hidden=true class="bp5-icon bp5-icon-star-empty"><svg data-icon=star-empty height=14 role=img viewBox="0 0 16 16" width=14><path d="M16 6.11l-5.53-.84L8 0 5.53 5.27 0 6.11l4 4.1L3.06 16 8 13.27 12.94 16 12 10.21l4-4.1zM4.91 13.2l.59-3.62L3 7.02l3.45-.53L8 3.2l1.55 3.29 3.45.53-2.5 2.56.59 3.62L8 11.49 4.91 13.2z" fill-rule=evenodd></path></svg></span></button><span class=bp5-popover-target><button type=button class="bp5-button bp5-minimal bp5-small settings" title=快捷设置 aria-expanded=false aria-haspopup=menu><span aria-hidden=true class="bp5-icon bp5-icon-cog"><svg data-icon=cog height=14 role=img viewBox="0 0 16 16" width=14><path d="M15.19 6.39h-1.85c-.11-.37-.27-.71-.45-1.04l1.36-1.36c.31-.31.31-.82 0-1.13l-1.13-1.13a.803.803 0 00-1.13 0l-1.36 1.36c-.33-.17-.67-.33-1.04-.44V.79c0-.44-.36-.8-.8-.8h-1.6c-.44 0-.8.36-.8.8v1.86c-.39.12-.75.28-1.1.47l-1.3-1.3c-.3-.3-.79-.3-1.09 0L1.82 2.91c-.3.3-.3.79 0 1.09l1.3 1.3c-.2.34-.36.7-.48 1.09H.79c-.44 0-.8.36-.8.8v1.6c0 .44.36.8.8.8h1.85c.11.37.27.71.45 1.04l-1.36 1.36c-.31.31-.31.82 0 1.13l1.13 1.13c.31.31.82.31 1.13 0l1.36-1.36c.33.18.67.33 1.04.44v1.86c0 .44.36.8.8.8h1.6c.44 0 .8-.36.8-.8v-1.86c.39-.12.75-.28 1.1-.47l1.3 1.3c.3.3.79.3 1.09 0l1.09-1.09c.3-.3.3-.79 0-1.09l-1.3-1.3c.19-.35.36-.71.48-1.1h1.85c.44 0 .8-.36.8-.8v-1.6a.816.816 0 00-.81-.79zm-7.2 4.6c-1.66 0-3-1.34-3-3s1.34-3 3-3 3 1.34 3 3-1.34 3-3 3z" fill-rule=evenodd></path></svg></span></button></span><button type=button title=关闭(Esc) class="bp5-button bp5-minimal bp5-small"><span aria-hidden=true class="bp5-icon bp5-icon-cross"><svg data-icon=cross height=18 role=img viewBox="0 0 16 16" width=18><path d="M9.41 8l3.29-3.29c.19-.18.3-.43.3-.71a1.003 1.003 0 00-1.71-.71L8 6.59l-3.29-3.3a1.003 1.003 0 00-1.42 1.42L6.59 8 3.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 001.71.71L8 9.41l3.29 3.29c.18.19.43.3.71.3a1.003 1.003 0 00.71-1.71L9.41 8z" fill-rule=evenodd></path></svg></span></button></div></div><div class=bp5-collapse><div class="bp5-collapse-body sf-hidden" aria-hidden=true></div></div></div><div class=body><p>请输入需要翻译的文本。</p></div></div><div class="arrow sf-hidden"></div></div><div id=web-trs-panel></div></div></div></template></div></div><script data-template-shadow-root>(()=>{document.currentScript.remove();processNode(document);function processNode(node){node.querySelectorAll("template[shadowrootmode]").forEach(element=>{let shadowRoot = element.parentElement.shadowRoot;if (!shadowRoot) {try {shadowRoot=element.parentElement.attachShadow({mode:element.getAttribute("shadowrootmode"),delegatesFocus:element.getAttribute("shadowrootdelegatesfocus")!=null,clonable:element.getAttribute("shadowrootclonable")!=null,serializable:element.getAttribute("shadowrootserializable")!=null});shadowRoot.innerHTML=element.innerHTML;element.remove()} catch (error) {} if (shadowRoot) {processNode(shadowRoot)}}})}})()</script>